["```py\nraw_data = spark.read.format(\"delta\").load(\"dbfs:/FileStore/shared_uploads/delta/retail_silver.delta\")\nraw_data.printSchema()\n(select_data = raw_data.select(\"invoice_num\", \"stock_code\",\n                               \"quantity\", \"invoice_date\", \n                               \"unit_price\",\"country_code\",\n                               \"age\", \"work_class\", \n                               \"final_weight\")\nselect_data.describe().show()\n```", "```py\ndedupe_data = select_data.drop_duplicates([\"invoice_num\",\n                                           \"invoice_date\", \n                                           \"stock_code\"])\ninterim_data = (select_data\n    .withColumn(\"invoice_time\", to_timestamp(\"invoice_date\", \n                                             'dd/M/yy HH:mm'))\n    .withColumn(\"cust_age\", col(\"age\").cast(FloatType()))\n    .withColumn(\"working_class\", \n                col(\"work_class\").cast(FloatType()))\n    .withColumn(\"fin_wt\", \n                col(\"final_weight\").cast(FloatType()))\n)\nclean_data = interim_data.na.fill(0)\n```", "```py\nfinal_data = (clean_data.where(\"year(invoice_time) = 2009\")\n                       .withColumnRenamed(\"working_class\", \n                                          \"work_type\")\n                       .withColumnRenamed(\"fin_wt\", \n                                          \"final_weight\")\n                       .drop(\"age\")\n                       .drop(\"work_class\")\n                       .drop(\"fn_wt\"))\npd_data = final_data.toPandas()\n```"]