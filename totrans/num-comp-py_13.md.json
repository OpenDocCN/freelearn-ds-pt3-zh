["```py\n>>> df.groupby(['list', 'of', 'grouping', 'columns'])\n>>> df.groupby('single_column')  # when grouping by a single column\n```", "```py\n>>> flights = pd.read_csv('data/flights.csv')\n>>> flights.head()\n```", "```py\n>>> flights.groupby('AIRLINE').agg({'ARR_DELAY':'mean'}).head()\n```", "```py\n>>> flights.groupby('AIRLINE')['ARR_DELAY'].agg('mean').head()\nAIRLINE\nAA     5.542661\nAS    -0.833333\nB6     8.692593\nDL     0.339691\nEV     7.034580\nName: ARR_DELAY, dtype: float64\n```", "```py\n>>> flights.groupby('AIRLINE')['ARR_DELAY'].agg(np.mean).head()\n```", "```py\n>>> flights.groupby('AIRLINE')['ARR_DELAY'].mean().head()\n```", "```py\n>>> grouped = flights.groupby('AIRLINE')\n>>> type(grouped)\npandas.core.groupby.DataFrameGroupBy\n```", "```py\nmin     max    mean    median    sum    count    std    var   \nsize    describe    nunique     idxmin     idxmax\n```", "```py\n>>> flights.groupby('AIRLINE')['ARR_DELAY'].agg(np.sqrt)\nValueError: function does not reduce\n```", "```py\n>>> flights.groupby(['AIRLINE', 'WEEKDAY'])['CANCELLED'] \\\n           .agg('sum').head(7)\nAIRLINE  WEEKDAY\nAA       1          41\n         2           9\n         3          16\n         4          20\n         5          18\n         6          21\n         7          29\nName: CANCELLED, dtype: int64\n```", "```py\n>>> flights.groupby(['AIRLINE', 'WEEKDAY']) \\\n            ['CANCELLED', 'DIVERTED'].agg(['sum', 'mean']).head(7)\n```", "```py\n>>> group_cols = ['ORG_AIR', 'DEST_AIR']\n>>> agg_dict = {'CANCELLED':['sum', 'mean', 'size'], \n                'AIR_TIME':['mean', 'var']}\n>>> flights.groupby(group_cols).agg(agg_dict).head()\n```", "```py\n>>> df.groupby(['grouping', 'columns']) \\\n      .agg({'agg_cols1':['list', 'of', 'functions'], \n            'agg_cols2':['other', 'functions']})\n```", "```py\n>>> df.groupby(['grouping', 'columns'])['aggregating', 'columns'] \\\n      .agg([aggregating, functions])\n```", "```py\n>>> df.groupby(['grouping', 'columns'])['aggregating', 'columns'] \\\n      .aggregating_method()\n```", "```py\n>>> df.groupby(['grouping', 'columns']).aggregating_method()\n```", "```py\n>>> flights = pd.read_csv('data/flights.csv')\n>>> airline_info = flights.groupby(['AIRLINE', 'WEEKDAY'])\\\n                          .agg({'DIST':['sum', 'mean'], \n                                'ARR_DELAY':['min', 'max']}) \\\n                          .astype(int)\n>>> airline_info.head(7)\n```", "```py\n>>> level0 = airline_info.columns.get_level_values(0)\nIndex(['DIST', 'DIST', 'ARR_DELAY', 'ARR_DELAY'], dtype='object')\n\n>>> level1 = airline_info.columns.get_level_values(1)\nIndex(['sum', 'mean', 'min', 'max'], dtype='object')\n\n>>> airline_info.columns = level0 + '_' + level1\n>>> airline_info.head(7)\n```", "```py\n>>> airline_info.reset_index().head(7)\n```", "```py\n>>> flights.groupby(['AIRLINE'], as_index=False)['DIST'].agg('mean') \\\n                                                        .round(0)\n```", "```py\n>>> college = pd.read_csv('data/college.csv')\n>>> college.groupby('STABBR')['UGDS'].agg(['mean', 'std']) \\\n                                     .round(0).head()\n```", "```py\n>>> def max_deviation(s):\n        std_score = (s - s.mean()) / s.std()\n        return std_score.abs().max()\n```", "```py\n>>> college.groupby('STABBR')['UGDS'].agg(max_deviation) \\\n                                     .round(1).head()\nSTABBR\nAK    2.6\nAL    5.8\nAR    6.3\nAS    NaN\nAZ    9.9\nName: UGDS, dtype: float64\n```", "```py\n>>> college.groupby('STABBR')['UGDS', 'SATVRMID', 'SATMTMID'] \\\n           .agg(max_deviation).round(1).head()\n```", "```py\n>>> college.groupby(['STABBR', 'RELAFFIL']) \\\n            ['UGDS', 'SATVRMID', 'SATMTMID'] \\\n           .agg([max_deviation, 'mean', 'std']).round(1).head()\n```", "```py\n>>> max_deviation.__name__\n'max_deviation'\n\n>>> max_deviation.__name__ = 'Max Deviation'\n>>> college.groupby(['STABBR', 'RELAFFIL']) \\\n            ['UGDS', 'SATVRMID', 'SATMTMID'] \\\n           .agg([max_deviation, 'mean', 'std']).round(1).head()\n```", "```py\n>>> college = pd.read_csv('data/college.csv')\n>>> grouped = college.groupby(['STABBR', 'RELAFFIL'])\n\n>>> import inspect\n>>> inspect.signature(grouped.agg)\n<Signature (arg, *args, **kwargs)>\n```", "```py\n>>> def pct_between_1_3k(s):\n        return s.between(1000, 3000).mean()\n```", "```py\n>>> college.groupby(['STABBR', 'RELAFFIL'])['UGDS'] \\\n           .agg(pct_between_1_3k).head(9)\nSTABBR  RELAFFIL\nAK      0           0.142857\n        1           0.000000\nAL      0           0.236111\n        1           0.333333\nAR      0           0.279412\n        1           0.111111\nAS      0           1.000000\nAZ      0           0.096774\n        1           0.000000\nName: UGDS, dtype: float64\n```", "```py\n>>> def pct_between(s, low, high):\n        return s.between(low, high).mean()\n```", "```py\n>>> college.groupby(['STABBR', 'RELAFFIL'])['UGDS'] \\\n           .agg(pct_between, 1000, 10000).head(9)\nSTABBR  RELAFFIL\nAK      0           0.428571\n        1           0.000000\nAL      0           0.458333\n        1           0.375000\nAR      0           0.397059\n        1           0.166667\nAS      0           1.000000\nAZ      0           0.233871\n        1           0.111111\nName: UGDS, dtype: float64\n```", "```py\n>>> college.groupby(['STABBR', 'RELAFFIL'])['UGDS'] \\\n           .agg(pct_between, high=10000, low=1000).head(9)\n```", "```py\n>>> college.groupby(['STABBR', 'RELAFFIL'])['UGDS'] \\\n           .agg(pct_between, 1000, high=10000).head(9)\n```", "```py\n>>> college.groupby(['STABBR', 'RELAFFIL'])['UGDS'] \\\n           .agg(['mean', pct_between], low=100, high=1000) \nTypeError: pct_between() missing 2 required positional arguments: 'low' and 'high'\n```", "```py\n>>> def make_agg_func(func, name, *args, **kwargs):\n        def wrapper(x):\n            return func(x, *args, **kwargs)\n        wrapper.__name__ = name\n        return wrapper\n\n>>> my_agg1 = make_agg_func(pct_between, 'pct_1_3k', low=1000, high=3000)\n>>> my_agg2 = make_agg_func(pct_between, 'pct_10_30k', 10000, 30000)\n\n>>> college.groupby(['STABBR', 'RELAFFIL'])['UGDS'] \\\n           .agg(['mean', my_agg1, my_agg2]).head()\n```", "```py\n>>> college = pd.read_csv('data/college.csv')\n>>> grouped = college.groupby(['STABBR', 'RELAFFIL'])\n>>> type(grouped)\npandas.core.groupby.DataFrameGroupBy\n```", "```py\n>>> print([attr for attr in dir(grouped) if not attr.startswith('_')])\n['CITY', 'CURROPER', 'DISTANCEONLY', 'GRAD_DEBT_MDN_SUPP', 'HBCU', 'INSTNM', 'MD_EARN_WNE_P10', 'MENONLY', 'PCTFLOAN', 'PCTPELL', 'PPTUG_EF', 'RELAFFIL', 'SATMTMID', 'SATVRMID', 'STABBR', 'UG25ABV', 'UGDS', 'UGDS_2MOR', 'UGDS_AIAN', 'UGDS_ASIAN', 'UGDS_BLACK', 'UGDS_HISP', 'UGDS_NHPI', 'UGDS_NRA', 'UGDS_UNKN', 'UGDS_WHITE', 'WOMENONLY', 'agg', 'aggregate', 'all', 'any', 'apply', 'backfill', 'bfill', 'boxplot', 'corr', 'corrwith', 'count', 'cov', 'cumcount', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'dtypes', 'expanding', 'ffill', 'fillna', 'filter', 'first', 'get_group', 'groups', 'head', 'hist', 'idxmax', 'idxmin', 'indices', 'last', 'mad', 'max', 'mean', 'median', 'min', 'ndim', 'ngroup', 'ngroups', 'nth', 'nunique', 'ohlc', 'pad', 'pct_change', 'plot', 'prod', 'quantile', 'rank', 'resample', 'rolling', 'sem', 'shift', 'size', 'skew', 'std', 'sum', 'tail', 'take', 'transform', 'tshift', 'var']\n```", "```py\n>>> grouped.ngroups\n112\n```", "```py\n>>> groups = list(grouped.groups.keys())\n>>> groups[:6]\n[('AK', 0), ('AK', 1), ('AL', 0), ('AL', 1), ('AR', 0), ('AR', 1)]\n```", "```py\n>>> grouped.get_group(('FL', 1)).head()\n```", "```py\n>>> from IPython.display import display\n>>> for name, group in grouped:\n        print(name)\n        display(group.head(3))\n```", "```py\n>>> grouped.head(2).head(6)\n```", "```py\n>>> grouped.nth([1, -1]).head(8)\n```", "```py\n>>> college = pd.read_csv('data/college.csv', index_col='INSTNM')\n>>> grouped = college.groupby('STABBR')\n>>> grouped.ngroups\n59\n\n>>> college['STABBR'].nunique() # verifying the same number\n59\n```", "```py\n>>> def check_minority(df, threshold):\n        minority_pct = 1 - df['UGDS_WHITE']\n        total_minority = (df['UGDS'] * minority_pct).sum()\n        total_ugds = df['UGDS'].sum()\n        total_minority_pct = total_minority / total_ugds\n        return total_minority_pct > threshold\n```", "```py\n>>> college_filtered = grouped.filter(check_minority, threshold=.5)\n>>> college_filtered.head()\n```", "```py\n>>> college.shape\n(7535, 26)\n\n>>> college_filtered.shape\n(3028, 26)\n\n>>> college_filtered['STABBR'].nunique()\n20\n```", "```py\n>>> college_filtered_20 = grouped.filter(check_minority, threshold=.2)\n>>> college_filtered_20.shape\n(7461, 26)\n\n>>> college_filtered_20['STABBR'].nunique()\n57\n\n>>> college_filtered_70 = grouped.filter(check_minority, threshold=.7)\n>>> college_filtered_70.shape\n(957, 26)\n\n>>> college_filtered_70['STABBR'].nunique()\n10\n```", "```py\n>>> weight_loss = pd.read_csv('data/weight_loss.csv')\n>>> weight_loss.query('Month == \"Jan\"')\n```", "```py\n>>> def find_perc_loss(s):\n        return (s - s.iloc[0]) / s.iloc[0]\n```", "```py\n>>> bob_jan = weight_loss.query('Name==\"Bob\" and Month==\"Jan\"')\n>>> find_perc_loss(bob_jan['Weight'])\n0    0.000000\n2   -0.010309\n4   -0.027491\n6   -0.027491\nName: Weight, dtype: float64\n```", "```py\n>>> pcnt_loss = weight_loss.groupby(['Name', 'Month'])['Weight'] \\\n                           .transform(find_perc_loss)\n>>> pcnt_loss.head(8)\n0    0.000000\n1    0.000000\n2   -0.010309\n3   -0.040609\n4   -0.027491\n5   -0.040609\n6   -0.027491\n7   -0.035533\nName: Weight, dtype: float64\n```", "```py\n>>> weight_loss['Perc Weight Loss'] = pcnt_loss.round(3)\n>>> weight_loss.query('Name==\"Bob\" and Month in [\"Jan\", \"Feb\"]')\n```", "```py\n>>> week4 = weight_loss.query('Week == \"Week 4\"')\n>>> week4 \n```", "```py\n>>> winner = week4.pivot(index='Month', columns='Name',\n                         values='Perc Weight Loss')\n>>> winner\n```", "```py\n>>> winner['Winner'] = np.where(winner['Amy'] < winner['Bob'],\n                                'Amy', 'Bob')\n>>> winner.style.highlight_min(axis=1)\n```", "```py\n>>> winner.Winner.value_counts()\nAmy    3\nBob    1\nName: Winner, dtype: int64\n```", "```py\n>>> week4a = week4.copy()\n>>> month_chron = week4a['Month'].unique() # or use drop_duplicates\n>>> month_chron\narray(['Jan', 'Feb', 'Mar', 'Apr'], dtype=object)\n\n>>> week4a['Month'] = pd.Categorical(week4a['Month'],\n                                     categories=month_chron,\n                                     ordered=True)\n>>> week4a.pivot(index='Month', columns='Name',\n                 values='Perc Weight Loss')\n```", "```py\n>>> college = pd.read_csv('data/college.csv')\n>>> subset = ['UGDS', 'SATMTMID', 'SATVRMID']\n>>> college2 = college.dropna(subset=subset)\n>>> college.shape\n(7535, 27)\n\n>>> college2.shape\n(1184, 27)\n```", "```py\n>>> def weighted_math_average(df):\n        weighted_math = df['UGDS'] * df['SATMTMID']\n        return int(weighted_math.sum() / df['UGDS'].sum())\n```", "```py\n>>> college2.groupby('STABBR').apply(weighted_math_average).head()\nSTABBR\nAK    503\nAL    536\nAR    529\nAZ    569\nCA    564\ndtype: int64\n```", "```py\n>>> college2.groupby('STABBR').agg(weighted_math_average).head()\n```", "```py\n>>> college2.groupby('STABBR')['SATMTMID'] \\\n            .agg(weighted_math_average)\nKeyError: 'UGDS'\n```", "```py\n>>> from collections import OrderedDict\n>>> def weighted_average(df):\n        data = OrderedDict()\n        weight_m = df['UGDS'] * df['SATMTMID']\n        weight_v = df['UGDS'] * df['SATVRMID']\n\n        wm_avg = weight_m.sum() / df['UGDS'].sum()\n        wv_avg = weight_v.sum() / df['UGDS'].sum()\n\n        data['weighted_math_avg'] = wm_avg\n        data['weighted_verbal_avg'] = wv_avg\n        data['math_avg'] = df['SATMTMID'].mean()\n        data['verbal_avg'] = df['SATVRMID'].mean()\n        data['count'] = len(df)\n        return pd.Series(data, dtype='int')\n\n>>> college2.groupby('STABBR').apply(weighted_average).head(10)\n```", "```py\n>>> from scipy.stats import gmean, hmean\n>>> def calculate_means(df):\n        df_means = pd.DataFrame(index=['Arithmetic', 'Weighted',\n                                       'Geometric', 'Harmonic'])\n        cols = ['SATMTMID', 'SATVRMID']\n        for col in cols:\n            arithmetic = df[col].mean()\n            weighted = np.average(df[col], weights=df['UGDS'])\n            geometric = gmean(df[col])\n            harmonic = hmean(df[col])\n            df_means[col] = [arithmetic, weighted,\n                             geometric, harmonic]\n\n        df_means['count'] = len(df)\n        return df_means.astype(int)\n\n>>> college2.groupby('STABBR').apply(calculate_means).head(12)\n```", "```py\n>>> flights = pd.read_csv('data/flights.csv')\n>>> flights.head()\n```", "```py\n>>> bins = [-np.inf, 200, 500, 1000, 2000, np.inf]\n>>> cuts = pd.cut(flights['DIST'], bins=bins)\n>>> cuts.head()\n0     (500.0, 1000.0]\n1    (1000.0, 2000.0]\n2     (500.0, 1000.0]\n3    (1000.0, 2000.0]\n4    (1000.0, 2000.0]\nName: DIST, dtype: category\nCategories (5, interval[float64]): [(-inf, 200.0] < (200.0, 500.0] < (500.0, 1000.0] < (1000.0, 2000.0] < (2000.0, inf]]\n```", "```py\n>>> cuts.value_counts()\n(500.0, 1000.0]     20659\n(200.0, 500.0]      15874\n(1000.0, 2000.0]    14186\n(2000.0, inf]        4054\n(-inf, 200.0]        3719\nName: DIST, dtype: int64\n```", "```py\n>>> flights.groupby(cuts)['AIRLINE'].value_counts(normalize=True) \\\n                                    .round(3).head(15)\nDIST            AIRLINE\n(-inf, 200.0]   OO         0.326\n                EV         0.289\n                MQ         0.211\n                DL         0.086\n                AA         0.052\n                UA         0.027\n                WN         0.009\n(200.0, 500.0]  WN         0.194\n                DL         0.189\n                OO         0.159\n                EV         0.156\n                MQ         0.100\n                AA         0.071\n                UA         0.062\n                VX         0.028\nName: AIRLINE, dtype: float64\n```", "```py\n>>> flights.groupby(cuts)['AIR_TIME'].quantile(q=[.25, .5, .75]) \\\n                                     .div(60).round(2)\nDIST                  \n(-inf, 200.0]     0.25    0.43\n                  0.50    0.50\n                  0.75    0.57\n(200.0, 500.0]    0.25    0.77\n                  0.50    0.92\n                  0.75    1.05\n(500.0, 1000.0]   0.25    1.43\n                  0.50    1.65\n                  0.75    1.92\n(1000.0, 2000.0]  0.25    2.50\n                  0.50    2.93\n                  0.75    3.40\n(2000.0, inf]     0.25    4.30\n                  0.50    4.70\n                  0.75    5.03\nName: AIR_TIME, dtype: float64\n```", "```py\n>>> labels=['Under an Hour', '1 Hour', '1-2 Hours',\n            '2-4 Hours', '4+ Hours']\n>>> cuts2 = pd.cut(flights['DIST'], bins=bins, labels=labels)\n>>> flights.groupby(cuts2)['AIRLINE'].value_counts(normalize=True) \\\n                                     .round(3) \\\n                                     .unstack() \\\n                                     .style.highlight_max(axis=1)\n```", "```py\n>>> flights = pd.read_csv('data/flights.csv')\n>>> flights_ct = flights.groupby(['ORG_AIR', 'DEST_AIR']).size()\n>>> flights_ct.head()\nORG_AIR  DEST_AIR\nATL      ABE         31\n         ABQ         16\n         ABY         19\n         ACY          6\n         AEX         40\ndtype: int64\n```", "```py\n>>> flights_ct.loc[[('ATL', 'IAH'), ('IAH', 'ATL')]]\nORG_AIR  DEST_AIR\nATL      IAH         121\nIAH      ATL         148\ndtype: int64\n```", "```py\n>>> flights_sort = flights[['ORG_AIR', 'DEST_AIR']] \\\n                          .apply(sorted, axis=1)\n>>> flights_sort.head()\n```", "```py\n>>> rename_dict = {'ORG_AIR':'AIR1', 'DEST_AIR':'AIR2'}\n>>> flights_sort = flights_sort.rename(columns=rename_dict)\n>>> flights_ct2 = flights_sort.groupby(['AIR1', 'AIR2']).size()\n>>> flights_ct2.head()\nAIR1  AIR2\nABE   ATL     31\n      ORD     24\nABI   DFW     74\nABQ   ATL     16\n      DEN     46\ndtype: int64\n```", "```py\n>>> flights_ct2.loc[('ATL', 'IAH')]\n269\n```", "```py\n>>> flights_ct2.loc[('IAH', 'ATL')]\nIndexingError: Too many indexers\n```", "```py\n>>> sorted(flights.loc[0, ['ORG_AIR', 'DEST_AIR']])\n['LAX', 'SLC']\n```", "```py\n>>> data_sorted = np.sort(flights[['ORG_AIR', 'DEST_AIR']])\n>>> data_sorted[:10]\narray([['LAX', 'SLC'],\n       ['DEN', 'IAD'],\n       ['DFW', 'VPS'],\n       ['DCA', 'DFW'],\n       ['LAX', 'MCI'],\n       ['IAH', 'SAN'],\n       ['DFW', 'MSY'],\n       ['PHX', 'SFO'],\n       ['ORD', 'STL'],\n       ['IAH', 'SJC']], dtype=object)\n```", "```py\n>>> flights_sort2 = pd.DataFrame(data_sorted, columns=['AIR1', 'AIR2'])\n>>> fs_orig = flights_sort.rename(columns={'ORG_AIR':'AIR1',\n                                           'DEST_AIR':'AIR2'})\n>>> flights_sort2.equals(fs_orig)\nTrue\n```", "```py\n>>> %%timeit \n>>> flights_sort = flights[['ORG_AIR', 'DEST_AIR']] \\\n                          .apply(sorted, axis=1)\n7.41 s ± 189 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n>>> %%timeit\n>>> data_sorted = np.sort(flights[['ORG_AIR', 'DEST_AIR']])\n>>> flights_sort2 = pd.DataFrame(data_sorted,\n                                 columns=['AIR1', 'AIR2'])\n10.6 ms ± 453 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n```", "```py\n>>> s = pd.Series([0, 1, 1, 0, 1, 1, 1, 0])\n>>> s\n0    0\n1    1\n2    1\n3    0\n4    1\n5    1\n6    1\n7    0\ndtype: int64\n```", "```py\n>>> s1 = s.cumsum()\n>>> s1\n0    0\n1    1\n2    2\n3    2\n4    3\n5    4\n6    5\n7    5\ndtype: int64\n```", "```py\n>>> s.mul(s1)\n0    0\n1    1\n2    2\n3    0\n4    3\n5    4\n6    5\n7    0\ndtype: int64\n```", "```py\n>>> s.mul(s1).diff()\n0    NaN\n1    1.0\n2    1.0\n3   -2.0\n4    3.0\n5    1.0\n6    1.0\n7   -5.0\ndtype: float64\n```", "```py\n>>> s.mul(s1).diff().where(lambda x: x < 0)\n0    NaN\n1    NaN\n2    NaN\n3   -2.0\n4    NaN\n5    NaN\n6    NaN\n7   -5.0\ndtype: float64\n```", "```py\n>>> s.mul(s1).diff().where(lambda x: x < 0).ffill()\n0    NaN\n1    NaN\n2    NaN\n3   -2.0\n4   -2.0\n5   -2.0\n6   -2.0\n7   -5.0\ndtype: float64\n```", "```py\n>>> s.mul(s1).diff().where(lambda x: x < 0).ffill() \\\n     .add(s1, fill_value=0)\n0    0.0\n1    1.0\n2    2.0\n3    0.0\n4    1.0\n5    2.0\n6    3.0\n7    0.0\ndtype: float64\n```", "```py\n>>> flights = pd.read_csv('data/flights.csv')\n>>> flights['ON_TIME'] = flights['ARR_DELAY'].lt(15).astype(int)\n>>> flights[['AIRLINE', 'ORG_AIR', 'ON_TIME']].head(10)\n```", "```py\n>>> def max_streak(s):\n        s1 = s.cumsum()\n        return s.mul(s1).diff().where(lambda x: x < 0) \\\n                .ffill().add(s1, fill_value=0).max()\n```", "```py\n>>> flights.sort_values(['MONTH', 'DAY', 'SCHED_DEP']) \\\n           .groupby(['AIRLINE', 'ORG_AIR'])['ON_TIME'] \\\n           .agg(['mean', 'size', max_streak]).round(2).head()\n```", "```py\n>>> def max_delay_streak(df):\n        df = df.reset_index(drop=True)\n        s = 1 - df['ON_TIME']\n        s1 = s.cumsum()\n        streak = s.mul(s1).diff().where(lambda x: x < 0) \\\n                  .ffill().add(s1, fill_value=0)\n        last_idx = streak.idxmax()\n        first_idx = last_idx - streak.max() + 1\n        df_return = df.loc[[first_idx, last_idx], ['MONTH', 'DAY']]\n        df_return['streak'] = streak.max()\n        df_return.index = ['first', 'last']\n        df_return.index.name='type'\n        return df_return\n\n>>> flights.sort_values(['MONTH', 'DAY', 'SCHED_DEP']) \\\n           .groupby(['AIRLINE', 'ORG_AIR']) \\\n           .apply(max_delay_streak) \\\n           .sort_values('streak', ascending=False).head(10)\n```"]