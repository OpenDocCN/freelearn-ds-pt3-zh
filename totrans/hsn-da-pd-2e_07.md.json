["```py\nimport matplotlib.pyplot as plt\n```", "```py\n>>> import matplotlib.pyplot as plt\n>>> import pandas as pd\n```", "```py\n>>> fb = pd.read_csv(\n...     'data/fb_stock_prices_2018.csv', \n...     index_col='date',\n...     parse_dates=True\n... )\n```", "```py\n>>> plt.plot(fb.index, fb.open)\n>>> plt.show()\n```", "```py\n>>> %matplotlib inline\n>>> import matplotlib.pyplot as plt\n>>> import pandas as pd\n>>> fb = pd.read_csv(\n...     'data/fb_stock_prices_2018.csv', \n...     index_col='date',\n...     parse_dates=True\n... )\n>>> plt.plot(fb.index, fb.open)\n```", "```py\n>>> plt.plot('high', 'low', 'or', data=fb.head(20))\n```", "```py\n>>> quakes = pd.read_csv('data/earthquakes.csv')\n>>> plt.hist(quakes.query('magType == \"ml\"').mag)\n```", "```py\n>>> x = quakes.query('magType == \"ml\"').mag\n>>> fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n>>> for ax, bins in zip(axes, [7, 35]):\n...     ax.hist(x, bins=bins)\n...     ax.set_title(f'bins param: {bins}')\n```", "```py\n>>> fig = plt.figure()\n<Figure size 432x288 with 0 Axes>\n```", "```py\n>>> fig, axes = plt.subplots(1, 2)\n```", "```py\n>>> fig = plt.figure(figsize=(3, 3))\n>>> outside = fig.add_axes([0.1, 0.1, 0.9, 0.9])\n>>> inside = fig.add_axes([0.7, 0.7, 0.25, 0.25])\n```", "```py\n>>> fig = plt.figure(figsize=(8, 8))\n>>> gs = fig.add_gridspec(3, 3)\n>>> top_left = fig.add_subplot(gs[0, 0])\n>>> mid_left = fig.add_subplot(gs[1, 0])\n>>> top_right = fig.add_subplot(gs[:2, 1:])\n>>> bottom = fig.add_subplot(gs[2,:])\n```", "```py\n>>> fig.savefig('empty.png')\n```", "```py\n>>> plt.close('all')\n```", "```py\n>>> fig = plt.figure(figsize=(10, 4))\n<Figure size 720x288 with 0 Axes>\n>>> fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n```", "```py\n>>> import random\n>>> import matplotlib as mpl\n>>> rcparams_list = list(mpl.rcParams.keys())\n>>> random.seed(20) # make this repeatable\n>>> random.shuffle(rcparams_list)\n>>> sorted(rcparams_list[:20])\n['axes.axisbelow',\n 'axes.formatter.limits',\n 'boxplot.vertical',\n 'contour.corner_mask',\n 'date.autoformatter.month',\n 'legend.labelspacing',\n 'lines.dashed_pattern',\n 'lines.dotted_pattern',\n 'lines.scale_dashes',\n 'lines.solid_capstyle',\n 'lines.solid_joinstyle',\n 'mathtext.tt',\n 'patch.linewidth',\n 'pdf.fonttype',\n 'savefig.jpeg_quality',\n 'svg.fonttype',\n 'text.latex.preview',\n 'toolbar',\n 'ytick.labelright',\n 'ytick.minor.size'] \n```", "```py\n>>> mpl.rcParams['figure.figsize']\n[6.0, 4.0]\n```", "```py\n>>> mpl.rcParams['figure.figsize'] = (300, 10)\n>>> mpl.rcParams['figure.figsize']\n[300.0, 10.0]\n```", "```py\n>>> mpl.rcdefaults()\n>>> mpl.rcParams['figure.figsize']\n[6.8, 4.8]\n```", "```py\n# change `figsize` default to (20, 20)\n>>> plt.rc('figure', figsize=(20, 20)) \n>>> plt.rcdefaults() # reset the default\n```", "```py\n>>> %matplotlib inline\n>>> import matplotlib.pyplot as plt\n>>> import numpy as np\n>>> import pandas as pd\n>>> fb = pd.read_csv(\n...     'data/fb_stock_prices_2018.csv', \n...     index_col='date',\n...     parse_dates=True\n... )\n>>> quakes = pd.read_csv('data/earthquakes.csv')\n>>> covid = pd.read_csv('data/covid19_cases.csv').assign(\n...     date=lambda x: \\\n...         pd.to_datetime(x.dateRep, format='%d/%m/%Y')\n... ).set_index('date').replace(\n...     'United_States_of_America', 'USA'\n... ).sort_index()['2020-01-18':'2020-09-18']\n```", "```py\n>>> fb.plot(\n...     kind='line', y='open', figsize=(10, 5), style='-b',\n...     legend=False, title='Evolution of Facebook Open Price'\n... )\n```", "```py\nfb.plot(\n    kind='line', y='open', figsize=(10, 5),\n    color='blue', linestyle='solid',\n    legend=False, title='Evolution of Facebook Open Price'\n)\n```", "```py\n>>> fb.first('1W').plot(\n...     y=['open', 'high', 'low', 'close'], \n...     style=['o-b', '--r', ':k', '.-g'],\n...     title='Facebook OHLC Prices during '\n...           '1st Week of Trading 2018'\n... ).autoscale() # add space between data and axes\n```", "```py\n>>> fb.plot(\n...     kind='line', subplots=True, layout=(3, 2),\n...     figsize=(15, 10), title='Facebook Stock 2018'\n... )\n```", "```py\n>>> new_cases_rolling_average = covid.pivot_table(\n...     index=covid.index,\n...     columns='countriesAndTerritories',\n...     values='cases'\n... ).rolling(7).mean()\n```", "```py\n>>> fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n>>> new_cases_rolling_average[['China']]\\\n...     .plot(ax=axes[0], style='-.c')\n>>> new_cases_rolling_average[['Italy', 'Spain']].plot(\n...     ax=axes[1], style=['-', '--'],\n...     title='7-day rolling average of new '\n...           'COVID-19 cases\\n(source: ECDC)'\n... )\n>>> new_cases_rolling_average[['Brazil', 'India', 'USA']]\\ \n...     .plot(ax=axes[2], style=['--', ':', '-'])\n```", "```py\n>>> cols = [\n...     col for col in new_cases_rolling_average.columns \n...     if col not in [\n...         'USA', 'Brazil', 'India', 'Italy & Spain'\n...     ]\n... ]\n>>> new_cases_rolling_average.assign(\n...     **{'Italy & Spain': lambda x: x.Italy + x.Spain}\n... ).sort_index(axis=1).assign(\n...     Other=lambda x: x[cols].sum(axis=1)\n... ).drop(columns=cols).plot(\n...     kind='area', figsize=(15, 5), \n...     title='7-day rolling average of new '\n...           'COVID-19 cases\\n(source: ECDC)'\n... )\n```", "```py\n>>> fig, axes = plt.subplots(1, 3, figsize=(15, 3))\n>>> cumulative_covid_cases = covid.groupby(\n...     ['countriesAndTerritories', pd.Grouper(freq='1D')]\n... ).cases.sum().unstack(0).apply('cumsum')\n>>> cumulative_covid_cases[['China']]\\\n...     .plot(ax=axes[0], style='-.c')\n>>> cumulative_covid_cases[['Italy', 'Spain']].plot(\n...     ax=axes[1], style=['-', '--'], \n...     title='Cumulative COVID-19 Cases\\n(source: ECDC)'\n... )\n>>> cumulative_covid_cases[['Brazil', 'India', 'USA']]\\ \n...     .plot(ax=axes[2], style=['--', ':', '-'])\n```", "```py\n>>> fb.assign(\n...     max_abs_change=fb.high - fb.low\n... ).plot(\n...     kind='scatter', x='volume', y='max_abs_change',\n...     title='Facebook Daily High - Low vs. Volume Traded'\n... )\n```", "```py\n>>> fb.assign(\n...     max_abs_change=fb.high - fb.low\n... ).plot(\n...     kind='scatter', x='volume', y='max_abs_change',\n...     title='Facebook Daily High - '\n...           'Low vs. log(Volume Traded)',\n...     logx=True\n... )\n```", "```py\n>>> fb.assign(\n...     max_abs_change=fb.high - fb.low\n... ).plot(\n...     kind='scatter', x='volume', y='max_abs_change',\n...     title='Facebook Daily High - '\n...           'Low vs. log(Volume Traded)', \n...     logx=True, alpha=0.25\n... )\n```", "```py\n>>> fb.assign(\n...     log_volume=np.log(fb.volume),\n...     max_abs_change=fb.high - fb.low\n... ).plot(\n...     kind='hexbin', \n...     x='log_volume', \n...     y='max_abs_change', \n...     title='Facebook Daily High - '\n...           'Low vs. log(Volume Traded)', \n...     colormap='gray_r', \n...     gridsize=20,\n...     sharex=False # bug fix to keep the x-axis label\n... )\n```", "```py\n>>> fig, ax = plt.subplots(figsize=(20, 10))\n# calculate the correlation matrix\n>>> fb_corr = fb.assign(\n...     log_volume=np.log(fb.volume),\n...     max_abs_change=fb.high - fb.low\n... ).corr()\n# create the heatmap and colorbar\n>>> im = ax.matshow(fb_corr, cmap='seismic')\n>>> im.set_clim(-1, 1)\n>>> fig.colorbar(im)\n# label the ticks with the column names\n>>> labels = [col.lower() for col in fb_corr.columns]\n>>> ax.set_xticks(ax.get_xticks()[1:-1])\n>>> ax.set_xtickabels(labels, rotation=45)\n>>> ax.set_yticks(ax.get_yticks()[1:-1])\n>>> ax.set_yticklabels(labels)\n# include the value of the correlation coefficient in the boxes\n>>> for (i, j), coef in np.ndenumerate(fb_corr):\n...     ax.text(\n...         i, j, fr'$\\rho$ = {coef:.2f}', \n...         ha='center', va='center', \n...         color='white', fontsize=14\n...     )\n```", "```py\nim = ax.matshow(fb_corr, cmap='seismic')\nim.set_clim(-1, 1) # set the bounds of the color scale\nfig.colorbar(im) # add the colorbar to the figure\n```", "```py\nlabels = [col.lower() for col in fb_corr.columns]\nax.set_xticks(ax.get_xticks()[1:-1]) # to handle matplotlib bug\nax.set_xticklabels(labels, rotation=45)\nax.set_yticks(ax.get_yticks()[1:-1]) # to handle matplotlib bug\nax.set_yticklabels(labels)\n```", "```py\n# iterate over the matrix \nfor (i, j), coef in np.ndenumerate(fb_corr): \n    ax.text(\n        i, j, \n        fr'$\\rho$ = {coef:.2f}', # raw (r), format (f) string\n        ha='center', va='center', \n        color='white', fontsize=14\n    )\n```", "```py\n>>> fb.volume.plot(\n...     kind='hist', \n...     title='Histogram of Daily Volume Traded '\n...           'in Facebook Stock'\n... )\n>>> plt.xlabel('Volume traded') # label x-axis (see ch 6)\n```", "```py\n>>> fig, axes = plt.subplots(figsize=(8, 5))\n>>> for magtype in quakes.magType.unique():\n...     data = quakes.query(f'magType == \"{magtype}\"').mag\n...     if not data.empty:\n...         data.plot(\n...             kind='hist', \n...             ax=axes, \n...             alpha=0.4, \n...             label=magtype, \n...             legend=True, \n...             title='Comparing histograms '\n...                   'of earthquake magnitude by magType'\n...         )\n>>> plt.xlabel('magnitude') # label x-axis (discussed in ch 6)\n```", "```py\n>>> fb.high.plot(\n...     kind='kde', \n...     title='KDE of Daily High Price for Facebook Stock'\n... )\n>>> plt.xlabel('Price ($)') # label x-axis (discussed in ch 6)\n```", "```py\n>>> ax = fb.high.plot(kind='hist', density=True, alpha=0.5)\n>>> fb.high.plot(\n...     ax=ax, kind='kde', color='blue', \n...     title='Distribution of Facebook Stock\\'s '\n...           'Daily High Price in 2018'\n... )\n>>> plt.xlabel('Price ($)') # label x-axis (discussed in ch 6)\n```", "```py\n>>> from statsmodels.distributions.empirical_distribution \\\n...     import ECDF\n>>> ecdf = ECDF(quakes.query('magType == \"ml\"').mag)\n>>> plt.plot(ecdf.x, ecdf.y)\n# axis labels (we will cover this in chapter 6)\n>>> plt.xlabel('mag') # add x-axis label \n>>> plt.ylabel('cumulative probability') # add y-axis label\n# add title (we will cover this in chapter 6)\n>>> plt.title('ECDF of earthquake magnitude with magType ml')\n```", "```py\n>>> fb.iloc[:,:4].plot(\n...     kind='box', \n...     title='Facebook OHLC Prices Box Plot'\n... )\n>>> plt.ylabel('price ($)') # label x-axis (discussed in ch 6)\n```", "```py\n>>> fb.assign(\n...     volume_bin=\\\n...         pd.cut(fb.volume, 3, labels=['low', 'med', 'high']) \n... ).groupby('volume_bin').boxplot(\n...     column=['open', 'high', 'low', 'close'], \n...     layout=(1, 3), figsize=(12, 3)\n... )\n>>> plt.suptitle(\n...     'Facebook OHLC Box Plots by Volume Traded', y=1.1\n... )\n```", "```py\n>>> quakes[['mag', 'magType']]\\\n...     .groupby('magType')\\\n...     .boxplot(figsize=(15, 8), subplots=False)\n# formatting (covered in chapter 6)\n>>> plt.title('Earthquake Magnitude Box Plots by magType')\n>>> plt.ylabel('magnitude')\n```", "```py\n>>> quakes.parsed_place.value_counts().iloc[14::-1,].plot(\n...     kind='barh', figsize=(10, 5), \n...     title='Top 15 Places for Earthquakes '\n...           '(September 18, 2018 - October 13, 2018)'\n... )\n>>> plt.xlabel('earthquakes') # label x-axis (see ch 6)\n```", "```py\n>>> quakes.groupby(\n...     'parsed_place'\n... ).tsunami.sum().sort_values().iloc[-10:,].plot(\n...     kind='barh', figsize=(10, 5), \n...     title='Top 10 Places for Tsunamis '\n...           '(September 18, 2018 - October 13, 2018)'\n... )\n>>> plt.xlabel('tsunamis') # label x-axis (discussed in ch 6)\n```", "```py\n>>> indonesia_quakes = quakes.query(\n...     'parsed_place == \"Indonesia\"'\n... ).assign(\n...     time=lambda x: pd.to_datetime(x.time, unit='ms'),\n...     earthquake=1\n... ).set_index('time').resample('1D').sum()\n# format the datetimes in the index for the x-axis\n>>> indonesia_quakes.index = \\\n...     indonesia_quakes.index.strftime('%b\\n%d')\n>>> indonesia_quakes.plot(\n...     y=['earthquake', 'tsunami'], kind='bar', rot=0, \n...     figsize=(15, 3), label=['earthquakes', 'tsunamis'], \n...     title='Earthquakes and Tsunamis in Indonesia '\n...           '(September 18, 2018 - October 13, 2018)'\n... )\n# label the axes (discussed in chapter 6)\n>>> plt.xlabel('date')\n>>> plt.ylabel('count')\n```", "```py\n>>> quakes.groupby(['parsed_place', 'tsunami']).mag.count()\\\n...     .unstack().apply(lambda x: x / x.sum(), axis=1)\\\n...     .rename(columns={0: 'no', 1: 'yes'})\\\n...     .sort_values('yes', ascending=False)[7::-1]\\\n...     .plot.barh(\n...         title='Frequency of a tsunami accompanying '\n...               'an earthquake'\n...     )\n# move legend to the right of the plot; label axes\n>>> plt.legend(title='tsunami?', bbox_to_anchor=(1, 0.65))\n>>> plt.xlabel('percentage of earthquakes')\n>>> plt.ylabel('')\n```", "```py\n>>> quakes.magType.value_counts().plot(\n...     kind='bar', rot=0,\n...     title='Earthquakes Recorded per magType'\n... )\n# label the axes (discussed in ch 6)\n>>> plt.xlabel('magType')\n>>> plt.ylabel('earthquakes')\n```", "```py\n>>> pivot = quakes.assign(\n...     mag_bin=lambda x: np.floor(x.mag)\n... ).pivot_table(\n...     index='mag_bin', \n...     columns='magType', \n...     values='mag', \n...     aggfunc='count'\n... )\n```", "```py\n>>> pivot.plot.bar(\n...     stacked=True,\n...     rot=0, \n...     title='Earthquakes by integer magnitude and magType'\n... )\n>>> plt.ylabel('earthquakes') # label axes (discussed in ch 6)\n```", "```py\n>>> normalized_pivot = \\\n...     pivot.fillna(0).apply(lambda x: x / x.sum(), axis=1)\n... \n>>> ax = normalized_pivot.plot.bar(\n...     stacked=True, rot=0, figsize=(10, 5),\n...     title='Percentage of earthquakes by integer magnitude '\n...           'for each magType'\n... )\n>>> ax.legend(bbox_to_anchor=(1, 0.8)) # move legend\n>>> plt.ylabel('percentage') # label axes (discussed in ch 6)\n```", "```py\n>>> quakes.groupby(['parsed_place', 'tsunami']).mag.count()\\\n...     .unstack().apply(lambda x: x / x.sum(), axis=1)\\\n...     .rename(columns={0: 'no', 1: 'yes'})\\\n...     .sort_values('yes', ascending=False)[7::-1]\\\n...     .plot.barh(\n...         title='Frequency of a tsunami accompanying '\n...               'an earthquake',\n...         stacked=True\n...     )\n# move legend to the right of the plot\n>>> plt.legend(title='tsunami?', bbox_to_anchor=(1, 0.65))\n# label the axes (discussed in chapter 6)\n>>> plt.xlabel('percentage of earthquakes')\n>>> plt.ylabel('')\n```", "```py\n>>> %matplotlib inline\n>>> import matplotlib.pyplot as plt\n>>> import numpy as np\n>>> import pandas as pd\n>>> fb = pd.read_csv(\n...     'data/fb_stock_prices_2018.csv', \n...     index_col='date', \n...     parse_dates=True\n... )\n```", "```py\n>>> from pandas.plotting import scatter_matrix\n>>> scatter_matrix(fb, figsize=(10, 10))\n```", "```py\n>>> scatter_matrix(fb, figsize=(10, 10), diagonal='kde')\n```", "```py\n>>> from pandas.plotting import lag_plot\n>>> np.random.seed(0) # make this repeatable\n>>> lag_plot(pd.Series(np.random.random(size=200)))\n```", "```py\n>>> lag_plot(fb.close)\n```", "```py\n>>> lag_plot(fb.close, lag=5)\n```", "```py\n>>> from pandas.plotting import autocorrelation_plot\n>>> np.random.seed(0) # make this repeatable\n>>> autocorrelation_plot(pd.Series(np.random.random(size=200)))\n```", "```py\n>>> autocorrelation_plot(fb.close)\n```", "```py\n>>> from pandas.plotting import bootstrap_plot\n>>> fig = bootstrap_plot(\n...     fb.volume, fig=plt.figure(figsize=(10, 6))\n... )\n```"]