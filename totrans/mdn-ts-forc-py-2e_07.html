<html><head></head><body>
  <div id="_idContainer194" class="Basic-Text-Frame">
    <h1 class="chapterNumber">5</h1>
    <h1 id="_idParaDest-127" class="chapterTitle">Time Series Forecasting as Regression</h1>
    <p class="normal">In the previous part of the book, we developed a fundamental understanding of time series and equipped ourselves with tools and techniques to analyze and visualize time series and even generate our first baseline forecasts. We have mainly covered classical and statistical techniques in this book so far. Let’s now dip our toes into modern <strong class="keyWord">machine learning</strong> and learn how we can leverage this comparatively new field for <strong class="keyWord">time series forecasting</strong>. Machine learning is a field that has grown in leaps and bounds in recent times, and being able to leverage these new techniques for time series forecasting is a skill that will be invaluable in today’s world.</p>
    <p class="normal">In this chapter, we will be covering these main topics:</p>
    <ul>
      <li class="bulletList">Understanding the basics of machine learning</li>
      <li class="bulletList">Time series forecasting as regression</li>
      <li class="bulletList">Local versus global models</li>
    </ul>
    <h1 id="_idParaDest-128" class="heading-1">Understanding the basics of machine learning</h1>
    <p class="normal">We want to use machine learning for time series forecasting. But before we get started with it, let’s spend some time <a id="_idIndexMarker411"/>establishing what machine learning is and setting up a framework to demonstrate what it does (if you are already very comfortable with machine learning, feel free to skip ahead to the next section, <em class="italic">Time series forecasting as regression</em>, or just stay with us and refresh the concepts). In 1959, Arthur Samuel defined machine learning as a “<em class="italic">field of study that gives computers the ability to learn without being explicitly programmed</em>.” Traditionally, programming has been a paradigm under which we know a set of rules/logic to perform an action, and that action is performed on the given data to get the output that we want. But machine learning flipped this on its head. </p>
    <p class="normal">In machine learning, we start with data and the output, and we ask the <a id="_idIndexMarker412"/>computer to tell us about the rules with which the <a id="_idIndexMarker413"/>desired output can be achieved from the data:</p>
    <figure class="mediaobject"><img src="../Images/B22389_05_01.png" alt="Figure 5.1 – Traditional programming versus machine learning "/></figure>
    <p class="packt_figref">Figure 5.1: Traditional programming versus machine learning</p>
    <p class="normal">There are many kinds of problem settings in machine learning, such as supervised learning, unsupervised learning, self-supervised learning, and so on, but we will stick to supervised learning, which is the most common one and the most applicable to the content of this book. Supervised learning refers to what we already touched upon in the paradigm shift example with the program, data, and output. We use a dataset with paired examples of input and expected output and ask the model to learn the relationship.</p>
    <p class="normal">Let’s start our discussion small and slowly build up to the whole schematic, which encapsulates most of the key components of a supervised machine learning problem:</p>
    <figure class="mediaobject"><img src="../Images/B22389_05_02.png" alt="Figure 5.2 – Supervised machine learning schematic, part 1 – the ideal function "/></figure>
    <p class="packt_figref">Figure 5.2: Supervised machine learning schematic, part 1—the ideal function</p>
    <p class="normal">As we have already discussed, what we want from machine learning is to <em class="italic">learn</em> from the data and come up with a set of rules/logic. The closest analogy in mathematics for logic/rules is a function, which takes in <a id="_idIndexMarker414"/>an input (here, data) and provides<a id="_idIndexMarker415"/> an output. Mathematically, it can be written as follows:</p>
    <p class="center"><em class="italic">y </em>= <em class="italic">g</em>(<em class="italic">X</em>)</p>
    <p class="normal">where <em class="italic">X</em> is the set of features <a id="_idIndexMarker416"/>and <em class="italic">g</em> is the <strong class="keyWord">ideal target function </strong>(denoted by <strong class="keyWord">1</strong> in <em class="italic">Figure 5.2</em>) that maps the <em class="italic">X</em> input (denoted by <strong class="keyWord">2</strong> in the schematic) to the target (ideal) output, <em class="italic">y</em> (denoted by <strong class="keyWord">3</strong> in the schematic). The ideal target function is largely an unknown <a id="_idIndexMarker417"/>function, similar to the <strong class="keyWord">data-generating process</strong> (<strong class="keyWord">DGP</strong>) we saw in <em class="chapterRef">Chapter 1</em>, <em class="italic">Introducing Time Series</em>, which is not in our control.</p>
    <figure class="mediaobject"><img src="../Images/B22389_05_03.png" alt="Figure 5.3 – Supervised machine learning schematic, part 2 – the learned approximation "/></figure>
    <p class="packt_figref">Figure 5.3: Supervised machine learning schematic, part 2—the learned approximation</p>
    <p class="normal">But we want the computer to <em class="italic">learn</em> this ideal target function. This approximation of the ideal target function is denoted by another function, <em class="italic">h</em> (<strong class="keyWord">4</strong> in the schematic), which takes in the same set of features, <em class="italic">X</em>, and outputs a<a id="_idIndexMarker418"/> predicted target, <img src="../Images/B22389_05_001.png" alt=""/> (<strong class="keyWord">5</strong> in the schematic). <img src="../Images/B22389_05_002.png" alt=""/> is the parameters of the <em class="italic">h</em> function (or model parameters):</p>
    <figure class="mediaobject"><img src="../Images/B22389_05_04.png" alt="Figure 5.4 – Supervised machine learning schematic, part 3 – putting it all together "/></figure>
    <p class="packt_figref">Figure 5.4: Supervised machine learning schematic, part 3—putting it all together</p>
    <p class="normal">Now, how do we find this approximation <em class="italic">h</em> function and its parameters, <img src="../Images/B22389_05_002.png" alt=""/>? With the dataset of examples (<strong class="keyWord">6</strong> in the schematic). The supervised machine learning problem works on the premise that we are able to collect a set of examples that shows the features, <em class="italic">X</em>, and the corresponding target, <em class="italic">y</em>, which is also referred to as <em class="italic">labels</em> in the literature. It is from this set of examples (the dataset) that the computer <em class="italic">learns</em> the approximation function, <em class="italic">h</em>, and the optimal model parameters, <img src="../Images/B22389_05_002.png" alt=""/>. In the preceding diagram, the only real unknown entity is the ideal target function, <em class="italic">g</em>. So, we can use the training dataset, <em class="italic">D</em>, to get predicted targets for every sample in the dataset. We already know the ideal target for all the examples. We need a way to compare the ideal targets and predicted targets, and this is where the loss function (<strong class="keyWord">7</strong> in the schematic) comes in. This loss function tells us how far away from the real truth we are with the approximated function, <em class="italic">h</em>.</p>
    <p class="normal">Although <em class="italic">h</em> can be any function, it is typically chosen from a set of a well-known class of functions, <em class="italic">H</em>. <em class="italic">H</em> is the finite set of functions that can be fit to the data. This class of functions is what we colloquially call <strong class="keyWord">models</strong>. For instance, <em class="italic">h</em> can be chosen from all the linear functions or all the <a id="_idIndexMarker419"/>tree-based functions, and so on. Choosing an <em class="italic">h</em> from <em class="italic">H</em> is done by a combination of hyperparameters (which the modeler specifies) and the model parameter, which is learned from data.</p>
    <p class="normal">Now, all that is left is to run through the different functions so that we find the best approximation function, <em class="italic">h</em>, which<a id="_idIndexMarker420"/> gives us the lowest loss. This is an optimization process that we call <strong class="keyWord">training</strong>.</p>
    <p class="normal">Let’s also take a look at a few key concepts, which will be important in all our discussions ahead.</p>
    <h2 id="_idParaDest-129" class="heading-2">Supervised machine learning tasks</h2>
    <p class="normal">Machine learning <a id="_idIndexMarker421"/>can be used to solve a wide<a id="_idIndexMarker422"/> variety of tasks, such as <strong class="keyWord">regression</strong>, <strong class="keyWord">classification</strong>, and <strong class="keyWord">recommendation</strong>. But since <a id="_idIndexMarker423"/>classification and regression are the most common classes of problems, we will spend just a little bit of time reviewing what they are.</p>
    <p class="normal">The difference between classification and regression tasks is very simple. In the machine learning schematic (<em class="italic">Figure 5.2</em>), we talked about <em class="italic">y</em>, the target. This target can be either a real-valued number or a class of items. For instance, we could be predicting the stock price for next week or we could just predict whether the stock was going to go up or down. In the first case, we are<a id="_idIndexMarker424"/> predicting a real-valued number, which is called <strong class="keyWord">regression</strong>. In the other case, we are <a id="_idIndexMarker425"/>predicting one out of two classes (<em class="italic">up</em> or <em class="italic">down</em>), and this is called <strong class="keyWord">classification</strong>.</p>
    <h2 id="_idParaDest-130" class="heading-2">Overfitting and underfitting</h2>
    <p class="normal">The biggest challenge in <a id="_idIndexMarker426"/>machine learning systems is that the model we trained must perform well on a new and unseen dataset. The ability of a machine learning model to do that is <a id="_idIndexMarker427"/>called the <strong class="keyWord">generalization capability</strong> of the model. The training process in a machine learning setup is akin to mathematical optimization, with one subtle difference. The aim of mathematical optimization is to arrive at the global maxima in the provided dataset. But in machine learning, the aim is to achieve a low test error by using the training error as a proxy. How well a machine learning model is doing on the training error and testing error is closely related to the concepts of overfitting and underfitting. Let’s use an example to understand these terms.</p>
    <p class="normal">The learning process of a machine learning model has many parallels to how humans learn. Suppose three students, <em class="italic">A</em>, <em class="italic">B</em>, and <em class="italic">C</em>, are studying for an examination. <em class="italic">A</em> is a slacker and went clubbing the night before. <em class="italic">B</em> decided to double down and memorize the textbook from end to end. <em class="italic">C</em> paid attention in class and understood the topics for the examination.</p>
    <p class="normal">As expected, <em class="italic">A</em> flunked the examination, <em class="italic">C</em> got the highest score, and <em class="italic">B</em> did OK.</p>
    <p class="normal"><em class="italic">A</em> flunked the examination because they didn’t learn enough. This happens to machine learning models as well when they don’t learn enough patterns, and this is called <strong class="keyWord">underfitting</strong>. This is characterized<a id="_idIndexMarker428"/> by high training errors and high test<a id="_idIndexMarker429"/> errors.</p>
    <p class="normal"><em class="italic">B</em> didn’t score as highly as expected; after all, they did memorize the whole text, word for word. But many questions in the examination weren’t directly from the textbook and <em class="italic">B</em> wasn’t able to answer them correctly. In other words, the questions in the examination were <em class="italic">new and unseen</em>. And because <em class="italic">B</em> memorized everything but didn’t make an effort to understand the underlying concepts, <em class="italic">B</em> wasn’t able to <em class="italic">generalize</em> the knowledge they had to new questions. This situation, in <a id="_idIndexMarker430"/>machine learning, is called <strong class="keyWord">overfitting</strong>. This is typically <a id="_idIndexMarker431"/>characterized by a big delta in training and test errors. Typically, we will see very low training errors and high test errors.</p>
    <p class="normal">The third student, <em class="italic">C</em>, learned the right way and understood the underlying concepts, and because of that was able to <em class="italic">generalize</em> to <em class="italic">new and unseen</em> questions. This is the ideal state for a machine learning model, as well. This is characterized by reasonably low test errors and a small delta between training and test errors.</p>
    <p class="normal">We just saw the two greatest challenges in machine learning. Now, let’s also look at a few ways we have that can be used to tackle these challenges.</p>
    <p class="normal">There is a close relationship between the <strong class="keyWord">capacity</strong> of a model and underfitting or overfitting. A model’s capacity is its ability to be flexible enough to fit a wide variety of functions. Models with low capacity may struggle to fit the training data, leading to underfitting. Models with high capacity may overfit by memorizing the training data too much. Just to develop an understanding of this concept of capacity, let’s look at an example. When we move from linear regression to polynomial regression, we are adding more capacity to the model. Instead of fitting just straight lines, we are letting the model fit curved lines as well. </p>
    <p class="normal">Machine learning models generally do well when their capacity is appropriate for the learning problem at hand.</p>
    <figure class="mediaobject"><img src="../Images/B22389_05_05.png" alt="Figure 5.5 – Underfitting versus overfitting "/></figure>
    <figure class="mediaobject">Figure 5.5: Underfitting versus overfitting</figure>
    <p class="normal"><em class="italic">Figure 5.5</em> shows a very popular case to illustrate overfitting and underfitting. We create a few random points using a known function and try to learn that by using those data samples. We can see that the linear regression, which is one of the simplest models, has underfitted the data by drawing a straight line through those points. Polynomial regression is linear regression, but with some higher-order features. For now, you can consider the move from linear regression to polynomial regression with higher degrees as increasing the capacity of the model. So, when we use a degree of 4, we see that the learned function fits the data well and matches our ideal function. But if we keep increasing the capacity of the model and reach <code class="inlineCode">degree = 15</code>, we see that the learned function is still passing through the training samples, but has learned a very different function, overfitting to the training data. Finding the optimal capacity to learn a generalizable function is one of the core challenges of machine learning.</p>
    <p class="normal">While capacity is one aspect of the model, another aspect is <strong class="keyWord">regularization</strong>. Even <a id="_idIndexMarker432"/>with the same capacity, there are multiple functions a model can choose from the hypothesis space of all functions. With regularization, we try to give preference to a set of functions in the hypothesis space over the others. </p>
    <p class="normal">While all these functions are valid functions that can be chosen, we nudge the optimization process in such a way that we end up with a kind of function toward which we have a preference. Although regularization is a general term used to refer to any kind of constraint we place on the learning process to reduce the complexity of the learned function, more commonly, it is used in the form of a weight decay. Let’s take an example of linear regression, which is when we fit a straight line to the input features by learning a weight associated with each feature.</p>
    <p class="normal">A linear regression model can be written mathematically as follows:</p>
    <p class="center"><img src="../Images/B22389_05_005.png" alt=""/></p>
    <p class="normal">Here, <em class="italic">N</em> is the number of features, <em class="italic">c</em> is the intercept, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">i</sub> is the <em class="italic">i</em><sup class="superscript">th</sup> feature, and <em class="italic">w</em><sub class="subscript-italic" style="font-style: italic;">i</sub> is the weight associated with the <em class="italic">i</em><sup class="superscript">th</sup> feature. We estimate the right weight (<em class="italic">L</em>) by considering this as an optimization problem that minimizes the error between <img src="../Images/B22389_05_001.png" alt=""/> and <em class="italic">y</em> (real output).</p>
    <p class="normal">Now, with regularization, we add an additional term to <em class="italic">L</em>, which forces the weights to become smaller. Commonly, this is done using an <em class="italic">L1</em> or <em class="italic">L2</em> regularizer. An <em class="italic">L1</em> regularizer is when you add the sum of squared weights to <em class="italic">L</em>:</p>
    <p class="center"><img src="../Images/B22389_05_007.png" alt=""/></p>
    <p class="normal">where <img src="../Images/B22389_05_008.png" alt=""/> is the regularization coefficient that determines how strongly we penalize the weights. An <em class="italic">L2</em> regularizer is when you add the sum of absolute weights to <em class="italic">L</em>:</p>
    <p class="center"><img src="../Images/B22389_05_009.png" alt=""/></p>
    <p class="normal">In both cases, we are enforcing a preference for smaller weights over larger weights because it keeps the function from relying too much on any one feature from the ones used in the machine learning model. Regularization is an entire topic unto itself; if you want to learn more, head over to the <em class="italic">Further reading</em> section for a few resources on regularization.</p>
    <p class="normal">Another really effective way<a id="_idIndexMarker433"/> to reduce overfitting is to simply train the model with more data. With a larger dataset, the chances of the model overfitting become less because of the sheer variety that can be captured in a large dataset.</p>
    <p class="normal">Now, how do we tune the knobs to strike a balance between underfitting and overfitting? Let’s look at it in the following section.</p>
    <h2 id="_idParaDest-131" class="heading-2">Hyperparameters and validation sets</h2>
    <p class="normal">Almost all machine learning models have a few hyperparameters associated with them. <strong class="keyWord">Hyperparameters</strong> are <a id="_idIndexMarker434"/>parameters of the model that are not learned <a id="_idIndexMarker435"/>from data but rather are set before the start of training. For instance, the weight of the regularization is a hyperparameter. Most hyperparameters either help us control the capacity of the model or apply regularization to the model. By controlling either capacity or regularization or both, we can travel the frontier between underfitting and overfitting models and arrive at a model that is just right.</p>
    <p class="normal">But since these hyperparameters have to be set outside of the algorithm, how do we estimate the best hyperparameters? Although it is not part of the core <em class="italic">learning process</em>, we also learn the hyperparameters from the data. But if we just use the training data to learn the hyperparameters, it will just choose the maximum possible model capacity, which results in overfitting. This is where we <a id="_idIndexMarker436"/>need a <strong class="keyWord">validation set</strong>, a part of the data <a id="_idIndexMarker437"/>that the training process does not have access to. Following the same analogy we saw earlier, the validation set is the mock exam students take to check if they have learned well enough. But when the dataset is small (not hundreds of thousands of samples), the performance on a single validation set doesn’t guarantee a fair <a id="_idIndexMarker438"/>evaluation. In such cases, we<a id="_idIndexMarker439"/> rely on <strong class="keyWord">cross-validation</strong>. The general trick is to repeat the training and evaluation procedure on different subsets of the original dataset. A common way of doing this <a id="_idIndexMarker440"/>is called <strong class="keyWord">k-fold cross-validation</strong>, where the original dataset is divided into <em class="italic">k</em> equal, non-overlapping, and random <a id="_idIndexMarker441"/>subsets, and each subset is evaluated after training on all the other subsets. We have provided a link in the <em class="italic">Further reading</em> section if you want to read up on cross-validation techniques. Later in the book, we will also be covering this topic, but from the time series perspective, which has a few differences from the standard way of doing cross-validation.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Suggested reading</strong>:</p>
      <p class="normal">Although we have scratched the surface of machine learning in this book, there is a lot more, and to truly appreciate the rest of the book better, we suggest gaining more understanding of machine learning. We suggest starting with <em class="italic">Machine Learning by Stanford (Andrew Ng)</em>—<a href="https://www.coursera.org/learn/machine-learning"><span class="url">https://www.coursera.org/learn/machine-learning</span></a>. If you are in a hurry, <em class="italic">Machine Learning Crash Course</em> by <em class="italic">Google</em> is also a good starting point—<a href="https://developers.google.com/machine-learning/crash-course/ml-intro"><span class="url">https://developers.google.com/machine-learning/crash-course/ml-intro</span></a>.</p>
    </div>
    <p class="normal">Machine learning has progressed a lot in recent times, and along with it, powerful models that are able to learn complex patterns from data have come out of it. When we compare these models with the classical models of time series forecasting, we can see that there is a lot of potential in these newer classes of models. But there are some fundamental differences between machine learning and time series forecasting. In the next section, let’s understand how we can get over those differences and use machine learning for time series forecasting.</p>
    <h1 id="_idParaDest-132" class="heading-1">Time series forecasting as regression</h1>
    <p class="normal">A time series, as we saw in <em class="chapterRef">Chapter 1</em>, <em class="italic">Introducing Time Series</em>, is a set of observations taken sequentially in time. And typically, time series<a id="_idIndexMarker442"/> forecasting is about trying to predict what these observations will be in the future. Given a sequence of observations of arbitrary length of history, we predict the future to an arbitrary horizon.</p>
    <p class="normal">We saw that regression, or <a id="_idIndexMarker443"/>machine learning to predict a continuous variable, works on a dataset of examples, and each example is a set of input features and targets. We can see that regression, which is tasked with predicting a single output provided with a set of inputs, is fundamentally incompatible with forecasting, where we are given a set of historical values and asked to predict the future values. This fundamental incompatibility between the time series and machine learning regression paradigms is why we cannot use regression for time series forecasting directly.</p>
    <p class="normal">Moreover, time series forecasting, by definition, is an extrapolation problem, whereas regression, most of the time, is an interpolation one. Extrapolation is typically harder to solve using data-driven methods. Another key assumption in regression problems is that the samples used for training are <strong class="keyWord">independent and identically distributed</strong> (<strong class="keyWord">iid</strong>). But time series break that assumption as well because<a id="_idIndexMarker444"/> subsequent observations in a time series display considerable dependence.</p>
    <p class="normal">However, to use the wide variety of techniques from machine learning, we need to cast time series forecasting as a regression. Thankfully, there are ways to convert a time series into a regression and get over the IID assumption by introducing some memory to the machine learning model through some features. Let’s see how it can be done.</p>
    <h2 id="_idParaDest-133" class="heading-2">Time delay embedding</h2>
    <p class="normal">We talked about the<a id="_idIndexMarker445"/> ARIMA model in <em class="chapterRef">Chapter 4</em>, <em class="italic">Setting a Strong Baseline Forecast</em>, and saw how it is an autoregressive model. We can use the same <a id="_idIndexMarker446"/>concept to convert a time series problem into a regression one. Let’s use the following diagram to make the concept clear:</p>
    <figure class="mediaobject"><img src="../Images/B22389_05_06.png" alt="Figure 5.6 – Time series to regression conversion using a sliding window "/></figure>
    <p class="packt_figref">Figure 5.6: Time series to regression conversion using a sliding window</p>
    <p class="normal">Let’s assume we have a time series with <em class="italic">L</em> time steps, just like in the diagram. We have <em class="italic">T</em> as the latest observation, <em class="italic">T - 1</em>, <em class="italic">T - 2</em>, and so on as we move backward in time, all the way to<em class="italic">T - L</em>. In an ideal world, each observation should be conditioned on all the previous observations when we forecast. But this is not practical because <em class="italic">L</em> can be arbitrarily long. We often restrict <a id="_idIndexMarker447"/>the forecasting function to use only the most recent <em class="italic">M</em> observations of the series, where <em class="italic">M &lt; L</em>. These are called finite <a id="_idIndexMarker448"/>memory models, or <strong class="keyWord">Markov models</strong>, and <em class="italic">M</em> is called the order of autoregression, memory size, or the receptive field.</p>
    <p class="normal">Therefore, in time delay<a id="_idIndexMarker449"/> embedding, we assume a window of arbitrary length <em class="italic">M &lt; L</em> and extract fixed-length subsequences from the time series by sliding the window over the length of the time series.</p>
    <p class="normal">In the diagram, we have taken a sliding window with a memory size of <strong class="keyWord">3</strong>. So, the first subsequence we can extract (if we are starting from the most recent and working backward) is <em class="italic">T – 3</em>, <em class="italic">T – 2</em>, <em class="italic">T - 1</em>. And <em class="italic">T</em> is the observation that comes right after the subsequence. This becomes our first example in the dataset (row <strong class="keyWord">1</strong> in the table in the diagram). </p>
    <p class="normal">Now, we slide the window one time step to the left (backward in time) and extract the new subsequence, <em class="italic">T – 4</em>, <em class="italic">T – 3</em>, <em class="italic">T - 2</em>. The corresponding target would become <em class="italic">T - 1</em>. We repeat this process as we move back to the beginning of the time series, and at each step of the sliding window, we add one more example to the dataset.</p>
    <p class="normal">At the end of it, we have an aligned dataset with a fixed vector size of features (which will be equal to the window size) and a single target, which is what a typical machine learning dataset looks like.</p>
    <p class="normal">Now that we have a table with three features, let’s also assign semantic meaning to the three features. If we look at the right-most column in the table in the diagram, we can see that the time step present in <a id="_idIndexMarker450"/>the column is always one time step behind the target. We call it <strong class="keyWord">Lag 1</strong>. The second column from the right is always two time steps behind the target, and this is called <strong class="keyWord">Lag 2</strong>. Generalizing this, the feature that has observations that are <em class="italic">n</em> time steps behind the <a id="_idIndexMarker451"/>target, we call <strong class="keyWord">Lag n</strong>.</p>
    <p class="normal">This transformation from time series to regression using <strong class="keyWord">time-delay embedding</strong> encodes the autoregressive structure of a time series in a way that can be utilized by standard regression frameworks. Another way we can think about using regression for time series forecasting is to perform <strong class="keyWord">regression on time</strong>.</p>
    <h2 id="_idParaDest-134" class="heading-2">Temporal embedding</h2>
    <p class="normal">If we rely on previous observations in <a id="_idIndexMarker452"/>autoregressive models, we rely on the concept of time for temporal embedding models. The core idea is that we forget the autoregressive nature of the time series and assume that any value in the time series is only dependent on time. We derive features that capture time, the passage of time, the periodicity of time, and so on, from the timestamps associated with the time series, and then we use these features to predict the target using a regression model. There are many ways to do this, from simply aligning a monotonically and uniformly increasing numerical column that captures the passage of time to<a id="_idIndexMarker453"/> sophisticated <strong class="keyWord">Fourier</strong> terms to capture the periodic components in time. We will talk about those techniques in detail in <em class="chapterRef">Chapter 6</em>, <em class="italic">Feature Engineering for Time Series Forecasting</em>.</p>
    <p class="normal">Before we wind up the chapter, let’s also talk about a key concept that is gaining ground steadily in the time series forecasting space. A large part of this book embraces this new paradigm of forecasting.</p>
    <h1 id="_idParaDest-135" class="heading-1">Global forecasting models—a paradigm shift</h1>
    <p class="normal">Traditionally, each time series was treated in isolation. Because of that, traditional forecasting has always<a id="_idIndexMarker454"/> looked at the history of a single time series alone in fitting a forecasting function. But recently, because of the ease of collecting data in today’s digital-first world, many companies have started collecting large amounts of time series from similar sources, or related time series.</p>
    <p class="normal">For example, retailers such as Walmart collect data on the sales of millions of products across thousands of stores. Companies such as Uber and Lyft collect the demand for rides from all the zones in a city. In the energy sector, energy consumption data is collected across all consumers. All these sets<a id="_idIndexMarker455"/> of time series have shared behavior and are hence called <strong class="keyWord">related time series</strong>.</p>
    <p class="normal">We can consider that all the time series in a related time series come from separate DGPs, and thereby <a id="_idIndexMarker456"/>model them all separately. We call these the <strong class="keyWord">local</strong> models of forecasting. An alternative to this approach is to assume that all the time series are coming from a single DGP. Instead of fitting a separate forecast function for each time series individually, we fit a single forecast function to all the<a id="_idIndexMarker457"/> related time series. This approach has been called <strong class="keyWord">global</strong> or <strong class="keyWord">cross-learning</strong> in the literature. Most modern deep learning models as well <a id="_idIndexMarker458"/>as machine learning approaches adopt the global model paradigm. We will see those in detail in the coming chapters.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Reference check</strong>:</p>
      <p class="normal">The term <em class="italic">global</em> was introduced by <em class="italic">David Salinas et al</em>. in the <em class="italic">DeepAR</em> paper (reference <em class="italic">1</em>) and <em class="italic">cross-learning</em> by <em class="italic">Slawek Smyl</em> (reference <em class="italic">2</em>).</p>
    </div>
    <p class="normal">We saw earlier that having more data will lead to lower chances of overfitting and, therefore, lowers the generalization error (the difference between training and testing errors). This is one of the shortcomings of the local approach. Traditionally, time series are not very long, and in many cases, it is difficult and time-consuming to collect more data as well. Fitting a machine learning model (with all its expressiveness) on small data is prone to overfitting. This is why time series models that enforce strong priors were used to forecast such time series, traditionally. But these strong priors, which restrict the fitting of traditional<a id="_idIndexMarker459"/> time series models, can also lead to a form of underfitting and limit accuracy.</p>
    <p class="normal">Strong and expressive data-driven models, as in machine learning, require a larger amount of data to have a model that generalizes to new and unseen data. A time series, by definition, is tied to time, and sometimes, collecting more data means waiting for months or years and that is not desirable. So, if we cannot increase the <em class="italic">length</em> of the time series dataset, we can increase the <em class="italic">width</em> of the time series dataset. If we add multiple time series to the dataset, we increase the width of the dataset, and thereby increase the amount of data the model is getting trained with. </p>
    <p class="normal"><em class="italic">Figure 5.7</em> shows the concept of increasing<a id="_idIndexMarker460"/> the width of a time series dataset visually:</p>
    <figure class="mediaobject"><img src="../Images/B22389_05_07.png" alt="Figure 5.7 – The length and width of a time series dataset "/></figure>
    <figure class="mediaobject">Figure 5.7: The length and width of a time series dataset</figure>
    <p class="normal">This works in favor of<a id="_idIndexMarker461"/> machine learning models because with higher flexibility in fitting a forecast function and the addition of more data to work with, the machine learning model can learn a more complex forecast function than traditional time series models, which are typically shared between the related time series, in a completely data-driven way.</p>
    <p class="normal">Another shortcoming of the local approach revolves around scalability. In the case of Walmart we mentioned earlier, there are millions of time series that need to be forecasted and it is not possible to have human oversight on all these models. If we think about this from an engineering perspective, training and maintaining millions of models in a production system would give any engineer a nightmare. But under the global approach, we only<a id="_idIndexMarker462"/> train a single model for all these time series, which drastically reduces the number of models we need to maintain and yet can generate all the required forecasts.</p>
    <p class="normal">This new paradigm of forecasting has gained traction and has consistently been shown to improve the local approaches in multiple time series competitions, mostly in datasets of related time series. In Kaggle competitions, such as <em class="italic">Rossman Store Sales</em> (2015), <em class="italic">Wikipedia WebTraffic Time Series Forecasting</em> (2017), <em class="italic">Corporación Favorita Grocery Sales Forecasting</em> (2018), and <em class="italic">M5 Competition</em> (2020), the winning entries were all global models—either machine learning or deep learning or a combination of both. The <em class="italic">Intermarché Forecasting Competition</em> (2021) also had global models as the winning submissions. Links to these competitions are provided in the <em class="italic">Further reading</em> section.</p>
    <p class="normal">Although we have many empirical findings where the global models have outperformed local models for related time series, global models are still a relatively new area of research. <em class="italic">Montero-Manson and Hyndman</em> (2020) showed a few very interesting results and showed that any local method can be approximated by a global model with required complexity, and the most interesting finding they put forward is that the global model will perform better, even with unrelated time series. We will talk more about global models and strategies for global models in <em class="chapterRef">Chapter 10</em>, <em class="italic">Global Forecasting Models</em>.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Reference check</strong>:</p>
      <p class="normal">The <em class="italic">Montero-Manson and Hyndman</em> (2020) research paper is cited in <em class="italic">References</em> under reference <em class="italic">3</em>.</p>
    </div>
    <h1 id="_idParaDest-136" class="heading-1">Summary</h1>
    <p class="normal">We have started our journey beyond baseline forecasting methods and dipped our toes into the world of machine learning. After a brief refresher on machine learning, where we looked at key concepts such as overfitting, underfitting, regularization, and so on, we saw how we can convert a time series forecasting problem into a regression problem from the machine learning world. We also developed a conceptual understanding of different embeddings, such as time delay embedding and temporal embedding, which can be used to convert a time series problem into a regression problem. To wrap things up, we also learned about a new paradigm in time series forecasting—global models—and contrasted them with local models on a conceptual level. In the next few chapters, we will start putting these concepts into practice, and see techniques for feature engineering and strategies for global models.</p>
    <h1 id="_idParaDest-137" class="heading-1">References</h1>
    <p class="normal">The following are the references that we used in this chapter:</p>
    <ol>
      <li class="numberedList" value="1">David Salinas, Valentin Flunkert, Jan Gasthaus, Tim Januschowski (2020). <em class="italic">DeepAR: Probabilistic forecasting with autoregressive recurrent networks</em>. International Journal of Forecasting. 36-3. 1181–1191: <a href="https://doi.org/10.1016/j.ijforecast.2019.07.001"><span class="url">https://doi.org/10.1016/j.ijforecast.2019.07.001</span></a></li>
      <li class="numberedList">Slawek Smyl (2020). <em class="italic">A hybrid method of exponential smoothing and recurrent neural networks for time series forecasting</em>. International Journal of Forecasting. 36-1: 75–85 <a href="https://doi.org/10.1016/j.ijforecast.2019.03.017"><span class="url">https://doi.org/10.1016/j.ijforecast.2019.03.017</span></a></li>
      <li class="numberedList">Pablo Montero-Manso, Rob J Hyndman (2020), <em class="italic">Principles and Algorithms for Forecasting Groups of Time Series: Locality and Globality</em>. arXiv:2008.00444[cs.LG]: <a href="https://arxiv.org/abs/2008.00444 "><span class="url">https://arxiv.org/abs/2008.00444</span></a></li>
    </ol>
    <h1 id="_idParaDest-138" class="heading-1">Further reading</h1>
    <p class="normal">You can check out the following resources for further reading:</p>
    <ul>
      <li class="bulletList"><em class="italic">Regularization for Sparsity from Google Machine Learning Crash Course</em>: <a href="https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/l1-regularization"><span class="url">https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/l1-regularization</span></a></li>
      <li class="bulletList"><em class="italic">L1 &amp; L2 Regularization, Inside Bloomberg</em>: <a href="https://www.youtube.com/watch?v=d6XDOS4btck"><span class="url">https://www.youtube.com/watch?v=d6XDOS4btck</span></a></li>
      <li class="bulletList"><em class="italic">Cross-validation: evaluating estimator performance from scikit-learn</em>: <a href="https://scikit-learn.org/stable/modules/cross_validation.html"><span class="url">https://scikit-learn.org/stable/modules/cross_validation.html</span></a></li>
      <li class="bulletList"><em class="italic">Rossmann Store Sales</em>: <a href="https://www.kaggle.com/c/rossmann-store-sales"><span class="url">https://www.kaggle.com/c/rossmann-store-sales</span></a></li>
      <li class="bulletList"><em class="italic">Web Traffic Time Series Forecasting</em>: <a href="https://www.kaggle.com/c/web-traffic-time-series-forecasting"><span class="url">https://www.kaggle.com/c/web-traffic-time-series-forecasting</span></a></li>
      <li class="bulletList"><em class="italic">Corporación Favorita Grocery Sales Forecasting</em>: <a href="https://www.kaggle.com/c/favorita-grocery-sales-forecasting"><span class="url">https://www.kaggle.com/c/favorita-grocery-sales-forecasting</span></a></li>
      <li class="bulletList"><em class="italic">M5 Forecasting—Accuracy</em>: <a href="https://www.kaggle.com/c/m5-forecasting-accuracy"><span class="url">https://www.kaggle.com/c/m5-forecasting-accuracy</span></a></li>
    </ul>
    <h1 class="heading-1">Join our community on Discord</h1>
    <p class="normal">Join our community’s Discord space for discussions with authors and other readers:</p>
    <p class="normal"><a href="https://packt.link/mts"><span class="url">https://packt.link/mts</span></a></p>
    <p class="normal"><img src="../Images/QR_Code15080603222089750.png" alt=""/></p>
  </div>
</body></html>