<html><head></head><body>
  <div id="sbo-rt-content"><div class="chapter" title="Chapter 9. Numerical Optimization"><div class="titlepage"><div><div><h1 class="title"><a id="ch09"/>Chapter 9. Numerical Optimization</h1></div></div></div><p>In this chapter, we will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Finding the root of a mathematical function</li><li class="listitem" style="list-style-type: disc">Minimizing a mathematical function</li><li class="listitem" style="list-style-type: disc">Fitting a function to data with nonlinear least squares</li><li class="listitem" style="list-style-type: disc">Finding the equilibrium state of a physical system by minimizing its potential energy</li></ul></div><div class="section" title="Introduction"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec83"/>Introduction</h1></div></div></div><p>
<span class="strong"><strong>Mathematical optimization</strong></span><a id="id1430" class="indexterm"/> is a wide area of applied mathematics. It consists of finding the best solution to a given problem. Many real-world problems can be expressed in an optimization framework. What is the shortest path on the road from point A to point B? What is the best strategy to solve a puzzle? What is the most energy-efficient shape of a car (automotive aerodynamics)? Mathematical optimization is relevant in many domains including engineering, economics, finance, operations research, image processing, data analysis, and others.</p><p>Mathematically, an optimization problem generally consists of finding the maximum or minimum value of a function. We sometimes use the terms <a id="id1431" class="indexterm"/><span class="strong"><strong>continuous optimization</strong></span> or <a id="id1432" class="indexterm"/><span class="strong"><strong>discrete optimization</strong></span>, according to whether the function variable is real-valued or discrete.</p><p>In this chapter, we will focus on numerical methods for solving continuous optimization problems. Many optimization algorithms are implemented in the <code class="literal">scipy.optimize</code> module. We will come across other instances of optimization problems in several other chapters of this book. For example, we will see discrete optimization problems in <a class="link" href="ch14.html" title="Chapter 14. Graphs, Geometry, and Geographic Information Systems">Chapter 14</a>, <span class="emphasis"><em>Graphs, Geometry, and Geographic Information Systems</em></span>. In this introduction, we will give a few important definitions and key concepts related to mathematical optimization.</p><div class="section" title="The objective function"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec308"/>The objective function</h2></div></div></div><p>We will study methods to find a root or an <span class="strong"><strong>extremum</strong></span><a id="id1433" class="indexterm"/> of a real-valued function <span class="emphasis"><em>f</em></span> called the<a id="id1434" class="indexterm"/> <span class="strong"><strong>objective function</strong></span>. An extremum is either a maximum or a minimum of a function. This mathematical function is generally implemented in a Python function. It can accept one or several variables, it can be continuous or not, and so on. The more assumptions we have about the function, the easier it can be optimized.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note31"/>Note</h3><p>A maximum of <span class="emphasis"><em>f</em></span> is a minimum of <span class="emphasis"><em>-f</em></span>, so any minimization algorithm can be used to maximize a function by considering the <span class="emphasis"><em>opposite</em></span> of that function. Therefore, from now on, when we talk about <span class="emphasis"><em>minimization</em></span>, we will really mean <span class="emphasis"><em>minimization or maximization</em></span>.</p></div></div><p>
<span class="strong"><strong>Convex functions</strong></span><a id="id1435" class="indexterm"/> are generally easier to optimize than non-convex functions, as they satisfy certain useful properties. For example, any local minimum is necessarily a global minimum. The field of <span class="strong"><strong>convex optimization</strong></span><a id="id1436" class="indexterm"/> deals with algorithms that are specifically adapted to the optimization of convex functions on convex domains. Convex optimization is an advanced topic, and we can't cover much of it here.</p><p>
<span class="strong"><strong>Differentiable functions</strong></span><a id="id1437" class="indexterm"/> have gradients, and these gradients can be particularly useful in optimization algorithms. Similarly, <span class="strong"><strong>continuous functions</strong></span><a id="id1438" class="indexterm"/> are typically easier to optimize than non-continuous functions.</p><p>Also, functions with a single variable are easier to optimize than functions with multiple variables.</p><p>The choice of the most adequate optimization algorithm depends on the properties satisfied by the objective function.</p></div><div class="section" title="Local and global minima"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec309"/>Local and global minima</h2></div></div></div><p>A <span class="strong"><strong>minimum</strong></span><a id="id1439" class="indexterm"/> of a function <span class="emphasis"><em>f</em></span> is a point x<sub>0</sub> such that <span class="emphasis"><em>f(x) </em></span><span class="inlinemediaobject"><img src="images/4818OS_09_22.jpg" alt="Local and global minima"/></span><span class="emphasis"><em> f(x<sub>0</sub></em></span><span class="emphasis"><em>)</em></span>, for a particular set of points <span class="emphasis"><em>x</em></span> in <span class="emphasis"><em>E</em></span>. When this inequality is satisfied on the whole set <span class="emphasis"><em>E</em></span>, we refer to <span class="emphasis"><em>x<sub>0</sub></em></span> as a<a id="id1440" class="indexterm"/> <span class="strong"><strong>global minimum</strong></span>. When it is only satisfied locally (around the point <span class="emphasis"><em>x<sub>0</sub></em></span>), we say that <span class="emphasis"><em>x<sub>0</sub></em></span> is a<a id="id1441" class="indexterm"/> <span class="strong"><strong>local minimum</strong></span>. A <span class="strong"><strong>maximum</strong></span><a id="id1442" class="indexterm"/> is defined similarly.</p><p>If <span class="emphasis"><em>f</em></span> is differentiable, an extremum <span class="emphasis"><em>x<sub>0</sub></em></span> satisfies:</p><div class="mediaobject"><img src="images/4818OS_09_01.jpg" alt="Local and global minima"/></div><p>Therefore, finding the extrema of an objective function is closely related to finding the roots of the derivative. However, a point x<sub>0</sub> satisfying this property is not necessarily an extremum.</p><p>It is more difficult to find global minima than to find local minima. In general, when an algorithm finds a <a id="id1443" class="indexterm"/>local minimum, there is no guarantee that it is also a<a id="id1444" class="indexterm"/> global minimum. Frequently, an algorithm seeking a global minimum stays <span class="emphasis"><em>stuck</em></span> in a local minimum. This problem needs to be accounted for, specifically in global minimization algorithms. However, things are simpler with convex functions since these do not have strictly local minima. Moreover, there are many cases where finding a local minimum is good enough (for example, when looking for a good solution to a problem rather than the absolute best solution). Finally, let's note that a global minimum or maximum does not necessarily exist (the function can go to infinity). In that case, it may be necessary to constrain the space search; this is the subject of <a id="id1445" class="indexterm"/><span class="strong"><strong>constrained optimization</strong></span>.</p><div class="mediaobject"><img src="images/4818OS_09_02.jpg" alt="Local and global minima"/><div class="caption"><p>Local and global extrema</p></div></div></div><div class="section" title="Constrained and unconstrained optimization"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec310"/>Constrained and unconstrained optimization</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Unconstrained optimization</strong></span>: Finding the <a id="id1446" class="indexterm"/>minimum of a function <span class="emphasis"><em>f</em></span> on the full set <span class="emphasis"><em>E</em></span> where <span class="emphasis"><em>f</em></span> is defined</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Constrained optimization</strong></span>: Finding the <a id="id1447" class="indexterm"/>minimum of a function <span class="emphasis"><em>f</em></span> on a subset <span class="emphasis"><em>E'</em></span> of <span class="emphasis"><em>E</em></span>; this set is generally described by equalities and inequalities:<div class="mediaobject"><img src="images/4818OS_09_03.jpg" alt="Constrained and unconstrained optimization"/></div><p>Here, the <span class="emphasis"><em>g<sub>i</sub></em></span> and <span class="emphasis"><em>h<sub>j</sub></em></span> are arbitrary functions defining the constraints.</p></li></ul></div><p>For example, optimizing the aerodynamic shape of a car requires constraints on parameters such as the volume and mass of the car, the cost of the production process, and others.</p><p>Constrained optimization is generally harder than unconstrained optimization.</p></div><div class="section" title="Deterministic and stochastic algorithms"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec311"/>Deterministic and stochastic algorithms</h2></div></div></div><p>Some global optimization algorithms are <a id="id1448" class="indexterm"/><span class="strong"><strong>deterministic</strong></span>, others are<a id="id1449" class="indexterm"/> <span class="strong"><strong>stochastic</strong></span>. Typically, deterministic methods are adapted to well-behaved functions, whereas stochastic methods may be useful with highly irregular and noisy functions.</p><p>The reason is that deterministic algorithms may be stuck in local minima, particularly if there are many non-global local minima. By spending some time exploring the space <span class="emphasis"><em>E</em></span>, stochastic algorithms may have a chance of finding a global minimum.</p></div><div class="section" title="References"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec312"/>References</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The SciPy lecture notes are an excellent reference on mathematical optimization with SciPy<a id="id1450" class="indexterm"/> and are available at <a class="ulink" href="http://scipy-lectures.github.io/advanced/mathematical_optimization/index.html">http://scipy-lectures.github.io/advanced/mathematical_optimization/index.html</a></li><li class="listitem" style="list-style-type: disc">Reference manual of <code class="literal">scipy.optimize</code> available <a id="id1451" class="indexterm"/>at <a class="ulink" href="http://docs.scipy.org/doc/scipy/reference/optimize.html">http://docs.scipy.org/doc/scipy/reference/optimize.html</a></li><li class="listitem" style="list-style-type: disc">Overview of mathematical optimization<a id="id1452" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Mathematical_optimization">http://en.wikipedia.org/wiki/Mathematical_optimization</a></li><li class="listitem" style="list-style-type: disc">Extrema, <a id="id1453" class="indexterm"/>minima, and maxima<a id="id1454" class="indexterm"/> on Wikipedia, available <a id="id1455" class="indexterm"/>at <a class="ulink" href="http://en.wikipedia.org/wiki/Maxima_and_minima">http://en.wikipedia.org/wiki/Maxima_and_minima</a></li><li class="listitem" style="list-style-type: disc">Convex optimization<a id="id1456" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Convex_optimization">http://en.wikipedia.org/wiki/Convex_optimization</a></li><li class="listitem" style="list-style-type: disc">Advanced optimization methods for image processing<a id="id1457" class="indexterm"/> by Gabriel Peyré, available at <a class="ulink" href="http://github.com/gpeyre/numerical-tours">http://github.com/gpeyre/numerical-tours</a></li></ul></div></div></div></div></div>


  <div id="sbo-rt-content"><div class="section" title="Finding the root of a mathematical function"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec84"/>Finding the root of a mathematical function</h1></div></div></div><p>In this short recipe, we will see how to use SciPy to find the root of a simple mathematical function of a single real variable.</p><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec313"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Let's import <a id="id1458" class="indexterm"/>NumPy, SciPy, <code class="literal">scipy.optimize</code>, and <a id="id1459" class="indexterm"/>matplotlib:<div class="informalexample"><pre class="programlisting">In [1]: import numpy as np
        import scipy as sp
        import scipy.optimize as opt
        import matplotlib.pyplot as plt
        %matplotlib inline</pre></div></li><li class="listitem">We define the mathematical function <span class="emphasis"><em>f(x)=cos(x)-x</em></span> in Python. We will try to find a root of this function numerically. Here, a root corresponds to a fixed point of the cosine function:<div class="informalexample"><pre class="programlisting">In [2]: f = lambda x: np.cos(x) - x</pre></div></li><li class="listitem">Let's plot this function on the interval <span class="emphasis"><em>[-5, 5]</em></span> (using 1000 samples):<div class="informalexample"><pre class="programlisting">In [3]: x = np.linspace(-5, 5, 1000)
        y = f(x)
        plt.plot(x, y)
        plt.axhline(0, color='k')
        plt.xlim(-5,5)</pre></div><div class="mediaobject"><img src="images/4818OS_09_04.jpg" alt="How to do it…"/></div></li><li class="listitem">We see that this function has a unique root on this interval (this is because the function's sign changes on this interval). The <code class="literal">scipy.optimize</code> module<a id="id1460" class="indexterm"/> contains a few root-finding functions that are adapted here. For example, the <code class="literal">bisect()</code> function<a id="id1461" class="indexterm"/> implements the <span class="strong"><strong>bisection method</strong></span><a id="id1462" class="indexterm"/> (also called the <span class="strong"><strong>dichotomy method</strong></span>). It takes<a id="id1463" class="indexterm"/> as input the function and the <a id="id1464" class="indexterm"/>interval to find the root in:<div class="informalexample"><pre class="programlisting">In [4]: opt.bisect(f, -5, 5)
Out[4]: 0.7390851332155535</pre></div><p>Let's visualize the root on the plot:</p><div class="informalexample"><pre class="programlisting">In [5]: plt.plot(x, y)
        plt.axhline(0, color='k')
        plt.scatter([_], [0], c='r', s=100)
        plt.xlim(-5,5)</pre></div><div class="mediaobject"><img src="images/4818OS_09_05.jpg" alt="How to do it…"/></div></li><li class="listitem">A faster and more<a id="id1465" class="indexterm"/> powerful method is <code class="literal">brentq()</code> (<span class="strong"><strong>Brent's method</strong></span>). This algorithm also <a id="id1466" class="indexterm"/>requires <span class="emphasis"><em>f</em></span> to be continuous and <span class="emphasis"><em>f(a)</em></span> and <span class="emphasis"><em>f(b)</em></span> to have different signs:<div class="informalexample"><pre class="programlisting">In [6]: opt.brentq(f, -5, 5)
Out[6]: 0.7390851332151607</pre></div><p>The <code class="literal">brentq()</code> method is faster than <code class="literal">bisect()</code>. If the conditions are satisfied, it is a good idea to try Brent's method first:</p><div class="informalexample"><pre class="programlisting">In [7]: %timeit opt.bisect(f, -5, 5)
        %timeit opt.brentq(f, -5, 5)
1000 loops, best of 3: 331 µs per loop
10000 loops, best of 3: 71 µs per loop</pre></div></li></ol></div></div><div class="section" title="How it works…"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec314"/>How it works…</h2></div></div></div><p>The bisection method consists of iteratively cutting an interval in half and selecting a subinterval that necessarily contains a root. This method is based on the fact that, if <span class="emphasis"><em>f</em></span> is a continuous function of a single real variable, <span class="emphasis"><em>f(a)&gt;0</em></span>, and <span class="emphasis"><em>f(b)&lt;0</em></span>, then <span class="emphasis"><em>f</em></span> has a root in<a id="id1467" class="indexterm"/> <span class="emphasis"><em>(a,b)</em></span> (<span class="strong"><strong>intermediate value theorem</strong></span>).</p><p>
<span class="strong"><strong>Brent's method</strong></span> is a popular hybrid algorithm combining root bracketing, interval bisection, and inverse quadratic interpolation. It is a default method that works in many cases.</p><p>Let's also mention <a id="id1468" class="indexterm"/><span class="strong"><strong>Newton's method</strong></span>. The idea is to approximate <span class="emphasis"><em>f(x)</em></span> by its tangent (found with <span class="emphasis"><em>f'(x)</em></span>) and <a id="id1469" class="indexterm"/>find the intersection with the <span class="emphasis"><em>y=0</em></span> line. If <span class="emphasis"><em>f</em></span> is<a id="id1470" class="indexterm"/> regular enough, the intersection point will be closer to the actual root of <span class="emphasis"><em>f</em></span>. By iterating this operation, the algorithm generally converges to the sought solution.</p></div><div class="section" title="There's more…"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec315"/>There's more…</h2></div></div></div><p>Here are a few references:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Documentation<a id="id1471" class="indexterm"/> of <code class="literal">scipy.optimize</code> available at <a class="ulink" href="http://docs.scipy.org/doc/scipy/reference/optimize.html#root-finding">http://docs.scipy.org/doc/scipy/reference/optimize.html#root-finding</a></li><li class="listitem" style="list-style-type: disc">A course on root finding with SciPy<a id="id1472" class="indexterm"/> available at <a class="ulink" href="http://quant-econ.net/scipy.html#roots-and-fixed-points">http://quant-econ.net/scipy.html#roots-and-fixed-points</a></li><li class="listitem" style="list-style-type: disc">The Bisection method<a id="id1473" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Bisection_method">http://en.wikipedia.org/wiki/Bisection_method</a></li><li class="listitem" style="list-style-type: disc">The intermediate value theorem<a id="id1474" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Intermediate_value_theorem">http://en.wikipedia.org/wiki/Intermediate_value_theorem</a></li><li class="listitem" style="list-style-type: disc">Brent's method <a id="id1475" class="indexterm"/>on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Brent%27s_method">http://en.wikipedia.org/wiki/Brent%27s_method</a></li><li class="listitem" style="list-style-type: disc">Newton's method <a id="id1476" class="indexterm"/>on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Newton%27s_method">http://en.wikipedia.org/wiki/Newton%27s_method</a></li></ul></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec316"/>See also</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <span class="emphasis"><em>Minimizing a mathematical function</em></span> recipe</li></ul></div></div></div></div>


  <div id="sbo-rt-content"><div class="section" title="Minimizing a mathematical function"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec85"/>Minimizing a mathematical function</h1></div></div></div><p>Mathematical optimization deals mainly with the problem of finding a minimum or a maximum of a mathematical function. Frequently, a real-world numerical problem can be expressed as a function minimization problem. Such examples can be found in statistical inference, machine learning, graph theory, and other areas.</p><p>Although there are many <a id="id1477" class="indexterm"/>function minimization algorithms, a generic and universal method does not exist. Therefore, it is important to understand the differences between existing classes of algorithms, their specificities, and their respective use cases. We should also have a good understanding of our problem and our objective function; is it continuous, differentiable, convex, multidimensional, regular, or noisy? Is our problem constrained or unconstrained? Are we seeking local or global minima?</p><p>In this recipe, we will demonstrate a few usage examples of the function minimization algorithms implemented in SciPy.</p><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec317"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">We import the libraries:<div class="informalexample"><pre class="programlisting">In [1]: import numpy as np
        import scipy as sp
        import scipy.optimize as opt
        import matplotlib.pyplot as plt
        %matplotlib inline</pre></div></li><li class="listitem">First, let's define a simple mathematical function (the opposite of the <span class="strong"><strong>cardinal sine</strong></span>). This <a id="id1478" class="indexterm"/>function has many local minima but a single global minimum (<a class="ulink" href="http://en.wikipedia.org/wiki/Sinc_function">http://en.wikipedia.org/wiki/Sinc_function</a>):<div class="informalexample"><pre class="programlisting">In [2]: f = lambda x: 1-np.sin(x)/x</pre></div></li><li class="listitem">Let's plot this <a id="id1479" class="indexterm"/>function on the interval <span class="emphasis"><em>[-20, 20]</em></span> (with 1000 samples):<div class="informalexample"><pre class="programlisting">In [3]: x = np.linspace(-20., 20., 1000)
        y = f(x)
In [4]: plt.plot(x, y)</pre></div><div class="mediaobject"><img src="images/4818OS_09_06.jpg" alt="How to do it…"/></div></li><li class="listitem">The <code class="literal">scipy.optimize</code> module<a id="id1480" class="indexterm"/> comes with many function minimization routines. The <code class="literal">minimize()</code> function<a id="id1481" class="indexterm"/> offers a unified interface to many algorithms. The <span class="strong"><strong>Broyden–Fletcher–Goldfarb–Shanno</strong></span> (<span class="strong"><strong>BFGS</strong></span>) algorithm<a id="id1482" class="indexterm"/> (the default algorithm in <code class="literal">minimize()</code>) gives good results in general. The <code class="literal">minimize()</code> function requires an initial point as argument. For scalar univariate functions, we can also <a id="id1483" class="indexterm"/>use <code class="literal">minimize_scalar()</code>:<div class="informalexample"><pre class="programlisting">In [5]: x0 = 3
        xmin = opt.minimize(f, x0).x</pre></div><p>Starting from <span class="emphasis"><em>x<sub>0</sub></em></span><span class="emphasis"><em>=3</em></span>, the algorithm was able to find the actual global minimum, as shown in the following figure:</p><div class="informalexample"><pre class="programlisting">In [6]: plt.plot(x, y)
        plt.scatter(x0, f(x0), marker='o', s=300)
        plt.scatter(xmin, f(xmin), marker='v', s=300)
        plt.xlim(-20, 20)</pre></div><div class="mediaobject"><img src="images/4818OS_09_07.jpg" alt="How to do it…"/></div></li><li class="listitem">Now, if we start from<a id="id1484" class="indexterm"/> an initial point that is further away from the actual global minimum, the algorithm converges towards a <span class="emphasis"><em>local</em></span> minimum only:<div class="informalexample"><pre class="programlisting">In [7]: x0 = 10
        xmin = opt.minimize(f, x0).x
In [8]: plt.plot(x, y)
        plt.scatter(x0, f(x0), marker='o', s=300)
        plt.scatter(xmin, f(xmin), marker='v', s=300)
        plt.xlim(-20, 20)</pre></div><div class="mediaobject"><img src="images/4818OS_09_08.jpg" alt="How to do it…"/></div></li><li class="listitem">Like most function minimization algorithms, the BFGS algorithm is efficient at finding <span class="emphasis"><em>local</em></span> minima, but not necessarily <span class="emphasis"><em>global</em></span> minima, especially on complicated or noisy objective functions. A general strategy to overcome this problem is to combine such algorithms with an exploratory grid search on the initial points. Another option is to use a different class of algorithms based on heuristics and stochastic methods. A<a id="id1485" class="indexterm"/> popular example is the <span class="strong"><strong>simulated annealing method</strong></span>:<div class="informalexample"><pre class="programlisting">In [9]: xmin = opt.minimize(f, x0, method='Anneal').x
In [10]: plt.plot(x, y)
         plt.scatter(x0, f(x0), marker='o', s=300)
         plt.scatter(xmin, f(xmin), marker='v', s=300)
         plt.xlim(-20, 20)</pre></div><div class="mediaobject"><img src="images/4818OS_09_09.jpg" alt="How to do it…"/></div><p>This time, the <a id="id1486" class="indexterm"/>algorithm was able to find the global minimum.</p></li><li class="listitem">Now, let's define a new function, in two dimensions this time, called the<a id="id1487" class="indexterm"/> <span class="strong"><strong>Lévi function</strong></span>:<div class="mediaobject"><img src="images/4818OS_09_10.jpg" alt="How to do it…"/></div><p>This function is very irregular and may be difficult to minimize in general. It is one of the many <span class="strong"><strong>test functions for optimization</strong></span><a id="id1488" class="indexterm"/> that researchers have developed to study and benchmark optimization algorithms (<a class="ulink" href="http://en.wikipedia.org/wiki/Test_functions_for_optimization">http://en.wikipedia.org/wiki/Test_functions_for_optimization</a>):</p><div class="informalexample"><pre class="programlisting">In [11]: def g(X):
             # X is a 2*N matrix, each column contains
             # x and y coordinates.
             x, y = X
             return (np.sin(3*np.pi*x)**2 +
                     (x-1)**2 * (1+np.sin(3*np.pi*y)**2) +
                     (y-1)**2 * (1+np.sin(2*np.pi*y)**2))</pre></div></li><li class="listitem">Let's display this function with <code class="literal">imshow()</code>, on the square <span class="emphasis"><em>[-10,10]<sup>2</sup></em></span>:<div class="informalexample"><pre class="programlisting">In [12]: n = 200
         k = 10
         X, Y = np.mgrid[-k:k:n*1j,-k:k:n*1j]
In [13]: Z = g(np.vstack((X.ravel(),
                          Y.ravel()))).reshape(n,n)
In [14]: # We use a logarithmic scale for the color here.
         plt.imshow(np.log(Z), cmap=plt.cm.hot_r)
         plt.xticks([]); plt.yticks([])</pre></div><div class="mediaobject"><img src="images/4818OS_09_11.jpg" alt="How to do it…"/></div></li><li class="listitem">The BFGS <a id="id1489" class="indexterm"/>algorithm also works in multiple dimensions:<div class="informalexample"><pre class="programlisting">In [15]: x0, y0 = opt.minimize(g, (8, 3)).x
In [16]: plt.imshow(np.log(Z), cmap=plt.cm.hot_r,
                    extent=(-k, k, -k, k), origin=0)
         plt.scatter([x0], [y0], c=['r'], s=100)
         plt.xticks([]); plt.yticks([])</pre></div><div class="mediaobject"><img src="images/4818OS_09_12.jpg" alt="How to do it…"/></div></li></ol></div></div><div class="section" title="How it works…"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec318"/>How it works…</h2></div></div></div><p>Many function minimization algorithms are based on the fundamental idea of <a id="id1490" class="indexterm"/><span class="strong"><strong>gradient descent</strong></span>. If a function <span class="emphasis"><em>f</em></span> is differentiable, then at every point, the opposite of its gradient points to the direction of the greatest decrease rate of the function. By following this direction, we can expect to find a local minimum.</p><p>This operation <a id="id1491" class="indexterm"/>is generally done iteratively, by following the direction of the gradient with a small step. The way this step is computed depends on the optimization method.</p><p>Newton's method can also be used in this context of function minimization. The idea is to find a root of <span class="emphasis"><em>f'</em></span> with Newton's method, thereby making use of the <span class="emphasis"><em>second</em></span> derivative <span class="emphasis"><em>f''</em></span>. In other words, we approximate <span class="emphasis"><em>f</em></span> with a <span class="emphasis"><em>quadratic</em></span> function instead of a <span class="emphasis"><em>linear</em></span> function. In multiple dimensions, this is done by computing the<a id="id1492" class="indexterm"/> <span class="strong"><strong>Hessian</strong></span> (second derivatives) of <span class="emphasis"><em>f</em></span>. By performing this operation iteratively, we can expect the algorithm to converge towards a local minimum.</p><p>When the computation of the Hessian is too costly, we can compute an <span class="emphasis"><em>approximation</em></span> of the Hessian. Such methods are called <a id="id1493" class="indexterm"/><span class="strong"><strong>Quasi-Newton methods</strong></span>. The BFGS algorithm belongs to this class of algorithms.</p><p>These algorithms make use of the objective function's gradient. If we can compute an analytical expression of the gradient, we should provide it to the minimization routine. Otherwise, the algorithm will compute an approximation of the gradient that may not be reliable.</p><p>The <span class="strong"><strong>simulated annealing</strong></span> algorithm<a id="id1494" class="indexterm"/> is a generic probabilistic metaheuristic for the global optimization problem. It is based on an analogy with thermodynamic systems: by increasing and decreasing the temperature, the configuration may converge to a state of low energy.</p><p>There are many stochastic global optimization methods based on metaheuristics. They are generally less well-theoretically grounded than the deterministic optimization algorithms previously described, and convergence is not always guaranteed. However, they may be useful in situations where the objective function is very irregular and noisy, with many local minima. The <span class="strong"><strong>Covariance Matrix Adaptation Evolution Strategy</strong></span> (<span class="strong"><strong>CMA-ES</strong></span>) algorithm<a id="id1495" class="indexterm"/> is a metaheuristic that performs well in many situations. It is currently not implemented in SciPy, but there's a Python implementation in one of the references given later.</p><p>SciPy's <code class="literal">minimize()</code> function accepts a <code class="literal">method</code> keyword argument to specify the minimization algorithm to use. This function returns an object containing the results of the optimization. The <code class="literal">x</code> attribute is the point reaching the minimum.</p></div><div class="section" title="There's more…"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec319"/>There's more…</h2></div></div></div><p>Here are a few further references:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <code class="literal">scipy.optimize</code> reference <a id="id1496" class="indexterm"/>documentation available at <a class="ulink" href="http://docs.scipy.org/doc/scipy/reference/optimize.html">http://docs.scipy.org/doc/scipy/reference/optimize.html</a></li><li class="listitem" style="list-style-type: disc">An excellent lecture on mathematical optimization<a id="id1497" class="indexterm"/> with SciPy available at <a class="ulink" href="http://scipy-lectures.github.io/advanced/mathematical_optimization/">http://scipy-lectures.github.io/advanced/mathematical_optimization/</a></li><li class="listitem" style="list-style-type: disc">Definition of the gradient<a id="id1498" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Gradient">http://en.wikipedia.org/wiki/Gradient</a></li><li class="listitem" style="list-style-type: disc">Newton's method<a id="id1499" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Newton%27s_method_in_optimization">http://en.wikipedia.org/wiki/Newton%27s_method_in_optimization</a></li><li class="listitem" style="list-style-type: disc">Quasi-Newton methods<a id="id1500" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Quasi-Newton_method">http://en.wikipedia.org/wiki/Quasi-Newton_method</a></li><li class="listitem" style="list-style-type: disc">Metaheuristics for function minimization on <a id="id1501" class="indexterm"/>Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Metaheuristic">http://en.wikipedia.org/wiki/Metaheuristic</a></li><li class="listitem" style="list-style-type: disc">Simulated annealing<a id="id1502" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Simulated_annealing">http://en.wikipedia.org/wiki/Simulated_annealing</a></li><li class="listitem" style="list-style-type: disc">The CMA-ES algorithm<a id="id1503" class="indexterm"/> described at <a class="ulink" href="http://en.wikipedia.org/wiki/CMA-ES">http://en.wikipedia.org/wiki/CMA-ES</a></li><li class="listitem" style="list-style-type: disc">A Python implementation of CMA-ES<a id="id1504" class="indexterm"/> available at <a class="ulink" href="http://www.lri.fr/~hansen/cmaes_inmatlab.html#python">http://www.lri.fr/~hansen/cmaes_inmatlab.html#python</a></li></ul></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec320"/>See also</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <span class="emphasis"><em>Finding the root of a mathematical function</em></span> recipe</li></ul></div></div></div></div>


  <div id="sbo-rt-content"><div class="section" title="Fitting a function to data with nonlinear least squares"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec86"/>Fitting a function to data with nonlinear least squares</h1></div></div></div><p>In this recipe, we will show an application of numerical optimization to <a id="id1505" class="indexterm"/><span class="strong"><strong>nonlinear least squares curve fitting</strong></span>. The goal is to fit a function, depending on several parameters, to data points. In contrast to the linear least squares method, this function does not have to be linear in those parameters.</p><p>We will illustrate this method on artificial data.</p><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec321"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Let's import the usual libraries:<div class="informalexample"><pre class="programlisting">In [1]: import numpy as np
        import scipy.optimize as opt
        import matplotlib.pyplot as plt
        %matplotlib inline</pre></div></li><li class="listitem">We define a logistic function with four parameters:<div class="mediaobject"><img src="images/4818OS_09_13.jpg" alt="How to do it…"/></div><div class="informalexample"><pre class="programlisting">In [2]: def f(x, a, b, c, d):
            return a/(1 + np.exp(-c * (x-d))) + b</pre></div></li><li class="listitem">Let's define<a id="id1506" class="indexterm"/> four random <a id="id1507" class="indexterm"/>parameters:<div class="informalexample"><pre class="programlisting">In [3]: a, c = np.random.exponential(size=2)
        b, d = np.random.randn(2)</pre></div></li><li class="listitem">Now, we generate random data points by using the sigmoid function and adding a bit of noise:<div class="informalexample"><pre class="programlisting">In [4]: n = 100
        x = np.linspace(-10., 10., n)
        y_model = f(x, a, b, c, d)
        y = y_model + a * .2 * np.random.randn(n)</pre></div></li><li class="listitem">Here is a plot of the data points, with the particular sigmoid used for their generation (in dashed black):<div class="informalexample"><pre class="programlisting">In [5]: plt.plot(x, y_model, '--k')
        plt.plot(x, y, 'o')</pre></div><div class="mediaobject"><img src="images/4818OS_09_14.jpg" alt="How to do it…"/></div></li><li class="listitem">We now assume that we only have access to the data points and not the underlying generative function. These points could have been obtained during an experiment. By looking at the data, the points appear to approximately follow a sigmoid, so we may want to try to fit such a curve to the points. That's what <span class="strong"><strong>curve fitting</strong></span><a id="id1508" class="indexterm"/> is about. SciPy's <code class="literal">curve_fit()</code> function <a id="id1509" class="indexterm"/>allows us to fit a curve defined by an arbitrary Python function to the data:<div class="informalexample"><pre class="programlisting">In [6]: (a_, b_, c_, d_), _ = opt.curve_fit(f, x, y,
                                            (a, b, c, d))</pre></div></li><li class="listitem">Now, let's <a id="id1510" class="indexterm"/>take a look at the <a id="id1511" class="indexterm"/>fitted sigmoid curve:<div class="informalexample"><pre class="programlisting">In [7]: y_fit = f(x, a_, b_, c_, d_)
In [8]: plt.plot(x, y_model, '--k')
        plt.plot(x, y, 'o')
        plt.plot(x, y_fit, '-')</pre></div><div class="mediaobject"><img src="images/4818OS_09_15.jpg" alt="How to do it…"/></div><p>The fitted sigmoid appears to be reasonably close to the original sigmoid used for data generation.</p></li></ol></div></div><div class="section" title="How it works…"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec322"/>How it works…</h2></div></div></div><p>In SciPy, nonlinear <a id="id1512" class="indexterm"/>least squares curve fitting works <a id="id1513" class="indexterm"/>by minimizing the following cost function:</p><div class="mediaobject"><img src="images/4818OS_09_16.jpg" alt="How it works…"/></div><p>Here, <span class="inlinemediaobject"><img src="images/4818OS_09_20.jpg" alt="How it works…"/></span> is the vector of parameters (in our example, <span class="inlinemediaobject"><img src="images/4818OS_09_20.jpg" alt="How it works…"/></span>
<span class="emphasis"><em>=(a,b,c,d)</em></span>).</p><p>Nonlinear least squares is really similar to linear least squares for linear regression. Whereas the function <span class="emphasis"><em>f</em></span> is <span class="emphasis"><em>linear</em></span> in the parameters with the linear least squares method, it is <span class="emphasis"><em>not linear</em></span> here. Therefore, the minimization of <span class="emphasis"><em>S(</em></span><span class="inlinemediaobject"><img src="images/4818OS_09_20.jpg" alt="How it works…"/></span>
<span class="emphasis"><em>)</em></span> cannot be done analytically by solving the derivative of <span class="emphasis"><em>S</em></span> with respect to <span class="inlinemediaobject"><img src="images/4818OS_09_20.jpg" alt="How it works…"/></span>. SciPy implements an iterative method called the<a id="id1514" class="indexterm"/> <span class="strong"><strong>Levenberg-Marquardt algorithm</strong></span> (an extension of the Gauss–Newton algorithm).</p></div><div class="section" title="There's more…"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec323"/>There's more…</h2></div></div></div><p>Here are further references:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Reference documentation <a id="id1515" class="indexterm"/>of <code class="literal">curvefit</code> available at <a class="ulink" href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html">http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html</a></li><li class="listitem" style="list-style-type: disc">Nonlinear least squares <a id="id1516" class="indexterm"/>on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Non-linear_least_squares">http://en.wikipedia.org/wiki/Non-linear_least_squares</a></li><li class="listitem" style="list-style-type: disc">Levenberg-Marquardt algorithm<a id="id1517" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm">http://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm</a></li></ul></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec324"/>See also</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <span class="emphasis"><em>Minimizing a mathematical function</em></span> recipe</li></ul></div></div></div></div>


  <div id="sbo-rt-content"><div class="section" title="Finding the equilibrium state of a physical system by minimizing its potential energy"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec87"/>Finding the equilibrium state of a physical system by minimizing its potential energy</h1></div></div></div><p>In this recipe, we will give an application example of the function minimization algorithms described earlier. We will try to numerically find the equilibrium state of a physical system by minimizing its potential energy.</p><p>More specifically, we'll <a id="id1518" class="indexterm"/>consider a structure made of masses and springs, attached to a vertical wall and subject to gravity. Starting from an initial position, we'll search for the equilibrium configuration where the gravity and elastic forces compensate.</p><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec325"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Let's import NumPy, SciPy, and matplotlib:<div class="informalexample"><pre class="programlisting">In [1]: import numpy as np
        import scipy.optimize as opt
        import matplotlib.pyplot as plt
        %matplotlib inline</pre></div></li><li class="listitem">We define a few constants in the International System of Units:<div class="informalexample"><pre class="programlisting">In [2]: g = 9.81  # gravity of Earth
        m = .1  # mass, in kg
        n = 20  # number of masses
        e = .1  # initial distance between the masses
        l = e  # relaxed length of the springs
        k = 10000  # spring stiffness</pre></div></li><li class="listitem">We define the initial positions of the masses. They are arranged on a two-dimensional grid with two lines and <span class="emphasis"><em>n/2</em></span> columns:<div class="informalexample"><pre class="programlisting">In [3]: P0 = np.zeros((n, 2))
        P0[:,0] = np.repeat(e*np.arange(n//2), 2)
        P0[:,1] = np.tile((0,-e), n//2)</pre></div></li><li class="listitem">Now, let's define the connectivity matrix between the masses. Coefficient <span class="emphasis"><em>(i,j)</em></span> is 1 if masses <span class="emphasis"><em>i</em></span> and <span class="emphasis"><em>j</em></span> are connected by a spring, 0 otherwise:<div class="informalexample"><pre class="programlisting">In [4]: A = np.eye(n, n, 1) + np.eye(n, n, 2)</pre></div></li><li class="listitem">
We also specify the spring stiffness of each spring. It is <span class="emphasis"><em>l</em></span>, except for <span class="emphasis"><em>diagonal</em></span> springs where it is <span class="inlinemediaobject"><img src="images/4818OS_09_21.jpg" alt="How to do it…"/></span>:
<div class="informalexample"><pre class="programlisting">In [5]: L = l * (np.eye(n, n, 1) + np.eye(n, n, 2))
        for i in range(n//2-1):
            L[2*i+1,2*i+2] *= np.sqrt(2)</pre></div></li><li class="listitem">We get the indices of the spring connections:<div class="informalexample"><pre class="programlisting">In [6]: I, J = np.nonzero(A)</pre></div></li><li class="listitem">This <code class="literal">dist</code> function computes the distance matrix (distance between any pair of masses):<div class="informalexample"><pre class="programlisting">In [7]: dist = lambda P: np.sqrt(
                    (P[:,0]-P[:,0][:, np.newaxis])**2 + 
                    (P[:,1]-P[:,1][:, np.newaxis])**2)</pre></div></li><li class="listitem">We define a<a id="id1519" class="indexterm"/> function that displays the system. The springs are colored according to their tension:<div class="informalexample"><pre class="programlisting">In [8]: def show_bar(P):
            # Wall.
            plt.axvline(0, color='k', lw=3)
            # Distance matrix.
            D = dist(P)
            # We plot the springs.
            for i, j in zip(I, J):
                # The color depends on the spring tension,
                # which is proportional to the spring 
                # elongation.
                c = D[i,j] - L[i,j]
                plt.plot(P[[i,j],0], P[[i,j],1], 
                         lw=2, color=plt.cm.copper(c*150))
            # We plot the masses.
            plt.plot(P[[I,J],0], P[[I,J],1], 'ok',)
            # We configure the axes.
            plt.axis('equal')
            plt.xlim(P[:,0].min()-e/2, P[:,0].max()+e/2)
            plt.ylim(P[:,1].min()-e/2, P[:,1].max()+e/2)
            plt.xticks([]); plt.yticks([])</pre></div></li><li class="listitem">Here is the system in its initial configuration:<div class="informalexample"><pre class="programlisting">In [9]: show_bar(P0)
        plt.title("Initial configuration")</pre></div><div class="mediaobject"><img src="images/4818OS_09_17.jpg" alt="How to do it…"/></div></li><li class="listitem">To find the equilibrium state, we need to minimize the total potential energy of the system. The following function computes the energy of the system given the positions of the masses. This function is explained in the <span class="emphasis"><em>How it works…</em></span> section:<div class="informalexample"><pre class="programlisting">In [10]: def energy(P):
             # The argument P is a vector (flattened 
             # matrix). We convert it to a matrix here.
             P = P.reshape((-1, 2))
             # We compute the distance matrix.
             D = dist(P)
             # The potential energy is the sum of the
             # gravitational and elastic potential 
             # energies.
             return (g * m * P[:,1].sum() + 
                     .5 * (k * A * (D - L)**2).sum())</pre></div></li><li class="listitem">Let's <a id="id1520" class="indexterm"/>compute the potential energy of the initial configuration:<div class="informalexample"><pre class="programlisting">In [11]: energy(P0.ravel())
Out[11]: -0.98099</pre></div></li><li class="listitem">Now, let's minimize the potential energy with a function minimization method. We need a <a id="id1521" class="indexterm"/><span class="strong"><strong>constrained optimization algorithm</strong></span>, because we make the assumption that the first two masses are fixed to the wall. Therefore, their positions cannot change. The <a id="id1522" class="indexterm"/><span class="strong"><strong>L-BFGS-B</strong></span> algorithm, a variant of the BFGS algorithm, accepts bound constraints. Here, we force the first two points to stay at their initial positions, whereas there are no constraints on the other points. The <code class="literal">minimize()</code> function accepts a <code class="literal">bounds</code> list containing, for each dimension, a pair of <code class="literal">[min, max]</code> values:<div class="informalexample"><pre class="programlisting">In [12]: bounds = np.c_[P0[:2,:].ravel(),
                        P0[:2,:].ravel()].tolist() + \
                              [[None, None]] * (2*(n-2))
In [13]: P1 = opt.minimize(energy, P0.ravel(),
                           method='L-BFGS-B',
                           bounds=bounds).x \
                                     .reshape((-1, 2))</pre></div></li><li class="listitem">Let's display the stable configuration:<div class="informalexample"><pre class="programlisting">In [14]: show_bar(P1)
         plt.title("Equilibrium configuration")</pre></div><div class="mediaobject"><img src="images/4818OS_09_18.jpg" alt="How to do it…"/></div><p>This configuration looks realistic. The tension appears to be maximal on the top springs near the wall.</p></li></ol></div></div><div class="section" title="How it works…"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec326"/>How it works…</h2></div></div></div><p>This <a id="id1523" class="indexterm"/>example is conceptually simple. The state of the system is only described by the positions of the masses. If we can write a Python function that returns the total energy of the system, finding the equilibrium is just a matter of minimizing this function. This is the<a id="id1524" class="indexterm"/> <span class="strong"><strong>principle of minimum total potential energy</strong></span>, due to the second law of thermodynamics.</p><p>Here, we give an expression of the total energy of the system. Since we are only interested in the <span class="emphasis"><em>equilibrium</em></span>, we omit any kinetic aspect and we only consider potential energy due to <a id="id1525" class="indexterm"/>gravity (<span class="strong"><strong>gravitational force</strong></span>) and<a id="id1526" class="indexterm"/> spring forces (<span class="strong"><strong>elastic potential energy</strong></span>).</p><p>Letting <span class="emphasis"><em>U</em></span> be the total potential energy of the system, <span class="emphasis"><em>U</em></span> can be expressed as the sum of the gravitational potential energies of the masses and the elastic potential energies of the springs. Therefore:</p><div class="mediaobject"><img src="images/4818OS_09_19.jpg" alt="How it works…"/></div><p>Here:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="emphasis"><em>m</em></span> is the mass</li><li class="listitem" style="list-style-type: disc"><span class="emphasis"><em>g</em></span> is the gravity of Earth</li><li class="listitem" style="list-style-type: disc"><span class="emphasis"><em>k</em></span> is the stiffness of the springs</li><li class="listitem" style="list-style-type: disc"><span class="emphasis"><em>p<sub>i</sub> = (x<sub>i</sub>, y<sub>i</sub>)</em></span> is the position of mass <span class="emphasis"><em>i</em></span></li><li class="listitem" style="list-style-type: disc"><span class="emphasis"><em>a<sub>ij</sub></em></span> is 1 if masses <span class="emphasis"><em>i</em></span> and <span class="emphasis"><em>j</em></span> are attached by a spring, 0 otherwise</li><li class="listitem" style="list-style-type: disc"><span class="emphasis"><em>l<sub>ij</sub></em></span> is the relaxed length of spring <span class="emphasis"><em>(i,j)</em></span>, or 0 if masses <span class="emphasis"><em>i</em></span> and <span class="emphasis"><em>j</em></span> are not attached</li></ul></div><p>The <code class="literal">energy()</code> function<a id="id1527" class="indexterm"/> implements<a id="id1528" class="indexterm"/> this formula using vectorized computations on NumPy arrays.</p></div><div class="section" title="There's more…"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec327"/>There's more…</h2></div></div></div><p>The following references contain details about the physics behind this formula:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Potential energy on <a id="id1529" class="indexterm"/>Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Potential_energy">http://en.wikipedia.org/wiki/Potential_energy</a></li><li class="listitem" style="list-style-type: disc">Elastic potential energy<a id="id1530" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Elastic_potential_energy">http://en.wikipedia.org/wiki/Elastic_potential_energy</a></li><li class="listitem" style="list-style-type: disc">Hooke's law, which is the <a id="id1531" class="indexterm"/>linear approximation of the springs' response, described at <a class="ulink" href="http://en.wikipedia.org/wiki/Hooke%27s_law">http://en.wikipedia.org/wiki/Hooke%27s_law</a></li><li class="listitem" style="list-style-type: disc">Principle of minimum energy<a id="id1532" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Minimum_total_potential_energy_principle">http://en.wikipedia.org/wiki/Minimum_total_potential_energy_principle</a></li></ul></div><p>Here is a reference about the optimization algorithm:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">L-BFGS-B algorithm<a id="id1533" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Limited-memory_BFGS#L-BFGS-B">http://en.wikipedia.org/wiki/Limited-memory_BFGS#L-BFGS-B</a></li></ul></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec328"/>See also</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <span class="emphasis"><em>Minimizing a mathematical function</em></span> recipe</li></ul></div></div></div></div>
</body></html>