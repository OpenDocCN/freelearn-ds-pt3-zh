["```py\nfrom sklearn.datasets import make_classification\nX, y = make_classification(n_samples=5000, n_features=40,\\\n                           n_informative=3, n_redundant=2,\\\n                           n_repeated=0, n_classes=2,\\\n                           n_clusters_per_class=3,\\\n                           weights=None, flip_y=0.05,\\\n                           class_sep=0.1, hypercube=True,\\\n                           shift=0.0,scale=1.0, shuffle=True,\\\n                           random_state=2)\n```", "```py\ny.mean()\n```", "```py\n0.4986\n```", "```py\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = \\\ntrain_test_split(X, y, test_size=0.2, random_state=24)\n```", "```py\nxgb_model_1 = xgb.XGBClassifier(n_estimators=1000,\\\n                                verbosity=1,\\\n                                use_label_encoder=False,\\\n                                objective='binary:logistic',\\\n                                learning_rate=0.3)\n```", "```py\n%%time\nxgb_model_1.fit(X_train, y_train,\\\n                eval_metric=\"auc\",\\\n                verbose=True)\n```", "```py\nCPU times: user 52.5 s, sys: 986 ms, total: 53.4 s\nWall time: 17.5 s\nOut[7]:\nXGBClassifier(base_score=0.5, booster='gbtree',\\\n              colsample_bylevel=1, colsample_bynode=1,\\\n              colsample_bytree=1, gamma=0, gpu_id=-1,\\\n              importance_type='gain',interaction_constraints='',\\\n              learning_rate=0.3, max_delta_step=0, max_depth=6,\\\n              min_child_weight=1, missing=nan,\\\n              monotone_constraints='()', n_estimators=1000,\\\n              n_jobs=4, num_parallel_tree=1, random_state=0,\\\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\\\n              subsample=1, tree_method='exact',\\\n              use_label_encoder=False, validate_parameters=1,\\\n              verbosity=1)\n```", "```py\nval_set_pred_proba = xgb_model_1.predict_proba(X_val)[:,1]\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(y_val, val_set_pred_proba)\n```", "```py\n0.7773798710782294\n```", "```py\neval_set = [(X_train, y_train), (X_val, y_val)]\n```", "```py\n%%time\nxgb_model_1.fit(X_train, y_train, eval_set=eval_set,\\\n                eval_metric='auc',\\\n                verbose=True, early_stopping_rounds=30)\n```", "```py\n[0]\tvalidation_0-auc:0.80412\tvalidation_1-auc:0.75223\n[1]\tvalidation_0-auc:0.84422\tvalidation_1-auc:0.79207\n[2]\tvalidation_0-auc:0.85920\tvalidation_1-auc:0.79278\n[3]\tvalidation_0-auc:0.86616\tvalidation_1-auc:0.79517\n[4]\tvalidation_0-auc:0.88261\tvalidation_1-auc:0.79659\n[5]\tvalidation_0-auc:0.88605\tvalidation_1-auc:0.80061\n[6]\tvalidation_0-auc:0.89226\tvalidation_1-auc:0.80224\n[7]\tvalidation_0-auc:0.89826\tvalidation_1-auc:0.80305\n[8]\tvalidation_0-auc:0.90559\tvalidation_1-auc:0.80095\n[9]\tvalidation_0-auc:0.91954\tvalidation_1-auc:0.79685\n[10]\tvalidation_0-auc:0.92113\tvalidation_1-auc:0.79608\n…\n[33]\tvalidation_0-auc:0.99169\tvalidation_1-auc:0.78323\n[34]\tvalidation_0-auc:0.99278\tvalidation_1-auc:0.78261\n[35]\tvalidation_0-auc:0.99329\tvalidation_1-auc:0.78139\n[36]\tvalidation_0-auc:0.99344\tvalidation_1-auc:0.77994\nCPU times: user 2.65 s, sys: 136 ms, total: 2.78 s\nWall time: 2.36 s\n…\n```", "```py\nxgb_model_1.get_booster().attributes()\n```", "```py\n{'best_iteration': '7', 'best_score': '0.80305'}\n```", "```py\nval_set_pred_proba_2 = xgb_model_1.predict_proba(X_val)[:,1]\nroc_auc_score(y_val, val_set_pred_proba_2)\n```", "```py\n0.8030501882609966\n```", "```py\nlearning_rates = np.linspace(start=0.01, stop=1, num=25)\n```", "```py\n%%time\nval_aucs = []\nbest_iters = []\nfor learning_rate in learning_rates:\n```", "```py\n    xgb_model_1.set_params(**{'learning_rate':learning_rate})\n```", "```py\n    xgb_model_1.fit(X_train, y_train, eval_set=eval_set,\\\n                    eval_metric='auc',\\\n                    verbose=False, early_stopping_rounds=30)\n```", "```py\n    val_set_pred_proba_2 = xgb_model_1.predict_proba(X_val)[:,1]\n    val_aucs.append(roc_auc_score(y_val, val_set_pred_proba_2))\n```", "```py\n     best_iters.append(\n        int(xgb_model_1.get_booster().\\\n                        attributes()['best_iteration']))\n```", "```py\nCPU times: user 1min 23s, sys: 526 ms, total: 1min 24s\nWall time: 22.2 s\n```", "```py\nlearning_rate_df = \\\npd.DataFrame({'Learning rate':learning_rates,\\\n              'Validation AUC':val_aucs,\\\n              'Best iteration':best_iters})\n```", "```py\n    mpl.rcParams['figure.dpi'] = 400\n    learning_rate_df.set_index('Learning rate')\\\n    .plot(secondary_y='Best iteration', style=['-o', '--o'])\n    ```", "```py\nmax(val_aucs)\n```", "```py\n0.8115309360232714\n```", "```py\n    from scipy.stats import uniform\n    param_grid = {'max_depth':[2,3,4,5,6,7],\n                  'gamma':uniform(loc=0.0, scale=3),\n                  'min_child_weight':list(range(1,151)),\n                  'colsample_bytree':uniform(loc=0.1, scale=0.9),\n                  'subsample':uniform(loc=0.5, scale=0.5),\n                  'learning_rate':uniform(loc=0.01, scale=0.5)}\n    ```", "```py\n    from sklearn.model_selection import ParameterSampler\n    rng = np.random.RandomState(0)\n    n_iter=1000\n    param_list = list(ParameterSampler(param_grid, n_iter=n_iter,\n                                       random_state=rng))\n    ```", "```py\n    param_list[0]\n    ```", "```py\n    {'colsample_bytree': 0.5939321535345923,\n     'gamma': 2.1455680991172583,\n     'learning_rate': 0.31138168803582195,\n     'max_depth': 5,\n     'min_child_weight': 104,\n     'subsample': 0.7118273996694524}\n    ```", "```py\n    xgb_model_2 = xgb.XGBClassifier(\n        n_estimators=1000,\n        verbosity=1,\n        use_label_encoder=False,\n        objective='binary:logistic')\n    xgb_model_2.set_params(**param_list[0])\n    ```", "```py\n    XGBClassifier(base_score=0.5, booster='gbtree',\\\n                  colsample_bylevel=1, colsample_bynode=1,\\\n                  colsample_bytree=0.5939321535345923,\\\n                  gamma=2.1455680991172583, gpu_id=-1,\\\n                  importance_type='gain',interaction_constraints='',\\\n                  learning_rate=0.31138168803582195,\\\n                  max_delta_step=0, max_depth=5,\\\n                  min_child_weight=104, missing=nan,\\\n                  monotone_constraints='()', n_estimators=1000,\\\n                  n_jobs=4, num_parallel_tree=1,\\\n                  random_state=0, reg_alpha=0, reg_lambda=1,\\\n                  scale_pos_weight=1, subsample=0.7118273996694524,\\\n                  tree_method='exact', use_label_encoder=False,\\\n                  validate_parameters=1, verbosity=1)\n    ```", "```py\n    %%time\n    val_aucs = []\n    counter = 1\n    ```", "```py\n    for params in param_list:\n        #Set hyperparameters and fit model\n        xgb_model_2.set_params(**params)\n        xgb_model_2.fit(X_train, y_train, eval_set=eval_set,\\\n                        eval_metric='auc',\\\n                        verbose=False, early_stopping_rounds=30)\n    ```", "```py\n        #Get predicted probabilities and save validation ROC AUC\n        val_set_pred_proba = xgb_model_2.predict_proba(X_val)[:,1]\n        val_aucs.append(roc_auc_score(y_val, val_set_pred_proba))\n    ```", "```py\n        #Print progress\n        if counter % 50 == 0:\n            print('Done with {counter} of {n_iter}'.format(\n                counter=counter, n_iter=n_iter))\n        counter += 1\n    ```", "```py\n    Done with 50 of 1000\n    Done with 100 of 1000\n    …\n    Done with 950 of 1000\n    Done with 1000 of 1000\n    CPU times: user 24min 20s, sys: 18.9 s, total: 24min 39s\n    Wall time: 6min 27s\n    ```", "```py\n    xgb_param_search_df = pd.DataFrame(param_list)\n    xgb_param_search_df.head()\n    ```", "```py\n    xgb_param_search_df['Validation ROC AUC'] = val_aucs\n    max_auc = xgb_param_search_df['Validation ROC AUC'].max()\n    max_auc\n    ```", "```py\n    0.8151220995602575\n    ```", "```py\n    mpl.rcParams['figure.dpi'] = 400\n    fig, axs = plt.subplots(3,2,figsize=(8,6))\n    counter = 0\n    ```", "```py\n    for col in xgb_param_search_df.columns[:-1]:\n        this_ax = axs.flatten()[counter]\n        xgb_param_search_df.plot.scatter(x=col,\\\n                                         y='Validation ROC AUC',\\\n                                         ax=this_ax, marker='o',\\\n                                         color='w',\\\n                                         edgecolor='k',\\\n                                         linewidth=0.5)\n    ```", "```py\n        if counter > 0:\n            this_ax.set_ylabel('')\n        counter += 1\n    ```", "```py\n        if col != 'max_depth':\n            out, bins = pd.qcut(xgb_param_search_df[col], q=10,\\\n                                retbins=True, duplicates='drop')\n            half_points = [(bins[ix] + bins[ix+1])/2\n                           for ix in range(len(bins)-1)]\n    ```", "```py\n        else:\n            out = xgb_param_search_df[col]\n            half_points = np.sort(xgb_param_search_df[col].unique())\n    ```", "```py\n        tmp_df = xgb_param_search_df.copy()\n        tmp_df['param_decile'] = out\n        mean_df = tmp_df.groupby('param_decile').agg(\n            {'Validation ROC AUC':'mean'})\n    ```", "```py\n        this_ax.plot(half_points,\\\n                     mean_df.values,\\\n                     color='k',\\\n                     linestyle='--')\n    plt.tight_layout()\n    ```", "```py\n    max_ix = xgb_param_search_df['Validation ROC AUC'] == max_auc\n    xgb_param_search_df[max_ix]\n    ```", "```py\nxgb_model_3 = xgb.XGBClassifier(\n    n_estimators=1000,\n    max_depth=0,\n    learning_rate=0.1,\n    verbosity=1,\n    objective='binary:logistic',\n    use_label_encoder=False,\n    n_jobs=-1,\n    tree_method='hist',\n    grow_policy='lossguide')\n```", "```py\nmax_leaves_values = list(range(5,105,5))\nprint(max_leaves_values[:5])\nprint(max_leaves_values[-5:])\n```", "```py\n[5, 10, 15, 20, 25]\n[80, 85, 90, 95, 100]\n```", "```py\n%%time\nval_aucs = []\nfor max_leaves in max_leaves_values:\n    #Set parameter and fit model\n    xgb_model_3.set_params(**{'max_leaves':max_leaves})\n    xgb_model_3.fit(X_train, y_train, eval_set=eval_set,\\\n                    eval_metric='auc', verbose=False,\\\n                    early_stopping_rounds=30)\n    #Get validation score\n    val_set_pred_proba = xgb_model_3.predict_proba(X_val)[:,1]\n    val_aucs.append(roc_auc_score(y_val, val_set_pred_proba))\n```", "```py\nmax_leaves_df = \\\npd.DataFrame({'Max leaves':max_leaves_values,\n              'Validation AUC':val_aucs})\n```", "```py\nmpl.rcParams['figure.dpi'] = 400\nmax_leaves_df.set_index('Max leaves').plot()\n```", "```py\nmax_auc = max_leaves_df['Validation AUC'].max()\nmax_auc\n```", "```py\n0.8151200989120475\n```", "```py\nmax_ix = max_leaves_df['Validation AUC'] == max_auc\nmax_leaves_df[max_ix]\n```", "```py\n%%time\nxgb_model_3.set_params(**{'max_leaves':20})\nxgb_model_3.fit(X_train, y_train,\\\n                eval_set=eval_set,\\\n                eval_metric='auc',\n                verbose=False,\\\n                early_stopping_rounds=30)\n```", "```py\nX_val.shape\n```", "```py\n(1000, 40)\n```", "```py\nfeature_names = ['Feature {number}'.format(number=number)\n                 for number in range(X_val.shape[1])]\nX_val_df = pd.DataFrame(data=X_val, columns=feature_names)\nX_val_df.head()\n```", "```py\nexplainer = shap.explainers.Tree(xgb_model_3, data=X_val_df)\n```", "```py\nshap_values = explainer(X_val_df)\n```", "```py\nshap_values.values.shape\n```", "```py\n(1000, 40)\n```", "```py\nmpl.rcParams['figure.dpi'] = 75\nshap.summary_plot(shap_values.values, X_val_df)\n```", "```py\nshap.plots.scatter(shap_values[:,'Feature 3'])\n```", "```py\nshap.plots.scatter(shap_values[:,'Feature 3'],\n                   color=shap_values[:,'Feature 5'])\n```", "```py\n    shap.plots.scatter(shap_values[:,'Feature 5'],\n                       color=shap_values[:,'Feature 3'])\n    ```", "```py\n    mpl.rcParams['figure.dpi'] = 75\n    shap.summary_plot(shap_values.values, X_val, plot_type='bar')\n    ```", "```py\n    explainer.expected_value\n    ```", "```py\n    -0.30949621941894295\n    ```", "```py\n    shap_sum = shap_values.values.sum(axis=1) + explainer.expected_value\n    shap_sum.shape\n    ```", "```py\n    (1000,)\n    ```", "```py\n    shap_sum_prob = 1 / (1 + np.exp(-1 * shap_sum))\n    ```", "```py\n    y_pred_proba = xgb_model_3.predict_proba(X_val)[:,1]\n    y_pred_proba.shape\n    ```", "```py\n    (1000,)\n    ```", "```py\n    df_check = pd.DataFrame(\n        {'SHAP sum':shap_sum_prob,\n         'Predicted probability':y_pred_proba})\n    df_check.sample(5, random_state=1)\n    ```", "```py\n    np.allclose(df_check['SHAP sum'],\\\n                df_check['Predicted probability'])\n    ```", "```py\n    True\n    ```", "```py\nwith open('filename.pkl', 'wb') as f:\n    pickle.dump([var_1, var_2], f)\n```", "```py\nwith open('filename.pkl', 'rb') as f:\n    var_1, var_2 = pickle.load(f)\n```"]