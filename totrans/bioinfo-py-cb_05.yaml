- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Advanced NGS Data Processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you work with **next-generation sequencing** (**NGS**) data, you know that
    quality analysis and processing are two of the great time-sinks in getting results.
    In the first part of this chapter, we will delve deeper into NGS analysis by using
    a dataset that includes information about relatives – in our case, a mother, a
    father, and around 20 offspring. This is a common technique for performing quality
    analysis, as pedigree information will allow us to make inferences on the number
    of errors that our filtering rules might produce. We will also take the opportunity
    to use the same dataset to find genomic features based on existing annotations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last recipe of this chapter will delve into another advanced topic using
    NGS data: metagenomics. We will QIIME2, a Python package for metagenomics, to
    analyze data.'
  prefs: []
  type: TYPE_NORMAL
- en: If you are using Docker, please use the tiagoantao/bioinformatics_base image.
    The QIIME2 content has a special setup process that will be discussed in the relevant
    recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, there are the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing a dataset for analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Mendelian error information for quality control
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring data with standard statistics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding genomic features from sequencing annotations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doing metagenomics with QIIME2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing a dataset for analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our starting point will be a VCF file (or equivalent) with calls made by a
    genotyper (**Genome Analysis Toolkit** (**GATK**) in our case), including annotations.
    As we will be filtering NGS data, we need reliable decision criteria to call a
    site. So, how do we get that information? Generally, we can’t, but if we need
    to do so, there are three basic approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: Using a more robust sequencing technology for comparison – for example, using
    Sanger sequencing to verify NGS datasets. This is cost-prohibitive and can only
    be done for a few loci.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequencing closely related individuals, for example, two parents and their offspring.
    In this case, we use Mendelian inheritance rules to decide whether a certain call
    is acceptable or not. This was the strategy used by both the Human Genome Project
    and the Anopheles gambiae 1000 Genomes project.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we can use simulations. This setup is not only quite complex but also
    of dubious reliability. It’s more of a theoretical option.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will use the second option, based on the Anopheles gambiae
    1000 Genomes project. This project makes available information based on crosses
    between mosquitoes. A cross will include the parents (mother and father) and up
    to 20 offspring.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we are going to prepare our data for usage in the later recipes.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will download our files in HDF5 format for faster processing. Please be
    advised that these files are quite big; you will need a good network connection
    and plenty of disk space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The files have four crosses with around 20 offspring each. We will use chromosome
    arms 3L and 2L. At this stage, we also compute Mendelian errors (a subject of
    the next recipe, so we will delay a detailed discussion until then).
  prefs: []
  type: TYPE_NORMAL
- en: The relevant notebook is `Chapter04/Preparation.py`. There is also a local sample
    metadata file in the directory called `samples.tsv`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After downloading the data, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, start with a few imports:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s get the sample metadata:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We also print some basic information about the cross we are going to use and
    all the parents.
  prefs: []
  type: TYPE_NORMAL
- en: 'We prepare to deal with chromosome arm 3L based on its HDF5 file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The code to compute Mendelian errors is the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will discuss this in the next recipe, *Using Mendelian error information
    for quality control*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now define a support generator and function to select acceptable positions
    and accumulate basic data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We now need to find the indexes of our cross (mother, father, and 20 offspring)
    on the HDF5 file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we will actually compute Mendelian errors and save them to disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will now generate an efficient NumPy array with annotations and Mendelian
    error information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Buried in this code is one of the most important decisions of the whole chapter:
    how do we weigh Mendelian errors? In our case, we only store a 1 if there is any
    kind of error, and we store a 0 if there is none. An alternative would be to count
    the number of errors – as we have up to 20 offspring, that would require some
    sophisticated statistical analysis that we will not be doing here.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Changing gears, let’s extract some information from chromosome arm 2L now:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, we are only interested in the parents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We extract the sample DP for each parent:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, we have prepared the dataset for analysis in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Using Mendelian error information for quality control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So, how can we infer the quality of calls using Mendelian inheritance rules?
    Let’s look at expectations for different genotypical configurations of the parents:'
  prefs: []
  type: TYPE_NORMAL
- en: For a certain potential bi-allelic SNP, if the mother is AA and the father is
    also AA, then all offspring will be AA.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the mother is AA and the father TT, then all offspring will have to be heterozygous
    (AT). They always get an A from the mother, and they always get a T from the father.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the mother is AA and the father is AT, then the offspring can be either AA
    or AT. They always get an A from the mother, but they can get either an A or a
    T from the father.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If both the mother and the father are heterozygous (AT), then the offspring
    can be anything. In theory, there is not much we can do here.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In practice, we can ignore mutations, which is safe to do with most eukaryotes.
    The number of mutations (noise, from our perspective) is several orders of magnitude
    lower than the signal we are looking for.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we are going to do a small theoretical study of the distribution
    and Mendelian errors, and further process the data for downstream analysis based
    on errors. The relevant notebook file is `Chapter04/Mendel.py`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will need a few imports:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Before we do any empirical analysis, let’s try to understand what information
    we can extract from the case where the mother is AA and the father is AT. Let’s
    answer the question, *If we have 20 offspring, what is the probability of all
    of them being heterozygous?*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 - Results from 100,000 simulations: the number of offspring that
    are heterozygous for certain loci where the mother is AA and the father is heterozygous
    ](img/B17942_04_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.1 - Results from 100,000 simulations: the number of offspring that
    are heterozygous for certain loci where the mother is AA and the father is heterozygous'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we have done 100,000 simulations. In my case (this is stochastic, so your
    result might vary), I got exactly zero simulations where all offspring were heterozygous.
    Indeed, these are permutations with repetition, so the probability of all being
    heterozygous is ![](img/Formula_04_001.png) or 9.5367431640625e-07 – not very
    likely. So, even if for a single offspring, we can have AT or AA; for 20, it is
    very unlikely that all of them are of the same type. This is the information we
    can use for a less naive interpretation of Mendelian errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s repeat the analysis where the mother and the father are both AT:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 - Results from 100,000 simulations: the number of offspring that
    are AA or heterozygous for a certain locus where both parents are also heterozygous
    ](img/B17942_04_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.2 - Results from 100,000 simulations: the number of offspring that
    are AA or heterozygous for a certain locus where both parents are also heterozygous'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, we have also permutations with repetition, but we have four possible
    values, not two: AA, AT, TA, and TT. We end up with the same probability for all
    individuals being AT: 9.5367431640625e-07\. It’s even worse (twice as bad, in
    fact) for all of them being homozygous of the same type (all TT or all AA).'
  prefs: []
  type: TYPE_NORMAL
- en: 'OK, after this probabilistic prelude, let’s get down to more data-moving stuff.
    The first thing that we will do is check how many errors we have. Let’s load the
    data from the previous recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s see how many errors we have:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Not many of the calls have Mendelian errors – only around 5%, great.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a balanced set where roughly half of the set has errors. For that,
    we will randomly drop a lot of good calls. First, we compute the fraction of errors:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We use that information to get a set of accepted entries: all the errors plus
    an approximately equal quantity of OK calls. We print the number of entries at
    the end (this will vary as the OK list is stochastic):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we save it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With regards to Mendelian errors and their impact on cost functions, let’s
    think about the following case: the mother is AA, the father is AT, and all offspring
    are AA. Does this mean that the father is wrongly called, or that we failed to
    detect a few heterozygous offspring? From this reasoning, it’s probably the father
    that is wrongly called. This has an impact in terms of some more refined Mendelian
    error estimation functions: it’s probably more costly to have a few offspring
    wrong than just a single sample (the father) wrong. In this case, you might think
    it’s trivial (the probability of having no heterozygous offspring is so low that
    it’s probably the father), but if you have 18 offspring AA and two AT, is it still
    “trivial”? This is not just a theoretical problem, because it severely impacts
    the design of a proper cost function.'
  prefs: []
  type: TYPE_NORMAL
- en: Our function in a previous recipe, *Preparing the dataset for analysis*, is
    naive but is enough for the level of refinement that will allow us to have some
    interesting results further down the road.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the data with standard statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have the insights for our Mendelian error analysis, let’s explore
    the data in order to get more insights that might help us to better filter the
    data. You can find this content in `Chapter04/Exploration.py`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We start, as usual, with the necessary imports:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then we load the data. We will use pandas to navigate it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s ask pandas to show a histogram of all annotations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following histogram is generated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 - Histogram of all annotations for a dataset with roughly 50%
    of errors ](img/B17942_04_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 - Histogram of all annotations for a dataset with roughly 50% of
    errors
  prefs: []
  type: TYPE_NORMAL
- en: 'For some annotations, we do not get interesting information. We can try to
    zoom in, for example, with DP:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 4.4 - Histogram zooming in on an area of interest for DP ](img/B17942_04_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.4 - Histogram zooming in on an area of interest for DP
  prefs: []
  type: TYPE_NORMAL
- en: We are actually dividing DP by the number of samples in order to get a more
    meaningful number.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will split the dataset in two, one for the errors and the other for the
    positions with no Mendelian errors:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s have a look at `QUAL` and split it on 0.005, and check how we get errors
    and correct calls split:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Clearly, `['QUAL']>0.005` gets lots of errors, while not getting lots of OK
    positions. This is positive, as we have some hope for filtering it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s do the same with QD:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Again, we have some interesting results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s take an area where there are fewer errors and study the relationships
    between annotations on errors. We will plot annotations pairwise:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The preceding code generates the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 - Scatter matrix of annotations of errors for an area of the search
    space ](img/B17942_04_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.5 - Scatter matrix of annotations of errors for an area of the search
    space
  prefs: []
  type: TYPE_NORMAL
- en: 'And now do the same on the good calls:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 - Scatter matrix of annotations of good calls for an area of the
    search space ](img/B17942_04_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.6 - Scatter matrix of annotations of good calls for an area of the
    search space
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s see how our rules would perform on the complete dataset (remember
    that we are using a dataset roughly composed of 50% errors and 50% OK calls):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Let’s remember that there are roughly 10.9 million markers in our full dataset,
    with around 5% errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s get some statistics on our `good_corner`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: So, we reduced the error rate to 0.33% (from 5%), while having only reduced
    to 9.6 million markers.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Is a reduction in error from 5% to 0.3% while losing 12% of markers good or
    bad? Well, it depends on what analysis you want to do next. Maybe your method
    is resilient to loss of markers but not too many errors, in which case this might
    help. But if it is the other way around, maybe you prefer to have the complete
    dataset even if it has more errors. If you apply different methods, maybe you
    will use different datasets from method to method. In the specific case of this
    Anopheles dataset, there is so much data that reducing the size will probably
    be fine for almost anything. But if you have fewer markers, you will have to assess
    your needs in terms of markers and quality.
  prefs: []
  type: TYPE_NORMAL
- en: Finding genomic features from sequencing annotations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will conclude this chapter and this book with a simple recipe that suggests
    that sometimes you can learn important things from simple unexpected results,
    and that apparent quality issues might mask important biological questions.
  prefs: []
  type: TYPE_NORMAL
- en: We will plot read depth – `DP` – across chromosome arm 2L for all the parents
    on our crosses. The recipe can be found in `Chapter04/2L.py`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll get started with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with the usual imports:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s load the data that we saved in the first recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And let’s print the median DP for the whole chromosome arm, and a part of it
    in the middle for all parents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Interestingly, the median for the whole chromosome sometimes does not hold for
    that big region in the middle, so let’s dig further.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will print the median DP for 200,000 kbp windows across the chromosome arm.
    Let’s start with the window code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s plot it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following plot shows the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.7 - Median DP per window for all parents of the dataset on chromosome
    arm 2L ](img/B17942_04_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.7 - Median DP per window for all parents of the dataset on chromosome
    arm 2L
  prefs: []
  type: TYPE_NORMAL
- en: You will notice that for some mosquitoes, for example, the ones on the first
    and last columns, there is a clear drop of DP in the middle of the chromosome
    arm. In some of them, such as in the third column, there is a bit of drop – not
    so pronounced. And for the bottom parent of the second column, there is no drop
    at all.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The preceding pattern has a biological cause that ends up having consequences
    for sequencing: Anopheles mosquitoes might have a big chromosomal inversion in
    the middle of arm 2L. Karyotypes that are not the same as those on the reference
    genome used to make the calls are harder to call due to evolutionary divergence.
    These make the number of sequencer reads in that area lower. This is very specific
    to this species, but you might expect other kinds of features to appear in other
    organisms.'
  prefs: []
  type: TYPE_NORMAL
- en: A more widely known case is `n`, then you can expect to see a DP of `n` times
    the median across the genome.
  prefs: []
  type: TYPE_NORMAL
- en: 'But, in the general case, it is a good idea to be on the lookout for *strange*
    results throughout the analysis. Sometimes, that is the hallmark of an interesting
    biological feature, as it is here. Either that, or it’s a pointer to a mistake:
    for example, **Principal Components Analysis** (**PCA**) can be used to find mislabeled
    samples (as they might cluster in the wrong group).'
  prefs: []
  type: TYPE_NORMAL
- en: Doing metagenomics with QIIME 2 Python API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Wikipedia says that metagenomics is the study of genetic material that’s recovered
    directly from environmental samples. Note that “environment” here should be interpreted
    broadly: in the case of our example, we will deal with gastrointestinal microbiomes
    in a study of a fecal microbiome transplant in children with gastrointestinal
    problems. The study is one of the tutorials of QIIME 2, which is one of the most
    widely used applications for data analysis in metagenomics. QIIME 2 has several
    interfaces: a GUI, a command line, and a Python API called the Artifact API.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Tomasz Kościółek has an outstanding tutorial for using the Artifact API based
    on the most well-developed (client-based, not artifact-based) tutorial on QIIME
    2, the *“Moving Pictures” tutorial* ([http://nbviewer.jupyter.org/gist/tkosciol/29de5198a4be81559a075756c2490fde](http://nbviewer.jupyter.org/gist/tkosciol/29de5198a4be81559a075756c2490fde)).
    Here, we will create a Python version of the fecal microbiota transplant study
    that’s available, as with the client interface, at [https://docs.qiime2.org/2022.2/tutorials/fmt/](https://docs.qiime2.org/2022.2/tutorials/fmt/).
    You should get familiar with it as we won’t go into the details of the biology
    here. I do follow a more convoluted route than Tomasz: this will allow you to
    get a bit more acquainted with QIIME 2 Python internals. After you get this experience,
    you will probably want to follow Tomasz’s route, not mine. However, the experience
    you get here will make you more comfortable and confident with QIIME’s internals.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe is slightly more complicated to set up. We will have to create a
    `conda` environment where packages from QIIME 2 are segregated from packages from
    all other applications. The steps that you need to follow are simple.
  prefs: []
  type: TYPE_NORMAL
- en: 'On OS X, use the following code to create a new `conda` environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'On Linux, use the following code to create the environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: If these instructions do not work, check the QIIME 2 website for an updated
    version ([https://docs.qiime2.org/2022.2/install/native](https://docs.qiime2.org/2022.2/install/native)).
    QIIME 2 is updated regularly.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this stage, you need to enter the QIIME 2 `conda` environment by using `source
    activate qiime2-2022.2`. If you want to get to the standard `conda` environment,
    use `source deactivate` instead. We will want to install `jupyter lab` and `jupytext`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: You might want to install other packages you want inside QIIME 2’s environment
    using `conda install`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To prepare for Jupyter execution, you should install the QIIME 2 extension,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: TIP
  prefs: []
  type: TYPE_NORMAL
- en: The extension is highly interactive and allows you to look at data from different
    viewpoints that cannot be captured in this book. The downside is that it won’t
    work in `nbviewer` (some cell outputs won’t be visible with the static viewer).
    Remember to interact with the outputs from the extension, since many are dynamic.
  prefs: []
  type: TYPE_NORMAL
- en: You can now start Jupyter. The notebook can be found in the `Chapter4/QIIME2_Metagenomics.py`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: WARNING
  prefs: []
  type: TYPE_NORMAL
- en: Due to the fluidity of package installation with QIIME, we don’t provide a Docker
    environment for it. This means that if you are working from our Docker installation
    you will have to download the recipe and install the packages manually.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the instructions to get the data of both the Notebook files and
    the QIIME 2 tutorial.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s take a look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by checking what plugins are available:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We are also accessing the demultiplexing plugin and its summarize action.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a peek at the summarize action, namely `inputs`, `outputs`, and
    `parameters`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now load the first dataset, demultiplex it, and visualize some demultiplexing
    statistics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here is a part of the output from the QIIME extension for Juypter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8 - A part of the output of the QIIME2 extension for Jupyter ](img/B17942_04_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.8 - A part of the output of the QIIME2 extension for Jupyter
  prefs: []
  type: TYPE_NORMAL
- en: Remember that the extension is iterative and provides substantially more information
    than only this chart.
  prefs: []
  type: TYPE_NORMAL
- en: TIP
  prefs: []
  type: TYPE_NORMAL
- en: The original data for this recipe is supplied in QIIME 2 format. Obviously,
    you will have your own original data in some other format (probably FASTQ) – see
    the *There’s more...* section for a way to load a standard format.
  prefs: []
  type: TYPE_NORMAL
- en: QIIME 2’s `.qza` and `.qzv` formats are simply zipped files. You can have a
    look at the content with `unzip`.
  prefs: []
  type: TYPE_NORMAL
- en: The chart will be similar to in the QIIME CLI tutorial, but be sure to check
    the interactive quality plot of our output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s do the same for the second dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s use the DADA2 ([https://github.com/benjjneb/dada2](https://github.com/benjjneb/dada2))
    plugin for quality control:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s extract some statistics from denoising (first set):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Again, the result can be found online in the QIIME 2 CLI version of the tutorial.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s do the same for the second set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, merge the denoised data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, gather some quality statistics from the merge:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, let’s get some information about the merged sequences:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The preceding code does not show you how to import data. The actual code will
    vary from case to case (single-end data, paired-end data, or already-demultiplexed
    data), but for the main QIIME 2 tutorial, *Moving Pictures*, assuming that you
    have downloaded the single-end, non-demultiplexed data and barcodes into a directory
    called `data`, you can do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: As stated in the preceding code, if you look on GitHub for this notebook, the
    static `nbviewer` system will not be able to render the notebook correctly (you
    have to run it yourself). This is far from perfect; it is not interactive, since
    the quality is not great, but at least it lets you get an idea of the output without
    running the code.
  prefs: []
  type: TYPE_NORMAL
