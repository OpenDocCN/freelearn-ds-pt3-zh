- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next-Generation Sequencing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Next-generation sequencing** (**NGS**) is one of the fundamental technological
    developments of the century in life sciences. **Whole-genome sequencing** (**WGS**),
    **restriction site-associated DNA sequencing** (**RAD-Seq**), **ribonucleic acid
    sequencing** (**RNA-Seq**), **chromatin immunoprecipitation sequencing** (**ChIP-Seq**),
    and several other technologies are routinely used to investigate important biological
    problems. These are also called high-throughput sequencing technologies, and with
    good reason: they generate vast amounts of data that needs to be processed. NGS
    is the main reason that computational biology has become a big-data discipline.
    More than anything else, this is a field that requires strong bioinformatics techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we will not discuss each individual NGS technique *per se* (this would
    require a whole book of its own). We will use an existing WGS dataset—the 1,000
    Genomes Project—to illustrate the most common steps necessary to analyze genomic
    data. The recipes presented here will be easily applicable to other genomic sequencing
    approaches. Some of them can also be used for transcriptomic analysis (for example,
    RNA-Seq). The recipes are also species-independent, so you will be able to apply
    them to any other species for which you have sequenced data. The biggest difference
    in processing data from different species is related to genome size, diversity,
    and the quality of the reference genome (if it exists for your species). These
    will not affect the automated Python part of NGS processing much. In any case,
    we will discuss different genomes in [*Chapter 5*](B17942_05.xhtml#_idTextAnchor122),
    *Working with Genomes*.
  prefs: []
  type: TYPE_NORMAL
- en: As this is not an introductory book, you are expected to know at least what
    **FASTA** (**FASTA**), FASTQ, **Binary Alignment Map** (**BAM**), and **Variant
    Call Format** (**VCF**) files are. I will also make use of basic genomic terminology
    without introducing it (such as exomes, nonsynonymous mutations, and so on). You
    are required to be familiar with basic Python. We will leverage this knowledge
    to introduce the fundamental libraries in Python to perform NGS analysis. Here,
    we will follow the flow of a standard bioinformatics pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: However, before we delve into real data from a real project, let’s get comfortable
    with accessing existing genomic databases and basic sequence processing—a simple
    start before the storm.
  prefs: []
  type: TYPE_NORMAL
- en: If you are running the content via Docker, you can use the `tiagoantao/bioinformatics_ngs`
    image. If you are using Anaconda Python, the required software for the chapter
    will be introduced in each recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Accessing GenBank and moving around **National Center for Biotechnology Information**
    (**NCBI**) databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing basic sequence analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with modern sequence formats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with alignment data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting data from VCF files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Studying genome accessibility and filtering **single-nucleotide polymorphism**
    (**SNP**) data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing NGS data with HTSeq
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accessing GenBank and moving around NCBI databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although you may have your own data to analyze, you will probably need existing
    genomic datasets. Here, we will look at how to access such databases from NCBI.
    We will not only discuss GenBank but also other databases from NCBI. Many people
    refer (wrongly) to the whole set of NCBI databases as GenBank, but NCBI includes
    the nucleotide database and many others—for example, PubMed.
  prefs: []
  type: TYPE_NORMAL
- en: As sequencing analysis is a long subject and this book targets intermediate
    to advanced users, we will not be very exhaustive with a topic that is, at its
    core, not very complicated.
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, it’s a good warm-up for the more complex recipes that we will see
    at the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will use Biopython, which you installed in [*Chapter 1*](B17942_01.xhtml#_idTextAnchor020),
    *Python and the Surrounding Software Ecology*. Biopython provides an interface
    to `Entrez`, the data retrieval system made available by NCBI.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe is made available in the `Chapter03/Accessing_Databases.py` file.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: You will be accessing a live **application programming interface** (**API**)
    from NCBI. Note that the performance of the system may vary during the day. Furthermore,
    you are expected to be a “good citizen” while using it. You will find some recommendations
    at [https://www.ncbi.nlm.nih.gov/books/NBK25497/#chapter2.Usage_Guidelines_and_Requiremen](https://www.ncbi.nlm.nih.gov/books/NBK25497/#chapter2.Usage_Guidelines_and_Requiremen).
    Notably, you are required to specify an email address with your query. You should
    try to avoid a large number of requests (100 or more) during peak times (between
    9.00 a.m. and 5.00 p.m. American Eastern Time on weekdays), and do not post more
    than three queries per second (Biopython will take care of this for you). It’s
    not only good citizenship, but you risk getting blocked if you overuse NCBI’s
    servers (a good reason to give a real email address, because NCBI may try to contact
    you).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let’s look at how we can search and fetch data from NCBI databases:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by importing the relevant module and configuring the email address:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will also import the module to process sequences. Do not forget to put in
    the correct email address.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now try to find the `Plasmodium falciparum` (the parasite that causes
    the deadliest form of malaria) on the `nucleotide` database:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will search the `nucleotide` database for our gene and organism (for the
    syntax of the search string, check the NCBI website). Then, we will read the result
    that is returned. Note that the standard search will limit the number of record
    references to 20, so if you have more, you may want to repeat the query with an
    increased maximum limit. In our case, we will actually override the default limit
    with `retmax`. The `Entrez` system provides quite a few sophisticated ways to
    retrieve a large number of results (for more information, check the Biopython
    or NCBI Entrez documentation). Although you now have the **identifiers** (**IDs**)
    of all of the records, you still need to retrieve the records properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s try to retrieve all of these records. The following query will download
    all matching nucleotide sequences from GenBank, which is 1,374 at the time of
    writing this book. You probably won’t want to do this all the time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Well, in this case, go ahead and do it. However, be careful with this technique,
    because you will retrieve a large number of complete records, and some of them
    will have fairly large sequences inside. You risk downloading a lot of data (which
    would be a strain both on your side and on the NCBI servers).
  prefs: []
  type: TYPE_NORMAL
- en: There are several ways around this. One way is to make a more restrictive query
    and/or download just a few at a time and stop when you have found the one that
    you need. The precise strategy will depend on what you are trying to achieve.
    In any case, we will retrieve a list of records in the GenBank format (which includes
    sequences, plus a lot of interesting metadata).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s read and parse the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that we have converted an iterator (the result of `SeqIO.parse`) to a list.
    The advantage of doing this is that we can use the result as many times as we
    want (for example, iterate many times over), without repeating the query on the
    server.
  prefs: []
  type: TYPE_NORMAL
- en: This saves time, bandwidth, and server usage if you plan to iterate many times
    over. The disadvantage is that it will allocate memory for all records. This will
    not work for very large datasets; you might not want to do this conversion genome-wide
    as in [*Chapter 5*](B17942_05.xhtml#_idTextAnchor122), *Working with Genomes*.
    We will return to this topic in the last part of this book. If you are doing interactive
    computing, you will probably prefer to have a list (so that you can analyze and
    experiment with it multiple times), but if you are developing a library, an iterator
    will probably be the best approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now just concentrate on a single record. This will only work if you
    used the exact same preceding query:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `rec` variable now has our record of interest. The `rec.description` file
    will contain its human-readable description.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s extract some sequence features that contain information such as
    `gene` products and `exon` positions on the sequence:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If the `feature.type` value is `gene`, we will print its name, which will be
    in the `qualifiers` dictionary. We will also print all the locations of exons.
    Exons, as with all features, have locations in this sequence: a start, an end,
    and the strand from where they are read. While all the start and end positions
    for our exons are `ExactPosition`, note that Biopython supports many other types
    of positions. One type of position is `BeforePosition`, which specifies that a
    location point is before a certain sequence position. Another type of position
    is `BetweenPosition`, which gives the interval for a certain location start/end.
    There are quite a few more position types; these are just some examples.'
  prefs: []
  type: TYPE_NORMAL
- en: Coordinates will be specified in such a way that you will be able to easily
    retrieve the sequence from a Python array with ranges, so generally, the start
    will be one before the value on the record, and the end will be equal. The issue
    of coordinate systems will be revisited in future recipes.
  prefs: []
  type: TYPE_NORMAL
- en: For other feature types, we simply print them. Note that Biopython will provide
    a human-readable version of the feature when you print it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now look at the annotations on the record, which are mostly metadata
    that is not related to the sequence position:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that some values are not strings; they can be numbers or even lists (for
    example, the taxonomy annotation is a list).
  prefs: []
  type: TYPE_NORMAL
- en: 'Last but not least, you can access a fundamental piece of information—the sequence:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The sequence object will be the main topic of our next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many more databases at NCBI. You will probably want to check the **Sequence
    Read Archive** (**SRA**) database (previously known as **Short Read Archive**)
    if you are working with NGS data. The SNP database contains information on SNPs,
    whereas the protein database has protein sequences, and so on. A full list of
    databases in Entrez is linked in the *See also* section of this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another database that you probably already know about with regard to NCBI is
    PubMed, which includes a list of scientific and medical citations, abstracts,
    and even full texts. You can also access it via Biopython. Furthermore, GenBank
    records often contain links to PubMed. For example, we can perform this on our
    previous record, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This will take all reference annotations, check whether they have a PubMed ID,
    and then access the PubMed database to retrieve the records, parse them, and then
    print them.
  prefs: []
  type: TYPE_NORMAL
- en: The output per record is a Python dictionary. Note that there are many references
    to external databases on a typical GenBank record.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, there are many other biological databases outside NCBI, such as Ensembl
    ([http://www.ensembl.org](http://www.ensembl.org)) and **University of California,
    Santa Cruz** (**UCSC**) Genome Bioinformatics ([http://genome.ucsc.edu/](http://genome.ucsc.edu/)).
    The support for many of these databases in Python will vary a lot.
  prefs: []
  type: TYPE_NORMAL
- en: An introductory recipe on biological databases would not be complete without
    at least a passing reference to **Basic Local Alignment Search Tool** (**BLAST**).
    BLAST is an algorithm that assesses the similarity of sequences. NCBI provides
    a service that allows you to compare your sequence of interest against its own
    database. Of course, you can use your local BLAST database instead of using NCBI’s
    service. Biopython provides extensive support for this, but as this is too introductory,
    I will just refer you to the Biopython tutorial.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This additional information will also be useful:'
  prefs: []
  type: TYPE_NORMAL
- en: You can find more examples on the Biopython tutorial at [http://biopython.org/DIST/docs/tutorial/Tutorial.xhtml](http://biopython.org/DIST/docs/tutorial/Tutorial.xhtml).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A list of accessible NCBI databases can be found at [http://www.ncbi.nlm.nih.gov/gquery/](http://www.ncbi.nlm.nih.gov/gquery/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A great **question and answer** (**Q&A**) site where you can find help for your
    problems with databases and sequence analysis is Biostars ([http://www.biostars.org](http://www.biostars.org));
    you can use it for all of the content in this book, not just for this recipe.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing basic sequence analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now do some basic analysis of DNA sequences. We will work with FASTA
    files and do some manipulation, such as reverse complementing or transcription.
    As with the previous recipe, we will use Biopython, which you installed in [*Chapter
    1*](B17942_01.xhtml#_idTextAnchor020), *Python and the Surrounding Software Ecology*.
    These two recipes provide you with the necessary introductory building blocks
    with which we will perform all the modern NGS analysis and then genome processing
    in this chapter and [*Chapter 5*](B17942_05.xhtml#_idTextAnchor122), *Working
    with Genomes*.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The code for this recipe is available in `Chapter03/Basic_Sequence_Processing.py`.
    We will use the human `Entrez` research interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the GenBank record, let’s extract the gene sequence. The record
    has a bit more than that, but let’s get the precise location of the gene first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Our example sequence is available on the Biopython sequence record.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s take a look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As our sequence of interest is available in a Biopython sequence object, let’s
    start by saving it to a FASTA file on our local disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `SeqIO.write` function takes a list of sequences to write (in our case,
    it’s just a single one). Be careful with this idiom. If you want to write many
    sequences (and you could easily write millions with NGS), do not use a list (as
    shown in the preceding code snippet) because this will allocate massive amounts
    of memory. Use either an iterator or the `SeqIO.write` function several times
    with a subset of the sequence on each write.
  prefs: []
  type: TYPE_NORMAL
- en: 'In most situations, you will actually have the sequence on the disk, so you
    will be interested in reading it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, we are concerned with processing a single sequence, but FASTA files can
    contain multiple records. The Python idiom to perform this is quite easy. To read
    a FASTA file, you just use standard iteration techniques, as shown in the following
    code snippet. For our example, the preceding code will print the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note that we printed `seq[:10]`. The sequence object can use typical array slices
    to get part of a sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we now have an unambiguous DNA, we can transcribe it as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can translate our gene into a protein:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, we have the amino acid sequence for our gene.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Much more can be said about the management of sequences in Biopython, but this
    is mostly introductory material that you can find in the Biopython tutorial. I
    think it’s important to give you a taste of sequence management, mostly for completion
    purposes. To support those of you who might have some experience in other fields
    of bioinformatics but are just starting with sequence analysis, there are, nonetheless,
    a few points that you should be aware of:'
  prefs: []
  type: TYPE_NORMAL
- en: When you perform an RNA translation to get your protein, be sure to use the
    correct genetic code. Even if you are working with “common” organisms (such as
    humans), remember that the mitochondrial genetic code is different.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Biopython’s `Seq` object is much more flexible than what’s shown here. For some
    good examples, refer to the Biopython tutorial. However, this recipe will be enough
    for the work we need to do with FASTQ files (see the next recipe).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To deal with strand-related issues, there are—as expected—sequence functions
    such as `reverse_complement`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The GenBank record from which we started includes a lot of metadata information
    about the sequence, so be sure to explore it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Genetic codes known to Biopython are the ones specified by NCBI, available at
    [http://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi](http://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As in the previous recipe, the Biopython tutorial is your main port of call
    and is available at [http://biopython.org/DIST/docs/tutorial/Tutorial.xhtml](http://biopython.org/DIST/docs/tutorial/Tutorial.xhtml).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be sure to also check the Biopython SeqIO page at [http://biopython.org/wiki/SeqIO](http://biopython.org/wiki/SeqIO).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with modern sequence formats
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here, we will work with FASTQ files, the standard format output used by modern
    sequencers. You will learn how to work with quality scores per base and also consider
    variations in output coming from different sequencing machines and databases.
    This is the first recipe that will use real data (big data) from the human 1,000
    Genomes Project. We will start with a brief description of the project.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The human 1,000 Genomes Project aims to catalog worldwide human genetic variation
    and takes advantage of modern sequencing technology to do WGS. This project makes
    all data publicly available, which includes output from sequencers, sequence alignments,
    and SNP calls, among many other artifacts. The name “1,000 Genomes” is actually
    a misnomer, because it currently includes more than 2,500 samples. These samples
    are divided into hundreds of populations, spanning the whole planet. We will mostly
    use data from four populations: **African Yorubans** (**YRI**), **Utah Residents
    with Northern and Western European Ancestry** (**CEU**), **Japanese in Tokyo**
    (**JPT**), and **Han Chinese in Beijing** (**CHB**). The reason we chose these
    specific populations is that they were the first ones that came from HapMap, an
    old project with similar goals. They used genotyping arrays to find out more about
    the quality of this subset. We will revisit the 1,000 Genomes and HapMap projects
    in [*Chapter 6*](B17942_06.xhtml#_idTextAnchor154), *Population Genetics*.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Next-generation datasets are generally very large. As we will be using real
    data, some of the files that you will download will be big. While I have tried
    to choose the smallest real examples possible, you will still need a good network
    connection and a considerably large amount of disk space. Waiting for the download
    will probably be your biggest hurdle in this recipe, but data management is a
    serious problem with NGS. In real life, you will need to budget time for data
    transfer, allocate disk space (which can be financially costly), and consider
    backup policies. The most common initial mistake with NGS is to think that these
    problems are trivial, but they are not. An operation such as copying a set of
    BAM files to a network, or even to your computer, will become a headache. Be prepared.
    After downloading large files, at the very least, you should check that the size
    is correct. Some databases offer **Message Digest 5** (**MD5**) checksums. You
    can compare these checksums with the ones on the files you downloaded by using
    tools such as md5sum.
  prefs: []
  type: TYPE_NORMAL
- en: The instructions to download the data are at the top of the notebook, as specified
    in the first cell of `Chapter03/Working_with_FASTQ.py`. This is a fairly small
    file (27 `NA18489`). If you refer to the 1,000 Genomes Project, you will see that
    the vast majority of FASTQ files are much bigger (up to two orders of magnitude
    bigger).
  prefs: []
  type: TYPE_NORMAL
- en: The processing of FASTQ sequence files will mostly be performed using Biopython.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we start coding, let’s take a look at the FASTQ file, in which you will
    have many records, as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '*Line 1* starts with `@`, followed by a sequence ID and a description string.
    The description string will vary from a sequencer or a database source, but will
    normally be amenable to automated parsing.'
  prefs: []
  type: TYPE_NORMAL
- en: The second line has the sequenced DNA, which is just like a FASTA file. The
    third line is a `+` sign, sometimes followed by the description line on the first
    line.
  prefs: []
  type: TYPE_NORMAL
- en: The fourth line contains quality values for each base that’s read on *line 2*.
    Each letter encodes a Phred quality score ([http://en.wikipedia.org/wiki/Phred_quality_score](http://en.wikipedia.org/wiki/Phred_quality_score)),
    which assigns a probability of error to each read. This encoding can vary a bit
    among platforms. Be sure to check for this on your specific platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s open the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will open a `gzip` module. We will also specify the `fastq` format. Note
    that some variations in this format will impact the interpretation of the Phred
    quality scores. You may want to specify a slightly different format. Refer to
    [http://biopython.org/wiki/SeqIO](http://biopython.org/wiki/SeqIO) for all formats.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: You should usually store your FASTQ files in a compressed format. Not only do
    you gain a lot of disk space, as these are text files, but you probably also gain
    some processing time. Although decompressing is a slow process, it can still be
    faster than reading a much bigger (uncompressed) file from a disk.
  prefs: []
  type: TYPE_NORMAL
- en: We print the standard fields and quality scores from the previous recipe into
    `rec.letter_annotations`. As long as we choose the correct parser, Biopython will
    convert all the Phred encoding letters to logarithmic scores, which we will use
    soon.
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, *don’t* do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Although this might work with some FASTA files (and with this very small FASTQ
    file), if you do something such as this, you will allocate memory so that you
    can load the complete file in memory. With an average FASTQ file, this is the
    best way to crash your computer. As a rule, always iterate over your file. If
    you have to perform several operations over it, you have two main options. The
    first option is to perform a single iteration or all operations at once. The second
    option to is open a file several times and repeat the iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s take a look at the distribution of nucleotide reads:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will reopen the file and use `defaultdict` to maintain a count of nucleotide
    references in the FASTQ file. If you have never used this Python standard dictionary
    type, you may want to consider it because it removes the need to initialize dictionary
    entries, assuming default values for each type.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: There is a residual number for `N` calls. These are calls in which a sequencer
    reports an unknown base. In our FASTQ file example, we have cheated a bit because
    we used a filtered file (the fraction of `N` calls will be quite low). Expect
    a much bigger number of `N` calls in a file that comes out of the sequencer unfiltered.
    In fact, you can even expect something more with regard to the spatial distribution
    of `N` calls.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s plot the distribution of `N`s according to their read position:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We import the `seaborn` library. Although we do not use it explicitly at this
    point, this library has the advantage of making `matplotlib` plots look better,
    because it tweaks the default `matplotlib` style.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then open the file to parse again (remember that you do not use a list but
    iterate again). We iterate through the file and get the position of any references
    to `N`. Then, we plot the distribution of `N`s as a function of the distance from
    the start of the sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – The number of N calls as a function of the distance from the
    start of the sequencer read ](img/B17942_03_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 – The number of N calls as a function of the distance from the start
    of the sequencer read
  prefs: []
  type: TYPE_NORMAL
- en: You will see that until position `25`, there are no errors. This is not what
    you will get from a typical sequencer output. Our example file is already filtered,
    and the 1,000 Genomes filtering rules enforce that no `N` calls can occur before
    position `25`.
  prefs: []
  type: TYPE_NORMAL
- en: While we cannot study the behavior of `N`s in this dataset before position `25`
    (feel free to use one of your own unfiltered FASTQ files with this code in order
    to see how `N`s distribute across the read position), we can see that after position
    `25`, the distribution is far from uniform. There is an important lesson here,
    which is that the quantity of uncalled bases is position-dependent. So, what about
    the quality of the reads?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s study the distribution of Phred scores (that is, the quality of our reads):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will start by reopening the file (again) and initializing a default dictionary.
    We then get the `phred_quality` letter annotation, but we ignore sequencing positions
    that are up to 24 **base pairs** (**bp**) from the start (because of the filtering
    of our FASTQ file, if you have an unfiltered file, you may want to drop this rule).
    We add the quality score to our default dictionary and, finally, print it.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: As a short reminder, the Phred quality score is a logarithmic representation
    of the probability of an accurate call. This probability is given as ![](img/B17942_03_009.png).
    So, a *Q* of 10 represents 90 percent call accuracy, 20 represents 99 percent
    call accuracy, and 30 will be 99.9 percent. For our file, the maximum accuracy
    will be 99.99 percent (40). In some cases, values of 60 are possible (99.9999
    percent accuracy).
  prefs: []
  type: TYPE_NORMAL
- en: 'More interestingly, we can plot the distribution of qualities according to
    their read position:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this case, we will ignore both positions sequenced as `25` bp from the start
    (again, remove this rule if you have unfiltered sequencer data) and the maximum
    quality score for this file (`40`). However, in your case, you can consider starting
    your plotting analysis with the maximum. You may want to check the maximum possible
    value for your sequencer hardware. Generally, as most calls can be performed with
    maximum quality, you may want to remove them if you are trying to understand where
    quality problems lie.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we are using the `boxplot` function of `seaborn`; we are only using
    this because the output looks slightly better than the standard `boxplot` function
    of `matplotlib`. If you prefer not to depend on `seaborn`, just use the stock
    `matplotlib` function. In this case, you will call `ax.boxplot(vps)` instead of
    `sns.boxplot(data=vps, ax=ax)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'As expected, the distribution is not uniform, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2 – The distribution of Phred scores as a function of the distance
    from the start of the sequencer read ](img/B17942_03_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 – The distribution of Phred scores as a function of the distance
    from the start of the sequencer read
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Although it’s impossible to discuss all the variations of output coming from
    sequencer files, paired-end reads are worth mentioning because they are common
    and require a different processing approach. With paired-end sequencing, both
    ends of a DNA fragment are sequenced with a gap in the middle (called the insert).
    In this case, two files will be produced: `X_1.FASTQ` and `X_2.FASTQ`. Both files
    will have the same order and the exact same number of sequences. The first sequence
    will be in `X_1` pairs with the first sequence of `X_2`, and so on. With regard
    to the programming technique, if you want to keep the pairing information, you
    might perform something such as this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code reads all pairs in order and just counts the number of pairs.
    You will probably want to do something more, but this exposes a dialect that is
    based on the Python `zip` function that allows you to iterate through both files
    simultaneously. Remember to replace `X` with your `FASTQ` prefix.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, if you are sequencing human genomes, you may want to use sequencing
    data from Complete Genomics. In this case, read the *There’s more…* section in
    the next recipe, where we briefly discuss Complete Genomics data.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are some links with more information:'
  prefs: []
  type: TYPE_NORMAL
- en: The Wikipedia page on the FASTQ format is quite informative ([http://en.wikipedia.org/wiki/FASTQ_format](http://en.wikipedia.org/wiki/FASTQ_format)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find more information on the 1,000 Genomes Project at [http://www.1000genomes.org/](http://www.1000genomes.org/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Information about the Phred quality score can be found at [http://en.wikipedia.org/wiki/Phred_quality_score](http://en.wikipedia.org/wiki/Phred_quality_score).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Illumina provides a good introduction page to paired-end reads at [https://www.illumina.com/science/technology/next-generation-sequencing/paired-end-vs-single-read-sequencing.xhtml](https://www.illumina.com/science/technology/next-generation-sequencing/paired-end-vs-single-read-sequencing.xhtml).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Computational methods for discovering structural variation with next-generation
    sequencing* paper from Medvedev et al. on nature methods ([http://www.nature.com/nmeth/journal/v6/n11s/abs/nmeth.1374.xhtml](http://www.nature.com/nmeth/journal/v6/n11s/abs/nmeth.1374.xhtml));
    note that this is not open access.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with alignment data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After you receive your data from the sequencer, you will normally use a tool
    such as `bwa`) to align your sequences to a reference genome. Most users will
    have a reference genome for their species. You can read more on reference genomes
    in [*Chapter 5*](B17942_05.xhtml#_idTextAnchor122), *Working with Genomes*.
  prefs: []
  type: TYPE_NORMAL
- en: The most common representation for aligned data is the `tabix` utility of SAMtools.
    SAMtools is probably the most widely used tool for manipulating SAM/BAM files.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As discussed in the previous recipe, we will use data from the 1,000 Genomes
    Project. We will use the exome alignment for chromosome 20 of female `NA18489`.
    This is just 312 MB. The whole-exome alignment for this individual is 14.2 **gigabytes**
    (**GB**), and the whole genome alignment (at low coverage of 4x) is 40.1 GB. This
    data is a paired end with reads of 76 bp. This is common nowadays, but slightly
    more complex to process. We will take this into account. If your data is not paired,
    just simplify the following recipe appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: The cell at the top of `Chapter03/Working_with_BAM.py` will download the data
    for you. The files you will want are `NA18490_20_exome.bam` and `NA18490_20_exome.bam.bai`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use `pysam`, a Python wrapper to the SAMtools C API. You can install
    it with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: OK—let’s get started.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before you start coding, note that you can inspect the BAM file using `samtools
    view -h` (this is if you have SAMtools installed, which we recommend, even if
    you use the **Genome Analysis Toolkit** (**GATK**) or something else for variant
    calling). We suggest that you take a look at the header file and the first few
    records. The SAM format is too complex to be described here. There is plenty of
    information on the internet about it; nonetheless, sometimes, there’s some really
    interesting information buried in these header files.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: One of the most complex operations in NGS is to generate good alignment files
    from raw sequence data. This not only calls the aligner but also cleans up data.
    Now, in the `@PG` headers of high-quality BAM files, you will find the actual
    command lines used for most—if not all—of the procedures used to generate this
    BAM file. In our example BAM file, you will find all the information needed to
    run bwa, SAMtools, GATK IndelRealigner, and the Picard application suite to clean
    up data. Remember that while you can generate BAM files easily, the programs after
    it will be quite picky in terms of the correctness of the BAM input. For instance,
    if you use GATK’s variant caller to generate genotype calls, the files will have
    to be extensively cleaned. The header of other BAM files can thus provide you
    with the best way to generate yours. A final recommendation is that if you do
    not work with human data, try to find good BAMs for your species, because the
    parameters of a given program may be slightly different. Also, if you use something
    other than the WGS data, check for similar types of sequencing data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s inspect the header files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The header is represented as a dictionary (where the key is `record_type`).
    As there can be several instances of the same `record_type`, the value of the
    dictionary is a list (where each element is—again—a dictionary, or sometimes a
    string containing tag/value pairs).
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now inspect a single record. The amount of data per record is quite
    complex. Here, we will focus on some of the fundamental fields for paired-end
    reads. Check the SAM file specification and the `pysam` API documentation for
    more details:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that the BAM file object can be iterated over its records. We will transverse
    it until we find a record whose **Concise Idiosyncratic Gapped Alignment Report**
    (**CIGAR**) string contains a match and a soft clip.
  prefs: []
  type: TYPE_NORMAL
- en: The CIGAR string gives an indication of the alignment of individual bases. The
    clipped part of the sequence is the part that the aligner failed to align (but
    is not removed from the sequence). We will also want the read, its mate ID, and
    position (of the pair, as we have paired-end reads) that was mapped to the reference
    genome.
  prefs: []
  type: TYPE_NORMAL
- en: First, we print the query template name, followed by the reference ID. The reference
    ID is a pointer to the name of the sequence on the given references on the lookup
    table of references. An example will make this clear. For all records on this
    BAM file, the reference ID is `19` (a non-informative number), but if you apply
    `bam.getrname(19)`, you will get `20`, which is the name of the chromosome. So,
    do not confuse the reference ID (in this case, `19`) with the name of the chromosome
    (`20`). This is then followed by the reference start and reference end. `pysam`
    is 0-based, not 1-based, so be careful when you convert coordinates to other libraries.
    You will notice that the start and end for this case are 59,996 and 60,048, which
    means an alignment of 52 bases. Why are there only 52 bases when the read size
    is 76 (remember—the read size used in this BAM file)? The answer can be found
    on the CIGAR string, which in our case will be `52M24S`, which is a 52-bases match,
    followed by 24 bases that were soft-clipped.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we print where the alignment starts and ends and calculate its length.
    By the way, you can compute this by looking at the CIGAR string. It starts at
    0 (as the first part of the read is mapped) and ends at 52\. The length is 76
    again.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we query the mate (something that you will only do if you have paired-end
    reads). We get its reference ID (as shown in the previous code snippet), its start
    position, and a measure of the distance between both pairs. This measure of distance
    only makes sense if both mates are mapped to the same chromosome.
  prefs: []
  type: TYPE_NORMAL
- en: We then plot the Phred score (refer to the previous recipe, *Working with modern
    sequence formats*, on Phred scores) for the sequence, and then only for the aligned
    part. Finally, we print the sequence (don’t forget to do this!). This is the complete
    sequence, not the clipped one (of course, you can use the preceding coordinates
    to clip).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s plot the distribution of the successfully mapped positions in a
    subset of sequences in the BAM file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will start by initializing an array to keep the count for the entire `76`
    positions. Note that we then fetch only the records for chromosome 20 between
    positions 0 and 10 `tabix`) for these kinds of fetch operations; the speed of
    execution will be completely different.
  prefs: []
  type: TYPE_NORMAL
- en: 'We traverse all records in the 10 Mbp boundary. For each boundary, we get the
    alignment start and end and increase the counter of mappability among the positions
    that were aligned. Finally, we convert this into frequencies, and then plot it,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 – The percentage of mapped calls as a function of the position
    from the start of the sequencer read ](img/B17942_03_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 – The percentage of mapped calls as a function of the position from
    the start of the sequencer read
  prefs: []
  type: TYPE_NORMAL
- en: It’s quite clear that the distribution of mappability is far from being uniform;
    it’s worse at the extremes, with a drop in the middle.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s get the distribution of Phred scores across the mapped part
    of the reads. As you may suspect, this is probably not going to be uniform:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we again use default dictionaries that allow you to use a bit of initialization
    code. We now fetch from start to end and create a list of Phred scores in a dictionary
    whose index is the relative position in the sequence read.
  prefs: []
  type: TYPE_NORMAL
- en: We then use NumPy to calculate the 95th, 50th (median), and 5th percentiles,
    along with the maximum of quality scores per position. For most computational
    biology analyses, having a statistical summarized view of the data is quite common.
    So, you’re probably already familiar with not only percentile calculations, but
    also with other Pythonic ways to calculate means, standard deviations, maximums,
    and minimums.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we will perform a stacked plot of the distribution of Phred scores
    per position. Due to the way `matplotlib` expects stacks, we have to subtract
    the value of the lower percentile from the one before with the `stackplot` call.
    We can use the list for the bottom percentiles, but we have to correct the median
    and the top, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4 – The distribution of Phred scores as a function of the position
    in the read; the bottom blue color spans from 0 to the 5th percentile; the green
    color up to the median, red to the 95th percentile, and purple to the maximum
    ](img/B17942_03_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 – The distribution of Phred scores as a function of the position
    in the read; the bottom blue color spans from 0 to the 5th percentile; the green
    color up to the median, red to the 95th percentile, and purple to the maximum
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although we will discuss data filtering in the *Studying genome accessibility
    and filtering SNP data* recipe of this chapter, it’s not our objective to explain
    the SAM format in detail or give a detailed course in data filtering. This task
    would require a book of its own, but with the basics of `pysam`, you can navigate
    through SAM/BAM files. However, in the last recipe of this chapter, we will take
    a look at extracting genome-wide metrics from BAM files (via annotations on VCF
    files that represent metrics of BAM files) for the purpose of understanding the
    overall quality of our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: You will probably have very large data files to work with. It’s possible that
    some BAM processing will take too much time. One of the first approaches to reducing
    the computation time is subsampling. For example, if you subsample at 10 percent,
    you ignore 9 records out of 10\. For many tasks, such as some of the analysis
    done for the quality assessment of BAM files, subsampling at 10 percent (or even
    1 percent) will be enough to get the gist of the quality of the file.
  prefs: []
  type: TYPE_NORMAL
- en: If you use human data, you may have your data sequenced at Complete Genomics.
    In this case, the alignment files will be different. Although Complete Genomics
    provides tools to convert to standard formats, you might be served better if you
    use its own data.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Additional information can be found at the following links:'
  prefs: []
  type: TYPE_NORMAL
- en: The SAM/BAM format is described at [http://samtools.github.io/hts-specs/SAMv1.pdf](http://samtools.github.io/hts-specs/SAMv1.pdf).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find an introductory explanation of the SAM format on the Abecasis group
    wiki page at [http://genome.sph.umich.edu/wiki/SAM](http://genome.sph.umich.edu/wiki/SAM).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you really need to get complex statistics from BAM files, Alistair Miles’
    `pysamstats` library is your port of call, at [https://github.com/alimanfoo/pysamstats](https://github.com/alimanfoo/pysamstats).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To convert your raw sequence data to alignment data, you will need an aligner;
    the most widely used is bwa ([http://bio-bwa.sourceforge.net/](http://bio-bwa.sourceforge.net/)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Picard (surely a reference to *Star Trek: The Next Generation*) is the most
    commonly used tool to clean up BAM files; refer to [http://broadinstitute.github.io/picard/](http://broadinstitute.github.io/picard/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The technical forum for sequence analysis is called *SEQanswers* ([http://seqanswers.com/](http://seqanswers.com/)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I would like to repeat the recommendation on Biostars here (which is referred
    to in the previous recipe, *Working with modern sequence formats*); it’s a treasure
    trove of information and has a very friendly community, at [http://www.biostars.org/](http://www.biostars.org/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have the Complete Genomics data, take a look at the **frequently asked
    questions** (**FAQs**) at [http://www.completegenomics.com/customer-support/faqs/](http://www.completegenomics.com/customer-support/faqs/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting data from VCF files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After running a genotype caller (for example, GATK or SAMtools), you will have
    a VCF file reporting on genomic variations, such as SNPs, `cyvcf2` module.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While NGS is all about big data, there is a limit to how much I can ask you
    to download as a dataset for this book. I believe that 2 to 20 GB of data for
    a tutorial is asking too much. While the 1,000 Genomes VCF files with realistic
    annotations are in this OOM, we will want to work with much less data here. Fortunately,
    the bioinformatics community has developed tools to allow for the partial download
    of data. As part of the SAMtools/`htslib` package ([http://www.htslib.org/](http://www.htslib.org/)),
    you can download `tabix` and `bgzip`, which will take care of data management.
    On the command line, perform the following operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The first line will partially download the VCF file for chromosome 22 (up to
    17 Mbp) of the 1,000 Genomes Project. Then, `bgzip` will compress it.
  prefs: []
  type: TYPE_NORMAL
- en: The second line will create an index, which we will need for direct access to
    a section of the genome. As usual, you have the code to do this in a notebook
    (the `Chapter03/Working_with_VCF.py` file).
  prefs: []
  type: TYPE_NORMAL
- en: 'You will need to install `cyvcf2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: If you have conflict resolution problems, you can try using `pip` instead. This
    is a last-resort solution that you will find yourself doing with `conda`, as it
    is incapable of resolving package dependencies, something that happens more often
    than not. You can execute `pip install cyvcf2`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Take a look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by inspecting the information that we can get per record:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We start by inspecting the annotations that are available for each record (remember
    that each record encodes a variant, such as SNP, CNV, INDELs, and so on, and the
    state of that variant per sample). At the variant (record) level, we find `AC`—the
    total number of `ALT` alleles in called genotypes, `AF`—the estimated allele frequency,
    `NS`—the number of samples with data, `AN`—the total number of alleles in called
    genotypes, and `DP`—the total read depth. There are others, but they are mostly
    specific to the 1,000 Genomes Project (here, we will try to be as general as possible).
    Your own dataset may have more annotations (or none of these).
  prefs: []
  type: TYPE_NORMAL
- en: 'At the sample level, there are only two annotations in this file: `GT`—genotype,
    and `DP`—the per-sample read depth. You have the per-variant (total) read depth
    and the per-sample read depth; be sure not to confuse both.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we know what information is available, let’s inspect a single VCF
    record:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will start by retrieving the standard information: the chromosome, position,
    ID, reference base (typically just one) and alternative bases (you can have more
    than one, but it’s not uncommon as a first filtering approach to only accept a
    single `ALT`, for example, only accept biallelic SNPs), quality (as you might
    expect, Phred-scaled), and filter status. Regarding the filter status, remember
    that whatever the VCF file says, you may still want to apply extra filters (as
    in the next recipe, *Studying genome accessibility and filtering SNP data*).'
  prefs: []
  type: TYPE_NORMAL
- en: We then print the additional variant-level information (`AC`, `AS`, `AF`, `AN`,
    `DP`, and so on), followed by the sample format (in this case, `DP` and `GT`).
    Finally, we count the number of samples and inspect a single sample to check whether
    it was called for this variant. Also, the reported alleles, heterozygosity, and
    phasing status (this dataset happens to be phased, which is not that common) are
    included.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s check the type of variant and the number of nonbiallelic SNPs in a single
    pass:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will now use the now-common Python default dictionary. We find that this
    dataset has INDELs, CNVs, and—of course—SNPs (roughly two-thirds being transitions
    with one-third transversions). There is a residual number (79) of triallelic SNPs.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The purpose of this recipe is to get you up to speed with the `cyvcf2` module.
    At this stage, you should be comfortable with the API. We will not spend too much
    time on usage details because this will be the main purpose of the next recipe:
    using the VCF module to study the quality of your variant calls.'
  prefs: []
  type: TYPE_NORMAL
- en: While `cyvcf2` is quite fast, it can still take a lot of time to process text-based
    VCF files. There are two main strategies for dealing with this problem. One strategy
    is parallel processing, which we will discuss in the last chapter, [*Chapter 9*](B17942_09.xhtml#_idTextAnchor237),
    *Bioinformatics Pipelines*. The second strategy is to convert to a more efficient
    format; we will provide an example of this in [*Chapter 6*](B17942_06.xhtml#_idTextAnchor154),
    *Population Genetics*. Note that VCF developers are working on a **Binary Variant
    Call Format** (**BCF**) version to deal with parts of these problems ([http://www.1000genomes.org/wiki/analysis/variant-call-format/bcf-binary-vcf-version-2](http://www.1000genomes.org/wiki/analysis/variant-call-format/bcf-binary-vcf-version-2)).
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some useful links are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The specification for VCF is available at [http://samtools.github.io/hts-specs/VCFv4.2.pdf](http://samtools.github.io/hts-specs/VCFv4.2.pdf).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GATK is one of the most widely used variant callers; check out [https://www.broadinstitute.org/gatk/](https://www.broadinstitute.org/gatk/)
    for details.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SAMtools and `htslib` are used for variant calling and SAM/BAM management; check
    out [http://htslib.org](http://htslib.org) for details.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Studying genome accessibility and filtering SNP data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the previous recipes were focused on giving an overview of Python libraries
    to deal with alignment and variant call data, in this recipe, we will concentrate
    on actually using them with a clear purpose in mind.
  prefs: []
  type: TYPE_NORMAL
- en: If you are using NGS data, chances are that your most important file to analyze
    is a VCF file, which is produced by a genotype caller such as SAMtools, `mpileup`,
    or GATK. The quality of your VCF calls may need to be assessed and filtered. Here,
    we will put in place a framework to filter SNP data. Rather than giving you filtering
    rules (an impossible task to be performed in a general way), we will give you
    procedures to assess the quality of your data. With this, you can devise your
    own filters.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the best-case scenario, you have a VCF file with proper filters applied.
    If this is the case, you can just go ahead and use your file. Note that all VCF
    files will have a `FILTER` column, but this might not mean that all of the proper
    filters were applied. You have to be sure that your data is properly filtered.
  prefs: []
  type: TYPE_NORMAL
- en: In the second case, which is one of the most common, your file will have unfiltered
    data, but you’ll have enough annotations and can apply hard filters (there is
    no need for programmatic filtering). If you have a GATK annotated file, refer
    to [http://gatkforums.broadinstitute.org/discussion/2806/howto-apply-hard-filters-to-a-call-set](http://gatkforums.broadinstitute.org/discussion/2806/howto-apply-hard-filters-to-a-call-set).
  prefs: []
  type: TYPE_NORMAL
- en: In the third case, you have a VCF file that has all the annotations that you
    need, but you may want to apply more flexible filters (for example, “if read depth
    > 20, accept if mapping quality > 30; otherwise, accept if mapping quality > 40”).
  prefs: []
  type: TYPE_NORMAL
- en: In the fourth case, your VCF file does not have all the necessary annotations
    and you have to revisit your BAM files (or even other sources of information).
    In this case, the best solution is to find whatever extra information you can
    and create a new VCF file with the required annotations. Some genotype callers
    (such as GATK) allow you to specify which annotations you want; you may also want
    to use extra programs to provide more annotations. For example, **SnpEff** ([http://snpeff.sourceforge.net/](http://snpeff.sourceforge.net/))
    will annotate your SNPs with predictions of their effect (for example, if they
    are in exons, are they coding or non-coding?).
  prefs: []
  type: TYPE_NORMAL
- en: It’s impossible to provide a clear-cut recipe, as it will vary with your type
    of sequencing data, your species of study, and your tolerance to errors, among
    other variables. What we can do is provide a set of typical analyses that is done
    for high-quality filtering.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will not use data from the human 1,000 Genomes Project. We
    want *dirty*, unfiltered data that has a lot of common annotations that can be
    used to filter it. We will use data from the Anopheles gambiae 1,000 Genomes Project
    (Anopheles is a mosquito vector involved in the transmission of a parasite that
    causes malaria), which makes filtered and unfiltered data available. You can find
    more information on this project at [http://www.malariagen.net/projects/vector/ag1000g](http://www.malariagen.net/projects/vector/ag1000g).
  prefs: []
  type: TYPE_NORMAL
- en: 'We will get a part of the centromere of chromosome `3L` for around 100 mosquitoes,
    which is followed by a part somewhere in the middle of this chromosome (and index
    both):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: If the links do not work, be sure to check [https://github.com/PacktPublishing/Bioinformatics-with-Python-Cookbook-third-edition/blob/main/Datasets.py](https://github.com/PacktPublishing/Bioinformatics-with-Python-Cookbook-third-edition/blob/main/Datasets.py)
    for updates. As usual, the code for downloading this data is available in the
    `Chapter02/Filtering_SNPs.ipynb` notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, a word of warning on this recipe: the level of Python here will be
    slightly more complicated than usual. The more general code we write, the easier
    it will be for you to reuse it for your specific case. We will use functional
    programming techniques (`lambda` functions) and the `partial` function application
    extensively.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Take a look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by plotting the distribution of variants across the genome in both
    files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will start by performing the required imports (as usual, remember to remove
    the first line if you are not using the IPython Notebook). Before I explain the
    function, note what we are doing.
  prefs: []
  type: TYPE_NORMAL
- en: For both files, we will compute windowed statistics. We will divide our file,
    which includes 200,000 bp of data, into windows of size 2,000 (100 windows). Every
    time we find a biallelic SNP, we will add a 1 to the list related to this window
    in the `window` function.
  prefs: []
  type: TYPE_NORMAL
- en: The `window` function will take a VCF record (a `rec.is_snp` SNP that is not
    biallelic len `(rec.ALT) == 1`), determine the window where that record belongs
    (by performing an integer division of `rec.POS` by size), and extend the list
    of results of that window by the function passed to it as the `fun` parameter
    (which, in our case, is just a 1).
  prefs: []
  type: TYPE_NORMAL
- en: So, now we have a list of 100 elements (each representing 2,000 bp). Each element
    will be another list that will have a 1 for each biallelic SNP found.
  prefs: []
  type: TYPE_NORMAL
- en: So, if you have 200 SNPs in the first 2,000 bp, the first element of the list
    will have 200 ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s continue, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we perform a plot that contains statistical information for each of our
    100 windows. `apply_win_funs` will calculate a set of statistics for every window.
    In this case, it will sum all the numbers in the window. Remember that every time
    we find an SNP, we add 1 to the window list. This means that if we have 200 SNPs,
    we will have 200 ones; hence, summing them will return 200.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, we are able to compute the number of SNPs per window in an apparently convoluted
    way. Why we perform things with this strategy will become apparent soon. However,
    for now, let’s check the result of this computation for both files, as shown in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 – The number of biallelic SNP distributed windows of 2,000 bp
    in size for an area of 200 kilobase pairs (kbp) near the centromere (orange),
    and in the middle of the chromosome (blue); both areas come from chromosome 3L
    for circa 100 Ugandan mosquitoes from the Anopheles 1,000 Genomes Project ](img/B17942_03_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 – The number of biallelic SNP distributed windows of 2,000 bp in
    size for an area of 200 kilobase pairs (kbp) near the centromere (orange), and
    in the middle of the chromosome (blue); both areas come from chromosome 3L for
    circa 100 Ugandan mosquitoes from the Anopheles 1,000 Genomes Project
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Note that the amount of SNPs in the centromere is smaller than in the middle
    of the chromosome. This is expected because calling variants in chromosomes is
    more difficult than calling in the middle. Also, there is probably less genomic
    diversity in centromeres. If you are used to humans or other mammals, you will
    find the density of variants obnoxiously high—that’s mosquitoes for you!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at the sample-level annotation. We will inspect mapping quality
    zero (refer to [https://www.broadinstitute.org/gatk/guide/tooldocs/org_broadinstitute_gatk_tools_walkers_annotator_MappingQualityZeroBySample.php](https://www.broadinstitute.org/gatk/guide/tooldocs/org_broadinstitute_gatk_tools_walkers_annotator_MappingQualityZeroBySample.php)
    for details), which is a measure of how well sequences involved in calling this
    variant map clearly to this position. Note that there is also an `MQ0` annotation
    at the variant level:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Start inspecting this by looking at the last `for`; we will perform a windowed
    analysis by reading the `MQ0` annotation from each record. We perform this by
    calling the `get_sample` function, which will return our preferred annotation
    (in this case, `MQ0`) that has been cast with a certain type (`my_type=np.int32`).
    We use the `partial` application function here. Python allows you to specify some
    parameters of a function and wait for other parameters to be specified later.
    Note that the most complicated thing here is the functional programming style.
    Also, note that it makes it very easy to compute other sample-level annotations.
    Just replace `MQ0` with `AB`, `AD`, `GQ`, and so on. You immediately have a computation
    for that annotation. If the annotation is not of the integer type, no problem;
    just adapt `my_type`. It’s a difficult programming style if you are not used to
    it, but you will reap its benefits very soon.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s print the median and the top 75 percentile for each window (in this
    case, with a size of 5,000):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Note that we now have two different statistics on `apply_win_funs` (percentile
    and median). Again, we pass functions as parameters (`np.median` and `np.percentile`),
    with `partial` function application done on `np.percentile`. The result looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.6 – Median (continuous line) and 75th percentile (dashed) of MQ0
    of sample SNPs distributed on windows of 5,000 bp in size for an area of 200 kbp
    near the centromere (blue) and in the middle of chromosome (green); both areas
    come from chromosome 3L for circa 100 Ugandan mosquitoes from the Anopheles 1,000
    Genomes Project ](img/B17942_03_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 – Median (continuous line) and 75th percentile (dashed) of MQ0 of
    sample SNPs distributed on windows of 5,000 bp in size for an area of 200 kbp
    near the centromere (blue) and in the middle of chromosome (green); both areas
    come from chromosome 3L for circa 100 Ugandan mosquitoes from the Anopheles 1,000
    Genomes Project
  prefs: []
  type: TYPE_NORMAL
- en: For the `standard.vcf.gz` file, the median `MQ0` is `0` (it’s plotted at the
    very bottom and is almost unseen). This is good as it suggests that most sequences
    involved in the calling of variants map clearly to this area of the genome. For
    the `centro.vcf.gz` file, `MQ0` is of poor quality. Furthermore, there are areas
    where the genotype caller cannot find any variants at all (hence the incomplete
    chart).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s compare heterozygosity with **DP**, the sample-level annotation. Here,
    we will plot the fraction of heterozygosity calls as a function of the **sample
    read depth** (**DP**) for every SNP. First, we will explain the result and then
    the code that generates it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following screenshot shows the fraction of calls that are heterozygous
    at a certain depth:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.7 – The continuous line represents the fraction of heterozygosite
    calls computed at a certain depth; in orange is the centromeric area; in blue
    is the “standard” area; the dashed lines represent the number of sample calls
    per depth; both areas come from chromosome 3L for circa 100 Ugandan mosquitoes
    from the Anopheles 1,000 Genomes Project ](img/B17942_03_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.7 – The continuous line represents the fraction of heterozygosite calls
    computed at a certain depth; in orange is the centromeric area; in blue is the
    “standard” area; the dashed lines represent the number of sample calls per depth;
    both areas come from chromosome 3L for circa 100 Ugandan mosquitoes from the Anopheles
    1,000 Genomes Project
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot, there are two considerations to take into account.
    At a very low depth, the fraction of heterozygote calls is biased—in this case,
    lower. This makes sense, as the number of reads per position does not allow you
    to make a correct estimate of the presence of both alleles in a sample. Therefore,
    you should not trust calls at very low depth.
  prefs: []
  type: TYPE_NORMAL
- en: As expected, the number of calls in the centromere is way lower than outside
    it. The distribution of SNPs outside the centromere follows a common pattern that
    you can expect in many datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this is presented here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Start by looking for the `for` loop. Again, we use functional programming; the
    `get_sample_relation` function will traverse all SNP records and apply two functional
    parameters. The first parameter determines heterozygosity, whereas the second
    parameter acquires the sample `DP` (remember that there is also a variant of `DP`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, since the code is as complex as it is, I opted for a naive data structure
    to be returned by `get_sample_relation`: a dictionary where the key is a pair
    of results (in this case, heterozygosity and `DP`) and the sum of SNPs that share
    both values. There are more elegant data structures with different trade-offs.
    For this, there are SciPy sparse matrices, pandas DataFrames, or you may want
    to consider PyTables. The fundamental point here is to have a framework that is
    general enough to compute relationships between a couple of sample annotations.'
  prefs: []
  type: TYPE_NORMAL
- en: Also, be careful with the dimension space of several annotations. For example,
    if your annotation is of the float type, you might have to round it (if not, the
    size of your data structure might become too big).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s take a look at the plotting code. Let’s perform this in two parts.
    Here is part one:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This function will take a data structure, as generated by `get_sample_relation`,
    expecting that the first parameter of the key tuple is the heterozygosity state
    (`0`=homozygote, `1`=heterozygote) and the second parameter is `DP`. With this,
    it will generate two lines: one with the fraction of samples (which are heterozygotes
    at a certain depth) and the other with the SNP count.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s call this function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we will use two axes. On the left-hand side, we will have the fraction
    of heterozygous SNPs. On the right-hand side, we will have the number of SNPs.
    We then call `plot_hz_rel` for both data files. The rest is standard `matplotlib`
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s compare the `DP` variant with a categorical variant-level annotation
    (`EFF`). `EFF` is provided by SnpEff and tells us (among many other things) the
    type of SNP (for example, intergenic, intronic, coding synonymous, and coding
    nonsynonymous). The Anopheles dataset provides this useful annotation. Let’s start
    by extracting variant-level annotations and the functional programming style:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The programming style here is similar to `get_sample_relation`, but we will
    not delve into any samples. Now, we define the type of effect that we’ll work
    with and convert its effect into an integer (as this will allow us to use it as
    an index—for example, matrices). Now, think about coding a categorical variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now traverse the file; the style should be clear to you now:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we plot the distribution of `DP` using the SNP effect:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, we just print a `boxplot` for the non-centromeric file, as shown in the
    following diagram. The results are as expected: SNPs in coding areas will probably
    have more depth because they are in more complex regions that are easier to call
    than intergenic SNPs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.8 – Boxplot for the distribution of variant read depth across different
    SNP effects ](img/B17942_03_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.8 – Boxplot for the distribution of variant read depth across different
    SNP effects
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The whole issue of filtering SNPs and other genome features will need a book
    of its own. This approach will depend on the type of sequencing data that you
    have, the number of samples, and potential extra information (for example, a pedigree
    among samples).
  prefs: []
  type: TYPE_NORMAL
- en: This recipe is very complex as it is, but parts of it are profoundly naive (there
    is a limit regarding the complexity that I can force on you in a simple recipe).
    For example, the window code does not support overlapping windows. Also, data
    structures are simplistic. However, I hope that they give you an idea of the general
    strategy to process genomic, high-throughput sequencing data. You can read more
    in [*Chapter 4*](B17942_04.xhtml#_idTextAnchor104), *Advanced NGS Processing*.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'More information can be found via these links:'
  prefs: []
  type: TYPE_NORMAL
- en: There are many filtering rules, but I would like to draw your attention to the
    need for reasonably good coverage (clearly above 10x). Refer to *Meynert et al.*,
    *Variant detection sensitivity and biases in whole genome and exome sequencing*,
    at [http://www.biomedcentral.com/1471-2105/15/247/](http://www.biomedcentral.com/1471-2105/15/247/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bcbio-nextgen` is a Python-based pipeline for high-throughput sequencing analysis
    and is worth checking out ([https://bcbio-nextgen.readthedocs.org](https://bcbio-nextgen.readthedocs.org)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing NGS data with HTSeq
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: HTSeq ([https://htseq.readthedocs.io](https://htseq.readthedocs.io)) is an alternative
    library that’s used for processing NGS data. Most of the functionality made available
    by HTSeq is actually available in other libraries covered in this book, but you
    should be aware of it as an alternative way of processing NGS data. HTSeq supports,
    among others, FASTA, FASTQ, SAM (via `pysam`), VCF, **General Feature Format**
    (**GFF**), and **Browser Extensible Data** (**BED**) file formats. It also includes
    a set of abstractions for processing (mapped) genomic data, encompassing concepts
    such as genomic positions and intervals or alignments. A complete examination
    of the features of this library is beyond our scope, so we will concentrate on
    a small subset of features. We will take this opportunity to also introduce the
    BED file format.
  prefs: []
  type: TYPE_NORMAL
- en: The BED format allows for the specification of features for annotations’ tracks.
    It has many uses, but it’s common to load BED files into genome browsers to visualize
    features. Each line includes information about at least the position (chromosome,
    start, and end) and also optional fields such as name or strand. Full details
    about the format can be found at [https://genome.ucsc.edu/FAQ/FAQformat.xhtml#format1](https://genome.ucsc.edu/FAQ/FAQformat.xhtml#format1).
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our simple example will use data from the region where the LCT gene is located
    in the human genome. The LCT gene codifies lactase, an enzyme involved in the
    digestion of lactose.
  prefs: []
  type: TYPE_NORMAL
- en: We will take this information from Ensembl. Go to [http://uswest.ensembl.org/Homo_sapiens/Gene/Summary?db=core;g=ENSG00000115850](http://uswest.ensembl.org/Homo_sapiens/Gene/Summary?db=core;g=ENSG00000115850)
    and choose `LCT.bed` is available in the `Chapter03` directory.
  prefs: []
  type: TYPE_NORMAL
- en: The notebook for this code is called `Chapter03/Processing_BED_with_HTSeq.py`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the file before we start. An example of a few lines of this
    file is provided here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The fourth column is the feature name. This will vary widely from file to file,
    and you will have to check it each and every time. However, in our case, it seems
    apparent that we have Ensembl exons (`ENSE`...), GenBank records (`NM`_...), and
    coding region information (`CCDS`) from the **Consensus Coding Sequence** (**CCDS**)
    database ([https://www.ncbi.nlm.nih.gov/CCDS/CcdsBrowse.cgi](https://www.ncbi.nlm.nih.gov/CCDS/CcdsBrowse.cgi)).
  prefs: []
  type: TYPE_NORMAL
- en: 'You will need to install HTSeq:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can begin.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Take a look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by setting up a reader for our file. Remember that this file
    has already been supplied to you, and should be in your current work directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We are now going to extract all the types of features via their name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Remember that this code is specific to our example. You will have to adapt it
    to your case.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: You will find that the preceding code uses a **regular expression** (**regex**).
    Be careful with regexes, as they tend to generate read-only code that is difficult
    to maintain. You might have better alternatives. In any case, regexes exist, and
    you will find them from time to time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output for our case looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'We stored the last record so that we can inspect it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'There are many fields available, most notably `name` and `interval`. For the
    preceding code, the output looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s dig deeper into the interval:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Note the genomic position (chromosome, start, and end). The most complex issue
    is how to deal with the strand. If the feature is coded in the negative strand,
    you have to be careful with processing. HTSeq offers the `start_d` and `end_d`
    fields to help you with this (that is, they will be reversed with regard to the
    start and end if the strand is negative).
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s extract some statistics from our coding regions (CCDS records).
    We will use CCDS since it’s probably better than the curated database here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should be self-explanatory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The BED format can be a bit more complex than this. Furthermore, the preceding
    code is based on quite specific premises with regard to the contents of our file.
    However, this example should be enough to get you started. Even at its worst,
    the BED format is not very complicated.
  prefs: []
  type: TYPE_NORMAL
- en: HTSeq has much more functionality than this, but this recipe is mostly provided
    as a starting point for the whole package. HTSeq has functionality that can be
    used as an alternative to most of the recipes that we’ve covered thus far.
  prefs: []
  type: TYPE_NORMAL
