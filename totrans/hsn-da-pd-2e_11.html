<html><head></head><body>
		<div id="_idContainer368">
			<h1 id="_idParaDest-173"><em class="italic"><a id="_idTextAnchor172"/>Chapter 8</em>: Rule-Based Anomaly Detection</h1>
			<p>It's time to catch some hackers trying to gain access to a website using a <strong class="bold">brute-force attack</strong>—trying to log in with a bunch of username-password combinations until they gain access. This type of attack is very noisy, so it gives us plenty of data points for <strong class="bold">anomaly detection</strong>, which is the process of looking for data generated from a process other than the one we deem to be typical activity. The hackers will be simulated and won't be as crafty as they can be in real life, but it will give us great exposure to anomaly detection.</p>
			<p>We will be creating a package that will handle the simulation of the login attempts in order to generate the data for this chapter. Knowing how to simulate is an essential skill to have in our toolbox. Sometimes, it's difficult to solve a problem with an exact mathematical solution; however, it might be easy to define how small components of the system work. In these cases, we can model the small components and simulate the behavior of the system as a whole. The result of the simulation gives us an approximation of the solution that may be sufficient for our purposes.</p>
			<p>We will utilize rule-based anomaly detection to identify suspicious activity in the simulated data. By the end of this chapter, we will have an understanding of how to simulate data using random numbers generated from various probability distributions, get more exposure to the Python standard library, gain additional experience building Python packages, practice performing exploratory data analysis, and get an introduction to anomaly detection.</p>
			<p>The following topics will be covered in this chapter:</p>
			<ul>
				<li>Simulating login attempts to create our dataset for the chapter</li>
				<li>Performing exploratory data analysis to understand the simulated data</li>
				<li>Using rules and baselines for anomaly detection</li>
			</ul>
			<h1 id="_idParaDest-174"><a id="_idTextAnchor173"/>Chapter materials</h1>
			<p>We will be building a simulation package to generate the data for this chapter; it is on GitHub at <a href="https://github.com/stefmolin/login-attempt-simulator/tree/2nd_edition">https://github.com/stefmolin/login-attempt-simulator/tree/2nd_edition</a>. This package was installed from GitHub when we set up our environment back in <a href="B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to Data Analysis</em>; however, you can follow the instructions in <a href="B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146"><em class="italic">Chapter 7</em></a>, <em class="italic">Financial Analysis – Bitcoin and the Stock Market</em>, to install a version of the package that you can edit.</p>
			<p>The repository for this chapter, which can be found at <a href="https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch_08">https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch_08</a>, has the notebook we will use for our actual analysis (<strong class="source-inline">anomaly_detection.ipynb</strong>), the data files we will be working with in the <strong class="source-inline">logs/</strong> folder, the data used for the simulation in the <strong class="source-inline">user_data/</strong> folder, and the <strong class="source-inline">simulate.py</strong> file, which contains a Python script that we can run on the command line to simulate the data for the chapter.</p>
			<h1 id="_idParaDest-175"><a id="_idTextAnchor174"/>Simulating login attempts</h1>
			<p>Since we can't easily find login attempt data from a breach (it's not typically shared due to its sensitive nature), we will be simulating it. Simulation requires a strong understanding of statistical modeling, estimating probabilities of certain events, and identifying appropriate assumptions to simplify where necessary. In order to run the simulation, we will build a Python package (<strong class="source-inline">login_attempt_simulator</strong>) to simulate a login process requiring a correct username and password (without any extra authentication measures, such as two-factor authentication) and a script (<strong class="source-inline">simulate.py</strong>) that can be run on the command line, both of which we will discuss in this section.</p>
			<h2 id="_idParaDest-176"><a id="_idTextAnchor175"/>Assumptions</h2>
			<p>Before we jump into the code that handles the simulation, we need to understand the assumptions. It is impossible to control for every possible variable when we make a simulation, so we must identify some simplifying assumptions to get started.</p>
			<p>The simulator makes the following assumptions regarding valid users of the website:</p>
			<ul>
				<li>Valid users come according to a <strong class="bold">Poisson process</strong> at an hourly rate that depends on the day of the week and the time of day. A Poisson process models arrivals per unit of time (our simulation will use an hour) as a Poisson distribution with mean λ (lambda). The interarrival times are exponentially distributed with mean 1/λ.</li>
				<li>Valid users connect from 1-3 IP addresses (a unique identifier for each device using the Internet), which comprise 4 random integers in the range [0, 255] separated by periods. It is possible, although highly unlikely, that two valid users share an IP address.</li>
				<li>Valid users are unlikely to make many mistakes while entering their credentials.<p class="callout-heading">Important note</p><p class="callout">The interarrival times have the <strong class="bold">memoryless</strong> property, meaning that the time between two consecutive arrivals has no bearing on when the subsequent arrival will happen.</p></li>
			</ul>
			<p>The simulator makes the following assumptions about the hackers:</p>
			<ul>
				<li>The hackers try to avoid an account lockout by only testing a few username-password combinations, rather than a full-blown <strong class="bold">dictionary attack</strong> (for every user, trying every password the hacker has in a dictionary of possible passwords that they maintain). However, they don't add delays between their attempts.</li>
				<li>Since the hackers don't want to cause a denial of service, they limit the volume of their attacks and only make one attempt at a time.</li>
				<li>The hackers know the number of accounts that exist in the system and have a good idea of the format the usernames are in, but are guessing the exact usernames. They will choose to try to guess all 133 usernames, or some subset of them.</li>
				<li>Each attack is standalone, meaning there is a single hacker acting for each attack, and a hacker never attacks more than once.</li>
				<li>The hackers don't share information about which username-password combinations are correct.</li>
				<li>The attacks come at random times.</li>
				<li>Each hacker will use a single IP address, which is generated in the same way the valid user ones are. However, our simulator is capable of varying this IP address, a feature that we will look at in <a href="B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237"><em class="italic">Chapter 11</em></a>, <em class="italic">Machine Learning Anomaly Detection</em>, to make this scenario more challenging.</li>
				<li>Although highly unlikely, it is possible the hacker has the same IP address as a valid user. The hacker may even be a valid user.</li>
			</ul>
			<p>We are abstracting away some of the complexity of password-guessing as well; instead, we are using random numbers to determine whether or not the password is guessed correctly—this means we aren't considering how the website stores passwords, perhaps as plaintext (hopefully not), hashes (the irreversible transformation of the plaintext password that allows verification without storing the actual password), or salted hashes (refer to the <em class="italic">Further reading</em> section for an article on this). In practice, a hacker could gain access to the stored passwords and figure out what they are offline (see the article on rainbow tables in the <em class="italic">Further reading</em> section at the end of this chapter), in which case the techniques discussed in this chapter wouldn't be as helpful, since the logs wouldn't have a record of their attempts. Keep in mind that the hackers in this simulation are very conspicuous.</p>
			<h2 id="_idParaDest-177"><a id="_idTextAnchor176"/>The login_attempt_simulator package</h2>
			<p>This package is much more lightweight than the <strong class="source-inline">stock_analysis</strong> package from the previous chapter; we only have three files:</p>
			<p class="source-code">login_attempt_simulator</p>
			<p class="source-code">|-- __init__.py</p>
			<p class="source-code">|-- login_attempt_simulator.py</p>
			<p class="source-code">`-- utils.py</p>
			<p>We will walk through each of these files in the following sections. Note that parts of the docstrings have been removed for brevity; check the files themselves for the full documentation.</p>
			<h3>Helper functions</h3>
			<p>Let's start our discussion with the <strong class="source-inline">utils.py</strong> functions, which are helpers for our simulator class. First, we create our docstring for the module and handle our imports:</p>
			<p class="source-code">"""Utility functions for the login attempt simulator."""</p>
			<p class="source-code">import ipaddress</p>
			<p class="source-code">import itertools</p>
			<p class="source-code">import json</p>
			<p class="source-code">import random</p>
			<p class="source-code">import string</p>
			<p>Next, we define the <strong class="source-inline">make_user_base()</strong> function, which makes the user base for our web application. It creates a file of usernames by combining one lowercase letter from the English alphabet with each last name in the list inside the function, and adds a few administrative accounts as well; this results in a user base of 133 accounts. By writing to a file, we ensure we don't have to generate this every time we run our simulation and can simply read from it to simulate in the future:</p>
			<p class="source-code">def make_user_base(out_file):</p>
			<p class="source-code">    """Generate a user base and save it to a file."""</p>
			<p class="source-code">    with open(out_file, 'w') as user_base:</p>
			<p class="source-code">        for first, last in <strong class="bold">itertools.product(</strong></p>
			<p class="source-code">            <strong class="bold">string.ascii_lowercase, </strong></p>
			<p class="source-code">            <strong class="bold">['smith', 'jones', 'kim', 'lopez', 'brown']</strong></p>
			<p class="source-code">        <strong class="bold">): </strong># makes 130 accounts</p>
			<p class="source-code">            user_base.write(first + last + '\n')</p>
			<p class="source-code">        # adds 3 more accounts</p>
			<p class="source-code">        for account in ['admin', 'master', 'dba']: </p>
			<p class="source-code">            user_base.write(account + '\n')</p>
			<p>Since we will need to use this user base in our simulator, we also write a function to read the user base file into a list. The <strong class="source-inline">get_valid_users()</strong> function reads the file written by the <strong class="source-inline">make_user_base()</strong> function back into a Python list:</p>
			<p class="source-code">def get_valid_users(user_base_file):</p>
			<p class="source-code">    """Read in users from the user base file."""</p>
			<p class="source-code">    with open(user_base_file, 'r') as file:</p>
			<p class="source-code">        return [user.strip() for user in file.readlines()]</p>
			<p>The <strong class="source-inline">random_ip_generator()</strong> function creates IP addresses from random numbers of the form <strong class="source-inline">xxx.xxx.xxx.xxx</strong>, where <strong class="source-inline">x</strong> is an integer in the range [0, 255]. We are using the <strong class="source-inline">ipaddress</strong> module from the Python standard library (<a href="https://docs.python.org/3/library/ipaddress.html">https://docs.python.org/3/library/ipaddress.html</a>) to avoid assigning private IP addresses:</p>
			<p class="source-code">def random_ip_generator():</p>
			<p class="source-code">    """Randomly generate a fake IP address."""</p>
			<p class="source-code">    try:</p>
			<p class="source-code">        ip_address = ipaddress.IPv4Address('%d.%d.%d.%d' %</p>
			<p class="source-code">            tuple(random.randint(0, 255) for _ in range(4))</p>
			<p class="source-code">        )</p>
			<p class="source-code">    except ipaddress.AddressValueError:</p>
			<p class="source-code">        ip_address = random_ip_generator()</p>
			<p class="source-code">    return str(ip_address) if ip_address.is_global \</p>
			<p class="source-code">        else random_ip_generator()</p>
			<p>Each of our users will have a few IP addresses from which they attempt to log in. The <strong class="source-inline">assign_ip_addresses()</strong> function maps 1-3 random IP addresses to each user, creating a dictionary:</p>
			<p class="source-code">def assign_ip_addresses(user_list):</p>
			<p class="source-code">    """Assign users 1-3 fake IP addresses."""</p>
			<p class="source-code">    return {</p>
			<p class="source-code">        user: [</p>
			<p class="source-code">            random_ip_generator()</p>
			<p class="source-code">            for _ in range(random.randint(1, 3))</p>
			<p class="source-code">        ] for user in user_list</p>
			<p class="source-code">    }</p>
			<p>The <strong class="source-inline">save_user_ips()</strong> and <strong class="source-inline">read_user_ips()</strong> functions save the user-IP address mapping to a JSON file and read it back into the dictionary file, respectively:</p>
			<p class="source-code">def save_user_ips(user_ip_dict, file):</p>
			<p class="source-code">    """Save the user-IP address mapping to a JSON file."""</p>
			<p class="source-code">    with open(file, 'w') as file:</p>
			<p class="source-code">        <strong class="bold">json.dump</strong>(user_ip_dict, file)</p>
			<p class="source-code">def read_user_ips(file):</p>
			<p class="source-code">    """Read in the JSON file of the user-IP address mapping."""</p>
			<p class="source-code">    with open(file, 'r') as file:</p>
			<p class="source-code">        return <strong class="bold">json.loads</strong>(file.read())</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">The Python standard library has lots of helpful modules that we might not find many occasions to use but are definitely worth knowing about. Here, we use the <strong class="source-inline">json</strong> module to save dictionaries to JSON files and read them back later. We are using the <strong class="source-inline">ipaddress</strong> module to work with IP addresses, and the <strong class="source-inline">string</strong> module to get the characters in the alphabet without having to type them all out.</p>
			<h3>The LoginAttemptSimulator class</h3>
			<p>The <strong class="source-inline">LoginAttemptSimulator</strong> class in the <strong class="source-inline">login_attempt_simulator.py</strong> file handles the heavy lifting of carrying out the simulation with all the random number generation logic. As usual, we start with our module docstring and imports:</p>
			<p class="source-code">"""Simulator of login attempts from valid users and hackers."""</p>
			<p class="source-code">import calendar</p>
			<p class="source-code">import datetime as dt</p>
			<p class="source-code">from functools import partial</p>
			<p class="source-code">import math</p>
			<p class="source-code">import random</p>
			<p class="source-code">import string</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">import pandas as pd</p>
			<p class="source-code">from .utils import random_ip_generator, read_user_ips</p>
			<p>Next, we begin defining the <strong class="source-inline">LoginAttemptSimulator</strong> class with its docstring, along with some class variables for storing constants. We do this to avoid magic numbers (numbers in the code that don't seem to have meaning) and spelling errors with strings we will use in multiple spots. Note that these messages are only for our logs; the web application doesn't show the end users why the authentication attempt failed (nor should it):</p>
			<p class="source-code">class LoginAttemptSimulator:</p>
			<p class="source-code">    """Simulate login attempts from valid users + attackers."""</p>
			<p class="source-code">    <strong class="bold">ATTEMPTS_BEFORE_LOCKOUT = 3</strong></p>
			<p class="source-code">    <strong class="bold">ACCOUNT_LOCKED = 'error_account_locked'</strong></p>
			<p class="source-code">    <strong class="bold">WRONG_USERNAME = 'error_wrong_username'</strong></p>
			<p class="source-code">    <strong class="bold">WRONG_PASSWORD = 'error_wrong_password'</strong></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Take note of how we used class variables to store constants, such as error messages, so that we don't risk typos in the code. This means that every time we use these error messages, the text will be identical, which will keep the data clean. In Python, constants are typically written in all caps (<a href="https://www.python.org/dev/peps/pep-0008/#constants">https://www.python.org/dev/peps/pep-0008/#constants</a>).</p>
			<p>The <strong class="source-inline">__init__()</strong> method will handle the setup for the simulator, such as reading in the user base from the file indicated, initializing the logs, storing success probabilities, and determining the start and end dates for the simulation, as needed:</p>
			<p class="source-code">    def __init__(self, user_base_json_file, start, end=None, *,</p>
			<p class="source-code">                 attacker_success_probs=[.25, .45],</p>
			<p class="source-code">                 valid_user_success_probs=[.87, .93, .95],</p>
			<p class="source-code">                 seed=None):</p>
			<p class="source-code">        # user, ip address dictionary</p>
			<p class="source-code">        self.user_base = read_user_ips(user_base_json_file)</p>
			<p class="source-code">        self.users = [user for user in self.user_base.keys()]</p>
			<p class="source-code">        self.start = start</p>
			<p class="source-code">        self.end = end if end else self.start + \</p>
			<p class="source-code">            dt.timedelta(days=random.uniform(1, 50))</p>
			<p class="source-code">        self.hacker_success_likelihoods = \</p>
			<p class="source-code">            attacker_success_probs</p>
			<p class="source-code">        self.valid_user_success_likelihoods = \</p>
			<p class="source-code">            valid_user_success_probs</p>
			<p class="source-code">        self.log = pd.DataFrame(columns=[</p>
			<p class="source-code">            'datetime', 'source_ip', 'username',</p>
			<p class="source-code">            'success', 'failure_reason'</p>
			<p class="source-code">        ])</p>
			<p class="source-code">        self.hack_log = \</p>
			<p class="source-code">            pd.DataFrame(columns=['start', 'end', 'source_ip'])</p>
			<p class="source-code">        self.locked_accounts = []</p>
			<p class="source-code">        # set seeds for random numbers from random and numpy:</p>
			<p class="source-code">        random.seed(seed)</p>
			<p class="source-code">        np.random.seed(seed)</p>
			<p>The <strong class="source-inline">_record()</strong> method appends the result of each attempt to the log, noting the IP address it came from, which username, at what time, whether it succeeded, and the reason for failure, if there was one:</p>
			<p class="source-code">    def _record(self, when, source_ip, username, success, </p>
			<p class="source-code">                failure_reason):</p>
			<p class="source-code">        """</p>
			<p class="source-code">        Record the outcome of a login attempt.</p>
			<p class="source-code">        Parameters:</p>
			<p class="source-code">            - when: The datetime of the event.</p>
			<p class="source-code">            - source_ip: IP address the attempt came from.</p>
			<p class="source-code">            - username: The username used in the attempt.</p>
			<p class="source-code">            - success: Whether the attempt succeeded (Boolean).</p>
			<p class="source-code">            - failure_reason: Reason for the failure.</p>
			<p class="source-code">        Returns: </p>
			<p class="source-code">            None, the `log` attribute is updated.</p>
			<p class="source-code">        """</p>
			<p class="source-code">        self.log = self.log.append({</p>
			<p class="source-code">            'datetime': when, </p>
			<p class="source-code">            'source_ip': source_ip, </p>
			<p class="source-code">            'username': username, </p>
			<p class="source-code">            'success': success, </p>
			<p class="source-code">            'failure_reason': failure_reason</p>
			<p class="source-code">        }, ignore_index=True)</p>
			<p>The <strong class="source-inline">_attempt_login()</strong> method handles the logic of determining whether the login attempt succeeds:</p>
			<div>
				<div id="_idContainer344" class="IMG---Figure">
					<img src="image/Figure_8.1_B16834.jpg" alt="Figure 8.1 – Simulation logic&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.1 – Simulation logic</p>
			<p>We provide the probability of entering a correct username (<strong class="source-inline">username_accuracy</strong>) and the probabilities of successfully entering the password for each attempt (<strong class="source-inline">success_likelihoods</strong>). The number of attempts is the minimum of the number of attempts allowed before an account lockout <a id="_idIndexMarker1044"/>and the length of the list of success probabilities (<strong class="source-inline">success_likelihoods</strong>). The outcome of each attempt is passed to <strong class="source-inline">_record()</strong> using <strong class="bold">partials</strong> (from <strong class="source-inline">functools</strong>), which allow us to create functions that fix certain parameters to a specific value (so we <a id="_idIndexMarker1045"/>don't have to pass the same value continuously):</p>
			<p class="source-code">    def _attempt_login(self, when, source_ip, username,</p>
			<p class="source-code">                       username_accuracy, success_likelihoods):</p>
			<p class="source-code">        """</p>
			<p class="source-code">        Simulates a login attempt, allowing for account</p>
			<p class="source-code">        lockouts, and recording the results.</p>
			<p class="source-code">        Parameters:</p>
			<p class="source-code">            - when: The datetime to start trying.</p>
			<p class="source-code">            - source_ip: IP address the attempt came from. </p>
			<p class="source-code">            - username: The username being used in the attempt.</p>
			<p class="source-code">            - username_accuracy: Prob. username is correct.</p>
			<p class="source-code">            - success_likelihoods: List of probabilities that </p>
			<p class="source-code">              password is correct (one per attempt).</p>
			<p class="source-code">        Returns:</p>
			<p class="source-code">            The datetime after trying.</p>
			<p class="source-code">        """</p>
			<p class="source-code">        current = when</p>
			<p class="source-code">        <strong class="bold">recorder = partial(self._record, source_ip=source_ip)</strong></p>
			<p class="source-code">        if random.random() &gt; username_accuracy:</p>
			<p class="source-code">            correct_username = username</p>
			<p class="source-code">            username = self._distort_username(username)</p>
			<p class="source-code">        if username not in self.locked_accounts:</p>
			<p class="source-code">            tries = len(success_likelihoods)</p>
			<p class="source-code">            for i in range(</p>
			<p class="source-code">                min(tries, self.ATTEMPTS_BEFORE_LOCKOUT)</p>
			<p class="source-code">            ):</p>
			<p class="source-code">                current += dt.timedelta(seconds=1)</p>
			<p class="source-code">                if username not in self.users:</p>
			<p class="source-code">                    recorder(</p>
			<p class="source-code">                        when=current, username=username, </p>
			<p class="source-code">                        success=False,</p>
			<p class="source-code">                        failure_reason=<strong class="bold">self.WRONG_USERNAME</strong></p>
			<p class="source-code">                    )</p>
			<p class="source-code">                    if random.random() &lt;= username_accuracy:</p>
			<p class="source-code">                        username = correct_username</p>
			<p class="source-code">                    continue</p>
			<p class="source-code">                if random.random() &lt;= success_likelihoods[i]:</p>
			<p class="source-code">                    recorder(</p>
			<p class="source-code">                        when=current, username=username,</p>
			<p class="source-code">                        success=True, failure_reason=None</p>
			<p class="source-code">                    )</p>
			<p class="source-code">                    break</p>
			<p class="source-code">                else:</p>
			<p class="source-code">                    recorder(</p>
			<p class="source-code">                        when=current, username=username, </p>
			<p class="source-code">                        success=False,</p>
			<p class="source-code">                        failure_reason=<strong class="bold">self.WRONG_PASSWORD</strong></p>
			<p class="source-code">                    )</p>
			<p class="source-code">            else:</p>
			<p class="source-code">                if tries &gt;= <strong class="bold">self.ATTEMPTS_BEFORE_LOCKOUT</strong> \</p>
			<p class="source-code">                and username in self.users:</p>
			<p class="source-code">                    self.locked_accounts.append(username)</p>
			<p class="source-code">        else:</p>
			<p class="source-code">            recorder(</p>
			<p class="source-code">                when=current, username=username, success=False,</p>
			<p class="source-code">                failure_reason=self.ACCOUNT_LOCKED</p>
			<p class="source-code">            )</p>
			<p class="source-code">            if random.random() &gt;= .5: # unlock account randomly</p>
			<p class="source-code">                self.locked_accounts.remove(username)</p>
			<p class="source-code">        return current</p>
			<p>The <strong class="source-inline">_valid_user_attempts_login()</strong> and <strong class="source-inline">_hacker_attempts_login()</strong> methods are wrappers around the <strong class="source-inline">_attempt_login()</strong> method that handle the adjustment in probabilities for valid users and hackers, respectively. Notice that while both use a Gaussian (normal) distribution to determine how accurate the username will be, the valid user's<a id="_idIndexMarker1046"/> distribution has a higher mean and lower standard deviation, meaning they are more likely to provide the correct username when trying to log in. This is because, while valid users may make typos (infrequently), the hackers are guessing:</p>
			<p class="source-code">    def _hacker_attempts_login(self, when, source_ip,</p>
			<p class="source-code">                               username):</p>
			<p class="source-code">        """Simulates a login attempt from an attacker."""</p>
			<p class="source-code">        return self._attempt_login(</p>
			<p class="source-code">            when=when, source_ip=source_ip, username=username,</p>
			<p class="source-code">            <strong class="bold">username_accuracy=random.gauss(mu=0.35, sigma=0.5)</strong>,</p>
			<p class="source-code">            success_likelihoods=self.hacker_success_likelihoods</p>
			<p class="source-code">        )</p>
			<p class="source-code">    def _valid_user_attempts_login(self, when, username):</p>
			<p class="source-code">        """Simulates a login attempt from a valid user."""</p>
			<p class="source-code">        return self._attempt_login(</p>
			<p class="source-code">            when=when, username=username,</p>
			<p class="source-code">            source_ip=random.choice(self.user_base[username]),</p>
			<p class="source-code">            <strong class="bold">username_accuracy=\</strong></p>
			<p class="source-code">                <strong class="bold">random.gauss(mu=1.01, sigma=0.01),</strong></p>
			<p class="source-code">            success_likelihoods=\</p>
			<p class="source-code">                self.valid_user_success_likelihoods</p>
			<p class="source-code">        )</p>
			<p>When the simulator determines that the username will not be provided correctly, it calls the <strong class="source-inline">_distort_username()</strong> method, which randomly decides to omit a letter from the valid username or to replace one of the letters with another one. While hackers enter incorrect usernames because they are <a id="_idIndexMarker1047"/>guessing (not due to typos), we abstract away this detail in order to use a single function for introducing username errors for both valid users and hackers:</p>
			<p class="source-code">    @staticmethod</p>
			<p class="source-code">    def _distort_username(username):</p>
			<p class="source-code">        """</p>
			<p class="source-code">        Alters the username to allow for wrong username login </p>
			<p class="source-code">        failures. Randomly removes a letter or replaces a </p>
			<p class="source-code">        letter in a valid username.</p>
			<p class="source-code">        """</p>
			<p class="source-code">        username = list(username)</p>
			<p class="source-code">        change_index = random.randint(0, len(username) - 1)</p>
			<p class="source-code">        if random.random() &lt; .5: # remove random letter</p>
			<p class="source-code">            username.pop(change_index)</p>
			<p class="source-code">        else: # randomly replace a single letter</p>
			<p class="source-code">            username[change_index] = \</p>
			<p class="source-code">                random.choice(string.ascii_lowercase)</p>
			<p class="source-code">        return ''.join(username)</p>
			<p>We use the <strong class="source-inline">_valid_user_arrivals()</strong> method to generate the number of users that will arrive in a given hour <a id="_idIndexMarker1048"/>and the interarrival times using Poisson and exponential distributions, respectively:</p>
			<p class="source-code">    @staticmethod</p>
			<p class="source-code">    def _valid_user_arrivals(when):</p>
			<p class="source-code">        """</p>
			<p class="source-code">        Static method for simulating Poisson process of </p>
			<p class="source-code">        arrivals (users wanting to log in). Lambda for the </p>
			<p class="source-code">        Poisson varies depending upon the day and time of week.</p>
			<p class="source-code">        """</p>
			<p class="source-code">        is_weekday = when.weekday() not in (</p>
			<p class="source-code">            calendar.SATURDAY, calendar.SUNDAY</p>
			<p class="source-code">        )</p>
			<p class="source-code">        late_night = when.hour &lt; 5 or when.hour &gt;= 11</p>
			<p class="source-code">        work_time = is_weekday \</p>
			<p class="source-code">                    and (when.hour &gt;= 9 or when.hour &lt;= 17)</p>
			<p class="source-code">        <strong class="bold">if work_time:</strong></p>
			<p class="source-code"><strong class="bold">            # hours 9-5 on work days get higher lambda </strong></p>
			<p class="source-code"><strong class="bold">            poisson_lambda = random.triangular(1.5, 5, 2.75)</strong></p>
			<p class="source-code"><strong class="bold">        elif late_night:</strong></p>
			<p class="source-code"><strong class="bold">            # hours in middle of night get lower lambda</strong></p>
			<p class="source-code"><strong class="bold">            poisson_lambda = random.uniform(0.0, 5.0)</strong></p>
			<p class="source-code"><strong class="bold">        else:</strong></p>
			<p class="source-code"><strong class="bold">            poisson_lambda = random.uniform(1.5, 4.25)</strong></p>
			<p class="source-code"><strong class="bold">        hourly_arrivals = np.random.poisson(poisson_lambda)</strong></p>
			<p class="source-code"><strong class="bold">        interarrival_times = np.random.exponential(</strong></p>
			<p class="source-code"><strong class="bold">            1/poisson_lambda, size=hourly_arrivals</strong></p>
			<p class="source-code"><strong class="bold">        )</strong></p>
			<p class="source-code">        return hourly_arrivals, interarrival_times</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">We are using <strong class="source-inline">numpy</strong> instead of <strong class="source-inline">random</strong> to generate random numbers from the exponential distribution because we can ask for multiple values at once (one for each of the hourly arrivals determined by the Poisson process). Also, note that <strong class="source-inline">random</strong> doesn't provide a Poisson distribution, so we need <strong class="source-inline">numpy</strong>.</p>
			<p>Our simulation uses many different <a id="_idIndexMarker1049"/>distributions, so it can be helpful to see what they look like. The following subplots show examples for each of the distributions we are using. Notice that the Poisson distribution is drawn differently. This is because the Poisson distribution is discrete. For this reason, we often use it to model arrivals—here, we use it for modeling the arrivals of users <a id="_idIndexMarker1050"/>attempting to log in. Discrete distributions have a <strong class="bold">probability mass function</strong> (<strong class="bold">PMF</strong>) instead <a id="_idIndexMarker1051"/>of a <strong class="bold">probability density function</strong> (<strong class="bold">PDF</strong>):</p>
			<div>
				<div id="_idContainer345" class="IMG---Figure">
					<img src="image/Figure_8.2_B16834.jpg" alt="Figure 8.2 – Distributions used in the simulation&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.2 – Distributions used in the simulation</p>
			<p>The <strong class="source-inline">_hack()</strong> method <a id="_idIndexMarker1052"/>generates a random IP address for the hacker and carries out a brute-force attack on a given user list:</p>
			<p class="source-code">    def _hack(self, when, user_list, vary_ips):</p>
			<p class="source-code">        """</p>
			<p class="source-code">        Simulate an attack by a random hacker.</p>
			<p class="source-code">        Parameters:</p>
			<p class="source-code">            - when: The datetime to start the attack.</p>
			<p class="source-code">            - user_list: The list of users to try to hack.</p>
			<p class="source-code">            - vary_ips: Whether or not to vary the IP address.</p>
			<p class="source-code">        Returns:</p>
			<p class="source-code">            Initial IP address and the end time for recording.</p>
			<p class="source-code">        """</p>
			<p class="source-code">        <strong class="bold">hacker_ip = random_ip_generator()</strong></p>
			<p class="source-code">        random.shuffle(user_list)</p>
			<p class="source-code">        for user in user_list:</p>
			<p class="source-code">            when = self._hacker_attempts_login(</p>
			<p class="source-code">                when=when, username=user,</p>
			<p class="source-code">                source_ip=random_ip_generator() if vary_ips \</p>
			<p class="source-code">                    else hacker_ip</p>
			<p class="source-code">            )</p>
			<p class="source-code">        return hacker_ip, when</p>
			<p>Now that we have the functionality to<a id="_idIndexMarker1053"/> carry out the main parts of the simulation, we write the <strong class="source-inline">simulate()</strong> method to put it all together:</p>
			<p class="source-code">    def simulate(self, *, attack_prob, try_all_users_prob,</p>
			<p class="source-code">                 vary_ips):</p>
			<p class="source-code">        """</p>
			<p class="source-code">        Simulate login attempts.</p>
			<p class="source-code">        Parameters:</p>
			<p class="source-code">            - attack_probs: Probability of attack in given hour</p>
			<p class="source-code">            - try_all_users_prob: Prob. hacker will try to </p>
			<p class="source-code">              guess credentials for all users vs random subset.</p>
			<p class="source-code">            - vary_ips: Whether to vary the IP address.</p>
			<p class="source-code">        """</p>
			<p class="source-code">        hours_in_date_range = math.floor(</p>
			<p class="source-code">            (self.end - self.start).total_seconds() / 60 / 60</p>
			<p class="source-code">        )</p>
			<p class="source-code">        for offset in range(hours_in_date_range + 1):</p>
			<p class="source-code">            current = self.start + dt.timedelta(hours=offset)</p>
			<p class="source-code">            <strong class="bold"># simulate hacker</strong></p>
			<p class="source-code"><strong class="bold">            if random.random() &lt; attack_prob:</strong></p>
			<p class="source-code">                attack_start = current \</p>
			<p class="source-code">                    + dt.timedelta(hours=random.random())</p>
			<p class="source-code">                source_ip, end_time = self._hack(</p>
			<p class="source-code">                    when=attack_start,</p>
			<p class="source-code">                    <strong class="bold">user_list=self.users if \</strong></p>
			<p class="source-code"><strong class="bold">                        random.random() &lt; try_all_users_prob \</strong></p>
			<p class="source-code"><strong class="bold">                        else random.sample(</strong></p>
			<p class="source-code"><strong class="bold">                            self.users, </strong></p>
			<p class="source-code"><strong class="bold">                            random.randint(0, len(self.users))</strong></p>
			<p class="source-code">                    <strong class="bold">),</strong></p>
			<p class="source-code">                    vary_ips=vary_ips</p>
			<p class="source-code">                )</p>
			<p class="source-code">                self.hack_log = self.hack_log.append(</p>
			<p class="source-code">                    dict(</p>
			<p class="source-code">                        start=attack_start, end=end_time, </p>
			<p class="source-code">                        source_ip=source_ip</p>
			<p class="source-code">                    ), ignore_index=True</p>
			<p class="source-code">                )</p>
			<p class="source-code">            <strong class="bold"># simulate valid users</strong></p>
			<p class="source-code">            hourly_arrivals, interarrival_times = \</p>
			<p class="source-code">                self._valid_user_arrivals(current)</p>
			<p class="source-code">            random_user = random.choice(self.users)</p>
			<p class="source-code">            random_ip = \</p>
			<p class="source-code">                random.choice(self.user_base[random_user])</p>
			<p class="source-code">            <strong class="bold">for i in range(hourly_arrivals):</strong></p>
			<p class="source-code"><strong class="bold">                current += \</strong></p>
			<p class="source-code"><strong class="bold">                    dt.timedelta(hours=interarrival_times[i])</strong></p>
			<p class="source-code"><strong class="bold">                current = self._valid_user_attempts_login(</strong></p>
			<p class="source-code"><strong class="bold">                    current, random_user</strong></p>
			<p class="source-code"><strong class="bold">                )</strong></p>
			<p>We want to save the logs to CSV files, so we add the <strong class="source-inline">_save()</strong> method as a static method to allow for less repetition in the code for the two save methods. The <strong class="source-inline">save_log()</strong> method will save the login attempts and the <strong class="source-inline">save_hack_log()</strong> method will save the<a id="_idIndexMarker1054"/> record of the attacks:</p>
			<p class="source-code">    @staticmethod</p>
			<p class="source-code">    def _save(data, filename, sort_column):</p>
			<p class="source-code">        """Sort data by the datetime and save to a CSV file."""</p>
			<p class="source-code">        data.sort_values(sort_column)\</p>
			<p class="source-code">            .to_csv(filename, index=False)</p>
			<p class="source-code">    def save_log(self, filename):</p>
			<p class="source-code">        """Save the login attempts log to a CSV file."""</p>
			<p class="source-code">        self._save(self.log, filename, 'datetime')</p>
			<p class="source-code">    def save_hack_log(self, filename):</p>
			<p class="source-code">        """Save the record of the attacks to a CSV file."""</p>
			<p class="source-code">        self._save(self.hack_log, filename, 'start')</p>
			<p>Notice that there were many private methods in this class; this is because users of this class only need to be able to create an instance of this class (<strong class="source-inline">__init__()</strong>), simulate by hour (<strong class="source-inline">simulate()</strong>), and save the output (<strong class="source-inline">save_log()</strong> and <strong class="source-inline">save_hack_log()</strong>)—all other methods are for internal use by objects of this class. The methods behind the scenes will handle the bulk of the work.</p>
			<p>Lastly, we have the <strong class="source-inline">__init__.py</strong> file, which makes this a package, but also provides us with an easier way to import the main class:</p>
			<p class="source-code">"""Package for simulating login data."""</p>
			<p class="source-code"><strong class="bold">from .login_attempt_simulator import LoginAttemptSimulator</strong></p>
			<p>Now that we understand how the simulator works, we will discuss how to run the simulation to collect<a id="_idIndexMarker1055"/> the login attempts data.</p>
			<h2 id="_idParaDest-178"><a id="_idTextAnchor177"/>Simulating from the command line</h2>
			<p>Rather than writing the <a id="_idIndexMarker1056"/>code to simulate the login attempts every time, we can package this up in a script that we can easily run from the command line. The Python standard library has the <strong class="source-inline">argparse</strong> module (<a href="https://docs.python.org/3/library/argparse.html">https://docs.python.org/3/library/argparse.html</a>), which allows us to specify arguments to our script that can be supplied from the command line.</p>
			<p>Let's take a look at the <strong class="source-inline">simulate.py</strong> file to see how to do this. We start with our imports:</p>
			<p class="source-code">"""Script for simulating login attempts."""</p>
			<p class="source-code"><strong class="bold">import argparse</strong></p>
			<p class="source-code">import datetime as dt</p>
			<p class="source-code">import os</p>
			<p class="source-code">import logging</p>
			<p class="source-code">import random</p>
			<p class="source-code"><strong class="bold">import login_attempt_simulator as sim</strong></p>
			<p>In order to provide status updates when using this from the command line, we are going to set up logging messages using the standard library's <strong class="source-inline">logging</strong> module (<a href="https://docs.python.org/3/library/logging.html">https://docs.python.org/3/library/logging.html</a>):</p>
			<p class="source-code"># Logging configuration</p>
			<p class="source-code"><strong class="bold">FORMAT = '[%(levelname)s] [ %(name)s ] %(message)s'</strong></p>
			<p class="source-code"><strong class="bold">logging.basicConfig(level=logging.INFO, format=FORMAT)</strong></p>
			<p class="source-code"><strong class="bold">logger = logging.getLogger(os.path.basename(__file__))</strong></p>
			<p>Next, we define some utility functions for generating file paths that we will need for reading and writing data during<a id="_idIndexMarker1057"/> the simulation:</p>
			<p class="source-code">def get_simulation_file_path(path_provided, directory,</p>
			<p class="source-code">                             default_file):</p>
			<p class="source-code">    """Get filepath, make directory if necessary."""</p>
			<p class="source-code">    if path_provided:</p>
			<p class="source-code">        file = path_provided</p>
			<p class="source-code">    else:</p>
			<p class="source-code">        if not os.path.exists(directory):</p>
			<p class="source-code">            os.mkdir(directory)</p>
			<p class="source-code">        file = os.path.join(directory, default_file)</p>
			<p class="source-code">    return file</p>
			<p class="source-code">def get_user_base_file_path(path_provided, default_file):</p>
			<p class="source-code">    """Get the path for a user_data directory file."""</p>
			<p class="source-code">    return get_simulation_file_path(</p>
			<p class="source-code">        path_provided, 'user_data', default_file</p>
			<p class="source-code">    )</p>
			<p class="source-code">def get_log_file_path(path_provided, default_file):</p>
			<p class="source-code">    """Get the path for a logs directory file."""</p>
			<p class="source-code">    return get_simulation_file_path(</p>
			<p class="source-code">        path_provided, 'logs', default_file</p>
			<p class="source-code">    )</p>
			<p>The largest part of this script defines which command-line parameters can be passed—we will allow the user to specify whether they want to create a new user base, set a seed, when to start the simulation, how long to simulate, and where to save all the files. The actual simulation is taken care of in a few lines thanks to the package we built. This section will only run when<a id="_idIndexMarker1058"/> this module is run, rather than imported:</p>
			<p class="source-code">if __name__ == '__main__':</p>
			<p class="source-code">    # command-line argument parsing</p>
			<p class="source-code">    <strong class="bold">parser = argparse.ArgumentParser()</strong></p>
			<p class="source-code"><strong class="bold">    parser.add_argument(</strong></p>
			<p class="source-code"><strong class="bold">        'days', type=float,</strong></p>
			<p class="source-code"><strong class="bold">        help='number of days to simulate from start'</strong></p>
			<p class="source-code"><strong class="bold">    )</strong></p>
			<p class="source-code"><strong class="bold">    parser.add_argument(</strong></p>
			<p class="source-code"><strong class="bold">        'start_date', type=str,</strong></p>
			<p class="source-code"><strong class="bold">        help="datetime to start in the form 'YYYY-MM-DD(...)'"</strong></p>
			<p class="source-code"><strong class="bold">    )</strong></p>
			<p class="source-code"><strong class="bold">    parser.add_argument(</strong></p>
			<p class="source-code"><strong class="bold">        '-m', '--make', action='store_true', </strong></p>
			<p class="source-code"><strong class="bold">        help='make user base'</strong></p>
			<p class="source-code"><strong class="bold">    )</strong></p>
			<p class="source-code"><strong class="bold">    parser.add_argument(</strong></p>
			<p class="source-code"><strong class="bold">        '-s', '--seed', type=int, </strong></p>
			<p class="source-code"><strong class="bold">        help='set a seed for reproducibility'</strong></p>
			<p class="source-code"><strong class="bold">    )</strong></p>
			<p class="source-code"><strong class="bold">    parser.add_argument(</strong></p>
			<p class="source-code"><strong class="bold">        '-u', '--userbase', </strong></p>
			<p class="source-code"><strong class="bold">        help='file to write the user base to'</strong></p>
			<p class="source-code"><strong class="bold">    )</strong></p>
			<p class="source-code"><strong class="bold">    parser.add_argument(</strong></p>
			<p class="source-code"><strong class="bold">        '-i', '--ip', </strong></p>
			<p class="source-code"><strong class="bold">        help='file to write user-IP address map to'</strong></p>
			<p class="source-code"><strong class="bold">    )</strong></p>
			<p class="source-code"><strong class="bold">    parser.add_argument(</strong></p>
			<p class="source-code"><strong class="bold">        '-l', '--log', help='file to write the attempt log to'</strong></p>
			<p class="source-code"><strong class="bold">    )</strong></p>
			<p class="source-code"><strong class="bold">    parser.add_argument(</strong></p>
			<p class="source-code"><strong class="bold">        '-hl', '--hacklog', </strong></p>
			<p class="source-code"><strong class="bold">        help='file to write the hack log to'</strong></p>
			<p class="source-code"><strong class="bold">    )</strong></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">The code placed in the <strong class="source-inline">if __name__ == '__main__'</strong> block will only be run when this module is run as a script. This makes it possible for us to import the functions defined in the module without running the simulation.</p>
			<p>After defining the<a id="_idIndexMarker1059"/> arguments, we need to parse them in order to use them:</p>
			<p class="source-code">    <strong class="bold">args = parser.parse_args()</strong></p>
			<p>Once we have the command-line arguments parsed, we check to see whether we need to generate the user base or read it in:</p>
			<p class="source-code">    user_ip_mapping_file = \</p>
			<p class="source-code">        get_user_base_file_path(args.ip, 'user_ips.json')</p>
			<p class="source-code">    if args.make:</p>
			<p class="source-code">        logger.warning(</p>
			<p class="source-code">            'Creating new user base, mapping IP addresses.'</p>
			<p class="source-code">        )</p>
			<p class="source-code">        user_base_file = get_user_base_file_path(</p>
			<p class="source-code">            args.userbase, 'user_base.txt'</p>
			<p class="source-code">        )</p>
			<p class="source-code">        # seed the creation of user base</p>
			<p class="source-code">        random.seed(args.seed)</p>
			<p class="source-code">        # create usernames and write to file</p>
			<p class="source-code">        sim.utils.make_user_base(user_base_file)</p>
			<p class="source-code">        # create 1 or more IP addresses per user, save mapping </p>
			<p class="source-code">        valid_users = sim.utils.get_valid_users(user_base_file)</p>
			<p class="source-code">        sim.utils.save_user_ips(</p>
			<p class="source-code">            sim.utils.assign_ip_addresses(valid_users), </p>
			<p class="source-code">            user_ip_mapping_file</p>
			<p class="source-code">        )</p>
			<p>Afterward, we parse the<a id="_idIndexMarker1060"/> start date from the command-line arguments, and determine the end date by adding the duration from the command-line arguments to the start date:</p>
			<p class="source-code">    <strong class="bold">try:</strong></p>
			<p class="source-code">        start = \</p>
			<p class="source-code">            dt.datetime(*map(int, args.start_date.split('-')))</p>
			<p class="source-code">    <strong class="bold">except TypeError:</strong></p>
			<p class="source-code">        logger.error('Start date must be in "YYYY-MM-DD" form')</p>
			<p class="source-code">        raise</p>
			<p class="source-code">    <strong class="bold">except ValueError:</strong></p>
			<p class="source-code">        logger.warning(</p>
			<p class="source-code">            f'Could not interpret {args.start_date}, '</p>
			<p class="source-code">            'using January 1, 2020 at 12AM as start instead'</p>
			<p class="source-code">        )</p>
			<p class="source-code">        start = dt.datetime(2020, 1, 1)</p>
			<p class="source-code">    end = start + dt.timedelta(days=args.days)</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Check out the <strong class="source-inline">try...except</strong> block in the previous code snippet. We have a single <strong class="source-inline">try</strong> clause and multiple <strong class="source-inline">except</strong> clauses. We can specify how to handle specific errors occurring during code <a id="_idIndexMarker1061"/>execution (called <strong class="bold">exceptions</strong>) by stating which exception type belongs to a given <strong class="source-inline">except</strong> clause. In this case, we have the <strong class="source-inline">logger</strong> object print a more helpful message for the user, and then re-raise the same exception (because we don't intend to handle it) by simply writing <strong class="source-inline">raise</strong>. This ends the program—the user can then try again with valid input. Try triggering this exception to see how much more useful this is. One thing to keep in mind, though, is that order matters—be sure to handle specific exceptions before having a general <strong class="source-inline">except</strong> clause; otherwise, the code specific to each exception type will never trigger. Also, note that using <strong class="source-inline">except</strong> without providing a specific exception will catch everything, even exceptions not meant to be caught.</p>
			<p>Finally, we run the actual simulation <a id="_idIndexMarker1062"/>and write our results to the files specified (or the default paths). We set the probability of attack in a given hour to 10% (<strong class="source-inline">attack_prob</strong>), the probability the hacker will attempt to guess all usernames at 20% (<strong class="source-inline">try_all_users_prob</strong>), and have the hackers use the same IP<a id="_idIndexMarker1063"/> address for all of their attempts (<strong class="source-inline">vary_ips</strong>):</p>
			<p class="source-code">    try:</p>
			<p class="source-code">        <strong class="bold">logger.info(f'Simulating {args.days} days...')</strong></p>
			<p class="source-code">        simulator = sim.LoginAttemptSimulator(</p>
			<p class="source-code">            user_ip_mapping_file, start, end, seed=args.seed</p>
			<p class="source-code">        )</p>
			<p class="source-code">        simulator.simulate(</p>
			<p class="source-code">            <strong class="bold">attack_prob=0.1, try_all_users_prob=0.2, </strong></p>
			<p class="source-code">            <strong class="bold">vary_ips=False</strong></p>
			<p class="source-code">        )</p>
			<p class="source-code">        # save logs</p>
			<p class="source-code">        logger.info('Saving logs')</p>
			<p class="source-code">        simulator.save_hack_log(</p>
			<p class="source-code">            get_log_file_path(args.hacklog, 'attacks.csv')</p>
			<p class="source-code">        )</p>
			<p class="source-code">        simulator.save_log(</p>
			<p class="source-code">            get_log_file_path(args.log, 'log.csv')</p>
			<p class="source-code">        )</p>
			<p class="source-code">        logger.info('All done!')</p>
			<p class="source-code">    except:</p>
			<p class="source-code">        logger.error('Oops! Something went wrong...')</p>
			<p class="source-code">        raise</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Notice that we used the <strong class="source-inline">logger</strong> object to print helpful messages to the screen throughout the script; this will help the users of this script know how far along in the process it is. These messages come in different levels of severity (we are using <strong class="source-inline">INFO</strong>, <strong class="source-inline">WARNING</strong>, and <strong class="source-inline">ERROR</strong> here), allowing them to be placed for debugging (the <strong class="source-inline">DEBUG</strong> level), and left there once the code goes into production, since the minimum level for printing can be raised to <strong class="source-inline">INFO</strong>, so that no <strong class="source-inline">DEBUG</strong> messages are printed. This is leaps and bounds above simple <strong class="source-inline">print()</strong> statements, since we don't have to worry about removing them as we move to production or adding back these messages as development continues.</p>
			<p>Let's now take a look at how we can<a id="_idIndexMarker1064"/> run this script. We know that <strong class="source-inline">simulate.py</strong> can be run on the command line, but how can we see what arguments we need to pass? Simple—we add the help flag (<strong class="source-inline">-h</strong> or <strong class="source-inline">--help</strong>) to the call:</p>
			<p class="source-code">(book_env) $ python3 simulate.py -h</p>
			<p class="source-code">usage: simulate.py [-h] [-m] [-s SEED] [-u USERBASE] [-i IP] </p>
			<p class="source-code">                   [-l LOG] [-hl HACKLOG]</p>
			<p class="source-code">                   days start_date</p>
			<p class="source-code">positional arguments:</p>
			<p class="source-code">  days                  number of days to simulate from start</p>
			<p class="source-code">  start_date            datetime to start in the form </p>
			<p class="source-code">                        'YYYY-MM-DD' or 'YYYY-MM-DD-HH'</p>
			<p class="source-code">optional arguments:</p>
			<p class="source-code">  -h, --help            show this help message and exit</p>
			<p class="source-code">  -m, --make            make user base</p>
			<p class="source-code">  -s SEED, --seed SEED  set a seed for reproducibility</p>
			<p class="source-code">  -u USERBASE, --userbase USERBASE</p>
			<p class="source-code">                        file to write the user base to</p>
			<p class="source-code">  -i IP, --ip IP        file to write the user-IP address </p>
			<p class="source-code">                        map to</p>
			<p class="source-code">  -l LOG, --log LOG     file to write the attempt log to</p>
			<p class="source-code">  -hl HACKLOG, --hacklog HACKLOG</p>
			<p class="source-code">                        file to write the hack log to</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Note that we didn't specify the <strong class="source-inline">help</strong> argument when we added the other arguments with <strong class="source-inline">argparse</strong>; it was automatically created by <strong class="source-inline">argparse</strong>.</p>
			<p>Once we know which arguments<a id="_idIndexMarker1065"/> we can pass and have decided which of these we want to provide, we can run the simulation. Let's simulate 30 days, starting from 12 AM on November 1, 2018, while having the script create the user base and IP address mappings needed:</p>
			<p class="source-code">(book_env) $ python3 simulate.py -ms 0 30 '2018-11-01'</p>
			<p class="source-code">[WARNING] [ simulate.py ] Creating new user base and mapping IP addresses to them.</p>
			<p class="source-code">[INFO] [ simulate.py ] Simulating 30.0 days...</p>
			<p class="source-code">[INFO] [ simulate.py ] Saving logs</p>
			<p class="source-code">[INFO] [ simulate.py ] All done!</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Since we set a seed (<strong class="source-inline">-s 0</strong>), the output of this simulation is reproducible. Simply remove the seed or change it to get a different result.</p>
			<p>Python modules can also be run as scripts. As opposed to importing a module, when we run one as a script, any code underneath <strong class="source-inline">if __name__ == '__main__'</strong> will also be run, meaning we don't always need to write a separate script. Most of the modules we have built only <a id="_idIndexMarker1066"/>defined functions and classes, so running them as scripts wouldn't do anything; however, the way we created our virtual environment with <strong class="source-inline">venv</strong> back in <a href="B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to Data Analysis</em>, was an example of this. The previous code block is therefore equivalent to the following command:</p>
			<p class="source-code"># leave off the .py</p>
			<p class="source-code">(book_env) $ python3 -m simulate -ms 0 30 "2018-11-01"</p>
			<p>Now that we have our simulated data, let's begin our analysis.</p>
			<h1 id="_idParaDest-179"><a id="_idTextAnchor178"/>Exploratory data analysis</h1>
			<p>In this scenario, we have the <a id="_idIndexMarker1067"/>benefit of access to labeled data (<strong class="source-inline">logs/attacks.csv</strong>) and will use it to investigate how to distinguish between valid users and attackers. However, this is a luxury that we often don't have, especially once we leave the research phase and enter the application phase. In <a href="B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237"><em class="italic">Chapter 11</em></a>, <em class="italic">Machine Learning Anomaly Detection</em>, we will revisit this scenario, but begin without the labeled data for more of a challenge. As usual, we start with our imports and reading in the data:</p>
			<p class="source-code">&gt;&gt;&gt; %matplotlib inline</p>
			<p class="source-code">&gt;&gt;&gt; import matplotlib.pyplot as plt</p>
			<p class="source-code">&gt;&gt;&gt; import numpy as np</p>
			<p class="source-code">&gt;&gt;&gt; import pandas as pd</p>
			<p class="source-code">&gt;&gt;&gt; import seaborn as sns</p>
			<p class="source-code">&gt;&gt;&gt; log = pd.read_csv(</p>
			<p class="source-code">...     'logs/log.csv', index_col='datetime', parse_dates=True</p>
			<p class="source-code">... )</p>
			<p>The login attempts dataframe (<strong class="source-inline">log</strong>) contains the date and time of each attempt in the <strong class="source-inline">datetime</strong> column, the IP address it <a id="_idIndexMarker1068"/>came from (<strong class="source-inline">source_ip</strong>), the username that was used (<strong class="source-inline">username</strong>), whether the attempt was successful (<strong class="source-inline">success</strong>), and the reason for failure if it wasn't (<strong class="source-inline">failure_reason</strong>):</p>
			<div>
				<div id="_idContainer346" class="IMG---Figure">
					<img src="image/Figure_8.3_B16834.jpg" alt="Figure 8.3 – Sample of the login attempt data&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.3 – Sample of the login attempt data</p>
			<p>When approaching this data, we need to think about what normal activity and hacker activity would look like. Any big differences between the groups could potentially be leveraged to identify the hackers. We would expect valid users to have high success rates, with the most common reason for failure being an incorrect password. We would expect users to log in from a few different IP addresses (phone, home computer, work computer, and any other device they may have), and it is possible that people share devices. Without knowing the nature of this web application, we can't say anything about whether it is normal to log in many times throughout the day. We also don't know what time zone this data is in, so we can't make any inferences about the login times. Potentially, we could look at which countries these IP addresses are from, but there are ways of masking IP addresses, so we won't go down that path. This leaves us with a few viable options, given our available data:</p>
			<ul>
				<li>Investigate any spikes in attempts and failures (both overall and per IP address).</li>
				<li>Examine cases where the failure reason was an incorrect username.</li>
				<li>Look at the failure rate per IP address.</li>
				<li>Find IP addresses trying to log in with many distinct usernames.</li>
			</ul>
			<p>One other thing to note is that we<a id="_idIndexMarker1069"/> would want to flag anomalous behavior sooner rather than later. Waiting a month to flag something is less valuable (the value drops quickly over time), so we need to find a way to flag much sooner; say, using an hourly frequency. Since we are in the research phase, we have some labeled data to work with:</p>
			<p class="source-code">&gt;&gt;&gt; attacks = pd.read_csv(</p>
			<p class="source-code">...     'logs/attacks.csv',</p>
			<p class="source-code">...     converters={</p>
			<p class="source-code">...         'start': np.datetime64, </p>
			<p class="source-code">...         'end': np.datetime64</p>
			<p class="source-code">...     }</p>
			<p class="source-code">... ) # make start and end columns datetimes but not the index</p>
			<p>This data is the record of attacks on the web application (<strong class="source-inline">attacks</strong>). It contains the date and time of the start of the attack (<strong class="source-inline">start</strong>), the date and time of the end of the attack (<strong class="source-inline">end</strong>), and the IP address associated with the attack (<strong class="source-inline">source_ip</strong>):</p>
			<div>
				<div id="_idContainer347" class="IMG---Figure">
					<img src="image/Figure_8.4_B16834.jpg" alt="Figure 8.4 – Sample of the labeled data&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.4 – Sample of the labeled data</p>
			<p>Using the <strong class="source-inline">shape</strong> property, we can see that we had 72 attacks and 12,836 login attempts from valid and nefarious users, and with <strong class="source-inline">nunique()</strong>, we see that 22% of the IP addresses were associated with attacks<a id="_idIndexMarker1070"/>:</p>
			<p class="source-code">&gt;&gt;&gt; attacks.shape, log.shape</p>
			<p class="source-code">((<strong class="bold">72</strong>, 3), (<strong class="bold">12836</strong>, 4))</p>
			<p class="source-code">&gt;&gt;&gt; attacks.source_ip.nunique() / log.source_ip.nunique()</p>
			<p class="source-code">0.22018348623853212</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Normally, it wouldn't be this trivial to know when the attacks occurred—they can go a long time without detection, and, even then, it's not so simple to isolate the attacker's actions from those of normal users.</p>
			<p>Our data is pretty clean (we designed it just for this purpose, after all), so let's see whether we can find anything interesting by performing some <strong class="bold">exploratory data analysis</strong> (<strong class="bold">EDA</strong>). First, let's look to see how many attempts are coming through on an hourly basis:</p>
			<p class="source-code">&gt;&gt;&gt; log.assign(attempts=1).attempts.resample('1H').sum()\</p>
			<p class="source-code">...     .plot(figsize=(15, 5), title='hourly attempts')\</p>
			<p class="source-code">...     .set(xlabel='datetime', ylabel='attempts')</p>
			<p>Several hours had very large peaks, which could possibly be when attacks occurred. Using this plot, we could report on hours that had a high level of login attempt activity, but nothing beyond that:</p>
			<div>
				<div id="_idContainer348" class="IMG---Figure">
					<img src="image/Figure_8.5_B16834.jpg" alt="Figure 8.5 – Hourly login attempts&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.5 – Hourly login attempts</p>
			<p>Another interesting avenue<a id="_idIndexMarker1071"/> of exploration would be to see how many attempts came from each IP address. We can achieve this by running the following command:</p>
			<p class="source-code">&gt;&gt;&gt; log.source_ip.value_counts().describe()</p>
			<p class="source-code">count    327.000000</p>
			<p class="source-code">mean      39.253823</p>
			<p class="source-code">std       69.279330</p>
			<p class="source-code">min        1.000000</p>
			<p class="source-code">25%        5.000000</p>
			<p class="source-code">50%       10.000000</p>
			<p class="source-code">75%       22.500000</p>
			<p class="source-code">max      257.000000</p>
			<p class="source-code">Name: source_ip, dtype: float64</p>
			<p>This data definitely appears to have some outliers, which pull the number of attempts per IP address up quite high. Let's create some plots to better assess this:</p>
			<p class="source-code">&gt;&gt;&gt; fig, axes = plt.subplots(1, 2, figsize=(15, 5))</p>
			<p class="source-code">&gt;&gt;&gt; log.source_ip.value_counts()\</p>
			<p class="source-code">...     .plot(kind='box', ax=axes[0]).set_ylabel('attempts')</p>
			<p class="source-code">&gt;&gt;&gt; log.source_ip.value_counts()\</p>
			<p class="source-code">...     .plot(kind='hist', bins=50, ax=axes[1])\</p>
			<p class="source-code">...     .set_xlabel('attempts')</p>
			<p class="source-code">&gt;&gt;&gt; fig.suptitle('Attempts per IP Address')</p>
			<p>The distribution of <a id="_idIndexMarker1072"/>attempts per IP address is the sum of the distributions for both valid users and attackers. The histogram indicates that this distribution is bimodal, but we are unable to determine whether all of those IP addresses with high attempts are actually hackers by just looking at the plot:</p>
			<div>
				<div id="_idContainer349" class="IMG---Figure">
					<img src="image/Figure_8.6_B16834.jpg" alt="Figure 8.6 – Distribution of login attempts per IP address&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.6 – Distribution of login attempts per IP address</p>
			<p>Since we have access to the details of each attack, we can check whether the right part of the histogram is the distribution for the hackers. Their IP addresses make up 88.9% of the top IP addresses ranked by<a id="_idIndexMarker1073"/> number of attempts:</p>
			<p class="source-code">&gt;&gt;&gt; num_hackers = attacks.source_ip.nunique()</p>
			<p class="source-code">&gt;&gt;&gt; log.source_ip.value_counts().index[:num_hackers]\</p>
			<p class="source-code">...     .isin(attacks.source_ip).sum() / num_hackers</p>
			<p class="source-code">0.8888888888888888</p>
			<p>We could simply stop here and flag any IP address that shows up in a list of IP addresses with the most attempts per month, but we most likely want a more robust solution, since the hackers could simply change their IP address each time and avoid detection. Ideally, we would also be able to detect the attacks without waiting for a full month's worth of data. Looking at the hourly attempts made by each IP address unfortunately doesn't give us much information, though:</p>
			<p class="source-code">&gt;&gt;&gt; log.assign(attempts=1).groupby('source_ip').attempts\</p>
			<p class="source-code">...     .resample('1H').sum().unstack().mean()\</p>
			<p class="source-code">...     .plot(</p>
			<p class="source-code">...         figsize=(15, 5), </p>
			<p class="source-code">...         title='average hourly attempts per IP address'</p>
			<p class="source-code">...     ).set_ylabel('average hourly attempts per IP address')</p>
			<p>Remember from <a href="B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to Data Analysis</em>, that the mean is not robust to outliers. If the attackers make many attempts, they will bring the average hourly attempts per IP address higher. We can see several large peaks in this line plot, but notice that many of them only go up to two or three. Can we really expect only one user to access the web application from a given IP address? This is probably not a realistic assumption:</p>
			<div>
				<div id="_idContainer350" class="IMG---Figure">
					<img src="image/Figure_8.7_B16834.jpg" alt="Figure 8.7 – Average hourly login attempts per IP address&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.7 – Average hourly login attempts per IP address</p>
			<p>So, if we can't rely on the IP address (after all, the hacker could be smart enough to spread the attack over many different addresses), what else can we try? Perhaps the hackers have more trouble<a id="_idIndexMarker1074"/> logging in successfully:</p>
			<p class="source-code">&gt;&gt;&gt; log[log.source_ip.isin(attacks.source_ip)]\</p>
			<p class="source-code">...     .success.value_counts(normalize=True)</p>
			<p class="source-code">False    0.831801</p>
			<p class="source-code"><strong class="bold">True     0.168199</strong></p>
			<p class="source-code">Name: success, dtype: float64</p>
			<p>The hackers are only successful 17% of the time, but how often are the valid users successful? This information is important for determining a baseline of what normal behavior looks like for the website. As we would expect, valid users have much higher success rates:</p>
			<p class="source-code">&gt;&gt;&gt; log[~log.source_ip.isin(attacks.source_ip)]\</p>
			<p class="source-code">...     .success.value_counts(normalize=True)</p>
			<p class="source-code"><strong class="bold">True     0.873957</strong></p>
			<p class="source-code">False    0.126043</p>
			<p class="source-code">Name: success, dtype: float64</p>
			<p>Since the logs come with the reason that a login attempt failed, we can use a crosstab to see why hackers and valid <a id="_idIndexMarker1075"/>users fail to log in successfully. Any differences here may help us separate the two groups:</p>
			<p class="source-code">&gt;&gt;&gt; pd.crosstab(</p>
			<p class="source-code">...     index=pd.Series(</p>
			<p class="source-code">...         log.source_ip.isin(attacks.source_ip),</p>
			<p class="source-code">...         name='is_hacker'</p>
			<p class="source-code">...     ), columns=log.failure_reason</p>
			<p class="source-code">... )</p>
			<p>Valid users sometimes enter their passwords or usernames incorrectly, but the hacker has way more issues getting both the username and password correct:</p>
			<div>
				<div id="_idContainer351" class="IMG---Figure">
					<img src="image/Figure_8.8_B16834.jpg" alt="Figure 8.8 – Reason for failed login attempts&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.8 – Reason for failed login attempts</p>
			<p>Valid users don't make many mistakes with their credentials, so if the hackers make many attempts with many users, we can flag it. To confirm, we can look at average hourly attempts per user:</p>
			<p class="source-code">&gt;&gt;&gt; log.assign(attempts=1).groupby('username').attempts\</p>
			<p class="source-code">...     .resample('1H').sum().unstack().mean()\</p>
			<p class="source-code">...     .plot(figsize=(15, 5),</p>
			<p class="source-code">...           title='average hourly attempts per user')\</p>
			<p class="source-code">...     .set_ylabel('average hourly attempts per user')</p>
			<p>For the most part, less than one attempt per hour is made per username. There's also no guarantee that spikes in this metric <a id="_idIndexMarker1076"/>are indications of an attack. Perhaps the website is having a flash sale; in that case, we would likely see a spike in this metric caused by valid users:</p>
			<div>
				<div id="_idContainer352" class="IMG---Figure">
					<img src="image/Figure_8.9_B16834.jpg" alt="Figure 8.9 – Average hourly login attempts per username&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.9 – Average hourly login attempts per username</p>
			<p>Based on our findings, error rates seem to be the most fruitful metric for detecting attacks, so we will look into IP addresses that have high error rates. To do so, we can create a pivot table to calculate some helpful metrics:</p>
			<p class="source-code">&gt;&gt;&gt; pivot = log.pivot_table(</p>
			<p class="source-code">...     values='success', index=log.source_ip, </p>
			<p class="source-code">...     columns=<strong class="bold">log.failure_reason.fillna('success')</strong>, </p>
			<p class="source-code">...     <strong class="bold">aggfunc='count', fill_value=0</strong></p>
			<p class="source-code">... )</p>
			<p class="source-code">&gt;&gt;&gt; <strong class="bold">pivot.insert(0, 'attempts', pivot.sum(axis=1))</strong></p>
			<p class="source-code">&gt;&gt;&gt; pivot = pivot.sort_values('attempts', ascending=False)\</p>
			<p class="source-code">...     .assign(</p>
			<p class="source-code">...         success_rate=lambda x: x.success / x.attempts,</p>
			<p class="source-code">...         error_rate=lambda x: 1 - x.success_rate</p>
			<p class="source-code">...     )</p>
			<p class="source-code">&gt;&gt;&gt; pivot.head()</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">The <strong class="source-inline">insert()</strong> method allows us to insert the newly created <strong class="source-inline">attempts</strong> column at a specific position in the current dataframe in place. We created the <strong class="source-inline">attempts</strong> column as the sum of errors and successes (we fill in the <strong class="source-inline">NaN</strong> values in the <strong class="source-inline">failure_reason</strong> column with <strong class="source-inline">success</strong> to count it here) by summing with <strong class="source-inline">axis=1</strong>.</p>
			<p>This yields the following pivot table sorted by <a id="_idIndexMarker1077"/>attempts (from most to fewest):</p>
			<div>
				<div id="_idContainer353" class="IMG---Figure">
					<img src="image/Figure_8.10_B16834.jpg" alt="Figure 8.10 – Metrics per IP address&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.10 – Metrics per IP address</p>
			<p>We know that certain IP addresses are making many attempts, so it's worth looking into how many usernames are attempting to log in per IP address; we would expect valid users to only log in from a few IP addresses and not to share their IP address with many others. This can be determined with a group by and an aggregation:</p>
			<p class="source-code">&gt;&gt;&gt; log.<strong class="bold">groupby('source_ip').agg(dict(username='nunique'))</strong>\</p>
			<p class="source-code">...     .username.value_counts().describe()</p>
			<p class="source-code">count     53.000000</p>
			<p class="source-code">mean       6.169811</p>
			<p class="source-code">std       34.562505</p>
			<p class="source-code">min        1.000000</p>
			<p class="source-code">25%        1.000000</p>
			<p class="source-code">50%        1.000000</p>
			<p class="source-code"><strong class="bold">75%        2.000000</strong></p>
			<p class="source-code"><strong class="bold">max      253.000000</strong></p>
			<p class="source-code">Name: username, dtype: float64</p>
			<p>This definitely appears to be a good strategy for isolating nefarious users. The majority of the IP addresses are used by two or fewer users, but the maximum stands at 253. While this criterion could <a id="_idIndexMarker1078"/>help us identify some of the attackers, it won't help if the hackers are clever enough to vary their IP addresses throughout their attack.</p>
			<p>Before we move on to anomaly detection methods, let's see whether we can visually identify the hackers. Let's create a scatter plot for the successes and attempts for each IP address:</p>
			<p class="source-code">&gt;&gt;&gt; pivot.plot(</p>
			<p class="source-code">...     kind='scatter', x='attempts', y='success', alpha=0.25,</p>
			<p class="source-code">...     title='successes vs. attempts by IP address' </p>
			<p class="source-code">... )</p>
			<p>There appear to be a few distinct clusters. In the bottom-left corner of the plot, we see points forming a line with a one-to-one relationship of successes to attempts. The upper-right portion of the plot contains a less dense cluster with a high number of attempts and moderate successes. Since we used the <strong class="source-inline">alpha</strong> parameter to control transparency, we can see that the trail of points that seem to connect the two clusters is not densely populated. Even without the axis scales, we would predict the bottom-left cluster to be regular users and the top-right to be hackers (since we imagine there are more regular users than hackers, and regular users have higher success rates). The points in the middle are more<a id="_idIndexMarker1079"/> difficult to judge, however:</p>
			<div>
				<div id="_idContainer354" class="IMG---Figure">
					<img src="image/Figure_8.11_B16834.jpg" alt="Figure 8.11 – Scatter plot of successes versus attempts by IP address&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.11 – Scatter plot of successes versus attempts by IP address</p>
			<p>Without making any assumptions, we can draw a boundary line grouping the middle points with their nearest cluster:</p>
			<p class="source-code">&gt;&gt;&gt; ax = pivot.plot(</p>
			<p class="source-code">...     kind='scatter', x='attempts', y='success', alpha=0.25, </p>
			<p class="source-code">...     title='successes vs. attempts by IP address'</p>
			<p class="source-code">... )</p>
			<p class="source-code">&gt;&gt;&gt; plt.axvline(</p>
			<p class="source-code">...     125, label='sample boundary',</p>
			<p class="source-code">...     color='red', linestyle='--'</p>
			<p class="source-code">... )</p>
			<p class="source-code">&gt;&gt;&gt; plt.legend(loc='lower right')</p>
			<p>Of course, when lacking labeled data, it is difficult to evaluate the effectiveness of this decision<a id="_idIndexMarker1080"/> boundary:</p>
			<div>
				<div id="_idContainer355" class="IMG---Figure">
					<img src="image/Figure_8.12_B16834.jpg" alt="Figure 8.12 – Visualizing a decision boundary&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.12 – Visualizing a decision boundary</p>
			<p>Luckily for us, we have data on which IP addresses the hackers used because we have been given labeled data to conduct our research, so we can use <strong class="source-inline">seaborn</strong> to actually see the separation:</p>
			<p class="source-code">&gt;&gt;&gt; fig, axes = plt.subplots(1, 2, figsize=(15, 5))</p>
			<p class="source-code">&gt;&gt;&gt; for ax in axes:</p>
			<p class="source-code">...     sns.scatterplot(</p>
			<p class="source-code">...         y=pivot.success, x=pivot.attempts, </p>
			<p class="source-code">...         hue=pivot.assign(</p>
			<p class="source-code">...             is_hacker=\</p>
			<p class="source-code">...                 lambda x: x.index.isin(attacks.source_ip)</p>
			<p class="source-code">...         ).is_hacker,</p>
			<p class="source-code">...         ax=ax, alpha=0.5</p>
			<p class="source-code">...     ) </p>
			<p class="source-code">...     for spine in ['top', 'right']: # make less boxy</p>
			<p class="source-code">...         ax.spines[spine].set_visible(False)</p>
			<p class="source-code">&gt;&gt;&gt; axes[1].set_xscale('log')</p>
			<p class="source-code">&gt;&gt;&gt; plt.suptitle('successes vs. attempts by IP address')</p>
			<p>Our intuition about there being two<a id="_idIndexMarker1081"/> distinct clusters was dead-on. The middle area, however, was much trickier to determine. The blue (darker) points on the left do appear to be following a line upward, while the orange (lighter) points on the left are following a line to the orange cluster. By plotting the log of the attempts instead, we get a little more separation between our orange middle points and the blue points:</p>
			<div>
				<div id="_idContainer356" class="IMG---Figure">
					<img src="image/Figure_8.13_B16834.jpg" alt="Figure 8.13 – Using labeled data to check our intuition&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.13 – Using labeled data to check our intuition</p>
			<p>Remember, we can also use a box plot to check for possible outliers, which will be shown as points. Let's see what successes and attempts look like per IP address:</p>
			<p class="source-code">&gt;&gt;&gt; pivot[['attempts', 'success']].plot(</p>
			<p class="source-code">...     kind='box', subplots=True, figsize=(10, 3),</p>
			<p class="source-code">...     title='stats per IP address'</p>
			<p class="source-code">... )</p>
			<p>The points marked as outliers coincide with the points in the upper-right corner of the scatter plots we<a id="_idIndexMarker1082"/> made:</p>
			<div>
				<div id="_idContainer357" class="IMG---Figure">
					<img src="image/Figure_8.14_B16834.jpg" alt="Figure 8.14 – Checking for outliers&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.14 – Checking for outliers</p>
			<p>Now that we have a good understanding of our data, we are ready to learn how to implement a few simple anomaly detection strategies. </p>
			<h1 id="_idParaDest-180"><a id="_idTextAnchor179"/>Implementing rule-based anomaly detection </h1>
			<p>It's time to catch<a id="_idIndexMarker1083"/> those hackers. After the EDA in the previous section, we have an idea of how we might go about this. In practice, this is much more difficult to do, as it involves many more dimensions, but we have simplified it here. <strong class="bold">We want to find the IP addresses with excessive amounts of attempts accompanied by low success rates, and those attempting to log in with more unique usernames than we would deem normal (anomalies)</strong>. To do this, we will employ threshold-based rules as our first foray into anomaly detection; then, in <a href="B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237"><em class="italic">Chapter 11</em></a>, <em class="italic">Machine Learning Anomaly Detection</em>, we will explore a few machine learning techniques as we revisit this scenario.</p>
			<p>Since we are interested in flagging IP addresses that are suspicious, we are going to arrange the data so that we have hourly aggregated data per IP address (if there was activity for that<a id="_idIndexMarker1084"/> hour):</p>
			<p class="source-code">&gt;&gt;&gt; hourly_ip_logs = log.assign(</p>
			<p class="source-code">...     failures=lambda x: np.invert(x.success)</p>
			<p class="source-code">... ).groupby('source_ip').resample('1H').agg({</p>
			<p class="source-code">...     'username': 'nunique', 'success': 'sum', </p>
			<p class="source-code">...     'failures': 'sum'</p>
			<p class="source-code">... }).assign(</p>
			<p class="source-code">...     attempts=lambda x: x.success + x.failures,</p>
			<p class="source-code">...     success_rate=lambda x: x.success / x.attempts,</p>
			<p class="source-code">...     failure_rate=lambda x: 1 - x.success_rate</p>
			<p class="source-code">... ).dropna().reset_index()</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">The <strong class="source-inline">np.invert()</strong> function is an easy way to flip Boolean values. It turns <strong class="source-inline">True</strong> to <strong class="source-inline">False</strong> and <strong class="source-inline">False</strong> to <strong class="source-inline">True</strong> along a NumPy array-like structure.</p>
			<p>The aggregated data looks like this:</p>
			<div>
				<div id="_idContainer358" class="IMG---Figure">
					<img src="image/Figure_8.15_B16834.jpg" alt="Figure 8.15 – Hourly aggregated data per IP address&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.15 – Hourly aggregated data per IP address</p>
			<p>The simplest form of rule-based anomaly detection involves calculating a threshold value and checking to see whether the data is beyond the threshold. This could mean values falling below some<a id="_idIndexMarker1085"/> lower bound threshold, or values exceeding some upper bound threshold. Since we are looking at login attempts, we are interested in values that are greater than normal. Therefore, we will be calculating the threshold for our upper bounds and comparing that to our data.</p>
			<h2 id="_idParaDest-181"><a id="_idTextAnchor180"/>Percent difference</h2>
			<p>Provided that we have an <a id="_idIndexMarker1086"/>idea of what normal login attempt activity (minus the hackers) looks like on the site, we can flag values that deviate from this by a certain percentage. In order to calculate this baseline, we could take a few IP addresses at random with replacement for each hour, and average the number of login attempts they made. We are bootstrapping since we don't have much data (about 50 unique IP addresses to pick from for each of the 24 hours).</p>
			<p>To do this, we could write a function that takes in the aggregated dataframe we just made, along with the name of a statistic to calculate per column of the data to use as the starting point for the threshold:</p>
			<p class="source-code">&gt;&gt;&gt; def get_baselines(hourly_ip_logs, func, *args, **kwargs):</p>
			<p class="source-code">...     """</p>
			<p class="source-code">...     Calculate hourly bootstrapped statistic per column.</p>
			<p class="source-code">...</p>
			<p class="source-code">...     Parameters:</p>
			<p class="source-code">...         - hourly_ip_logs: Data to sample from.</p>
			<p class="source-code">...         - func: Statistic to calculate.</p>
			<p class="source-code">...         - args: Additional positional arguments for `func`</p>
			<p class="source-code">...         - kwargs: Additional keyword arguments for `func`</p>
			<p class="source-code">...</p>
			<p class="source-code">...     Returns: </p>
			<p class="source-code">...         `DataFrame` of hourly bootstrapped statistics</p>
			<p class="source-code">...     """</p>
			<p class="source-code">...     if isinstance(func, str):</p>
			<p class="source-code">...         func = getattr(pd.DataFrame, func)</p>
			<p class="source-code">...</p>
			<p class="source-code">...     return hourly_ip_logs.assign(</p>
			<p class="source-code">...         hour=lambda x: x.datetime.dt.hour</p>
			<p class="source-code">...     ).groupby('hour').apply(</p>
			<p class="source-code">...         lambda x: x\</p>
			<p class="source-code">...             .sample(10, random_state=0, replace=True)\</p>
			<p class="source-code">...             .pipe(func, *args, **kwargs, numeric_only=True)</p>
			<p class="source-code">...     )</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">In the previous code snippet, <strong class="source-inline">random_state</strong> is used with <strong class="source-inline">sample()</strong> for reproducibility; however, in practice, we will probably not want to always pick the same rows.</p>
			<p>Notice that we can get equally sized <a id="_idIndexMarker1087"/>samples for all groups (hours, here) if we use <strong class="source-inline">sample()</strong> inside <strong class="source-inline">apply()</strong> after grouping by the column we want to sample with. This means that we are selecting 10 rows with replacement per hour for each column. We have to sample by hour here because, if we do simple random sampling, there is a good chance we won't have a statistic for every hour. Let's use <strong class="source-inline">get_baselines()</strong> to calculate the column baselines using the mean:</p>
			<p class="source-code">&gt;&gt;&gt; <strong class="bold">averages = get_baselines(hourly_ip_logs, 'mean')</strong></p>
			<p class="source-code">&gt;&gt;&gt; averages.shape</p>
			<p class="source-code">(<strong class="bold">24</strong>, 7)</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">If, instead, we wanted to perform stratified random sampling, we could replace <strong class="source-inline">10</strong> in the <strong class="source-inline">get_baselines()</strong> function with <strong class="source-inline">x.shape[0] * pct</strong>, where <strong class="source-inline">pct</strong> is the percentage we want to sample from each group.</p>
			<p>Each column has the mean per <a id="_idIndexMarker1088"/>hour for the 10 IP addresses chosen randomly to estimate normal behavior. This technique, however, doesn't guarantee that we won't mix any of the hacker activity into our baseline calculations. For example, let's take a look at the six hours with the highest baseline values for failure rate:</p>
			<p class="source-code">&gt;&gt;&gt; averages.nlargest(6, 'failure_rate')</p>
			<p>We might find it difficult to flag any activity at hours <strong class="bold">19</strong>, <strong class="bold">23</strong>, or <strong class="bold">14</strong> with this baseline because the failure rate and unique usernames tried are both high:</p>
			<div>
				<div id="_idContainer359" class="IMG---Figure">
					<img src="image/Figure_8.16_B16834.jpg" alt="Figure 8.16 – Hourly baselines using the mean&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.16 – Hourly baselines using the mean</p>
			<p>To combat this issue, we could trim our summary statistics by making the top <em class="italic">x</em>% ineligible for use in our baseline calculation. Let's remove values greater than the 95<span class="superscript">th</span> percentile of data from each <a id="_idIndexMarker1089"/>hour. First, we will write a function to trim rows from a given hour that have data above a given quantile:</p>
			<p class="source-code">&gt;&gt;&gt; def trim(x, quantile):</p>
			<p class="source-code">...     """</p>
			<p class="source-code">...     Remove rows with entries for the username, attempts, </p>
			<p class="source-code">...     or failure_rate columns above a given quantile.</p>
			<p class="source-code">...     """</p>
			<p class="source-code">...     mask = (</p>
			<p class="source-code">...         (x.username &lt;= x.username.quantile(quantile)) &amp;</p>
			<p class="source-code">...         (x.attempts &lt;= x.attempts.quantile(quantile)) &amp;</p>
			<p class="source-code">...         (x.failure_rate</p>
			<p class="source-code">...          &lt;= x.failure_rate.quantile(quantile))</p>
			<p class="source-code">...     )</p>
			<p class="source-code">...     return x[mask]</p>
			<p>Next, we will group the IP address data by hour and apply our trimming function. Since we will be using our bootstrapping function, we need to clean up some of the extra columns that will result from this operation, so we drop the <strong class="source-inline">hour</strong> column, reset the index, and then remove the grouping column and the old index:</p>
			<p class="source-code">&gt;&gt;&gt; trimmed_hourly_logs = hourly_ip_logs\</p>
			<p class="source-code">...     .assign(hour=lambda x: x.datetime.dt.hour)\</p>
			<p class="source-code">...     .groupby('hour').apply(lambda x: trim(x, 0.95))\</p>
			<p class="source-code">...     .drop(columns='hour').reset_index().iloc[:,2:]</p>
			<p>Now, we can use the <strong class="source-inline">get_baselines()</strong> function to grab our baseline using the average with<a id="_idIndexMarker1090"/> the trimmed data:</p>
			<p class="source-code">&gt;&gt;&gt; averages = get_baselines(trimmed_hourly_logs, 'mean')</p>
			<p class="source-code">&gt;&gt;&gt; averages.iloc[[19, 23, 3, 11, 14, 16]]</p>
			<p>The trimmed baseline is now quite different from <em class="italic">Figure 8.16</em> at hours <strong class="bold">19</strong>, <strong class="bold">23</strong>, and <strong class="bold">14</strong>:</p>
			<div>
				<div id="_idContainer360" class="IMG---Figure">
					<img src="image/Figure_8.17_B16834.jpg" alt="Figure 8.17 – Trimmed hourly baselines using the mean&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.17 – Trimmed hourly baselines using the mean</p>
			<p>Now that we have our baseline, let's write a function that will do the heavy lifting of calculating the threshold from our baseline and the percentage difference per column, returning the IP addresses that have been flagged as hackers:</p>
			<p class="source-code">&gt;&gt;&gt; def pct_change_threshold(hourly_ip_logs, baselines,</p>
			<p class="source-code">...                          pcts=None):</p>
			<p class="source-code">...     """</p>
			<p class="source-code">...     Return flagged IP addresses based on thresholds.</p>
			<p class="source-code">...</p>
			<p class="source-code">...     Parameters:</p>
			<p class="source-code">...         - hourly_ip_logs: Aggregated data per IP address.</p>
			<p class="source-code">...         - baselines: Hourly baselines per column in data.</p>
			<p class="source-code">...         - pcts: Dictionary of custom percentages per column </p>
			<p class="source-code">...           for calculating upper bound thresholds</p>
			<p class="source-code">...           (baseline * pct). If not provided, pct will be 1</p>
			<p class="source-code">...</p>
			<p class="source-code">...     Returns: `Series` containing the IP addresses flagged.</p>
			<p class="source-code">...     """</p>
			<p class="source-code">...     pcts = {} if not pcts else pcts</p>
			<p class="source-code">...</p>
			<p class="source-code">...     return hourly_ip_logs.assign(</p>
			<p class="source-code">...         hour=lambda x: x.datetime.dt.hour</p>
			<p class="source-code">...     ).join(</p>
			<p class="source-code">...         baselines, on='hour', <strong class="bold">rsuffix='_baseline'</strong></p>
			<p class="source-code">...     ).assign(</p>
			<p class="source-code">...         <strong class="bold">too_many_users=lambda x: x.username_baseline \</strong></p>
			<p class="source-code">...  <strong class="bold">           * pcts.get('username', 1) &lt;= x.username,</strong></p>
			<p class="source-code">...  <strong class="bold">       too_many_attempts=lambda x: x.attempts_baseline \</strong></p>
			<p class="source-code">...  <strong class="bold">           * pcts.get('attempts', 1) &lt;= x.attempts,</strong></p>
			<p class="source-code">...<strong class="bold">         high_failure_rate=lambda x: \</strong></p>
			<p class="source-code">...<strong class="bold">             x.failure_rate_baseline \</strong></p>
			<p class="source-code">...<strong class="bold">             * pcts.get('failure_rate', 1) &lt;= x.failure_rate</strong></p>
			<p class="source-code">...     ).<strong class="bold">query(</strong></p>
			<p class="source-code">...  <strong class="bold">       'too_many_users and too_many_attempts '</strong></p>
			<p class="source-code">...         <strong class="bold">'and high_failure_rate'</strong></p>
			<p class="source-code">...  <strong class="bold">   )</strong>.source_ip.drop_duplicates()</p>
			<p>The <strong class="source-inline">pct_change_threshold()</strong> function uses a series of chained operations to give us the flagged IP addresses:</p>
			<ol>
				<li>First, it joins the baselines to the <a id="_idIndexMarker1091"/>hourly IP address logs on the <strong class="source-inline">hour</strong> column. Since all the baseline columns have the same names as the hourly IP address logs, and we don't want to join on them, we suffix their names with <strong class="source-inline">'_baseline'</strong>.</li>
				<li>After that, all the data we need to check whether the thresholds were exceeded is in the same dataframe. We use <strong class="source-inline">assign()</strong> to make three new Boolean columns, indicating whether each of our conditions (too many users, too many attempts, and high failure rate) has been violated.</li>
				<li>Then, we chain a call to the <strong class="source-inline">query()</strong> method, which lets us easily select rows where all of these Boolean columns are <strong class="source-inline">True</strong> (notice we don't need to explicitly say <strong class="source-inline">&lt;column&gt; == True</strong>).</li>
				<li>Lastly, we make sure to return just the IP addresses and to drop any duplicates in case the same IP address was flagged for multiple hours.</li>
			</ol>
			<p>In order to use this function, we need to pick a percentage difference from each of our baselines. By default, that will be 100% of the baseline, which, since it is the average, will flag way too many IP addresses. Instead, let's get the IP addresses this flags with values 25% higher than the baseline for each criterion:</p>
			<p class="source-code">&gt;&gt;&gt; pct_from_mean_ips = pct_change_threshold(</p>
			<p class="source-code">...     hourly_ip_logs, averages, </p>
			<p class="source-code">...     {key: <strong class="bold">1.25</strong> for key in [</p>
			<p class="source-code">...         'username', 'attempts', 'failure_rate'</p>
			<p class="source-code">...     ]}</p>
			<p class="source-code">... )</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">The percentages we use are in a dictionary, with the key being the column they are for and the value being the percentage itself. If the caller of the function doesn't provide these, we have default values of 100%, since we are using <strong class="source-inline">get()</strong> to select from the dictionary.</p>
			<p>These rules flagged <a id="_idIndexMarker1092"/>73 IP addresses:</p>
			<p class="source-code">&gt;&gt;&gt; pct_from_mean_ips.nunique()</p>
			<p class="source-code">73</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">In practice, we probably wouldn't run this rule on the entries used to calculate the baselines because they influence the definition of the baseline with their behavior.</p>
			<h2 id="_idParaDest-182"><a id="_idTextAnchor181"/>Tukey fence</h2>
			<p>As we discussed in <a href="B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to Data Analysis</em>, the mean is not robust to outliers. If we feel there are many outliers influencing our baselines, we could go back to the percent difference <a id="_idIndexMarker1093"/>and try out the median or look into using a <strong class="bold">Tukey fence</strong>. Remember from previous chapters that the Tukey fence gets its bounds <a id="_idIndexMarker1094"/>from the first and third quartiles and the <strong class="bold">interquartile range</strong> (<strong class="bold">IQR</strong>). Since we only care about exceeding the<a id="_idIndexMarker1095"/> upper bound, this solves the issue with the mean, provided that outliers make up less than 25% of our data. We can use the following to calculate the upper bound:</p>
			<div>
				<div id="_idContainer361" class="IMG---Figure">
					<img src="image/Formula_08_005.jpg" alt=""/>
				</div>
			</div>
			<p>Our <strong class="source-inline">get_baselines()</strong> function will still help us, but we need to do some additional processing. We will write a function<a id="_idIndexMarker1096"/> that will calculate the upper bound of the Tukey fence and let us test out various values for the multiplier (<strong class="source-inline">k</strong>). Notice that we also have the<a id="_idIndexMarker1097"/> option to use percentages with the Tukey fence here:</p>
			<p class="source-code">&gt;&gt;&gt; def tukey_fence_test(trimmed_data, logs, k, pct=None):</p>
			<p class="source-code">...     """</p>
			<p class="source-code">...     See which IP addresses get flagged with a Tukey fence </p>
			<p class="source-code">...     with multiplier k and optional percent differences.</p>
			<p class="source-code">...  </p>
			<p class="source-code">...     Parameters: </p>
			<p class="source-code">...         - trimmed_data: Data for calculating the baselines</p>
			<p class="source-code">...         - logs: The data to test</p>
			<p class="source-code">...         - k: The multiplier for the IQR</p>
			<p class="source-code">...         - pct: Dictionary of percentages per column for use </p>
			<p class="source-code">...                with `pct_change_threshold()`</p>
			<p class="source-code">...</p>
			<p class="source-code">...     Returns: </p>
			<p class="source-code">...         `pandas.Series` of flagged IP addresses</p>
			<p class="source-code">...     """</p>
			<p class="source-code">...     q3 = get_baselines(trimmed_data, 'quantile', .75)\</p>
			<p class="source-code">...         .drop(columns=['hour'])</p>
			<p class="source-code">...</p>
			<p class="source-code">...     q1 = get_baselines(trimmed_data, 'quantile', .25)\</p>
			<p class="source-code">...         .drop(columns=['hour'])</p>
			<p class="source-code">...</p>
			<p class="source-code">...     iqr = q3 - q1</p>
			<p class="source-code">...     upper_bound = (q3 + k * iqr).reset_index()</p>
			<p class="source-code">...</p>
			<p class="source-code">...     return <strong class="bold">pct_change_threshold(logs, upper_bound, pct)</strong></p>
			<p>Let's use the <strong class="source-inline">tukey_fence_test()</strong> function to grab the IP addresses that exceed the upper bound <a id="_idIndexMarker1098"/>of the Tukey fence using an <a id="_idIndexMarker1099"/>IQR multiplier of <strong class="source-inline">3</strong>:</p>
			<p class="source-code">&gt;&gt;&gt; tukey_fence_ips = tukey_fence_test(</p>
			<p class="source-code">...     trimmed_hourly_logs, hourly_ip_logs, k=3</p>
			<p class="source-code">... )</p>
			<p>With this method, we flag 83 IP addresses:</p>
			<p class="source-code">&gt;&gt;&gt; tukey_fence_ips.nunique()</p>
			<p class="source-code">83</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">We used a multiplier of 3 here. However, depending on the application, we may see 1.5 used in order to be less restrictive. In reality, we can use any number; finding the best one may require some trial and error.</p>
			<h2 id="_idParaDest-183"><a id="_idTextAnchor182"/>Z-score</h2>
			<p>Remember, from <a href="B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to Data Analysis</em>, that we can also calculate Z-scores and flag IP addresses a given number of standard deviations from the mean. The <strong class="source-inline">pct_change_threshold()</strong> function we wrote earlier won't help us as is, since we aren't just <a id="_idIndexMarker1100"/>comparing with the baseline. Instead, we need to subtract the baseline for the mean from all the values and divide by the baseline for the standard deviation, so we must rework our approach.</p>
			<p>Let's write a new function, <strong class="source-inline">z_score_test()</strong>, to perform our Z-score tests using any number of standard deviations above the mean as a cutoff. First, we will use the <strong class="source-inline">get_baselines()</strong> function to calculate the baseline standard deviations by hour with the trimmed data. Then, we join the standard deviations and means together, adding the suffixes. This allows us to adapt the logic of <strong class="source-inline">pct_change_threshold()</strong> for this task:</p>
			<p class="source-code">&gt;&gt;&gt; def z_score_test(trimmed_data, logs, cutoff):</p>
			<p class="source-code">...     """</p>
			<p class="source-code">...     See which IP addresses get flagged with a Z-score</p>
			<p class="source-code">...     greater than or equal to a cutoff value.</p>
			<p class="source-code">...</p>
			<p class="source-code">...     Parameters: </p>
			<p class="source-code">...         - trimmed_data: Data for calculating the baselines</p>
			<p class="source-code">...         - logs: The data to test</p>
			<p class="source-code">...         - cutoff: Flag row when z_score &gt;= cutoff</p>
			<p class="source-code">...</p>
			<p class="source-code">...     Returns: </p>
			<p class="source-code">...         `pandas.Series` of flagged IP addresses</p>
			<p class="source-code">...     """</p>
			<p class="source-code">...     std_dev = get_baselines(trimmed_data, 'std')\</p>
			<p class="source-code">...         .drop(columns=['hour'])</p>
			<p class="source-code">...     averages = get_baselines(trimmed_data, 'mean')\</p>
			<p class="source-code">...         .drop(columns=['hour'])</p>
			<p class="source-code">...</p>
			<p class="source-code">...     return logs.assign(hour=lambda x: x.datetime.dt.hour)\</p>
			<p class="source-code">...         .join(std_dev.join(</p>
			<p class="source-code">...             averages, lsuffix='_std', rsuffix='_mean'</p>
			<p class="source-code">...         ), on='hour')\</p>
			<p class="source-code">...         .assign(</p>
			<p class="source-code">...             <strong class="bold">too_many_users=lambda x: (</strong></p>
			<p class="source-code">...  <strong class="bold">               x.username - x.username_mean</strong></p>
			<p class="source-code">...  <strong class="bold">           )/x.username_std &gt;= cutoff,</strong></p>
			<p class="source-code">...  <strong class="bold">           too_many_attempts=lambda x: (</strong></p>
			<p class="source-code">...  <strong class="bold">               x.attempts - x.attempts_mean</strong></p>
			<p class="source-code">...  <strong class="bold">           )/x.attempts_std &gt;= cutoff,</strong></p>
			<p class="source-code">...  <strong class="bold">           high_failure_rate=lambda x: (</strong></p>
			<p class="source-code">...  <strong class="bold">               x.failure_rate - x.failure_rate_mean</strong></p>
			<p class="source-code">...  <strong class="bold">           )/x.failure_rate_std &gt;= cutoff</strong></p>
			<p class="source-code">...         ).query(</p>
			<p class="source-code">...             'too_many_users and too_many_attempts '</p>
			<p class="source-code">...             'and high_failure_rate'</p>
			<p class="source-code">...         ).source_ip.drop_duplicates()</p>
			<p>Let's call our <a id="_idIndexMarker1101"/>function with a cutoff of three or more standard deviations from the mean:</p>
			<p class="source-code">&gt;&gt;&gt; z_score_ips = \</p>
			<p class="source-code">...     z_score_test(trimmed_hourly_logs, hourly_ip_logs, 3)</p>
			<p>With this method, we<a id="_idIndexMarker1102"/> flag 62 IP addresses:</p>
			<p class="source-code">&gt;&gt;&gt; z_score_ips.nunique()</p>
			<p class="source-code">62</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">In practice, the cutoff value for the Z-score is also a parameter we will want to tune.</p>
			<h2 id="_idParaDest-184"><a id="_idTextAnchor183"/>Evaluating performance</h2>
			<p>So, we now have a<a id="_idIndexMarker1103"/> series of IP addresses for each set of rules, but we would like to know how well each method did (assuming we can actually check). In this case, we have the attacker IP addresses for our research, so we can see how many each method got right—this is not so trivial in practice; instead, we could mark things that we have discovered to be malicious in the past and look out for similar behavior in the future.</p>
			<p>This is a classification<a id="_idIndexMarker1104"/> problem with two classes; we want to classify each IP address as either a valid user or a nefarious one. This leaves us with four possible outcomes that we can visualize using a <strong class="bold">confusion matrix</strong>:</p>
			<div>
				<div id="_idContainer362" class="IMG---Figure">
					<img src="image/Figure_8.18_B16834.jpg" alt="Figure 8.18 – The confusion matrix&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.18 – The confusion matrix</p>
			<p>In this application, these<a id="_idIndexMarker1105"/> outcomes mean the following:</p>
			<ul>
				<li><strong class="bold">True Positive (TP)</strong>: Our method flagged it as malicious, and it was.</li>
				<li><strong class="bold">True Negative (TN)</strong>: Our method didn't flag it, and it wasn't malicious.</li>
				<li><strong class="bold">False Positive (FP)</strong>: Our method flagged it, but it wasn't malicious.</li>
				<li><strong class="bold">False Negative (FN)</strong>: Our method didn't flag it, but it was malicious.</li>
			</ul>
			<p>True positives and true negatives mean our method did well, but false positives and false negatives are possible areas for improvement (bear in mind that this will never be perfect). Let's now write a function that will help determine where each method stands:</p>
			<p class="source-code">&gt;&gt;&gt; def evaluate(alerted_ips, attack_ips, log_ips):</p>
			<p class="source-code">...     """</p>
			<p class="source-code">...     Calculate true positives (TP), false positives (FP),</p>
			<p class="source-code">...     true negatives (TN), and false negatives (FN) for </p>
			<p class="source-code">...     IP addresses flagged as suspicious.</p>
			<p class="source-code">...</p>
			<p class="source-code">...     Parameters:</p>
			<p class="source-code">...         - alerted_ips: `Series` of flagged IP addresses</p>
			<p class="source-code">...         - attack_ips: `Series` of attacker IP addresses</p>
			<p class="source-code">...         - log_ips: `Series` of all IP addresses seen</p>
			<p class="source-code">...</p>
			<p class="source-code">...     Returns:</p>
			<p class="source-code">...         Tuple of the form (TP, FP, TN, FN)</p>
			<p class="source-code">...     """</p>
			<p class="source-code">...     tp = alerted_ips.isin(attack_ips).sum()</p>
			<p class="source-code">...     tn = np.invert(np.isin(</p>
			<p class="source-code">...         log_ips[~log_ips.isin(alerted_ips)].unique(),</p>
			<p class="source-code">...         attack_ips</p>
			<p class="source-code">...     )).sum()</p>
			<p class="source-code">...     fp = np.invert(alerted_ips.isin(attack_ips)).sum()</p>
			<p class="source-code">...     fn = np.invert(attack_ips.isin(alerted_ips)).sum()</p>
			<p class="source-code">...     return tp, fp, tn, fn</p>
			<p>Before we begin calculating <a id="_idIndexMarker1106"/>metrics, let's make a partial function so we don't have to keep passing in the series of attacker IP addresses (<strong class="source-inline">attacks.source_ip</strong>) and IP addresses in the logs (<strong class="source-inline">pivot.index</strong>). Remember, a partial function allows us to fix the values for certain arguments and call the function later:</p>
			<p class="source-code">&gt;&gt;&gt; from functools import partial</p>
			<p class="source-code">&gt;&gt;&gt; scores = partial(</p>
			<p class="source-code">...     evaluate, attack_ips=attacks.source_ip,</p>
			<p class="source-code">...     log_ips=pivot.index</p>
			<p class="source-code">... )</p>
			<p>Now, let's use this to calculate some metrics to measure our performance. One common metric is the <strong class="bold">false positive rate</strong> (<strong class="bold">FPR</strong>), which tells us the <strong class="bold">false alarm rate</strong>. It is calculated by taking the<a id="_idIndexMarker1107"/> ratio of false <a id="_idIndexMarker1108"/>positives to everything <a id="_idIndexMarker1109"/>that was actually negative:</p>
			<div>
				<div id="_idContainer363" class="IMG---Figure">
					<img src="image/Formula_08_001.jpg" alt=""/>
				</div>
			</div>
			<p>The <strong class="bold">false discovery rate</strong> (<strong class="bold">FDR</strong>), which tells <a id="_idIndexMarker1110"/>us the percentage of positives that are incorrect, is another way of looking at false alarms:</p>
			<div>
				<div id="_idContainer364" class="IMG---Figure">
					<img src="image/Formula_08_002.jpg" alt=""/>
				</div>
			</div>
			<p>Let's see what the FPR and FDR are for our percent difference from the mean approach:</p>
			<p class="source-code">&gt;&gt;&gt; tp, fp, tn, fn = scores(pct_from_mean_ips)</p>
			<p class="source-code">&gt;&gt;&gt; fp / (fp + tn), fp / (fp + tp)</p>
			<p class="source-code">(0.00392156862745098, 0.0136986301369863)</p>
			<p>Another metric<a id="_idIndexMarker1111"/> of interest is the <strong class="bold">false negative rate</strong> (<strong class="bold">FNR</strong>), which tells us what we<a id="_idIndexMarker1112"/> fail to detect (the <strong class="bold">miss rate</strong>). It is calculated by taking the ratio of false negatives to everything that was actually positive:</p>
			<div>
				<div id="_idContainer365" class="IMG---Figure">
					<img src="image/Formula_08_003.jpg" alt=""/>
				</div>
			</div>
			<p>An alternative way of looking at <a id="_idIndexMarker1113"/>false negatives is the <strong class="bold">false omission rate</strong> (<strong class="bold">FOR</strong>), which tells us the percentage of cases we incorrectly mark as negatives:</p>
			<div>
				<div id="_idContainer366" class="IMG---Figure">
					<img src="image/Formula_08_004.jpg" alt=""/>
				</div>
			</div>
			<p>Our percent difference from the mean method has no false negatives, so both FNR and FOR are zero:</p>
			<p class="source-code">&gt;&gt;&gt; fn / (fn + tp), fn / (fn + tn)</p>
			<p class="source-code">(0.0, 0.0)</p>
			<p>There is typically a<a id="_idIndexMarker1114"/> trade-off here—do we want to catch as many hackers as possible, and risk flagging valid users (by focusing on FNR/FOR), or do we want to keep from inconveniencing our valid users and risk missing hacker activity (by minimizing FPR/FDR)? These questions are tough to answer and will depend on the domain, as the cost of false positives is not necessarily equal to (or even close in scale to) the cost of false negatives.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">We will discuss additional metrics that can be used to evaluate our performance in <a href="B16834_09_Final_SK_ePub.xhtml#_idTextAnchor188"><em class="italic">Chapter 9</em></a>, <em class="italic">Getting Started with Machine Learning in Python</em>.</p>
			<p>Let's now write a function to handle all these calculations for us:</p>
			<p class="source-code">&gt;&gt;&gt; def classification_stats(tp, fp, tn, fn):</p>
			<p class="source-code">...     """Calculate metrics"""</p>
			<p class="source-code">...     return {</p>
			<p class="source-code">...         'FPR': fp / (fp + tn), 'FDR': fp / (fp + tp),</p>
			<p class="source-code">...         'FNR': fn / (fn + tp), 'FOR': fn / (fn + tn)</p>
			<p class="source-code">...     }</p>
			<p>We can now use the results from the <strong class="source-inline">evaluate()</strong> function to calculate our metrics. For the percentage<a id="_idIndexMarker1115"/> difference from the mean, we get the following output:</p>
			<p class="source-code">&gt;&gt;&gt; classification_stats(tp, fp, tn, fn)</p>
			<p class="source-code">{'FPR': 0.00392156862745098, 'FDR': 0.0136986301369863,</p>
			<p class="source-code"> 'FNR': 0.0, 'FOR': 0.0}</p>
			<p>It looks like our trio of criteria did quite well. If we were concerned with the hacker IP addresses being chosen when we calculated the baselines, but didn't want to trim, we could have run this with the median instead of the mean:</p>
			<p class="source-code">&gt;&gt;&gt; medians = get_baselines(hourly_ip_logs, <strong class="bold">'median'</strong>)</p>
			<p class="source-code">&gt;&gt;&gt; pct_from_median_ips = pct_change_threshold(</p>
			<p class="source-code">...     hourly_ip_logs, medians, </p>
			<p class="source-code">...     {key: 1.25 for key in</p>
			<p class="source-code">...      ['username', 'attempts', 'failure_rate']}</p>
			<p class="source-code">... )</p>
			<p>Using the median, we achieve similar performance to the mean. In this case, however, we didn't need to trim the data beforehand. This is because the median is robust to outliers, meaning that picking a single hacker IP address in a given hour doesn't affect that hour's baseline as it would the mean:</p>
			<p class="source-code">&gt;&gt;&gt; tp, fp, tn, fn = scores(pct_from_median_ips)</p>
			<p class="source-code">&gt;&gt;&gt; classification_stats(tp, fp, tn, fn)</p>
			<p class="source-code">{'FPR': 0.00784313725490196, 'FDR': 0.02702702702702703,</p>
			<p class="source-code"> 'FNR': 0.0, 'FOR': 0.0}</p>
			<p>To compare each of the methods discussed, we can use dictionary comprehensions to populate a <strong class="source-inline">DataFrame</strong> object with <a id="_idIndexMarker1116"/>the performance metrics:</p>
			<p class="source-code">&gt;&gt;&gt; pd.DataFrame({</p>
			<p class="source-code">...     method: classification_stats(*scores(ips))</p>
			<p class="source-code">...     for method, ips in {</p>
			<p class="source-code">...         'means': pct_from_mean_ips,</p>
			<p class="source-code">...         'medians': pct_from_median_ips,</p>
			<p class="source-code">...         'Tukey fence': tukey_fence_ips,</p>
			<p class="source-code">...         'Z-scores': z_score_ips</p>
			<p class="source-code">...     }.items()</p>
			<p class="source-code">... })</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">The <strong class="source-inline">scores()</strong> function returns a tuple of <strong class="source-inline">(tp, fp, tn, fn)</strong>, but the <strong class="source-inline">classification_stats()</strong> function expects four arguments. However, since <strong class="source-inline">scores()</strong> returns them in the same order that <strong class="source-inline">classification_stats()</strong> expects them, we can use <strong class="source-inline">*</strong> to unpack the tuple and send the values as four positional arguments.</p>
			<p>The mean is affected by outliers, but once we trimmed the data, it became a viable method. We didn't need to trim the data to work with the median; the usefulness of the median hinges on the data containing fewer than 50% outliers. The Tukey fence takes this a step further by using the third quartile and assuming that fewer than 25% of the data points are outliers. The Z-score method is also affected by outliers because it uses the mean; however, with the trimmed data, we were able to achieve good performance with a modest cutoff of three:</p>
			<div>
				<div id="_idContainer367" class="IMG---Figure">
					<img src="image/Figure_8.19_B16834.jpg" alt="Figure 8.19 – Comparing performance&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.19 – Comparing performance</p>
			<p>Ultimately, which method<a id="_idIndexMarker1117"/> we use in practice will depend on how costly it is to have a false positive versus a false negative—is it worse to raise the alarm when nothing is wrong, or to be silent when something is? In this case, we would err on the side of minimizing false negatives since we don't want to miss anything.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Another common use case for anomaly detection is in quality or process control in industrial settings, such as monitoring factory equipment performance and output. Process control uses threshold-based and pattern-based rules to determine whether systems are out of control. These can be used for things such as determining when the distribution of the underlying <a id="_idIndexMarker1118"/>data has changed, which could be a precursor for later problems. <strong class="bold">Western Electric rules</strong> and <strong class="bold">Nelson rules</strong> are common ones. References for both<a id="_idIndexMarker1119"/> can be found in the <em class="italic">Further reading</em> section at the end of this chapter.</p>
			<h1 id="_idParaDest-185"><a id="_idTextAnchor184"/>Summary</h1>
			<p>In our second application chapter, we learned how to simulate events in Python and got additional exposure to writing packages. We also saw how to write Python scripts that can be run from the command line, which we used to run our simulation of the login attempt data. Then, we performed some EDA on the simulated data to see whether we could figure out what would make hacker activity easy to spot.</p>
			<p>This led us to zero in on the number of distinct usernames attempting to authenticate per IP address per hour, as well as the number of attempts and failure rates. Using these metrics, we were able to create a scatter plot, which appeared to show two distinct groups of points, along with some other points connecting the two groups; naturally, these represented the groups of valid users and the nefarious ones, with some of the hackers not being as obvious as others.</p>
			<p>Finally, we set about creating rules that would flag the hacker IP addresses for their suspicious activity. First, we used <strong class="source-inline">pandas</strong> to reshape our data into hourly aggregates per IP address. Then, we wrote functions to trim values greater than the 95<span class="superscript">th</span> percentile and calculate baselines for a given statistic per hour, which we used to create our rules based on percentage difference from the mean and median, exceeding the upper bound of a Tukey fence, and using Z-scores. We saw that building good rules depended on carefully tuning our parameters: the percentage for the differences from the mean and median, the multiplier for the Tukey fence, and the threshold for the Z-score. To determine which of the rules was performing the best, we used the miss rate, false omission rate, false discovery rate, and the false alarm rate.</p>
			<p>In the next two chapters, we will introduce machine learning in Python using <strong class="source-inline">scikit-learn</strong>, and in <a href="B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237"><em class="italic">Chapter 11</em></a>, <em class="italic">Machine Learning Anomaly Detection</em>, we will revisit this scenario for anomaly detection using machine learning.</p>
			<h1 id="_idParaDest-186"><a id="_idTextAnchor185"/>Exercises</h1>
			<p>Complete the following exercises to practice the concepts covered in this chapter:</p>
			<ol>
				<li value="1">Run the simulation for December 2018 into new log files without making the user base again. Be sure to run <strong class="source-inline">python3 simulate.py -h</strong> to review the command-line arguments. Set the seed to <strong class="source-inline">27</strong>. This data will be used for the remaining exercises.</li>
				<li>Find the number of unique usernames, attempts, successes, and failures, as well as the success/failure rates per IP address, using the data simulated from exercise <em class="italic">1</em>.</li>
				<li>Create two subplots with failures versus attempts on the left, and failure rate versus distinct usernames on the right. Draw decision boundaries for the resulting plots. Be sure to color each data point by whether or not it is a hacker IP address.</li>
				<li>Build a rule-based criteria using the percentage difference from the median that flags an IP address if the failures and attempts are both five times their respective medians, or if the distinct usernames count is five times its median. Be sure to use a one-hour window. Remember to use the <strong class="source-inline">get_baselines()</strong> function to calculate the metrics needed for the baselines.</li>
				<li>Calculate metrics to evaluate how well these rules performed using the <strong class="source-inline">evaluate()</strong> and <strong class="source-inline">classification_stats()</strong> functions from this chapter.</li>
			</ol>
			<h1 id="_idParaDest-187"><a id="_idTextAnchor186"/>Further reading</h1>
			<p>Check out the following resources for more information on the topics covered in this chapter:</p>
			<ul>
				<li><em class="italic">A Gentle Introduction to the Bootstrap Method</em>: <a href="https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/">https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/</a></li>
				<li><em class="italic">An Introduction to the Bootstrap Method</em>: <a href="https://towardsdatascience.com/an-introduction-to-the-bootstrap-method-58bcb51b4d60">https://towardsdatascience.com/an-introduction-to-the-bootstrap-method-58bcb51b4d60</a></li>
				<li><em class="italic">Adding Salt to Hashing: A Better Way to Store Passwords</em>: <a href="https://auth0.com/blog/adding-salt-to-hashing-a-better-way-to-store-passwords/">https://auth0.com/blog/adding-salt-to-hashing-a-better-way-to-store-passwords/</a></li>
				<li><em class="italic">Brute-Force Attack</em>: <a href="https://en.wikipedia.org/wiki/Brute-force_attack">https://en.wikipedia.org/wiki/Brute-force_attack</a></li>
				<li><em class="italic">Classification Accuracy Is Not Enough: More Performance Measures You Can Use</em>: <a href="https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/">https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/</a></li>
				<li><em class="italic">Dictionary Attack</em>: <a href="https://en.wikipedia.org/wiki/Dictionary_attack">https://en.wikipedia.org/wiki/Dictionary_attack</a></li>
				<li><em class="italic">Nelson Rules</em>: <a href="https://en.wikipedia.org/wiki/Nelson_rules">https://en.wikipedia.org/wiki/Nelson_rules</a></li>
				<li><em class="italic">Offline Password Cracking: The Attack and the Best Defense</em>: <a href="https://www.alpinesecurity.com/blog/offline-password-cracking-the-attack-and-the-best-defense-against-it">https://www.alpinesecurity.com/blog/offline-password-cracking-the-attack-and-the-best-defense-against-it</a></li>
				<li><em class="italic">Poisson Point Process</em>: <a href="https://en.wikipedia.org/wiki/Poisson_point_process">https://en.wikipedia.org/wiki/Poisson_point_process</a></li>
				<li><em class="italic">Precision and Recall</em>: <a href="https://en.wikipedia.org/wiki/Precision_and_recall">https://en.wikipedia.org/wiki/Precision_and_recall</a></li>
				<li><em class="italic">Probability Distributions in Python</em>: <a href="https://www.datacamp.com/community/tutorials/probability-distributions-python">https://www.datacamp.com/community/tutorials/probability-distributions-python</a></li>
				<li><em class="italic">Rainbow Tables: Your Password's Worst Nightmare</em>: <a href="https://www.lifewire.com/rainbow-tables-your-passwords-worst-nightmare-2487288">https://www.lifewire.com/rainbow-tables-your-passwords-worst-nightmare-2487288</a></li>
				<li><em class="italic">RFC 1597 (Address Allocation for Private Internets)</em>: <a href="http://www.faqs.org/rfcs/rfc1597.html">http://www.faqs.org/rfcs/rfc1597.html</a></li>
				<li><em class="italic">Sampling Techniques</em>: <a href="https://towardsdatascience.com/sampling-techniques-a4e34111d808">https://towardsdatascience.com/sampling-techniques-a4e34111d808</a></li>
				<li><em class="italic">Trimmed Estimator</em>: <a href="https://en.wikipedia.org/wiki/Trimmed_estimator">https://en.wikipedia.org/wiki/Trimmed_estimator</a></li>
				<li><em class="italic">Western Electric rules</em>: <a href="https://en.wikipedia.org/wiki/Western_Electric_rules">https://en.wikipedia.org/wiki/Western_Electric_rules</a></li>
			</ul>
		</div>
	</body></html>