- en: '*Chapter 8*: Rule-Based Anomaly Detection'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's time to catch some hackers trying to gain access to a website using a **brute-force
    attack**—trying to log in with a bunch of username-password combinations until
    they gain access. This type of attack is very noisy, so it gives us plenty of
    data points for **anomaly detection**, which is the process of looking for data
    generated from a process other than the one we deem to be typical activity. The
    hackers will be simulated and won't be as crafty as they can be in real life,
    but it will give us great exposure to anomaly detection.
  prefs: []
  type: TYPE_NORMAL
- en: We will be creating a package that will handle the simulation of the login attempts
    in order to generate the data for this chapter. Knowing how to simulate is an
    essential skill to have in our toolbox. Sometimes, it's difficult to solve a problem
    with an exact mathematical solution; however, it might be easy to define how small
    components of the system work. In these cases, we can model the small components
    and simulate the behavior of the system as a whole. The result of the simulation
    gives us an approximation of the solution that may be sufficient for our purposes.
  prefs: []
  type: TYPE_NORMAL
- en: We will utilize rule-based anomaly detection to identify suspicious activity
    in the simulated data. By the end of this chapter, we will have an understanding
    of how to simulate data using random numbers generated from various probability
    distributions, get more exposure to the Python standard library, gain additional
    experience building Python packages, practice performing exploratory data analysis,
    and get an introduction to anomaly detection.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Simulating login attempts to create our dataset for the chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing exploratory data analysis to understand the simulated data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using rules and baselines for anomaly detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter materials
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will be building a simulation package to generate the data for this chapter;
    it is on GitHub at [https://github.com/stefmolin/login-attempt-simulator/tree/2nd_edition](https://github.com/stefmolin/login-attempt-simulator/tree/2nd_edition).
    This package was installed from GitHub when we set up our environment back in
    [*Chapter 1*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015), *Introduction to
    Data Analysis*; however, you can follow the instructions in [*Chapter 7*](B16834_07_Final_SK_ePub.xhtml#_idTextAnchor146),
    *Financial Analysis – Bitcoin and the Stock Market*, to install a version of the
    package that you can edit.
  prefs: []
  type: TYPE_NORMAL
- en: The repository for this chapter, which can be found at [https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch_08](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/tree/master/ch_08),
    has the notebook we will use for our actual analysis (`anomaly_detection.ipynb`),
    the data files we will be working with in the `logs/` folder, the data used for
    the simulation in the `user_data/` folder, and the `simulate.py` file, which contains
    a Python script that we can run on the command line to simulate the data for the
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Simulating login attempts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since we can't easily find login attempt data from a breach (it's not typically
    shared due to its sensitive nature), we will be simulating it. Simulation requires
    a strong understanding of statistical modeling, estimating probabilities of certain
    events, and identifying appropriate assumptions to simplify where necessary. In
    order to run the simulation, we will build a Python package (`login_attempt_simulator`)
    to simulate a login process requiring a correct username and password (without
    any extra authentication measures, such as two-factor authentication) and a script
    (`simulate.py`) that can be run on the command line, both of which we will discuss
    in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Assumptions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we jump into the code that handles the simulation, we need to understand
    the assumptions. It is impossible to control for every possible variable when
    we make a simulation, so we must identify some simplifying assumptions to get
    started.
  prefs: []
  type: TYPE_NORMAL
- en: 'The simulator makes the following assumptions regarding valid users of the
    website:'
  prefs: []
  type: TYPE_NORMAL
- en: Valid users come according to a **Poisson process** at an hourly rate that depends
    on the day of the week and the time of day. A Poisson process models arrivals
    per unit of time (our simulation will use an hour) as a Poisson distribution with
    mean λ (lambda). The interarrival times are exponentially distributed with mean
    1/λ.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Valid users connect from 1-3 IP addresses (a unique identifier for each device
    using the Internet), which comprise 4 random integers in the range [0, 255] separated
    by periods. It is possible, although highly unlikely, that two valid users share
    an IP address.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Valid users are unlikely to make many mistakes while entering their credentials.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The interarrival times have the **memoryless** property, meaning that the time
    between two consecutive arrivals has no bearing on when the subsequent arrival
    will happen.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The simulator makes the following assumptions about the hackers:'
  prefs: []
  type: TYPE_NORMAL
- en: The hackers try to avoid an account lockout by only testing a few username-password
    combinations, rather than a full-blown **dictionary attack** (for every user,
    trying every password the hacker has in a dictionary of possible passwords that
    they maintain). However, they don't add delays between their attempts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since the hackers don't want to cause a denial of service, they limit the volume
    of their attacks and only make one attempt at a time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The hackers know the number of accounts that exist in the system and have a
    good idea of the format the usernames are in, but are guessing the exact usernames.
    They will choose to try to guess all 133 usernames, or some subset of them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each attack is standalone, meaning there is a single hacker acting for each
    attack, and a hacker never attacks more than once.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The hackers don't share information about which username-password combinations
    are correct.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The attacks come at random times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each hacker will use a single IP address, which is generated in the same way
    the valid user ones are. However, our simulator is capable of varying this IP
    address, a feature that we will look at in [*Chapter 11*](B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237),
    *Machine Learning Anomaly Detection*, to make this scenario more challenging.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although highly unlikely, it is possible the hacker has the same IP address
    as a valid user. The hacker may even be a valid user.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are abstracting away some of the complexity of password-guessing as well;
    instead, we are using random numbers to determine whether or not the password
    is guessed correctly—this means we aren't considering how the website stores passwords,
    perhaps as plaintext (hopefully not), hashes (the irreversible transformation
    of the plaintext password that allows verification without storing the actual
    password), or salted hashes (refer to the *Further reading* section for an article
    on this). In practice, a hacker could gain access to the stored passwords and
    figure out what they are offline (see the article on rainbow tables in the *Further
    reading* section at the end of this chapter), in which case the techniques discussed
    in this chapter wouldn't be as helpful, since the logs wouldn't have a record
    of their attempts. Keep in mind that the hackers in this simulation are very conspicuous.
  prefs: []
  type: TYPE_NORMAL
- en: The login_attempt_simulator package
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This package is much more lightweight than the `stock_analysis` package from
    the previous chapter; we only have three files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We will walk through each of these files in the following sections. Note that
    parts of the docstrings have been removed for brevity; check the files themselves
    for the full documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Helper functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s start our discussion with the `utils.py` functions, which are helpers
    for our simulator class. First, we create our docstring for the module and handle
    our imports:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define the `make_user_base()` function, which makes the user base
    for our web application. It creates a file of usernames by combining one lowercase
    letter from the English alphabet with each last name in the list inside the function,
    and adds a few administrative accounts as well; this results in a user base of
    133 accounts. By writing to a file, we ensure we don''t have to generate this
    every time we run our simulation and can simply read from it to simulate in the
    future:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we will need to use this user base in our simulator, we also write a
    function to read the user base file into a list. The `get_valid_users()` function
    reads the file written by the `make_user_base()` function back into a Python list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `random_ip_generator()` function creates IP addresses from random numbers
    of the form `xxx.xxx.xxx.xxx`, where `x` is an integer in the range [0, 255].
    We are using the `ipaddress` module from the Python standard library ([https://docs.python.org/3/library/ipaddress.html](https://docs.python.org/3/library/ipaddress.html))
    to avoid assigning private IP addresses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Each of our users will have a few IP addresses from which they attempt to log
    in. The `assign_ip_addresses()` function maps 1-3 random IP addresses to each
    user, creating a dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The `save_user_ips()` and `read_user_ips()` functions save the user-IP address
    mapping to a JSON file and read it back into the dictionary file, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: The Python standard library has lots of helpful modules that we might not find
    many occasions to use but are definitely worth knowing about. Here, we use the
    `json` module to save dictionaries to JSON files and read them back later. We
    are using the `ipaddress` module to work with IP addresses, and the `string` module
    to get the characters in the alphabet without having to type them all out.
  prefs: []
  type: TYPE_NORMAL
- en: The LoginAttemptSimulator class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `LoginAttemptSimulator` class in the `login_attempt_simulator.py` file
    handles the heavy lifting of carrying out the simulation with all the random number
    generation logic. As usual, we start with our module docstring and imports:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we begin defining the `LoginAttemptSimulator` class with its docstring,
    along with some class variables for storing constants. We do this to avoid magic
    numbers (numbers in the code that don''t seem to have meaning) and spelling errors
    with strings we will use in multiple spots. Note that these messages are only
    for our logs; the web application doesn''t show the end users why the authentication
    attempt failed (nor should it):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Take note of how we used class variables to store constants, such as error messages,
    so that we don't risk typos in the code. This means that every time we use these
    error messages, the text will be identical, which will keep the data clean. In
    Python, constants are typically written in all caps ([https://www.python.org/dev/peps/pep-0008/#constants](https://www.python.org/dev/peps/pep-0008/#constants)).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `__init__()` method will handle the setup for the simulator, such as reading
    in the user base from the file indicated, initializing the logs, storing success
    probabilities, and determining the start and end dates for the simulation, as
    needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The `_record()` method appends the result of each attempt to the log, noting
    the IP address it came from, which username, at what time, whether it succeeded,
    and the reason for failure, if there was one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The `_attempt_login()` method handles the logic of determining whether the
    login attempt succeeds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Simulation logic'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.1_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.1 – Simulation logic
  prefs: []
  type: TYPE_NORMAL
- en: 'We provide the probability of entering a correct username (`username_accuracy`)
    and the probabilities of successfully entering the password for each attempt (`success_likelihoods`).
    The number of attempts is the minimum of the number of attempts allowed before
    an account lockout and the length of the list of success probabilities (`success_likelihoods`).
    The outcome of each attempt is passed to `_record()` using `functools`), which
    allow us to create functions that fix certain parameters to a specific value (so
    we don''t have to pass the same value continuously):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The `_valid_user_attempts_login()` and `_hacker_attempts_login()` methods are
    wrappers around the `_attempt_login()` method that handle the adjustment in probabilities
    for valid users and hackers, respectively. Notice that while both use a Gaussian
    (normal) distribution to determine how accurate the username will be, the valid
    user''s distribution has a higher mean and lower standard deviation, meaning they
    are more likely to provide the correct username when trying to log in. This is
    because, while valid users may make typos (infrequently), the hackers are guessing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'When the simulator determines that the username will not be provided correctly,
    it calls the `_distort_username()` method, which randomly decides to omit a letter
    from the valid username or to replace one of the letters with another one. While
    hackers enter incorrect usernames because they are guessing (not due to typos),
    we abstract away this detail in order to use a single function for introducing
    username errors for both valid users and hackers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We use the `_valid_user_arrivals()` method to generate the number of users
    that will arrive in a given hour and the interarrival times using Poisson and
    exponential distributions, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: We are using `numpy` instead of `random` to generate random numbers from the
    exponential distribution because we can ask for multiple values at once (one for
    each of the hourly arrivals determined by the Poisson process). Also, note that
    `random` doesn't provide a Poisson distribution, so we need `numpy`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our simulation uses many different distributions, so it can be helpful to see
    what they look like. The following subplots show examples for each of the distributions
    we are using. Notice that the Poisson distribution is drawn differently. This
    is because the Poisson distribution is discrete. For this reason, we often use
    it to model arrivals—here, we use it for modeling the arrivals of users attempting
    to log in. Discrete distributions have a **probability mass function** (**PMF**)
    instead of a **probability density function** (**PDF**):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Distributions used in the simulation'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.2_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.2 – Distributions used in the simulation
  prefs: []
  type: TYPE_NORMAL
- en: 'The `_hack()` method generates a random IP address for the hacker and carries
    out a brute-force attack on a given user list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the functionality to carry out the main parts of the simulation,
    we write the `simulate()` method to put it all together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We want to save the logs to CSV files, so we add the `_save()` method as a
    static method to allow for less repetition in the code for the two save methods.
    The `save_log()` method will save the login attempts and the `save_hack_log()`
    method will save the record of the attacks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Notice that there were many private methods in this class; this is because users
    of this class only need to be able to create an instance of this class (`__init__()`),
    simulate by hour (`simulate()`), and save the output (`save_log()` and `save_hack_log()`)—all
    other methods are for internal use by objects of this class. The methods behind
    the scenes will handle the bulk of the work.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, we have the `__init__.py` file, which makes this a package, but also
    provides us with an easier way to import the main class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Now that we understand how the simulator works, we will discuss how to run the
    simulation to collect the login attempts data.
  prefs: []
  type: TYPE_NORMAL
- en: Simulating from the command line
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Rather than writing the code to simulate the login attempts every time, we can
    package this up in a script that we can easily run from the command line. The
    Python standard library has the `argparse` module ([https://docs.python.org/3/library/argparse.html](https://docs.python.org/3/library/argparse.html)),
    which allows us to specify arguments to our script that can be supplied from the
    command line.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the `simulate.py` file to see how to do this. We start
    with our imports:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to provide status updates when using this from the command line, we
    are going to set up logging messages using the standard library''s `logging` module
    ([https://docs.python.org/3/library/logging.html](https://docs.python.org/3/library/logging.html)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define some utility functions for generating file paths that we will
    need for reading and writing data during the simulation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The largest part of this script defines which command-line parameters can be
    passed—we will allow the user to specify whether they want to create a new user
    base, set a seed, when to start the simulation, how long to simulate, and where
    to save all the files. The actual simulation is taken care of in a few lines thanks
    to the package we built. This section will only run when this module is run, rather
    than imported:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: The code placed in the `if __name__ == '__main__'` block will only be run when
    this module is run as a script. This makes it possible for us to import the functions
    defined in the module without running the simulation.
  prefs: []
  type: TYPE_NORMAL
- en: 'After defining the arguments, we need to parse them in order to use them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have the command-line arguments parsed, we check to see whether we
    need to generate the user base or read it in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Afterward, we parse the start date from the command-line arguments, and determine
    the end date by adding the duration from the command-line arguments to the start
    date:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we run the actual simulation and write our results to the files specified
    (or the default paths). We set the probability of attack in a given hour to 10%
    (`attack_prob`), the probability the hacker will attempt to guess all usernames
    at 20% (`try_all_users_prob`), and have the hackers use the same IP address for
    all of their attempts (`vary_ips`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we used the `logger` object to print helpful messages to the screen
    throughout the script; this will help the users of this script know how far along
    in the process it is. These messages come in different levels of severity (we
    are using `INFO`, `WARNING`, and `ERROR` here), allowing them to be placed for
    debugging (the `DEBUG` level), and left there once the code goes into production,
    since the minimum level for printing can be raised to `INFO`, so that no `DEBUG`
    messages are printed. This is leaps and bounds above simple `print()` statements,
    since we don't have to worry about removing them as we move to production or adding
    back these messages as development continues.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now take a look at how we can run this script. We know that `simulate.py`
    can be run on the command line, but how can we see what arguments we need to pass?
    Simple—we add the help flag (`-h` or `--help`) to the call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Note that we didn't specify the `help` argument when we added the other arguments
    with `argparse`; it was automatically created by `argparse`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we know which arguments we can pass and have decided which of these we
    want to provide, we can run the simulation. Let''s simulate 30 days, starting
    from 12 AM on November 1, 2018, while having the script create the user base and
    IP address mappings needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Since we set a seed (`-s 0`), the output of this simulation is reproducible.
    Simply remove the seed or change it to get a different result.
  prefs: []
  type: TYPE_NORMAL
- en: 'Python modules can also be run as scripts. As opposed to importing a module,
    when we run one as a script, any code underneath `if __name__ == ''__main__''`
    will also be run, meaning we don''t always need to write a separate script. Most
    of the modules we have built only defined functions and classes, so running them
    as scripts wouldn''t do anything; however, the way we created our virtual environment
    with `venv` back in [*Chapter 1*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015),
    *Introduction to Data Analysis*, was an example of this. The previous code block
    is therefore equivalent to the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have our simulated data, let's begin our analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory data analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this scenario, we have the benefit of access to labeled data (`logs/attacks.csv`)
    and will use it to investigate how to distinguish between valid users and attackers.
    However, this is a luxury that we often don''t have, especially once we leave
    the research phase and enter the application phase. In [*Chapter 11*](B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237),
    *Machine Learning Anomaly Detection*, we will revisit this scenario, but begin
    without the labeled data for more of a challenge. As usual, we start with our
    imports and reading in the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The login attempts dataframe (`log`) contains the date and time of each attempt
    in the `datetime` column, the IP address it came from (`source_ip`), the username
    that was used (`username`), whether the attempt was successful (`success`), and
    the reason for failure if it wasn''t (`failure_reason`):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – Sample of the login attempt data'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.3_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.3 – Sample of the login attempt data
  prefs: []
  type: TYPE_NORMAL
- en: 'When approaching this data, we need to think about what normal activity and
    hacker activity would look like. Any big differences between the groups could
    potentially be leveraged to identify the hackers. We would expect valid users
    to have high success rates, with the most common reason for failure being an incorrect
    password. We would expect users to log in from a few different IP addresses (phone,
    home computer, work computer, and any other device they may have), and it is possible
    that people share devices. Without knowing the nature of this web application,
    we can''t say anything about whether it is normal to log in many times throughout
    the day. We also don''t know what time zone this data is in, so we can''t make
    any inferences about the login times. Potentially, we could look at which countries
    these IP addresses are from, but there are ways of masking IP addresses, so we
    won''t go down that path. This leaves us with a few viable options, given our
    available data:'
  prefs: []
  type: TYPE_NORMAL
- en: Investigate any spikes in attempts and failures (both overall and per IP address).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examine cases where the failure reason was an incorrect username.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Look at the failure rate per IP address.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Find IP addresses trying to log in with many distinct usernames.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One other thing to note is that we would want to flag anomalous behavior sooner
    rather than later. Waiting a month to flag something is less valuable (the value
    drops quickly over time), so we need to find a way to flag much sooner; say, using
    an hourly frequency. Since we are in the research phase, we have some labeled
    data to work with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This data is the record of attacks on the web application (`attacks`). It contains
    the date and time of the start of the attack (`start`), the date and time of the
    end of the attack (`end`), and the IP address associated with the attack (`source_ip`):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – Sample of the labeled data'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.4_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.4 – Sample of the labeled data
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `shape` property, we can see that we had 72 attacks and 12,836 login
    attempts from valid and nefarious users, and with `nunique()`, we see that 22%
    of the IP addresses were associated with attacks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Normally, it wouldn't be this trivial to know when the attacks occurred—they
    can go a long time without detection, and, even then, it's not so simple to isolate
    the attacker's actions from those of normal users.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our data is pretty clean (we designed it just for this purpose, after all),
    so let''s see whether we can find anything interesting by performing some **exploratory
    data analysis** (**EDA**). First, let''s look to see how many attempts are coming
    through on an hourly basis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Several hours had very large peaks, which could possibly be when attacks occurred.
    Using this plot, we could report on hours that had a high level of login attempt
    activity, but nothing beyond that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Hourly login attempts'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.5_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.5 – Hourly login attempts
  prefs: []
  type: TYPE_NORMAL
- en: 'Another interesting avenue of exploration would be to see how many attempts
    came from each IP address. We can achieve this by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'This data definitely appears to have some outliers, which pull the number of
    attempts per IP address up quite high. Let''s create some plots to better assess
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The distribution of attempts per IP address is the sum of the distributions
    for both valid users and attackers. The histogram indicates that this distribution
    is bimodal, but we are unable to determine whether all of those IP addresses with
    high attempts are actually hackers by just looking at the plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – Distribution of login attempts per IP address'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.6_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.6 – Distribution of login attempts per IP address
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we have access to the details of each attack, we can check whether the
    right part of the histogram is the distribution for the hackers. Their IP addresses
    make up 88.9% of the top IP addresses ranked by number of attempts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We could simply stop here and flag any IP address that shows up in a list of
    IP addresses with the most attempts per month, but we most likely want a more
    robust solution, since the hackers could simply change their IP address each time
    and avoid detection. Ideally, we would also be able to detect the attacks without
    waiting for a full month''s worth of data. Looking at the hourly attempts made
    by each IP address unfortunately doesn''t give us much information, though:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember from [*Chapter 1*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015),
    *Introduction to Data Analysis*, that the mean is not robust to outliers. If the
    attackers make many attempts, they will bring the average hourly attempts per
    IP address higher. We can see several large peaks in this line plot, but notice
    that many of them only go up to two or three. Can we really expect only one user
    to access the web application from a given IP address? This is probably not a
    realistic assumption:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Average hourly login attempts per IP address'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.7_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.7 – Average hourly login attempts per IP address
  prefs: []
  type: TYPE_NORMAL
- en: 'So, if we can''t rely on the IP address (after all, the hacker could be smart
    enough to spread the attack over many different addresses), what else can we try?
    Perhaps the hackers have more trouble logging in successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The hackers are only successful 17% of the time, but how often are the valid
    users successful? This information is important for determining a baseline of
    what normal behavior looks like for the website. As we would expect, valid users
    have much higher success rates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the logs come with the reason that a login attempt failed, we can use
    a crosstab to see why hackers and valid users fail to log in successfully. Any
    differences here may help us separate the two groups:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Valid users sometimes enter their passwords or usernames incorrectly, but the
    hacker has way more issues getting both the username and password correct:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8 – Reason for failed login attempts'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.8_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.8 – Reason for failed login attempts
  prefs: []
  type: TYPE_NORMAL
- en: 'Valid users don''t make many mistakes with their credentials, so if the hackers
    make many attempts with many users, we can flag it. To confirm, we can look at
    average hourly attempts per user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'For the most part, less than one attempt per hour is made per username. There''s
    also no guarantee that spikes in this metric are indications of an attack. Perhaps
    the website is having a flash sale; in that case, we would likely see a spike
    in this metric caused by valid users:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.9 – Average hourly login attempts per username'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.9_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.9 – Average hourly login attempts per username
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on our findings, error rates seem to be the most fruitful metric for
    detecting attacks, so we will look into IP addresses that have high error rates.
    To do so, we can create a pivot table to calculate some helpful metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: The `insert()` method allows us to insert the newly created `attempts` column
    at a specific position in the current dataframe in place. We created the `attempts`
    column as the sum of errors and successes (we fill in the `NaN` values in the
    `failure_reason` column with `success` to count it here) by summing with `axis=1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This yields the following pivot table sorted by attempts (from most to fewest):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.10 – Metrics per IP address'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.10_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.10 – Metrics per IP address
  prefs: []
  type: TYPE_NORMAL
- en: 'We know that certain IP addresses are making many attempts, so it''s worth
    looking into how many usernames are attempting to log in per IP address; we would
    expect valid users to only log in from a few IP addresses and not to share their
    IP address with many others. This can be determined with a group by and an aggregation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: This definitely appears to be a good strategy for isolating nefarious users.
    The majority of the IP addresses are used by two or fewer users, but the maximum
    stands at 253\. While this criterion could help us identify some of the attackers,
    it won't help if the hackers are clever enough to vary their IP addresses throughout
    their attack.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we move on to anomaly detection methods, let''s see whether we can visually
    identify the hackers. Let''s create a scatter plot for the successes and attempts
    for each IP address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'There appear to be a few distinct clusters. In the bottom-left corner of the
    plot, we see points forming a line with a one-to-one relationship of successes
    to attempts. The upper-right portion of the plot contains a less dense cluster
    with a high number of attempts and moderate successes. Since we used the `alpha`
    parameter to control transparency, we can see that the trail of points that seem
    to connect the two clusters is not densely populated. Even without the axis scales,
    we would predict the bottom-left cluster to be regular users and the top-right
    to be hackers (since we imagine there are more regular users than hackers, and
    regular users have higher success rates). The points in the middle are more difficult
    to judge, however:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.11 – Scatter plot of successes versus attempts by IP address'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.11_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.11 – Scatter plot of successes versus attempts by IP address
  prefs: []
  type: TYPE_NORMAL
- en: 'Without making any assumptions, we can draw a boundary line grouping the middle
    points with their nearest cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, when lacking labeled data, it is difficult to evaluate the effectiveness
    of this decision boundary:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.12 – Visualizing a decision boundary'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.12_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.12 – Visualizing a decision boundary
  prefs: []
  type: TYPE_NORMAL
- en: 'Luckily for us, we have data on which IP addresses the hackers used because
    we have been given labeled data to conduct our research, so we can use `seaborn`
    to actually see the separation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Our intuition about there being two distinct clusters was dead-on. The middle
    area, however, was much trickier to determine. The blue (darker) points on the
    left do appear to be following a line upward, while the orange (lighter) points
    on the left are following a line to the orange cluster. By plotting the log of
    the attempts instead, we get a little more separation between our orange middle
    points and the blue points:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.13 – Using labeled data to check our intuition'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.13_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.13 – Using labeled data to check our intuition
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember, we can also use a box plot to check for possible outliers, which
    will be shown as points. Let''s see what successes and attempts look like per
    IP address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The points marked as outliers coincide with the points in the upper-right corner
    of the scatter plots we made:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.14 – Checking for outliers'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.14_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.14 – Checking for outliers
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a good understanding of our data, we are ready to learn how
    to implement a few simple anomaly detection strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing rule-based anomaly detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's time to catch those hackers. After the EDA in the previous section, we
    have an idea of how we might go about this. In practice, this is much more difficult
    to do, as it involves many more dimensions, but we have simplified it here. **We
    want to find the IP addresses with excessive amounts of attempts accompanied by
    low success rates, and those attempting to log in with more unique usernames than
    we would deem normal (anomalies)**. To do this, we will employ threshold-based
    rules as our first foray into anomaly detection; then, in [*Chapter 11*](B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237),
    *Machine Learning Anomaly Detection*, we will explore a few machine learning techniques
    as we revisit this scenario.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we are interested in flagging IP addresses that are suspicious, we are
    going to arrange the data so that we have hourly aggregated data per IP address
    (if there was activity for that hour):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: The `np.invert()` function is an easy way to flip Boolean values. It turns `True`
    to `False` and `False` to `True` along a NumPy array-like structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'The aggregated data looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.15 – Hourly aggregated data per IP address'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.15_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.15 – Hourly aggregated data per IP address
  prefs: []
  type: TYPE_NORMAL
- en: The simplest form of rule-based anomaly detection involves calculating a threshold
    value and checking to see whether the data is beyond the threshold. This could
    mean values falling below some lower bound threshold, or values exceeding some
    upper bound threshold. Since we are looking at login attempts, we are interested
    in values that are greater than normal. Therefore, we will be calculating the
    threshold for our upper bounds and comparing that to our data.
  prefs: []
  type: TYPE_NORMAL
- en: Percent difference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Provided that we have an idea of what normal login attempt activity (minus the
    hackers) looks like on the site, we can flag values that deviate from this by
    a certain percentage. In order to calculate this baseline, we could take a few
    IP addresses at random with replacement for each hour, and average the number
    of login attempts they made. We are bootstrapping since we don't have much data
    (about 50 unique IP addresses to pick from for each of the 24 hours).
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, we could write a function that takes in the aggregated dataframe
    we just made, along with the name of a statistic to calculate per column of the
    data to use as the starting point for the threshold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that we can get equally sized samples for all groups (hours, here) if
    we use `sample()` inside `apply()` after grouping by the column we want to sample
    with. This means that we are selecting 10 rows with replacement per hour for each
    column. We have to sample by hour here because, if we do simple random sampling,
    there is a good chance we won''t have a statistic for every hour. Let''s use `get_baselines()`
    to calculate the column baselines using the mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: If, instead, we wanted to perform stratified random sampling, we could replace
    `10` in the `get_baselines()` function with `x.shape[0] * pct`, where `pct` is
    the percentage we want to sample from each group.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each column has the mean per hour for the 10 IP addresses chosen randomly to
    estimate normal behavior. This technique, however, doesn''t guarantee that we
    won''t mix any of the hacker activity into our baseline calculations. For example,
    let''s take a look at the six hours with the highest baseline values for failure
    rate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'We might find it difficult to flag any activity at hours **19**, **23**, or
    **14** with this baseline because the failure rate and unique usernames tried
    are both high:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.16 – Hourly baselines using the mean'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.16_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.16 – Hourly baselines using the mean
  prefs: []
  type: TYPE_NORMAL
- en: 'To combat this issue, we could trim our summary statistics by making the top
    *x*% ineligible for use in our baseline calculation. Let''s remove values greater
    than the 95th percentile of data from each hour. First, we will write a function
    to trim rows from a given hour that have data above a given quantile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will group the IP address data by hour and apply our trimming function.
    Since we will be using our bootstrapping function, we need to clean up some of
    the extra columns that will result from this operation, so we drop the `hour`
    column, reset the index, and then remove the grouping column and the old index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can use the `get_baselines()` function to grab our baseline using the
    average with the trimmed data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The trimmed baseline is now quite different from *Figure 8.16* at hours **19**,
    **23**, and **14**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.17 – Trimmed hourly baselines using the mean'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.17_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.17 – Trimmed hourly baselines using the mean
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have our baseline, let''s write a function that will do the heavy
    lifting of calculating the threshold from our baseline and the percentage difference
    per column, returning the IP addresses that have been flagged as hackers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The `pct_change_threshold()` function uses a series of chained operations to
    give us the flagged IP addresses:'
  prefs: []
  type: TYPE_NORMAL
- en: First, it joins the baselines to the hourly IP address logs on the `hour` column.
    Since all the baseline columns have the same names as the hourly IP address logs,
    and we don't want to join on them, we suffix their names with `'_baseline'`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After that, all the data we need to check whether the thresholds were exceeded
    is in the same dataframe. We use `assign()` to make three new Boolean columns,
    indicating whether each of our conditions (too many users, too many attempts,
    and high failure rate) has been violated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we chain a call to the `query()` method, which lets us easily select rows
    where all of these Boolean columns are `True` (notice we don't need to explicitly
    say `<column> == True`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Lastly, we make sure to return just the IP addresses and to drop any duplicates
    in case the same IP address was flagged for multiple hours.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In order to use this function, we need to pick a percentage difference from
    each of our baselines. By default, that will be 100% of the baseline, which, since
    it is the average, will flag way too many IP addresses. Instead, let''s get the
    IP addresses this flags with values 25% higher than the baseline for each criterion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: The percentages we use are in a dictionary, with the key being the column they
    are for and the value being the percentage itself. If the caller of the function
    doesn't provide these, we have default values of 100%, since we are using `get()`
    to select from the dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: 'These rules flagged 73 IP addresses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: In practice, we probably wouldn't run this rule on the entries used to calculate
    the baselines because they influence the definition of the baseline with their
    behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Tukey fence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we discussed in [*Chapter 1*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015),
    *Introduction to Data Analysis*, the mean is not robust to outliers. If we feel
    there are many outliers influencing our baselines, we could go back to the percent
    difference and try out the median or look into using a **Tukey fence**. Remember
    from previous chapters that the Tukey fence gets its bounds from the first and
    third quartiles and the **interquartile range** (**IQR**). Since we only care
    about exceeding the upper bound, this solves the issue with the mean, provided
    that outliers make up less than 25% of our data. We can use the following to calculate
    the upper bound:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_08_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Our `get_baselines()` function will still help us, but we need to do some additional
    processing. We will write a function that will calculate the upper bound of the
    Tukey fence and let us test out various values for the multiplier (`k`). Notice
    that we also have the option to use percentages with the Tukey fence here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s use the `tukey_fence_test()` function to grab the IP addresses that
    exceed the upper bound of the Tukey fence using an IQR multiplier of `3`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'With this method, we flag 83 IP addresses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: We used a multiplier of 3 here. However, depending on the application, we may
    see 1.5 used in order to be less restrictive. In reality, we can use any number;
    finding the best one may require some trial and error.
  prefs: []
  type: TYPE_NORMAL
- en: Z-score
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Remember, from [*Chapter 1*](B16834_01_Final_SK_ePub.xhtml#_idTextAnchor015),
    *Introduction to Data Analysis*, that we can also calculate Z-scores and flag
    IP addresses a given number of standard deviations from the mean. The `pct_change_threshold()`
    function we wrote earlier won't help us as is, since we aren't just comparing
    with the baseline. Instead, we need to subtract the baseline for the mean from
    all the values and divide by the baseline for the standard deviation, so we must
    rework our approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s write a new function, `z_score_test()`, to perform our Z-score tests
    using any number of standard deviations above the mean as a cutoff. First, we
    will use the `get_baselines()` function to calculate the baseline standard deviations
    by hour with the trimmed data. Then, we join the standard deviations and means
    together, adding the suffixes. This allows us to adapt the logic of `pct_change_threshold()`
    for this task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s call our function with a cutoff of three or more standard deviations
    from the mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'With this method, we flag 62 IP addresses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: In practice, the cutoff value for the Z-score is also a parameter we will want
    to tune.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So, we now have a series of IP addresses for each set of rules, but we would
    like to know how well each method did (assuming we can actually check). In this
    case, we have the attacker IP addresses for our research, so we can see how many
    each method got right—this is not so trivial in practice; instead, we could mark
    things that we have discovered to be malicious in the past and look out for similar
    behavior in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a classification problem with two classes; we want to classify each
    IP address as either a valid user or a nefarious one. This leaves us with four
    possible outcomes that we can visualize using a **confusion matrix**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.18 – The confusion matrix'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.18_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.18 – The confusion matrix
  prefs: []
  type: TYPE_NORMAL
- en: 'In this application, these outcomes mean the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True Positive (TP)**: Our method flagged it as malicious, and it was.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**True Negative (TN)**: Our method didn''t flag it, and it wasn''t malicious.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Positive (FP)**: Our method flagged it, but it wasn''t malicious.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Negative (FN)**: Our method didn''t flag it, but it was malicious.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'True positives and true negatives mean our method did well, but false positives
    and false negatives are possible areas for improvement (bear in mind that this
    will never be perfect). Let''s now write a function that will help determine where
    each method stands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we begin calculating metrics, let''s make a partial function so we don''t
    have to keep passing in the series of attacker IP addresses (`attacks.source_ip`)
    and IP addresses in the logs (`pivot.index`). Remember, a partial function allows
    us to fix the values for certain arguments and call the function later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s use this to calculate some metrics to measure our performance.
    One common metric is the **false positive rate** (**FPR**), which tells us the
    **false alarm rate**. It is calculated by taking the ratio of false positives
    to everything that was actually negative:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_08_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The **false discovery rate** (**FDR**), which tells us the percentage of positives
    that are incorrect, is another way of looking at false alarms:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_08_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s see what the FPR and FDR are for our percent difference from the mean
    approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Another metric of interest is the **false negative rate** (**FNR**), which
    tells us what we fail to detect (the **miss rate**). It is calculated by taking
    the ratio of false negatives to everything that was actually positive:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_08_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'An alternative way of looking at false negatives is the **false omission rate**
    (**FOR**), which tells us the percentage of cases we incorrectly mark as negatives:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_08_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Our percent difference from the mean method has no false negatives, so both
    FNR and FOR are zero:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: There is typically a trade-off here—do we want to catch as many hackers as possible,
    and risk flagging valid users (by focusing on FNR/FOR), or do we want to keep
    from inconveniencing our valid users and risk missing hacker activity (by minimizing
    FPR/FDR)? These questions are tough to answer and will depend on the domain, as
    the cost of false positives is not necessarily equal to (or even close in scale
    to) the cost of false negatives.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: We will discuss additional metrics that can be used to evaluate our performance
    in [*Chapter 9*](B16834_09_Final_SK_ePub.xhtml#_idTextAnchor188), *Getting Started
    with Machine Learning in Python*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now write a function to handle all these calculations for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now use the results from the `evaluate()` function to calculate our
    metrics. For the percentage difference from the mean, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'It looks like our trio of criteria did quite well. If we were concerned with
    the hacker IP addresses being chosen when we calculated the baselines, but didn''t
    want to trim, we could have run this with the median instead of the mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the median, we achieve similar performance to the mean. In this case,
    however, we didn''t need to trim the data beforehand. This is because the median
    is robust to outliers, meaning that picking a single hacker IP address in a given
    hour doesn''t affect that hour''s baseline as it would the mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'To compare each of the methods discussed, we can use dictionary comprehensions
    to populate a `DataFrame` object with the performance metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: The `scores()` function returns a tuple of `(tp, fp, tn, fn)`, but the `classification_stats()`
    function expects four arguments. However, since `scores()` returns them in the
    same order that `classification_stats()` expects them, we can use `*` to unpack
    the tuple and send the values as four positional arguments.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mean is affected by outliers, but once we trimmed the data, it became a
    viable method. We didn''t need to trim the data to work with the median; the usefulness
    of the median hinges on the data containing fewer than 50% outliers. The Tukey
    fence takes this a step further by using the third quartile and assuming that
    fewer than 25% of the data points are outliers. The Z-score method is also affected
    by outliers because it uses the mean; however, with the trimmed data, we were
    able to achieve good performance with a modest cutoff of three:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.19 – Comparing performance'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.19_B16834.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.19 – Comparing performance
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, which method we use in practice will depend on how costly it is
    to have a false positive versus a false negative—is it worse to raise the alarm
    when nothing is wrong, or to be silent when something is? In this case, we would
    err on the side of minimizing false negatives since we don't want to miss anything.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Another common use case for anomaly detection is in quality or process control
    in industrial settings, such as monitoring factory equipment performance and output.
    Process control uses threshold-based and pattern-based rules to determine whether
    systems are out of control. These can be used for things such as determining when
    the distribution of the underlying data has changed, which could be a precursor
    for later problems. **Western Electric rules** and **Nelson rules** are common
    ones. References for both can be found in the *Further reading* section at the
    end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our second application chapter, we learned how to simulate events in Python
    and got additional exposure to writing packages. We also saw how to write Python
    scripts that can be run from the command line, which we used to run our simulation
    of the login attempt data. Then, we performed some EDA on the simulated data to
    see whether we could figure out what would make hacker activity easy to spot.
  prefs: []
  type: TYPE_NORMAL
- en: This led us to zero in on the number of distinct usernames attempting to authenticate
    per IP address per hour, as well as the number of attempts and failure rates.
    Using these metrics, we were able to create a scatter plot, which appeared to
    show two distinct groups of points, along with some other points connecting the
    two groups; naturally, these represented the groups of valid users and the nefarious
    ones, with some of the hackers not being as obvious as others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we set about creating rules that would flag the hacker IP addresses
    for their suspicious activity. First, we used `pandas` to reshape our data into
    hourly aggregates per IP address. Then, we wrote functions to trim values greater
    than the 95th percentile and calculate baselines for a given statistic per hour,
    which we used to create our rules based on percentage difference from the mean
    and median, exceeding the upper bound of a Tukey fence, and using Z-scores. We
    saw that building good rules depended on carefully tuning our parameters: the
    percentage for the differences from the mean and median, the multiplier for the
    Tukey fence, and the threshold for the Z-score. To determine which of the rules
    was performing the best, we used the miss rate, false omission rate, false discovery
    rate, and the false alarm rate.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next two chapters, we will introduce machine learning in Python using
    `scikit-learn`, and in [*Chapter 11*](B16834_11_Final_SK_ePub.xhtml#_idTextAnchor237),
    *Machine Learning Anomaly Detection*, we will revisit this scenario for anomaly
    detection using machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Complete the following exercises to practice the concepts covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Run the simulation for December 2018 into new log files without making the user
    base again. Be sure to run `python3 simulate.py -h` to review the command-line
    arguments. Set the seed to `27`. This data will be used for the remaining exercises.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the number of unique usernames, attempts, successes, and failures, as well
    as the success/failure rates per IP address, using the data simulated from exercise
    *1*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create two subplots with failures versus attempts on the left, and failure rate
    versus distinct usernames on the right. Draw decision boundaries for the resulting
    plots. Be sure to color each data point by whether or not it is a hacker IP address.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build a rule-based criteria using the percentage difference from the median
    that flags an IP address if the failures and attempts are both five times their
    respective medians, or if the distinct usernames count is five times its median.
    Be sure to use a one-hour window. Remember to use the `get_baselines()` function
    to calculate the metrics needed for the baselines.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate metrics to evaluate how well these rules performed using the `evaluate()`
    and `classification_stats()` functions from this chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Check out the following resources for more information on the topics covered
    in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '*A Gentle Introduction to the Bootstrap Method*: [https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/](https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*An Introduction to the Bootstrap Method*: [https://towardsdatascience.com/an-introduction-to-the-bootstrap-method-58bcb51b4d60](https://towardsdatascience.com/an-introduction-to-the-bootstrap-method-58bcb51b4d60)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Adding Salt to Hashing: A Better Way to Store Passwords*: [https://auth0.com/blog/adding-salt-to-hashing-a-better-way-to-store-passwords/](https://auth0.com/blog/adding-salt-to-hashing-a-better-way-to-store-passwords/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Brute-Force Attack*: [https://en.wikipedia.org/wiki/Brute-force_attack](https://en.wikipedia.org/wiki/Brute-force_attack)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Classification Accuracy Is Not Enough: More Performance Measures You Can Use*:
    [https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Dictionary Attack*: [https://en.wikipedia.org/wiki/Dictionary_attack](https://en.wikipedia.org/wiki/Dictionary_attack)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Nelson Rules*: [https://en.wikipedia.org/wiki/Nelson_rules](https://en.wikipedia.org/wiki/Nelson_rules)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Offline Password Cracking: The Attack and the Best Defense*: [https://www.alpinesecurity.com/blog/offline-password-cracking-the-attack-and-the-best-defense-against-it](https://www.alpinesecurity.com/blog/offline-password-cracking-the-attack-and-the-best-defense-against-it)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Poisson Point Process*: [https://en.wikipedia.org/wiki/Poisson_point_process](https://en.wikipedia.org/wiki/Poisson_point_process)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Precision and Recall*: [https://en.wikipedia.org/wiki/Precision_and_recall](https://en.wikipedia.org/wiki/Precision_and_recall)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Probability Distributions in Python*: [https://www.datacamp.com/community/tutorials/probability-distributions-python](https://www.datacamp.com/community/tutorials/probability-distributions-python)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Rainbow Tables: Your Password''s Worst Nightmare*: [https://www.lifewire.com/rainbow-tables-your-passwords-worst-nightmare-2487288](https://www.lifewire.com/rainbow-tables-your-passwords-worst-nightmare-2487288)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*RFC 1597 (Address Allocation for Private Internets)*: [http://www.faqs.org/rfcs/rfc1597.html](http://www.faqs.org/rfcs/rfc1597.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Sampling Techniques*: [https://towardsdatascience.com/sampling-techniques-a4e34111d808](https://towardsdatascience.com/sampling-techniques-a4e34111d808)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Trimmed Estimator*: [https://en.wikipedia.org/wiki/Trimmed_estimator](https://en.wikipedia.org/wiki/Trimmed_estimator)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Western Electric rules*: [https://en.wikipedia.org/wiki/Western_Electric_rules](https://en.wikipedia.org/wiki/Western_Electric_rules)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
