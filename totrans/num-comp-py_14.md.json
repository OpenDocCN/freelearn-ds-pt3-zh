["```py\n>>> state_fruit = pd.read_csv('data/state_fruit.csv', index_col=0)\n>>> state_fruit\n```", "```py\n>>> state_fruit.stack()\nTexas    Apple      12\n         Orange     10\n         Banana     40\nArizona  Apple       9\n         Orange      7\n         Banana     12\nFlorida  Apple       0\n         Orange     14\n         Banana    190\ndtype: int64\n```", "```py\n>>> state_fruit_tidy = state_fruit.stack().reset_index()\n>>> state_fruit_tidy\n```", "```py\n>>> state_fruit_tidy.columns = ['state', 'fruit', 'weight']\n>>> state_fruit_tidy\n```", "```py\n>>> state_fruit.stack()\\\n               .rename_axis(['state', 'fruit'])\n\nstate    fruit \nTexas    Apple      12\n         Orange     10\n         Banana     40\nArizona  Apple       9\n         Orange      7\n         Banana     12\nFlorida  Apple       0\n         Orange     14\n         Banana    190\ndtype: int64\n```", "```py\n>>> state_fruit.stack()\\\n               .rename_axis(['state', 'fruit'])\\\n               .reset_index(name='weight')\n```", "```py\n>>> state_fruit2 = pd.read_csv('data/state_fruit2.csv')\n>>> state_fruit2\n```", "```py\n>>> state_fruit2.stack()\n0  State       Texas\n   Apple          12\n   Orange         10\n   Banana         40\n1  State     Arizona\n   Apple           9\n   Orange          7\n   Banana         12\n2  State     Florida\n   Apple           0\n   Orange         14\n   Banana        190\ndtype: object\n```", "```py\n>>> state_fruit2.set_index('State').stack()\n```", "```py\n>>> state_fruit2 = pd.read_csv('data/state_fruit2.csv')\n>>> state_fruit2\n```", "```py\n>>> state_fruit2.melt(id_vars=['State'],\n                      value_vars=['Apple', 'Orange', 'Banana'])\n```", "```py\n>>> state_fruit2.melt(id_vars=['State'],\n                      value_vars=['Apple', 'Orange', 'Banana'],\n                      var_name='Fruit',\n                      value_name='Weight')\n```", "```py\n>>> state_fruit2.melt()\n```", "```py\n>>> state_fruit2.melt(id_vars='State')\n```", "```py\n>>> movie = pd.read_csv('data/movie.csv')\n>>> actor = movie[['movie_title', 'actor_1_name', \n                   'actor_2_name', 'actor_3_name', \n                   'actor_1_facebook_likes',\n                   'actor_2_facebook_likes',\n                   'actor_3_facebook_likes']]\n>>> actor.head()\n```", "```py\n>>> def change_col_name(col_name):\n        col_name = col_name.replace('_name', '')\n        if 'facebook' in col_name:\n            fb_idx = col_name.find('facebook')\n            col_name = col_name[:5] + col_name[fb_idx - 1:] \\\n                                    + col_name[5:fb_idx-1]\n        return col_name\n```", "```py\n>>> actor2 = actor.rename(columns=change_col_name)\n>>> actor2.head()\n```", "```py\n>>> stubs = ['actor', 'actor_facebook_likes']\n>>> actor2_tidy = pd.wide_to_long(actor2, \n                                  stubnames=stubs, \n                                  i=['movie_title'], \n                                  j='actor_num', \n                                  sep='_')\n>>> actor2_tidy.head()\n```", "```py\n>>> df = pd.read_csv('data/stackme.csv')\n>>> df\n```", "```py\n>>> df2 = df.rename(columns = {'a1':'group1_a1', 'b2':'group1_b2',\n                               'd':'group2_a1', 'e':'group2_b2'})\n>>> df2\n```", "```py\n>>> pd.wide_to_long(df2, \n                    stubnames=['group1', 'group2'], \n                    i=['State', 'Country', 'Test'], \n                    j='Label', \n                    suffix='.+', \n                    sep='_')\n```", "```py\n>>> usecol_func = lambda x: 'UGDS_' in x or x == 'INSTNM'\n>>> college = pd.read_csv('data/college.csv', \n                          index_col='INSTNM', \n                          usecols=usecol_func)\n>>> college.head()\n```", "```py\n>>> college_stacked = college.stack()\n>>> college_stacked.head(18)\nINSTNM                                         \nAlabama A &amp; M University         UGDS_WHITE    0.0333\n                                     UGDS_BLACK    0.9353\n                                     UGDS_HISP     0.0055\n                                     UGDS_ASIAN    0.0019\n                                     UGDS_AIAN     0.0024\n                                     UGDS_NHPI     0.0019\n                                     UGDS_2MOR     0.0000\n                                     UGDS_NRA      0.0059\n                                     UGDS_UNKN     0.0138\nUniversity of Alabama at Birmingham  UGDS_WHITE    0.5922\n                                     UGDS_BLACK    0.2600\n                                     UGDS_HISP     0.0283\n                                     UGDS_ASIAN    0.0518\n                                     UGDS_AIAN     0.0022\n                                     UGDS_NHPI     0.0007\n                                     UGDS_2MOR     0.0368\n                                     UGDS_NRA      0.0179\n                                     UGDS_UNKN     0.0100\ndtype: float64\n```", "```py\n>>> college_stacked.unstack()\n```", "```py\n>>> college2 = pd.read_csv('data/college.csv', \n                          usecols=usecol_func)\n>>> college2.head()\n```", "```py\n>>> college_melted = college2.melt(id_vars='INSTNM', \n                                   var_name='Race',\n                                   value_name='Percentage')\n>>> college_melted.head()\n```", "```py\n>>> melted_inv = college_melted.pivot(index='INSTNM', \n                                      columns='Race',\n                                      values='Percentage')\n>>> melted_inv.head()\n```", "```py\n>>> college2_replication = melted_inv.loc[college2['INSTNM'],\n                                          college2.columns[1:]]\\\n                                     .reset_index()\n>>> college2.equals(college2_replication)\nTrue\n```", "```py\n>>> college.stack().unstack(0)\n```", "```py\n>>> college.T\n>>> college.transpose()\n```", "```py\n>>> employee = pd.read_csv('data/employee.csv')\n>>> employee.groupby('RACE')['BASE_SALARY'].mean().astype(int)\nRACE\nAmerican Indian or Alaskan Native    60272\nAsian/Pacific Islander               61660\nBlack or African American            50137\nHispanic/Latino                      52345\nOthers                               51278\nWhite                                64419\nName: BASE_SALARY, dtype: int64\n```", "```py\n>>> agg = employee.groupby(['RACE', 'GENDER'])['BASE_SALARY'] \\\n                  .mean().astype(int)\n>>> agg\nRACE                               GENDER\nAmerican Indian or Alaskan Native  Female    60238\n                                   Male      60305\nAsian/Pacific Islander             Female    63226\n                                   Male      61033\nBlack or African American          Female    48915\n                                   Male      51082\nHispanic/Latino                    Female    46503\n                                   Male      54782\nOthers                             Female    63785\n                                   Male      38771\nWhite                              Female    66793\n                                   Male      63940\nName: BASE_SALARY, dtype: int64\n```", "```py\n>>> agg.unstack('GENDER')\n```", "```py\n>>> agg.unstack('RACE')\n```", "```py\n>>> agg2 = employee.groupby(['RACE', 'GENDER'])['BASE_SALARY'] \\\n                   .agg(['mean', 'max', 'min']).astype(int)\n>>> agg2\n```", "```py\n>>> agg2.unstack('GENDER')\n```", "```py\n>>> flights = pd.read_csv('data/flights.csv')\n>>> fp = flights.pivot_table(index='AIRLINE', \n                             columns='ORG_AIR', \n                             values='CANCELLED', \n                             aggfunc='sum',\n                             fill_value=0).round(2)\n>>> fp.head()\n```", "```py\n>>> fg = flights.groupby(['AIRLINE', 'ORG_AIR'])['CANCELLED'].sum()\n>>> fg.head()\nAIRLINE  ORG_AIR\nAA       ATL         3\n         DEN         4\n         DFW        86\n         IAH         3\n         LAS         3\nName: CANCELLED, dtype: int64\n```", "```py\n>>> fg_unstack = fg.unstack('ORG_AIR', fill_value=0)\n>>> fp.equals(fg_unstack)\nTrue\n```", "```py\n>>> flights.pivot_table(index=['AIRLINE', 'MONTH'],\n                        columns=['ORG_AIR', 'CANCELLED'],\n                        values=['DEP_DELAY', 'DIST'],\n                        aggfunc=[np.sum, np.mean],\n                        fill_value=0)\n```", "```py\n>>> flights.groupby(['AIRLINE', 'MONTH', 'ORG_AIR', 'CANCELLED']) \\\n           ['DEP_DELAY', 'DIST'] \\\n           .agg(['mean', 'sum']) \\\n           .unstack(['ORG_AIR', 'CANCELLED'], fill_value=0) \\\n           .swaplevel(0, 1, axis='columns')\n```", "```py\n>>> college = pd.read_csv('data/college.csv')\n>>> cg = college.groupby(['STABBR', 'RELAFFIL']) \\\n                ['UGDS', 'SATMTMID'] \\\n                .agg(['size', 'min', 'max']).head(6)\n```", "```py\n>>> cg = cg.rename_axis(['AGG_COLS', 'AGG_FUNCS'], axis='columns')\n>>> cg\n```", "```py\n>>> cg.stack('AGG_FUNCS').head()\n```", "```py\n>>> cg.stack('AGG_FUNCS').swaplevel('AGG_FUNCS', 'STABBR',\n                                    axis='index').head()\n```", "```py\n>>> cg.stack('AGG_FUNCS') \\\n      .swaplevel('AGG_FUNCS', 'STABBR', axis='index') \\\n      .sort_index(level='RELAFFIL', axis='index') \\\n      .sort_index(level='AGG_COLS', axis='columns').head(6)\n```", "```py\n>>> cg.stack('AGG_FUNCS').unstack(['RELAFFIL', 'STABBR'])\n```", "```py\n>>> cg.stack(['AGG_FUNCS', 'AGG_COLS']).head(12)\nSTABBR  RELAFFIL  AGG_FUNCS  AGG_COLS\nAK      0         count      UGDS            7.0\n                             SATMTMID        0.0\n                  min        UGDS          109.0\n                  max        UGDS        12865.0\n        1         count      UGDS            3.0\n                             SATMTMID        1.0\n                  min        UGDS           27.0\n                             SATMTMID      503.0\n                  max        UGDS          275.0\n                             SATMTMID      503.0\nAL      0         count      UGDS           71.0\n                             SATMTMID       13.0\ndtype: float64\n```", "```py\n>>> cg.rename_axis([None, None], axis='index') \\\n      .rename_axis([None, None], axis='columns')\n```", "```py\n>>> weightlifting = pd.read_csv('data/weightlifting_men.csv')\n>>> weightlifting\n```", "```py\n>>> wl_melt = weightlifting.melt(id_vars='Weight Category', \n                                 var_name='sex_age', \n                                 value_name='Qual Total')\n>>> wl_melt.head()\n```", "```py\n>>> sex_age = wl_melt['sex_age'].str.split(expand=True)\n>>> sex_age.head()\n```", "```py\n>>> sex_age.columns = ['Sex', 'Age Group']\n>>> sex_age.head()\n```", "```py\n>>> sex_age['Sex'] = sex_age['Sex'].str[0]\n>>> sex_age.head()\n```", "```py\n>>> wl_cat_total = wl_melt[['Weight Category', 'Qual Total']]\n>>> wl_tidy = pd.concat([sex_age, wl_cat_total], axis='columns')\n>>> wl_tidy.head()\n```", "```py\n>>> cols = ['Weight Category', 'Qual Total']\n>>> sex_age[cols] = wl_melt[cols]\n```", "```py\n>>> age_group = wl_melt.sex_age.str.extract('(\\d{2}[-+](?:\\d{2})?)',\n                                            expand=False)\n>>> sex = wl_melt.sex_age.str[0]\n>>> new_cols = {'Sex':sex, \n                'Age Group': age_group}\n>>> wl_tidy2 = wl_melt.assign(**new_cols) \\\n                      .drop('sex_age',axis='columns')\n\n>>> wl_tidy2.sort_index(axis=1).equals(wl_tidy.sort_index(axis=1))\nTrue\n```", "```py\n>>> inspections = pd.read_csv('data/restaurant_inspections.csv',\n                              parse_dates=['Date'])\n>>> inspections.head()\n```", "```py\n>>> inspections.pivot(index=['Name', 'Date'],\n                      columns='Info', values='Value')\nNotImplementedError: > 1 ndim Categorical are not supported at this time\n```", "```py\n>>> inspections.set_index(['Name','Date', 'Info']).head(10)\n```", "```py\n>>> inspections.set_index(['Name','Date', 'Info']) \\\n               .unstack('Info').head()\n```", "```py\n>>> insp_tidy = inspections.set_index(['Name','Date', 'Info']) \\\n                           .unstack('Info') \\\n                           .reset_index(col_level=-1)\n>>> insp_tidy.head()\n```", "```py\n>>> insp_tidy.columns = insp_tidy.columns.droplevel(0) \\\n                                         .rename(None)\n>>> insp_tidy.head()\n```", "```py\n>>> inspections.set_index(['Name','Date', 'Info']) \\\n               .squeeze() \\\n               .unstack('Info') \\\n               .reset_index() \\\n               .rename_axis(None, axis='columns')\n```", "```py\n>>> inspections.pivot_table(index=['Name', 'Date'], \n                            columns='Info', \n                            values='Value', \n                            aggfunc='first') \\\n               .reset_index() \\\n               .rename_axis(None, axis='columns')\n```", "```py\n>>> cities = pd.read_csv('data/texas_cities.csv')\n>>> cities\n```", "```py\n>>> geolocations = cities.Geolocation.str.split(pat='. ',\n                                                expand=True)\n>>> geolocations.columns = ['latitude', 'latitude direction',\n                            'longitude', 'longitude direction']\n>>> geolocations\n```", "```py\n>>> geolocations = geolocations.astype({'latitude':'float',\n                                        'longitude':'float'})\n>>> geolocations.dtypes\nlatitude               float64\nlatitude direction      object\nlongitude              float64\nlongitude direction     object\ndtype: object\n```", "```py\n>>> cities_tidy = pd.concat([cities['City'], geolocations],\n                            axis='columns')\n>>> cities_tidy\n```", "```py\n>>> geolocations.apply(pd.to_numeric, errors='ignore')\n```", "```py\n>>> cities.Geolocation.str.split(pat='° |, ', expand=True)\n```", "```py\n>>> cities.Geolocation.str.extract('([0-9.]+). (N|S), ([0-9.]+). (E|W)',\n                                   expand=True)\n```", "```py\n>>> sensors = pd.read_csv('data/sensors.csv')\n>>> sensors\n```", "```py\n>>> sensors.melt(id_vars=['Group', 'Property'], var_name='Year') \\\n           .head(6)\n```", "```py\n>>> sensors.melt(id_vars=['Group', 'Property'], var_name='Year') \\\n           .pivot_table(index=['Group', 'Year'],\n                        columns='Property', values='value') \\\n           .reset_index() \\\n           .rename_axis(None, axis='columns')\n```", "```py\n>>> sensors.set_index(['Group', 'Property']) \\\n           .stack() \\\n           .unstack('Property') \\\n           .rename_axis(['Group', 'Year'], axis='index') \\\n           .rename_axis(None, axis='columns') \\\n           .reset_index()\n```", "```py\n>>> movie = pd.read_csv('data/movie_altered.csv')\n>>> movie.head()\n```", "```py\n>>> movie.insert(0, 'id', np.arange(len(movie)))\n>>> movie.head()\n```", "```py\n>>> stubnames = ['director', 'director_fb_likes',\n                 'actor', 'actor_fb_likes']\n>>> movie_long = pd.wide_to_long(movie, \n                                 stubnames=stubnames, \n                                 i='id', \n                                 j='num', \n                                 sep='_').reset_index()\n\n>>> movie_long['num'] = movie_long['num'].astype(int)\n>>> movie_long.head(9)\n```", "```py\n>>> movie_table = movie_long[['id', 'title', 'year', 'duration', 'rating']]\n>>> director_table = movie_long[['id', 'num',\n                                 'director', 'director_fb_likes']]\n>>> actor_table = movie_long[['id', 'num',\n                              'actor', 'actor_fb_likes']]\n```", "```py\n>>> movie_table = movie_table.drop_duplicates() \\\n                               .reset_index(drop=True)\n>>> director_table = director_table.dropna() \\\n                                     .reset_index(drop=True)\n>>> actor_table = actor_table.dropna() \\\n                             .reset_index(drop=True)\n```", "```py\n>>> movie.memory_usage(deep=True).sum()\n2318234\n\n>>> movie_table.memory_usage(deep=True).sum() + \\\n    director_table.memory_usage(deep=True).sum() + \\\n    actor_table.memory_usage(deep=True).sum()\n2627306\n```", "```py\n>>> director_cat = pd.Categorical(director_table['director'])\n>>> director_table.insert(1, 'director_id', director_cat.codes)\n\n>>> actor_cat = pd.Categorical(actor_table['actor'])\n>>> actor_table.insert(1, 'actor_id', actor_cat.codes)\n```", "```py\n>>> director_associative = director_table[['id', 'director_id',\n                                           'num']]\n>>> dcols = ['director_id', 'director', 'director_fb_likes']\n>>> director_unique = director_table[dcols].drop_duplicates() \\\n                                           .reset_index(drop=True)\n```", "```py\n>>> actor_associative = actor_table[['id', 'actor_id', 'num']]\n>>> acols = ['actor_id', 'actor', 'actor_fb_likes']\n>>> actor_unique = actor_table[acols].drop_duplicates() \\\n                                     .reset_index(drop=True)\n```", "```py\n>>> movie_table.memory_usage(deep=True).sum() + \\\n    director_associative.memory_usage(deep=True).sum() + \\\n    director_unique.memory_usage(deep=True).sum() + \\\n    actor_associative.memory_usage(deep=True).sum() + \\\n    actor_unique.memory_usage(deep=True).sum()\n1833402\n```", "```py\n>>> actors = actor_associative.merge(actor_unique, on='actor_id') \\\n                              .drop('actor_id', 1) \\\n                              .pivot_table(index='id', \n                                           columns='num',\n                                           aggfunc='first')\n\n>>> actors.columns = actors.columns.get_level_values(0) + '_' + \\\n                     actors.columns.get_level_values(1).astype(str)\n\n>>> directors = director_associative.merge(director_unique,\n                                           on='director_id') \\\n                                    .drop('director_id', 1) \\\n                                    .pivot_table(index='id',\n                                                 columns='num',\n                                                 aggfunc='first')\n\n>>> directors.columns = directors.columns.get_level_values(0) + '_' + \\\n                        directors.columns.get_level_values(1) \\\n                                         .astype(str)\n```", "```py\n>>> movie2 = movie_table.merge(directors.reset_index(),\n                               on='id', how='left') \\\n                        .merge(actors.reset_index(),\n                               on='id', how='left')\n>>> movie.equals(movie2[movie.columns])\nTrue\n```"]