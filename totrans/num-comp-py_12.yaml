- en: Index Alignment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When multiple Series or DataFrames are combined in some way, each dimension
    of the data automatically aligns on each axis first before any computation happens.
    This silent and automatic alignment of axes can cause tremendous confusion for
    the uninitiated, but it gives great flexibility to the power user. This chapter
    explores the Index object in-depth before showcasing a variety of recipes that
    take advantage of its automatic alignment.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Examining the Index object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Producing Cartesian products
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploding indexes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filling values with unequal indexes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appending columns from different DataFrames
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Highlighting the maximum value from each column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replicating `idxmax` with method chaining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the most common maximum
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examining the Index object
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each axis of Series and DataFrames has an Index object that labels the values.
    There are many different types of Index objects, but they all share the same common
    behavior. All Index objects, except for the special MultiIndex, are single-dimensional
    data structures that combine the functionality and implementation of Python sets
    and NumPy ndarrays.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will examine the column index of the college dataset and
    explore much of its functionality.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the college dataset, assign for the column index to a variable, and
    output it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `values` attribute to access the underlying NumPy array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Select items from the index by integer location with scalars, lists, or slices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Indexes share many of the same methods as Series and DataFrames:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Use basic arithmetic and comparison operators directly on `Index` objects:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Trying to change an Index value directly after its creation fails. Indexes
    are immutable objects:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you can see from many of the Index object operations, it appears to have
    quite a bit in common with both Series and `ndarrays`. One of the biggest differences
    comes in step 6\. Indexes are immutable and their values cannot be changed once
    created.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Indexes support the set operations, union, intersection, difference, and symmetric
    difference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Indexes share some of the same operations as Python sets. Indexes are similar
    to Python sets in another important way. They are (usually) implemented using
    hash tables, which make for extremely fast access when selecting rows or columns
    from a DataFrame. As they are implemented using hash tables, the values for the
    Index object need to be immutable such as a string, integer, or tuple just like
    the keys in a Python dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: Indexes support duplicate values, and if there happens to be a duplicate in
    any Index, then a hash table can no longer be
  prefs: []
  type: TYPE_NORMAL
- en: used for its implementation, and object access becomes much slower.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pandas official documentation of `Index` ([http://bit.ly/2upfgtr](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Index.html))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Producing Cartesian products
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whenever two Series or DataFrames operate with another Series or DataFrame,
    the indexes (both the row index and column index) of each object align first before
    any operation begins. This index alignment happens silently and can be very surprising
    for those new to pandas. This alignment always creates a Cartesian product between
    the indexes unless the indexes are identical.
  prefs: []
  type: TYPE_NORMAL
- en: A Cartesian product is a mathematical term that usually appears in set theory.
    A Cartesian product between two sets is all the combinations of pairs of both
    sets. For example, the 52 cards in a standard playing card deck represent a Cartesian
    product between the 13 ranks (A, 2, 3,..., Q, K) and the four suits.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Producing a Cartesian product isn't always the intended outcome, but it's extremely
    important to be aware of how and when it occurs to avoid unintended consequences.
    In this recipe, two Series with overlapping but non-identical indexes are added
    together, yielding a surprising result.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these steps to create a Cartesian product:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Construct two Series that have indexes that are different but contain some
    of the same values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the two Series together to produce a Cartesian product:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each Series was created with the class constructor which accepts a wide variety
    of inputs with the simplest being a sequence of values for each of the parameters
    `index` and data.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical Cartesian products are slightly different from the outcome of operating
    on two pandas objects. Each `a` label in `s1` pairs up with each `a` label in
    `s2`. This pairing produces six `a` labels, three `b` labels, and one `c` label
    in the resulting Series. A Cartesian product happens between all identical index
    labels.
  prefs: []
  type: TYPE_NORMAL
- en: As the element with label `c` is unique to Series `s2`, pandas defaults its
    value to missing, as there is no label for it to align to in `s1`. Pandas defaults
    to a missing value whenever an index label is unique to one object. This has the
    unfortunate consequence of changing the data type of the Series to a float, whereas
    each Series had only integers as values. This occurred because of NumPy's missing
    value object; `np.nan` only exists for floats but not for integers. Series and
    DataFrame columns must have homogeneous numeric data types; therefore, each value
    was converted to a float. This makes very little difference for this small dataset,
    but for larger datasets, this can have a significant memory impact.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An exception to the preceding example takes place when the indexes contain
    the same exact elements in the same order. When this occurs, a Cartesian product
    does not take place, and the indexes instead align by their position. Notice here
    that each element aligned exactly by position and that the data type remained
    an integer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'If the elements of the index are identical, but the order is different between
    the Series, a Cartesian product occurs. Let''s change the order of the index in
    `s2` and rerun the same operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It is quite interesting that pandas has two drastically different outcomes for
    this same operation. If a Cartesian product was the only choice for pandas, then
    something as simple as adding DataFrame columns together would explode the number
    of elements returned.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, each Series had a different number of elements. Typically, array-like
    data structures in Python and other languages do not allow operations to take
    place when the operating dimensions do not contain the same number of elements.
    Pandas allows this to happen by aligning the indexes first before completing the
    operation.
  prefs: []
  type: TYPE_NORMAL
- en: Exploding indexes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous recipe walked through a trivial example of two small Series being
    added together with unequal indexes. This problem can produce comically incorrect
    results when dealing with larger data.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we add two larger Series that have indexes with only a few unique
    values but in different orders. The result will explode the number of values in
    the indexes.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the employee data and set the index equal to the race column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/3c2c2456-00e7-471b-9b21-c30ae0628d71.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select the `BASE_SALARY` column as two different Series. Check to see whether
    this operation actually did create two new objects:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The `salary1` and `salary2` variables are actually referring to the same object.
    This means that any change to one will change the other. To ensure that you receive
    a brand new copy of the data, use the `copy` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s change the order of the index for one of the Series by sorting it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s add these `salary` Series together:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The operation completed successfully. Let''s create one more Series of `salary1`
    added to itself and then output the lengths of each Series. We just exploded the
    index from 2,000 values to more than 1 million:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Step 2 appears at first to create two unique objects but in fact, it creates
    a single object that is referred to by two different variable names. The expression `employee['BASE_SALARY']`,
    technically creates a **view**, and not a brand new copy. This is verified with
    the `is` operator.
  prefs: []
  type: TYPE_NORMAL
- en: In pandas, a view is not a new object but just a reference to another object,
    usually some subset of a DataFrame. This shared object can be a cause for many
    issues.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure that both variables reference completely different objects, we use
    the `copy` Series method and again verify that they are different objects with
    the `is` operator. Step 4 uses the `sort_index` method to sort the Series by race.
    Step 5 adds these different Series together to produce some result. By just inspecting
    the head, it's still not clear what has been produced.
  prefs: []
  type: TYPE_NORMAL
- en: Step 6 adds `salary1` to itself to show a comparison between the two different
    Series additions. The length of all the Series in this recipe are output and we
    clearly see that `series_add` has now exploded to over one million values. A Cartesian
    product took place for each unique value in the index because the indexes were
    not exactly the same. This recipe dramatically shows how much of an impact the
    index can have when combining multiple Series or DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can verify the number of values of `salary_add` by doing a little mathematics.
    As a Cartesian product takes place between all of the same index values, we can
    sum the square of their individual counts. Even missing values in the index produce
    Cartesian products with themselves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Filling values with unequal indexes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When two Series are added together using the plus operator and one of the index
    labels does not appear in the other, the resulting value is always missing. Pandas
    offers the `add` method, which provides an option to fill the missing value.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we add together multiple Series from the `baseball` dataset
    with unequal indexes using the `fill_value` parameter of the `add` method to ensure
    that there are no missing values in the result.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the three `baseball` datasets and set the index as `playerID`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/3df8c217-9081-49b2-86c8-2737836ff6d9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the index method `difference` to discover which index labels are in `baseball_14`
    and not in `baseball_15`, and vice versa:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'There are quite a few players unique to each index. Let''s find out how many
    hits each player has in total over the three-year period. The `H` column contains
    the number of hits:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s first add together two Series using the plus operator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Even though players `congeha01` and `corpoca01` have recorded hits for 2015,
    their result is missing. Let''s use the `add` method and its parameter, `fill_value`,
    to avoid missing values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We add hits from 2016 by chaining the `add` method once more:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Check for missing values in the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `add` method works similarly to the plus operator but allows for more flexibility
    by providing the `fill_value` parameter to take the place of a non-matching index.
    In this problem, it makes sense to default the non-matching index value to 0,
    but you could have used any other number.
  prefs: []
  type: TYPE_NORMAL
- en: 'There will be occasions when each Series contains index labels that correspond
    to missing values. In this specific instance, when the two Series are added, the
    index label will still correspond to a missing value regardless if the `fill_value`
    parameter is used. To clarify this, take a look at the following example where
    the index label `a` corresponds to a missing value in each Series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe shows how to add Series with only a single index together. It is
    also entirely possible to add DataFrames together. Adding DataFrames together
    will align both the index and columns before computation and yield missing values
    for non-matching indexes. Let's start by selecting a few of the columns from the
    2014 baseball dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/925e3c65-b0b0-4610-8768-ed57f0f07d3e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s also select a few of the same and a few different columns from the 2015
    baseball dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/48c50717-2d2c-4ab0-b247-7ac9996abf1e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Adding the two DataFrames together create missing values wherever rows or column
    labels cannot align. Use the `style` attribute to access the `highlight_null`
    method to easily see where the missing values are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/7d3abb8d-db33-4a10-b126-7fcdb14c8e92.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Only the rows with `playerID` appearing in both DataFrames will be non-missing.
    Similarly, the columns `AB`, `H`, and `R` are the only ones that appear in both
    DataFrames. Even if we use the `add` method with the `fill_value` parameter specified,
    we still have missing values. This is because some combinations of rows and columns
    never existed in our input data. For example, the intersection of `playerID` *congeha01*
    and column `G`. He only appeared in the 2015 dataset that did not have the `G`
    column. Therefore, no value was filled with it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/034d596f-f6a3-4bef-a441-9876f382215f.png)'
  prefs: []
  type: TYPE_IMG
- en: Appending columns from different DataFrames
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All DataFrames can add new columns to themselves. However, as usual, whenever
    a DataFrame is adding a new column from another DataFrame or Series, the indexes
    align first before the new column is created.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe uses the `employee` dataset to append a new column containing the
    maximum salary of that employee's department.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Import the `employee` data and select the `DEPARTMENT` and `BASE_SALARY` columns
    in a new DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Sort this smaller DataFrame by salary within each department:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `drop_duplicates` method to keep the first row of each `DEPARTMENT`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/d8ceb0fc-6e16-478d-92aa-0c92e459cee3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Put the `DEPARTMENT` column into the index for each DataFrames:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that the indexes contain matching values, we can append a new column to
    the `employee` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/c4b7b4e0-0965-4667-aa95-5a77cb78a941.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can validate our results with the `query` method to check whether there
    exist any rows where `BASE_SALARY` is greater than `MAX_DEPT_SALARY`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/1e21fa39-41e4-46f4-9077-ce4e247d2181.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Steps 2 and 3 find the maximum salary for each department. For automatic index
    alignment to work properly, we set each DataFrame index as the department. Step
    5 works because each row index from the left DataFrame; `employee` aligns with
    one and only one index from the right DataFrame, `max_dept_sal`. If `max_dept_sal` had
    repeats of any departments in its index, then the operation would fail.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, let''s see what happens when we use a DataFrame on the right-hand
    side of the equality that has repeated index values. We use the `sample` DataFrame
    method to randomly choose ten rows without replacement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/c71b573f-af49-4b9e-9bbb-cacd9c5d9532.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Notice how there are several repeated departments in the index. Now when we
    attempt to create a new column, an error is raised alerting us that there are
    duplicates. At least one index label in the `employee` DataFrame is joining with
    two or more index labels from `random_salary`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Not all indexes on the left-hand side of the equal sign need to have a match,
    but at most can have one. If there is nothing for the left DataFrame index to
    align to, the resulting value will be missing. Let''s create an example where
    this happens. We will use only the first three rows of the `max_dept_sal` Series
    to create a new column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: The operation completed successfully but filled in salaries for only three of
    the departments. All the other departments that did not appear in the first three
    rows of the `max_dept_sal` Series resulted in a missing value.
  prefs: []
  type: TYPE_NORMAL
- en: Highlighting the maximum value from each column
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `college` dataset has many numeric columns describing different metrics
    about each school. Many people are interested in schools that perform the best
    for certain metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe discovers the school that has the maximum value for each numeric
    column and styles the DataFrame in order to highlight the information so that
    it is easily consumed by a user.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read the college dataset with the institution name as the index:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'All the other columns besides `CITY` and `STABBR` appear to be numeric. Examining
    the data types from the preceding step reveals unexpectedly that the `MD_EARN_WNE_P10`
    and `GRAD_DEBT_MDN_SUPP` columns are of type object and not numeric. To help get
    a better idea of what kind of values are in these columns, let''s examine their
    first value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'These values are strings but we would like them to be numeric. This means that
    there are likely to be non-numeric characters that appear elsewhere in the Series.
    One way to check for this is to sort these columns in descending order and examine
    the first few rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The culprit appears to be that some schools have privacy concerns about these
    two columns of data. To force these columns to be numeric, use the pandas function `to_numeric`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `select_dtypes` method to filter for only numeric columns. This will
    exclude `STABBR` and `CITY` columns, where a maximum value doesn''t make sense
    with this problem:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/8b94a8f7-cb84-4108-b3d3-798f75cdce6d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'By utilizing the data dictionary, there are several columns that have only
    binary (0/1) values that will not provide useful information. To programmatically
    find these columns, we can create boolean Series and find all the columns that
    have two unique values with the `nunique` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Pass this boolean Series to the indexing operator of the columns index object
    and create a list of the binary columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Remove the binary columns with the `drop` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/f0aef0a2-b9f1-404c-8fab-7b302aa8bada.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the `idxmax` method to find the index label of the maximum value for each
    column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Call the `unique` method on the `max_cols` Series. This returns an `ndarray`
    of the unique column names:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the values of `max_cols` to select only the rows that have schools with
    a maximum value and then use the `style` attribute to highlight these values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/eac420e0-ba86-4a95-95aa-059b068cb5fd.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `idxmax` method is very powerful and becomes quite useful when the index
    is meaningfully labeled. It was unexpected that both `MD_EARN_WNE_P10` and `GRAD_DEBT_MDN_SUPP`
    were of `object` data type. When importing, pandas coerces all numeric values
    of columns to strings if the column contains at least one string.
  prefs: []
  type: TYPE_NORMAL
- en: By examining a specific column value in step 2, we were able to see clearly
    that we had strings in these columns. In step 3, we sort in descending order as
    numeric characters appear first. This elevates all alphabetical values to the
    top of the Series. We uncover the `PrivacySuppressed` string causing havoc. Pandas
    has the ability to force all strings that contain only numeric characters to actual
    numeric data types with the `to_numeric` function. To override the default behavior
    of raising an error when `to_numeric` encounters a string that cannot be converted,
    you must pass *coerce* to the `errors` parameter. This forces all non-numeric
    character strings to become missing values (`np.nan`).
  prefs: []
  type: TYPE_NORMAL
- en: Several columns don't have useful or meaningful maximum values. They were removed
    in step 4 through step 6\. The `select_dtypes` can be extremely useful for very
    wide DataFrames with lots of columns.
  prefs: []
  type: TYPE_NORMAL
- en: In step 7, `idxmax` iterates through all the columns to find the index of the
    maximum value for each column. It outputs the results as a Series. The school
    with both the highest SAT math and verbal scores is California Institute of Technology.
    Dongguk University Los Angeles has the highest number of students older than 25.
  prefs: []
  type: TYPE_NORMAL
- en: Although the information provided by `idxmax` is nice, it does not yield the
    corresponding maximum value. To do this, we gather all the unique school names
    from the values of the `max_cols` Series.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in step 8, we use the `.loc` indexer to select rows based on the index
    label, which we made as school names in the first step. This filters for only
    schools that have a maximum value. DataFrames have an experimental `style` attribute
    that itself has some methods to alter the appearance of the displayed DataFrame.
    Highlighting the maximum value makes the result much clearer.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By default, the `highlight_max` method highlights the maximum value of each
    column. We can use the `axis` parameter to highlight the maximum value of each
    row instead. Here, we select just the race percentage columns of the `college`
    dataset and highlight the race with the highest percentage for each school:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/55f8f912-bfef-4d73-9205-ee2c8d67e1cb.png)'
  prefs: []
  type: TYPE_IMG
- en: Attempting to apply a style on a large DataFrame can cause Jupyter to crash,
    which is why the style was only applied to the head of the DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pandas official documentation on Dataframe *Styling* ([http://bit.ly/2hsZkVK](https://pandas.pydata.org/pandas-docs/stable/style.html))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replicating idxmax with method chaining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It can be a good exercise to attempt an implementation of a built-in DataFrame
    method on your own. This type of replication can give you a deeper understanding
    of other pandas methods that you normally wouldn't have come across. `idxmax`
    is a challenging method to replicate using only the methods covered thus far in
    the book.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe slowly chains together basic methods to eventually find all the
    row index values that contain a maximum column value.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Load in the college dataset and execute the same operations as the previous
    recipe to get only the numeric columns that are of interest:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Find the maximum of each column with the `max` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `eq` DataFrame method to test each value with its column `max`. By
    default, the `eq` method aligns the columns of the column DataFrame with the labels
    of the passed Series index:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/e0256497-0a05-4391-b89c-474c19ba9c8a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'All the rows in this DataFrame that have at least one `True` value must contain
    a column maximum. Let''s use the `any` method to find all such rows that have
    at least one `True` value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'There are only 18 columns, which means that there should only be at most 18
    `True` values in `has_row_max`. Let''s find out how many there actually are:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'This was a bit unexpected, but it turns out that there are columns with many
    rows that equal the maximum value. This is common with many of the percentage
    columns that have a maximum of 1\. `idxmax` returns the first occurrence of the
    maximum value. Let''s back up a bit, remove the `any` method, and look at the
    output from step 3\. Let''s run the `cumsum` method instead to accumulate all
    the `True` values. The first and last three rows are shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/3591f3ec-bbbd-49d3-834c-c838e44f4009.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Some columns have one unique maximum like `SATVRMID` and `SATMTMID`, while
    others like `UGDS_WHITE` have many. 109 schools have 100% of their undergraduates
    as white. If we chain the `cumsum` method one more time, the value 1 would only
    appear once in each column and it would be the first occurrence of the maximum:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/0528cfc1-4884-47df-a1d5-fa527e3ea823.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can now test the equality of each value against 1 with the `eq` method and
    then use the `any` method to find rows that have at least one `True` value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Test that `has_row_max2` has no more `True` values than the number of columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'We need all the institutions where `has_row_max2` is `True`. We can simply
    use boolean indexing on the Series itself:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'All 16 of these institutions are the index of the first maximum occurrence
    for at least one of the columns. We can check whether they are the same as the
    ones found with the `idxmax` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first step replicates work from the previous recipe by converting two columns
    to numeric and eliminating the binary columns. We find the maximum value of each
    column in step 2\. Care needs to be taken here as pandas silently drops columns
    that it cannot produce a maximum. If this happens, then step 3 will still complete
    but produce all `False` values for each column without an available maximum.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 uses the `any` method to scan across each row in search of at least one
    `True` value. Any row with at least one `True` value contains a maximum value
    for a column. We sum up the resulting boolean Series in step 5 to determine how
    many rows contain a maximum. Somewhat unexpectedly, there are far more rows than
    columns. Step 6 gives insight on why this happens. We take a cumulative sum of
    the output from step 3 and detect the total number of rows that equal the maximum
    for each column.
  prefs: []
  type: TYPE_NORMAL
- en: Many colleges have 100% of their student population as only a single race. This
    is by far the largest contributor to the multiple rows with maximums. As you can
    see, there is only one row with a maximum value for both SAT score columns and
    undergraduate population, but several of the race columns have a tie for the maximum.
  prefs: []
  type: TYPE_NORMAL
- en: Our goal is to find the first row with the maximum value. We need to take the
    cumulative sum once more so that each column has only a single row equal to 1\.
    Step 8 formats the code to have one method per line and runs the `any` method
    exactly as it was done in step 4\. If this step is successful, then we should
    have no more `True` values than the number of columns. Step 9 asserts that this
    is true.
  prefs: []
  type: TYPE_NORMAL
- en: To validate that we have found the same columns as `idxmax` in the previous
    columns, we use boolean selection on `has_row_max2` with itself. The columns will
    be in a different order so we convert the sequence of column names to sets, which
    are inherently unordered to compare equality.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is possible to complete this recipe in one long line of code chaining the
    indexing operator with an anonymous function. This little trick removes the need
    for step 10\. We can time the difference between the direct `idxmax` method and
    our manual effort in this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Our effort is, unfortunately, five times as slow as the built-in `idxmax` pandas
    method but regardless of its performance regression, many creative and practical
    solutions use the accumulation methods like `cumsum` with boolean Series to find
    streaks or specific patterns along an axis.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the most common maximum
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The college dataset contains the undergraduate population percentage of eight
    different races for over 7,500 colleges. It would be interesting to find the race
    with the highest undergrad population for each school and then find the distribution
    of this result for the entire dataset. We would be able to answer a question like,
    *What percentage of institutions have more white students than any other race?*
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we find the race with the highest percentage of the undergraduate
    population for each school with the `idxmax` method and then find the distribution
    of these maximums.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the college dataset and select just those columns with undergraduate
    race percentage information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/69b400f6-4d02-4018-9443-ba548c759335.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the `idxmax` method to get the column name with the highest race percentage
    for each row:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `value_counts` method to return the distribution of maximum occurrences:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The key to this recipe is recognizing that the columns all represent the same
    unit of information. We can compare these columns with each other, which is usually
    not the case. For instance, it wouldn't make sense to directly compare SAT verbal
    scores with the undergraduate population. As the data is structured in this manner,
    we can apply the `idxmax` method to each row of data to find the column with the
    largest value. We need to alter its default behavior with the `axis` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 completes this operation and returns a Series, to which we can now simply
    apply the `value_counts` method to return the distribution. We pass `True` to
    the `normalize` parameter as we are interested in the distribution (relative frequency)
    and not the raw counts.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We might want to explore more and answer the question: For the schools with
    more black students than any other race, what is the distribution of its second
    highest race percentage?'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: We needed to drop the `UGDS_BLACK` column before applying the same method from
    this recipe. Interestingly, it seems that these schools with higher black populations
    have a tendency to have higher Hispanic populations.
  prefs: []
  type: TYPE_NORMAL
