- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recent Developments in Time Series Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we reach the last chapter of this book, let’s do a brief recap of the journey
    we have been through. Starting with an introduction to time series and its components
    in [*Chapter 1*](B18568_01.xhtml#_idTextAnchor016), we looked at the different
    use cases for time series analysis in [*Chapter 2*](B18568_02.xhtml#_idTextAnchor044).
    We were then introduced to Apache Spark, its architecture, and how it works in
    [*Chapter 3*](B18568_03.xhtml#_idTextAnchor063). Before delving into the details
    of how Apache Spark is used for time series analysis, we stepped back, in [*Chapter
    4*](B18568_04.xhtml#_idTextAnchor087), to look at the big picture of an end-to-end
    time series project. We then turned our focus to each of the main stages of a
    project from [*Chapter 5*](B18568_05.xhtml#_idTextAnchor103) to [*Chapter 9*](B18568_09.xhtml#_idTextAnchor169),
    covering data preparation, exploratory data analysis, model development, testing,
    scaling, and going to production. In [*Chapter 10*](B18568_10.xhtml#_idTextAnchor190),
    we covered ways to go further with Apache Spark by using a managed data and AI
    platform such as Databricks.
  prefs: []
  type: TYPE_NORMAL
- en: In this concluding chapter, we will explore recent developments in the field
    of time series analysis, covering emerging methodologies, tools, and trends. We
    will cover an approach from the exciting field of generative AI applied to time
    series forecasting. Having a forecasting mechanism in place is great but not enough.
    Another area of interesting development is how forecasting is served and made
    available on demand to data analysts and applications. End users can also benefit
    from new approaches to making the outcome of time series analysis accessible to
    them in non-technical ways.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI for time series
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serving forecasts via API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Democratizing access to time series analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will be using a Databricks environment for the platform infrastructure. To
    set up the environment, follow the instructions in the *Environment setup* section
    of [*Chapter 10*](B18568_10.xhtml#_idTextAnchor190).
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this chapter can be found at this URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/tree/main/ch11](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/tree/main/ch11)'
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI for time series analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While effective, traditional time series models have limitations in performance
    and accuracy, especially with large-scale data or complex patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI, and particularly **time series transformers** (**TSTs**), offers
    a solution to these challenges. Similar to the transformer models in **natural
    language processing** (**NLP**), TSTs are adept at capturing complex, non-linear
    dependencies over long sequences. This capability makes them suitable for real-world
    data that includes missing values, seasonality, and irregular patterns. TSTs use
    a self-attention mechanism to analyze time series data and identify seasonal patterns.
    These models are pre-trained on vast datasets to create foundation models, which
    can then be fine-tuned for specific time series applications.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, several pre-built TSTs have been released enabling us to leverage
    their capabilities without requiring effort to engineer such solutions. Examples
    include Chronos, Moira, TimesFM, and TimeGPT, among others.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will examine the practicalities of using one of these
    with TimesFM.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to TimesFM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**TimesFM**, short for **Time Series Foundation Model**, is an open source
    forecasting model developed by Google Research, designed specifically for time
    series data. Built on a transformer-based architecture, TimesFM is versatile,
    handling a wide range of forecasting tasks from short-term to long-term predictions.
    Unlike models such as Chronos, which treat time series similarly to natural language,
    TimesFM includes specialized mechanisms for time series data, such as seasonality
    handling, support for missing values, and capturing multivariate dependencies.'
  prefs: []
  type: TYPE_NORMAL
- en: Pre-trained on over 100 billion real-world time series points, TimesFM generalizes
    effectively to new datasets, often providing accurate zero-shot predictions without
    additional training. This extensive pre-training allows TimesFM to recognize both
    short- and long-term dependencies in time series data, making it highly useful
    for applications requiring an understanding of seasonal patterns and trends.
  prefs: []
  type: TYPE_NORMAL
- en: 'For an overview of the TimesFM architecture and a detailed explanation, we
    recommend consulting the original research paper, *A decoder-only foundation model
    for time-series* *forecasting*, here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://research.google/blog/a-decoder-only-foundation-model-for-time-series-forecasting/](https://research.google/blog/a-decoder-only-foundation-model-for-time-series-forecasting/)'
  prefs: []
  type: TYPE_NORMAL
- en: We will see TimesFM in action with a forecasting example in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the time series forecasting example in this section, we will be using the
    Databricks environment as set up in the *Technical requirements* section. The
    code for this section can be uploaded into the Databricks workspace from the following
    URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch11/ts_spark_ch11_timesFM.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch11/ts_spark_ch11_timesFM.dbc)'
  prefs: []
  type: TYPE_NORMAL
- en: You can use the Databricks serverless compute to execute the code, as we did
    in [*Chapter 10*](B18568_10.xhtml#_idTextAnchor190). Alternatively, you can use
    the Databricks Runtime for ML. Version 14.3 is required for compatibility with
    the version of Python supported by TimesFM at the time of writing.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will go through the steps to install and use TimesFM here, with code extracts.
    Refer to the notebook for the full code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the following necessary libraries: `timesfm[torch]`, `torch`, and `sktime`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Specify the hyperparameters (`hparams`) and load the TimesFM model from a checkpoint
    in Hugging Face (`huggingface_repos_id`). Note that `500m` refers to the 500 million
    parameters supported by the model, and we will use the `pytorch` version due to
    compatibility with Databricks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: While we have used the default values for the hyperparameters, you will need
    to experiment to find the best ones to use depending on your forecasting requirement.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With the TimesFM model loaded, we can bring in the dataset for forecasting.
    We will reuse the energy consumption dataset from [*Chapter 10*](B18568_10.xhtml#_idTextAnchor190).
    Before proceeding with the next step, you must execute the code example, including
    the feature engineering pipeline from the previous chapter.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We will read from the `features_aggr_power_consumption` table and convert the
    Spark DataFrame into a pandas DataFrame, which is required by TimesFM. The `Date`
    column is renamed to `date` and converted to the `datetime` format, as expected
    by the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Function to create a data pipeline for batching time series
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: data
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: def get_batched_data_fn(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: …
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: examples["inputs"].append(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: sub_df["hourly_Global_active_power"][
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: start:(context_end := start + context_len)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '].tolist())'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: …
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: examples["outputs"].append(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: sub_df["hourly_Global_active_power"][
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: context_end:(context_end + horizon_len)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '].tolist())'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: …
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can then iterate over the batches of input data to generate the forecast
    using the `forecast` function, as in the following code extract:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We evaluate the forecast using the `mdape` metric, as we have done in the previous
    chapters. This is comparable to [*Chapter 10*](B18568_10.xhtml#_idTextAnchor190):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This gives the following result:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As we have seen in this section, using a pre-trained transformer-based foundation
    model such as TimesFM, with default hyperparameters, gives us comparable accuracy
    to the different approaches we have used in the previous chapters. With hyperparameter
    tuning and the use of covariates, which will be discussed next, we can seek to
    further improve accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Support for covariates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An important feature of TimesFM is its support for external **covariates**,
    as time series rarely occur in isolation. Various factors, such as economic indicators
    or weather conditions, can correlate with a time series, and incorporating these
    into the analysis can improve prediction accuracy. Put simply, a covariate is
    a separate variable that can help us forecast a time series.
  prefs: []
  type: TYPE_NORMAL
- en: TimesFM accommodates both univariate and multivariate forecasting with covariates,
    enabling it to capture correlations between the target series and these external
    variables. By inputting covariates as parallel sequences, the model learns how
    they relate to future values over time, enhancing its adaptability to real-world
    scenarios where external factors significantly impact outcomes. For example, we
    can investigate using the estimation of road traffic to forecast pollution levels.
    This capability to support covariates gives TimesFM a predictive edge over traditional
    time series models and other foundational models that do not incorporate these
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find more information on covariates support with an example here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://community.databricks.com/t5/technical-blog/genai-for-time-series-analysis-with-timesfm/ba-p/95507](https://community.databricks.com/t5/technical-blog/genai-for-time-series-analysis-with-timesfm/ba-p/95507)'
  prefs: []
  type: TYPE_NORMAL
- en: Other generative AI models and Many Model Forecasting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can test other generative models to find the best one for your use case.
    One way to do this is with the **Many Model Forecasting** (**MMF**) Solution Accelerator
    by Databricks. This offers a solution for organizations needing to create forecasts
    across numerous time series, such as for sales, demand, or inventory predictions.
    The repository provides a scalable approach using Databricks to deploy and manage
    many forecasting models simultaneously. It includes resources such as notebooks,
    model templates, and data pipelines that streamline the process of training, evaluating,
    and deploying time series models on a large scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find more information here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/databricks-industry-solutions/many-model-forecasting](https://github.com/databricks-industry-solutions/many-model-forecasting)'
  prefs: []
  type: TYPE_NORMAL
- en: With generative AI and MMF now part of our time series analysis toolkit, let's
    explore how we can enhance the availability of forecasts for applications and
    data analysts.
  prefs: []
  type: TYPE_NORMAL
- en: Serving forecasts via API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main part of this book has focused on preparing and analyzing a time series
    dataset. We also covered presenting the analysis’s outcomes in tables and graphs
    in notebooks and reporting dashboards. However, in many cases, forecasts must
    be served on-demand to data analysts and applications. We will now explore ways
    to achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting simplified with ai_forecast
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this situation, the data analyst has access to time series data and wants
    to provide this as input to get a forecast without first having to develop a model.
    By abstracting the forecast behind a function such as the `ai_forecast` function
    on the Databricks platform, the ability to forecast can be greatly simplified
    for someone without knowledge of forecasting models and algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see this action with a simple example at the following URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch11/ts_spark_ch11_aiforecast.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch11/ts_spark_ch11_aiforecast.dbc)'
  prefs: []
  type: TYPE_NORMAL
- en: 'This code is based on the example in the documentation, the link to which is
    provided at the end of this section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The output of running this example is shown in *Figure 11**.1*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18568_11_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.1: Example output of ai_forecast'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find and zoom in on a digital version of *Figure* *11**.1* here:'
  prefs: []
  type: TYPE_NORMAL
- en: https://packt.link/vg87q
  prefs: []
  type: TYPE_NORMAL
- en: Note that this feature is in public preview at the time of this writing, so
    you may need to request access from Databricks to try it.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find more information here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.databricks.com/en/sql/language-manual/functions/ai_forecast.html](https://docs.databricks.com/en/sql/language-manual/functions/ai_forecast.html)'
  prefs: []
  type: TYPE_NORMAL
- en: While a simplified and predefined function such as `ai_function` is a great
    way to quickly generate a forecast, we may want to make our own custom-developed
    forecasting model accessible easily to other applications, as we will cover next.
  prefs: []
  type: TYPE_NORMAL
- en: Model Serving
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In some cases, we need to programmatically get a forecast from our model from
    another application. For such application-to-application integration, the use
    of a REST API is a common practice. One way to provide a REST API interface to
    our model is by using Databricks’ **Model Serving**.
  prefs: []
  type: TYPE_NORMAL
- en: Databricks’ Model Serving provides the functionality for deploying, governing,
    and querying ML and AI models, for both real-time and batch inference. The deployed
    model is accessible via a REST API, which enables integration into web or client
    applications. Various model types are supported, including custom Python models
    packaged in the MLflow format and open foundation models provided. This service
    is designed for high availability and low latency, automatically scaling to changing
    demand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an overview of the steps to serve a model. Note that this is not a working
    example. The screenshots shown here are to illustrate the steps only:'
  prefs: []
  type: TYPE_NORMAL
- en: Access the model in Unity Catalog as per *Figure 11**.2* and click the **Serve
    this model** button at the top right.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18568_11_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.2: Model in Unity Catalog'
  prefs: []
  type: TYPE_NORMAL
- en: Create a serving endpoint as per *Figure 11**.3*. This will show the URL to
    use to access the REST API to invoke the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18568_11_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.3: Create serving endpoint'
  prefs: []
  type: TYPE_NORMAL
- en: When creating the serving endpoint, we can enable an inference table, as per
    *Figure 11**.4*, to store all the input and output of interactions with the model
    REST API.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18568_11_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.4: Inference tables'
  prefs: []
  type: TYPE_NORMAL
- en: Once created, the serving endpoint will be shown with the status of **Ready**,
    as per *Figure 11**.5*, and can be used.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18568_11_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.5: Serving endpoint is ready'
  prefs: []
  type: TYPE_NORMAL
- en: As the serving endpoint is used, its metrics can be monitored, as per *Figure
    11**.6*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18568_11_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.6: Service endpoint metrics'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find more information on Model Serving here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.databricks.com/en/machine-learning/serve-models.html](https://docs.databricks.com/en/machine-learning/serve-models.html)'
  prefs: []
  type: TYPE_NORMAL
- en: As we have seen in this section, exposing our time series analysis model via
    a REST API makes it easier to integrate the analysis with other applications.
    Continuing on the accessibility of time series analysis, we will look next at
    how to facilitate this for end users as well.
  prefs: []
  type: TYPE_NORMAL
- en: Democratizing access to time series analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explore how innovative approaches to accessing the
    outcome of time series can benefit non-technical users. This allows us to democratize
    time series analysis for the benefit of an even broader audience.
  prefs: []
  type: TYPE_NORMAL
- en: Genie spaces
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the first approach, we will be using a natural language chatbot-like interface
    on Databricks called **Genie spaces**.
  prefs: []
  type: TYPE_NORMAL
- en: The Databricks Genie spaces is a conversational UI enabling business users to
    ask questions in natural language and receive analytical insights without requiring
    technical expertise. This works by configuring Genie spaces with relevant datasets,
    sample queries, and instructions. Users can then interact in natural language,
    asking questions and visualizations about the data. Genie uses annotated table
    and column metadata to translate the user queries into SQL statements. These are
    used to query the data so that Genie can provide responses to users.
  prefs: []
  type: TYPE_NORMAL
- en: To see this in practice, we will use the dashboard that we created in [*Chapter
    10*](B18568_10.xhtml#_idTextAnchor190), as shown in *Figure 11**.7*. This is one
    way to access Genie – from the dashboard, we can click on the top-left **Ask Genie**
    button. This opens a chatbot-like interface at the bottom right, where we can
    start typing questions in natural language. Alternatively, we can choose to open
    the Genie space in a full screen.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18568_11_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.7: Access to Genie space from the dashboard'
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 11**.8*, we can see the complete Genie space with a query, the results,
    and the generated SQL used to get the results.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18568_11_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.8: Genie spaces query and results'
  prefs: []
  type: TYPE_NORMAL
- en: The query in this example is to show **Forecasted vs. Actual**, which can also
    be requested as a visualization, as shown in *Figure 11**.9*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18568_11_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.9: Genie spaces visualization'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find more information on Databricks Genie spaces here: [https://docs.databricks.com/en/genie/index.html](https://docs.databricks.com/en/genie/index.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Apps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In cases where more application-like interactivity is required, a dashboard
    or chatbot interface is not sufficient to meet the users’ needs. Databricks Apps
    provides a platform to build and deploy applications directly within the Databricks
    environment. Currently in public preview, Databricks Apps supports development
    frameworks such as Dash, Shiny, Gradio, Streamlit, and Flask, for the creation
    of data visualizations, AI applications, self-service analytics, and other data
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find more information on Databricks Apps here: [https://www.databricks.com/blog/introducing-databricks-apps](https://www.databricks.com/blog/introducing-databricks-apps)'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this final chapter, we delved into recent advancements in time series analysis,
    focusing on emerging methodologies, tools, and trends. We tried the innovative
    approach from the dynamic field of generative AI applied to time series forecasting.
    To answer the growing requirement for forecasts via API, we explored ways to provide
    on-demand forecasting to data analysts and applications. We concluded with the
    use of an AI chatbot and Databricks Apps to democratize access to time series
    analysis for non-technical users.
  prefs: []
  type: TYPE_NORMAL
- en: As we arrive at the end of the book, looking back at our journey and the skills
    we acquired, we have built a solid foundation on the multiple stages of time series
    analysis projects with Apache Spark and other components. Armed with the multiple
    use cases discussed in [*Chapter 2*](B18568_02.xhtml#_idTextAnchor044), the practical
    skills gained throughout the book, and the recent advancements in this chapter,
    we have the necessary ingredients to succeed in production-ready, scalable, and
    future-proofed time series analysis projects across industries.
  prefs: []
  type: TYPE_NORMAL
- en: We began this book with Pericles' wise counsel on the importance of time—now,
    at the end of this book, we have the ability to uncover the valuable insights
    hidden in time series and use them to our benefit. May this knowledge empower
    you to tackle challenges with new ideas and confidence. Wishing you happy learning
    and success on your journey with time series analysis and Apache Spark!
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/ds](https://packt.link/ds)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Join our community on Discord ](img/ds_(1).jpg)'
  prefs: []
  type: TYPE_IMG
