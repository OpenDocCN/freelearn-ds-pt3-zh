<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer008">
<h1 class="chapter-number" id="_idParaDest-21"><a id="_idTextAnchor020"/>1</h1>
<h1 id="_idParaDest-22"><a id="_idTextAnchor021"/>Python and the Surrounding Software Ecology</h1>
<p>We will start by installing the basic software that is required for most of this book. This will include the <strong class="bold">Python</strong> distribution, some fundamental Python libraries, and external bioinformatics software. Here, we will also look at the world outside of Python. In bioinformatics and big data, <strong class="bold">R</strong> is also a major player; therefore, you will learn how to interact with it via <strong class="bold">rpy2</strong>, which is a Python/R bridge. Additionally, we will explore the advantages that the <strong class="bold">IPython</strong> framework (via Jupyter Lab) can give us in order to efficiently interface with R. Given that source management with Git and GitHub is pervasive, we will make sure that our setup plays well with them. This chapter will set the stage for all of the computational biologies that we will perform in the remainder of this book.</p>
<p>As different users have different requirements, we will cover two different approaches for installing the software. One approach is using the Anaconda Python (<a href="http://docs.continuum.io/anaconda/">http://docs.continuum.io/anaconda/</a>) distribution and another approach for installing the software is via Docker (which is a server virtualization method based on containers sharing the same operating system kernel; please refer to https://www.docker.com/). This will still install Anaconda for you but inside a container. If you are using a Windows-based operating system, you are strongly encouraged to consider changing your operating system or using Docker via some of the existing options on Windows. On macOS, you might be able to install most of the software natively, though Docker is also available. Learning using a local distribution (Anaconda or something else) is easier than Docker, but given that package management can be complex in Python, Docker images provide a level of stability.</p>
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li>Installing the required software with Anaconda</li>
<li>Installing the required software with Docker</li>
<li>Interfacing with R via <strong class="source-inline">rpy2</strong></li>
<li>Performing R magic with Jupyter</li>
</ul>
<h1 id="_idParaDest-23"><a id="_idTextAnchor022"/>Installing the required basic software with Anaconda</h1>
<p>Before we get started, we need to install some basic prerequisite software. The following <a id="_idIndexMarker000"/>sections will take you through the software and the steps that are needed to install them. Each chapter and <a id="_idIndexMarker001"/>section might have extra requirements on top of these – we will make those clear as the book progresses. An alternative way to start is to use the Docker recipe, after which everything will be taken care of for you via a Docker container.</p>
<p>If you are already using a different Python distribution, you are strongly encouraged to consider Anaconda, as it has become the <em class="italic">de-facto</em> standard for data science and bioinformatics. Also, it is <a id="_idIndexMarker002"/>the distribution that will allow you to install software from <strong class="bold">Bioconda</strong> (<a href="https://bioconda.github.io/">https://bioconda.github.io/</a>).</p>
<h2 id="_idParaDest-24"><a id="_idTextAnchor023"/>Getting ready</h2>
<p>Python can be run on top of different environments. For instance, you can use Python inside <a id="_idIndexMarker003"/>the <strong class="bold">Java Virtual Machine</strong> (<strong class="bold">JVM</strong>) (via <strong class="bold">Jython</strong> or <a id="_idIndexMarker004"/>with .NET <a id="_idIndexMarker005"/>via <strong class="bold">IronPython</strong>). However, here, we are not only concerned with Python but also with the complete software ecology around it. Therefore, we will <a id="_idIndexMarker006"/>use the standard (<strong class="bold">CPython</strong>) implementation, since the JVM and .NET versions exist mostly to interact with the native libraries of these platforms.</p>
<p>For our code, we will be using Python 3.10. If you were starting with Python and bioinformatics, any operating system will work. But here, we are mostly concerned with intermediate to advanced usage. So, while you can probably use Windows and macOS, most of <a id="_idIndexMarker007"/>the heavy-duty analysis will be done on <a id="_idIndexMarker008"/>Linux (probably on a Linux <strong class="bold">high-performance computing</strong> or <strong class="bold">HPC</strong> cluster). <strong class="bold">Next-generation sequencing</strong> (<strong class="bold">NGS</strong>) data analysis and complex machine learning are mostly performed on Linux clusters.</p>
<p>If you are on Windows, you should consider upgrading to Linux for your bioinformatics work because most modern bioinformatics software will not run on Windows. Note that macOS will be fine for almost all analyses unless you plan to use a computer cluster, which will probably be Linux-based.</p>
<p>If you are on Windows or macOS and do not have easy access to Linux, don’t worry. Modern <a id="_idIndexMarker009"/>virtualization <a id="_idIndexMarker010"/>software (such as <strong class="bold">VirtualBox</strong> and <strong class="bold">Docker</strong>) will come to your rescue, which will allow you to install a virtual Linux on your <a id="_idIndexMarker011"/>operating system. If you are <a id="_idIndexMarker012"/>working with Windows and decide that you want to go native and not use Anaconda, be careful with your choice of libraries; you will probably be safer if you install the 32-bit version for everything (including Python itself).</p>
<p class="callout-heading">Note</p>
<p class="callout">If you are on Windows, many tools will be unavailable to you.</p>
<p>Bioinformatics and data science are moving at breakneck speed; this is not just hype, it’s a reality. When installing software libraries, choosing a version might be tricky. Depending on the code that you have, it might not work with some old versions or perhaps not even work with a newer version. Hopefully, any code that you use will indicate the correct dependencies – though this is not guaranteed. In this book, we will fix the precise versions of all software packages, and we will make sure that the code will work with them. It is quite natural that the code might need tweaking with other package versions.</p>
<p>The software developed for this book is available at <a href="https://github.com/PacktPublishing/Bioinformatics-with-Python-Cookbook-third-edition">https://github.com/PacktPublishing/Bioinformatics-with-Python-Cookbook-third-edition</a>. To access it, you will need to install Git. Getting used to Git might be a good idea because lots of scientific computing software is being developed with it.</p>
<p>Before you install the Python stack properly, you will need to install all of the external non-Python software that you will be interoperating with. The list will vary from chapter to chapter, and all chapter-specific packages will be explained in their respective chapters. Fortunately, since the previous editions of this book, most bioinformatics software has become available via the Bioconda project; therefore, installation is usually easy.</p>
<p>You will <a id="_idIndexMarker013"/>need to install some development compilers and libraries, all of which are free. On Ubuntu, consider installing <a id="_idIndexMarker014"/>the build-essential package (<strong class="source-inline">apt-get install build-essential</strong>), and on macOS, consider <strong class="bold">Xcode</strong> (<a href="https://developer.apple.com/xcode/">https://developer.apple.com/xcode/</a>).</p>
<p>In the following table, you will find a list of the most important software to develop bioinformatics with Python:</p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-1">
<colgroup>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold">Name</strong></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">Application</strong></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">URL</strong></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">Purpose</strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Project Jupyter</p>
</td>
<td class="No-Table-Style">
<p>All chapters</p>
</td>
<td class="No-Table-Style">
<p>https://jupyter.org/</p>
</td>
<td class="No-Table-Style">
<p>Interactive computing</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>pandas</p>
</td>
<td class="No-Table-Style">
<p>All chapters</p>
</td>
<td class="No-Table-Style">
<p>https://pandas.pydata.org/</p>
</td>
<td class="No-Table-Style">
<p>Data processing</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>NumPy</p>
</td>
<td class="No-Table-Style">
<p>All chapters</p>
</td>
<td class="No-Table-Style">
<p>http://www.numpy.org/</p>
</td>
<td class="No-Table-Style">
<p>Array/matrix processing</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>SciPy</p>
</td>
<td class="No-Table-Style">
<p>All chapters</p>
</td>
<td class="No-Table-Style">
<p>https://www.scipy.org/</p>
</td>
<td class="No-Table-Style">
<p>Scientific computing</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Biopython</p>
</td>
<td class="No-Table-Style">
<p>All chapters</p>
</td>
<td class="No-Table-Style">
<p>https://biopython.org/</p>
</td>
<td class="No-Table-Style">
<p>Bioinformatics library</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>seaborn</p>
</td>
<td class="No-Table-Style">
<p>All chapters</p>
</td>
<td class="No-Table-Style">
<p>http://seaborn.pydata.org/</p>
</td>
<td class="No-Table-Style">
<p>Statistical chart library</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>R</p>
</td>
<td class="No-Table-Style">
<p>Bioinformatics and Statistics</p>
</td>
<td class="No-Table-Style">
<p>https://www.r-project.org/</p>
</td>
<td class="No-Table-Style">
<p>Language for statistical computing</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>rpy2</p>
</td>
<td class="No-Table-Style">
<p>R connectivity</p>
</td>
<td class="No-Table-Style">
<p>https://rpy2.readthedocs.io</p>
</td>
<td class="No-Table-Style">
<p>R interface</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>PyVCF</p>
</td>
<td class="No-Table-Style">
<p>NGS</p>
</td>
<td class="No-Table-Style">
<p>https://pyvcf.readthedocs.io</p>
</td>
<td class="No-Table-Style">
<p>VCF processing</p>
</td>
</tr>
</tbody>
</table>
<table class="No-Table-Style _idGenTablePara-1" id="table002">
<colgroup>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Pysam</p>
</td>
<td class="No-Table-Style">
<p>NGS</p>
</td>
<td class="No-Table-Style">
<p>https://github.com/pysam-developers/pysam</p>
</td>
<td class="No-Table-Style">
<p>SAM/BAM processing</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>HTSeq</p>
</td>
<td class="No-Table-Style">
<p>NGS/Genomes</p>
</td>
<td class="No-Table-Style">
<p>https://htseq.readthedocs.io</p>
</td>
<td class="No-Table-Style">
<p>NGS processing</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>DendroPY</p>
</td>
<td class="No-Table-Style">
<p>Phylogenetics</p>
</td>
<td class="No-Table-Style">
<p>https://dendropy.org/</p>
</td>
<td class="No-Table-Style">
<p>Phylogenetics</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>PyMol</p>
</td>
<td class="No-Table-Style">
<p>Proteomics</p>
</td>
<td class="No-Table-Style">
<p>https://pymol.org</p>
</td>
<td class="No-Table-Style">
<p>Molecular visualization</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>scikit-learn</p>
</td>
<td class="No-Table-Style">
<p>Machine learning</p>
</td>
<td class="No-Table-Style">
<p>http://scikit-learn.org</p>
</td>
<td class="No-Table-Style">
<p>Machine learning library</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Cython</p>
</td>
<td class="No-Table-Style">
<p>Big data</p>
</td>
<td class="No-Table-Style">
<p>http://cython.org/</p>
</td>
<td class="No-Table-Style">
<p>High performance</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Numba</p>
</td>
<td class="No-Table-Style">
<p>Big data</p>
</td>
<td class="No-Table-Style">
<p>https://numba.pydata.org/</p>
</td>
<td class="No-Table-Style">
<p>High performance</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>Dask</p>
</td>
<td class="No-Table-Style">
<p>Big data</p>
</td>
<td class="No-Table-Style">
<p>http://dask.pydata.org</p>
</td>
<td class="No-Table-Style">
<p>Parallel processing</p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1 – A table showing the various software packages that are useful in bioinformatics</p>
<p>We will <a id="_idIndexMarker015"/>use <strong class="source-inline">pandas</strong> to process <a id="_idIndexMarker016"/>most table data. An alternative would be to use just standard Python. <strong class="source-inline">pandas</strong> has become so pervasive in data science that it will probably make sense to just process all tabular data with it (if it fits in memory).</p>
<p>All of our work will be developed inside project Jupyter, namely Jupyter Lab. Jupyter has become the <em class="italic">de facto</em> standard to write interactive data analysis scripts. Unfortunately, the default format for Jupyter Notebooks is based on JSON. This format is difficult to read, difficult to compare, and needs exporting to be fed into a normal Python interpreter. To obviate that problem, we will extend Jupyter with <strong class="source-inline">jupytext</strong> (<a href="https://jupytext.readthedocs.io/">https://jupytext.readthedocs.io/</a>), which <a id="_idIndexMarker017"/>allows us to save Jupyter notebooks as normal Python programs. </p>
<h2 id="_idParaDest-25"><a id="_idTextAnchor024"/>How to do it...</h2>
<p>To get <a id="_idIndexMarker018"/>started, take a look at the following <a id="_idIndexMarker019"/>steps:</p>
<ol>
<li>Start by downloading the Anaconda distribution from https://www.anaconda.com/products/individual. We will be using version 21.05, although you will probably be fine with the most recent one. You can accept all the installation’s default settings, but you might want to make sure that the <strong class="source-inline">conda</strong> binaries are in your path (do not forget to open a new window so that the path can be updated). If you have another Python distribution, be careful with your <strong class="source-inline">PYTHONPATH</strong> and existing Python libraries. It’s probably better to unset your <strong class="source-inline">PYTHONPATH</strong>. As much as possible, uninstall all other Python versions and installed Python libraries.</li>
<li>Let’s go ahead with the libraries. We will now create a new <strong class="source-inline">conda</strong> environment called <strong class="source-inline">bioinformatics_base</strong> with <strong class="source-inline">biopython=1.70</strong>, as shown in the following command:<p class="source-code">conda create -n bioinformatics_base python=3.10</p></li>
<li>Let’s activate the environment, as follows:<p class="source-code">conda activate bioinformatics_base</p></li>
<li>Let’s add the <strong class="source-inline">bioconda</strong> and <strong class="source-inline">conda-forge</strong> channels to our source list:<p class="source-code">conda config --add channels bioconda</p><p class="source-code">conda config --add channels conda-forge</p></li>
<li>Also, install the basic packages:<p class="source-code">conda install \</p><p class="source-code">biopython==1.79 \</p><p class="source-code">jupyterlab==3.2.1 \</p><p class="source-code">jupytext==1.13 \</p><p class="source-code">matplotlib==3.4.3 \</p><p class="source-code">numpy==1.21.3 \</p><p class="source-code">pandas==1.3.4 \</p><p class="source-code">scipy==1.7.1</p></li>
<li>Now, let’s <a id="_idIndexMarker020"/>save our environment <a id="_idIndexMarker021"/>so that we can reuse it later to create new environments in other machines or if you need to clean up the base environment:<p class="source-code">conda list –explicit &gt; bioinformatics_base.txt</p></li>
<li>We can even install R from <strong class="source-inline">conda</strong>:<p class="source-code">conda install rpy2 r-essentials r-gridextra</p></li>
</ol>
<p>Note that <strong class="source-inline">r-essentials</strong> installs a lot of R packages, including ggplot2, which we will use later. Additionally, we install <strong class="source-inline">r-gridextra</strong> since we will be using it in the Notebook.</p>
<h2 id="_idParaDest-26"><a id="_idTextAnchor025"/>There’s more...</h2>
<p>If you prefer not to use Anaconda, you will be able to install many of the Python libraries via <strong class="source-inline">pip</strong> using whatever distribution you choose. You will probably need quite a few compilers and build tools – not only C compilers but also C++ and Fortran.</p>
<p>We will not be using the environment we created in the preceding steps. Instead, we will use it as a base to clone working environments from it. This is because environment management with Python – even with the help of the <strong class="source-inline">conda</strong> package system – can still be quite painful. So, we will create a clean environment that we never spoil and can derive from if our development environments become unmanageable. </p>
<p>For example, imagine you want to create an environment for machine learning with <strong class="source-inline">scikit-learn</strong>. You can do the following:</p>
<ol>
<li value="1">Create a clone of the original environment with the following:<p class="source-code">conda create -n scikit-learn --clone bioinformatics_base</p></li>
<li>Add <strong class="source-inline">scikit-learn</strong>:<p class="source-code">conda activate scikit-learn</p><p class="source-code">conda install scikit-learn</p></li>
</ol>
<p>When inside <a id="_idIndexMarker022"/>JupyterLab, we should <a id="_idIndexMarker023"/>open our jupytext files with the notebook, not the text editor. As the jupytext files have the same extension as Python files – this is a feature, not a bug – by default, JupyterLab would use a normal text editor. When we open a jupytext file, we need to override the default. When opening it, right-click and choose <strong class="bold">Notebook</strong>, as shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer005">
<img alt="Figure 1.2 – Opening a jupytext file in Notebook " height="679" src="image/B17942_01_002.jpg" width="766"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2 – Opening a jupytext file in Notebook</p>
<p>Our jupytext files will not be saving graphical outputs and that will suffice for this book. If you <a id="_idIndexMarker024"/>want to have a version with <a id="_idIndexMarker025"/>images, this is possible using paired notebooks. For more details, check the Jupytext page (<a href="https://github.com/mwouts/jupytext">https://github.com/mwouts/jupytext</a>). </p>
<p class="callout-heading">Warning</p>
<p class="callout">As our code is meant to be run inside Jupyter, many times throughout this book, I will not use <strong class="source-inline">print</strong> to output content, as the last line of a cell will be automatically rendered. If you are not using notebooks, remember to do a <strong class="source-inline">print</strong>.</p>
<h1 id="_idParaDest-27"><a id="_idTextAnchor026"/>Installing the required software with Docker</h1>
<p>Docker is the most widely-used framework for implementing operating system-level virtualization. This technology allows you to have an independent container: a layer that is lighter <a id="_idIndexMarker026"/>than a virtual machine but still allows you to compartmentalize software. This mostly isolates all processes, making it feel like <a id="_idIndexMarker027"/>each container is a virtual machine.</p>
<p>Docker works quite well at both extremes of the development spectrum: it’s an expedient way to set up the content of this book for learning purposes and could become your platform of choice for deploying your applications in complex environments. This recipe is an alternative to the previous recipe.</p>
<p>However, for long-term development environments, something along the lines of the previous recipe is probably your best route, although it can entail a more laborious initial setup.</p>
<h2 id="_idParaDest-28"><a id="_idTextAnchor027"/>Getting ready</h2>
<p>If you are on Linux, the first thing you have to do is install Docker. The safest solution is to get the latest version from <a href="https://www.docker.com/">https://www.docker.com/</a>. While your Linux distribution might have a Docker package, it might be too old and buggy.</p>
<p>If you are <a id="_idIndexMarker028"/>on Windows or macOS, do not despair; take a look at the Docker site. There are various options available to save you, but <a id="_idIndexMarker029"/>there is no clear-cut formula, as Docker advances quite quickly on those platforms. A fairly recent computer is necessary to run our 64-bit virtual machine. If you have any problems, reboot your machine and make sure that the BIOS, VT-X, or AMD-V is enabled. At the very least, you will need 6 GB of memory, preferably more.</p>
<p class="callout-heading">Note</p>
<p class="callout">This will require a very large download from the internet, so be sure that you have plenty of bandwidth. Also, be ready to wait for a long time.</p>
<h2 id="_idParaDest-29"><a id="_idTextAnchor028"/>How to do it...</h2>
<p>To get started, follow these steps:</p>
<ol>
<li value="1">Use the following command on your Docker shell:<p class="source-code">docker build -t bio https://raw.githubusercontent.com/PacktPublishing/Bioinformatics-with-Python-Cookbook-third-edition/main/docker/main/Dockerfile</p></li>
</ol>
<p>On Linux, you will either need to have root privileges or be added to the Docker Unix group.</p>
<ol>
<li value="2">Now you are ready to run the container, as follows:<p class="source-code">docker run -ti -p 9875:9875 -v YOUR_DIRECTORY:/data bio</p></li>
<li>Replace <strong class="source-inline">YOUR_DIRECTORY</strong> with a directory on your operating system. This will be shared between your host operating system and the Docker container. <strong class="source-inline">YOUR_DIRECTORY</strong> will be seen in the container in <strong class="source-inline">/data</strong> and vice versa.</li>
</ol>
<p><strong class="source-inline">-p 9875:9875</strong> will expose the container’s TCP port <strong class="source-inline">9875</strong> on the host computer port, <strong class="source-inline">9875</strong>.</p>
<p>Especially on Windows (and maybe on macOS), make sure that your directory is actually <a id="_idIndexMarker030"/>visible inside the Docker <a id="_idIndexMarker031"/>shell environment. If not, check the official Docker documentation on how to expose directories.</p>
<ol>
<li value="4">Now you are ready to use the system. Point your browser to <strong class="source-inline">http://localhost:9875</strong>, and you should get the Jupyter environment.</li>
</ol>
<p>If this <a id="_idIndexMarker032"/>does not work on Windows, check the official Docker documentation (<a href="https://docs.docker.com/">https://docs.docker.com/</a>) on how to expose ports.</p>
<h2 id="_idParaDest-30"><a id="_idTextAnchor029"/>See also</h2>
<p>The following is also worth knowing:</p>
<ul>
<li>Docker is the most widely used containerization software and has seen enormous growth in usage in recent times. You can read more about it at <a href="https://www.docker.com/">https://www.docker.com/</a>.</li>
<li>A security-minded alternative to Docker is <strong class="bold">rkt</strong>, which <a id="_idIndexMarker033"/>can be found at <a href="https://coreos.com/rkt/">https://coreos.com/rkt/</a>.</li>
<li>If you are not able to use Docker, for example, if you do not have the necessary permissions, as will <a id="_idIndexMarker034"/>be the case on most computer clusters, then take a look at Singularity at <a href="https://www.sylabs.io/singularity/">https://www.sylabs.io/singularity/</a>.</li>
</ul>
<h1 id="_idParaDest-31"><a id="_idTextAnchor030"/>Interfacing with R via rpy2</h1>
<p>If there is some functionality that you need and you cannot find it in a Python library, your first <a id="_idIndexMarker035"/>port of call is to check whether it’s <a id="_idIndexMarker036"/>been implemented in R. For statistical methods, R is still the most complete framework; moreover, some bioinformatics functionalities are <em class="italic">only</em> available in R and are probably offered as a package belonging to the Bioconductor project.</p>
<p><strong class="bold">rpy2</strong> provides <a id="_idIndexMarker037"/>a declarative interface from Python to R. As you will see, you will be able to write very elegant Python code to perform the interfacing process. To show the interface (and to try out one of the most common R data structures, the DataFrame, and one of the most popular R libraries, <strong class="source-inline">ggplot2</strong>), we will download its metadata from the Human 1,000 Genomes Project (<a href="http://www.1000genomes.org/">http://www.1000genomes.org/</a>). This is not a book on R, but we want to provide interesting and functional examples.</p>
<h2 id="_idParaDest-32"><a id="_idTextAnchor031"/>Getting ready</h2>
<p>You will need to get the metadata file from the 1,000 Genomes sequence index. Please check <a href="https://github.com/PacktPublishing/Bioinformatics-with-Python-Cookbook-third-edition/blob/main/Datasets.py">https://github.com/PacktPublishing/Bioinformatics-with-Python-Cookbook-third-edition/blob/main/Datasets.py</a>, and download the <strong class="source-inline">sequence.index</strong> file. If you are using Jupyter Notebook, open the <strong class="source-inline">Chapter01/Interfacing_R.py</strong> file and simply execute the <strong class="source-inline">wget</strong> command on top.</p>
<p>This file has information about all of the FASTQ files in the project (we will use data from the Human 1,000 Genomes Project in the chapters to come). This includes the FASTQ file, the sample ID, the population of origin, and important statistical information per lane, such as the number of reads and the number of DNA bases read.</p>
<p>To set up Anaconda, you can run the following:</p>
<pre class="source-code">
conda create -n bioinformatics_r --clone bioinformatics_base
conda activate bioinformatics_r
conda install r-ggplot2=3.3.5 r-lazyeval r-gridextra rpy2</pre>
<p>With Docker, you can run the following:</p>
<pre class="source-code">
docker run -ti -p 9875:9875 -v YOUR_DIRECTORY:/data tiagoantao/bioinformatics_r</pre>
<p>Now we can begin.</p>
<h2 id="_idParaDest-33"><a id="_idTextAnchor032"/>How to do it...</h2>
<p>To get <a id="_idIndexMarker038"/>started, follow these steps:</p>
<ol>
<li value="1">Let’s start by doing some imports:<p class="source-code">import os</p><p class="source-code">from IPython.display import Image</p><p class="source-code">import rpy2.robjects as robjects</p><p class="source-code">import rpy2.robjects.lib.ggplot2 as ggplot2</p><p class="source-code">from rpy2.robjects.functions import SignatureTranslatedFunction</p><p class="source-code">import pandas as pd</p><p class="source-code">import rpy2.robjects as ro</p><p class="source-code">from rpy2.robjects import pandas2ri</p><p class="source-code">from rpy2.robjects import local_converter</p></li>
</ol>
<p>We will be using <strong class="source-inline">pandas</strong> on the Python side. R DataFrames map very well to <strong class="source-inline">pandas</strong>.</p>
<ol>
<li value="2">We will read the data from our file using R’s <strong class="source-inline">read.delim</strong> function:<p class="source-code">read_delim = robjects.r('read.delim')</p><p class="source-code">seq_data = read_delim('sequence.index', header=True, stringsAsFactors=False)</p><p class="source-code">#In R:</p><p class="source-code"># seq.data &lt;- read.delim('sequence.index', header=TRUE, stringsAsFactors=FALSE)</p></li>
</ol>
<p>The first thing that we do after importing is to access the <strong class="source-inline">read.delim</strong> R function, which allows you to read files. The R language specification allows you to put dots in the names of objects. Therefore, we have to convert a function name into <strong class="source-inline">read_delim</strong>. Then, we call the function name proper; note the following highly declarative features. Firstly, most atomic objects, such as strings, can be passed without conversion. Secondly, argument names are converted seamlessly (barring the dot issue). Finally, objects are available in the Python namespace (however, objects are actually not available in the R namespace; we will discuss this further later).</p>
<p>For reference, I have included the corresponding R code. I hope it’s clear that it’s an easy <a id="_idIndexMarker039"/>conversion. The <strong class="source-inline">seq_data</strong> object is a DataFrame. If you know basic R or <strong class="source-inline">pandas</strong>, you are probably <a id="_idIndexMarker040"/>aware of this type of data structure. If not, then this is essentially a table, that is, a sequence of rows where each column has the same type.</p>
<ol>
<li value="3">Let’s perform a basic inspection of this DataFrame, as follows:<p class="source-code">print('This dataframe has %d columns and %d rows' %</p><p class="source-code">(seq_data.ncol, seq_data.nrow))</p><p class="source-code">print(seq_data.colnames)</p><p class="source-code">#In R:</p><p class="source-code"># print(colnames(seq.data))</p><p class="source-code"># print(nrow(seq.data))</p><p class="source-code"># print(ncol(seq.data))</p></li>
</ol>
<p>Again, note the code similarity.</p>
<ol>
<li value="4">You can even mix styles using the following code:<p class="source-code">my_cols = robjects.r.ncol(seq_data)</p><p class="source-code">print(my_cols)</p></li>
</ol>
<p>You can call R functions directly; in this case, we will call <strong class="source-inline">ncol</strong> if they do not have dots in their name; however, be careful. This will display an output, not 26 (the number of columns), but [26], which is a vector that’s composed of the <strong class="source-inline">26</strong> element. This is because, by default, most operations in R return vectors. If you want the number of columns, you have to perform <strong class="source-inline">my_cols[0]</strong>. Also, talking about pitfalls, note that R array indexing starts with 1, whereas Python starts with 0.</p>
<ol>
<li value="5">Now, we <a id="_idIndexMarker041"/>need to perform some <a id="_idIndexMarker042"/>data cleanup. For example, some columns should be interpreted as numbers, but instead, they are read as strings:<p class="source-code">as_integer = robjects.r('as.integer')</p><p class="source-code">match = robjects.r.match</p><p class="source-code">my_col = match('READ_COUNT', seq_data.colnames)[0] # vector returned</p><p class="source-code">print('Type of read count before as.integer: %s' % seq_data[my_col - 1].rclass[0])</p><p class="source-code">seq_data[my_col - 1] = as_integer(seq_data[my_col - 1])</p><p class="source-code">print('Type of read count after as.integer: %s' % seq_data[my_col - 1].rclass[0])</p></li>
</ol>
<p>The <strong class="source-inline">match</strong> function is somewhat similar to the <strong class="source-inline">index</strong> method in Python lists. As expected, it returns a vector so that we can extract the <strong class="source-inline">0</strong> element. It’s also 1-indexed, so we subtract 1 when working on Python. The <strong class="source-inline">as_integer</strong> function will convert a column into integers. The first print will show strings (that is values surrounded by <strong class="source-inline">"</strong>), whereas the second print will show numbers.</p>
<ol>
<li value="6">We will need to massage this table a bit more; details on this can be found in the notebook. Here, we will finalize getting the DataFrame to R (remember that while it’s an R object, it’s actually visible on the Python namespace):<p class="source-code">robjects.r.assign('seq.data', seq_data)</p></li>
</ol>
<p>This <a id="_idIndexMarker043"/>will create a variable in the R namespace <a id="_idIndexMarker044"/>called <strong class="source-inline">seq.data</strong>, with the content of the <a id="_idIndexMarker045"/>DataFrame from the Python namespace. Note that after this operation, both objects will be independent (if you change one, it will not be reflected in the other).</p>
<p class="callout-heading">Note</p>
<p class="callout">While you can perform plotting on Python, R has default built-in plotting functionalities (which we will ignore here). It also <a id="_idIndexMarker046"/>has a library called <strong class="source-inline">ggplot2</strong> that implements the <strong class="bold">Grammar of Graphics</strong> (a declarative language to specify statistical charts).</p>
<ol>
<li value="7">Regarding our concrete example based on the Human 1,000 Genomes Project, first, we will plot a histogram with the distribution of center names, where all sequencing lanes were generated. For this, we will use <strong class="source-inline">ggplot</strong>:<p class="source-code">from rpy2.robjects.functions import SignatureTranslatedFunction</p><p class="source-code">ggplot2.theme = SignatureTranslatedFunction(ggplot2.theme, init_prm_translate = {'axis_text_x': 'axis.text.x'})</p><p class="source-code">bar = ggplot2.ggplot(seq_data) + ggplot2.geom_bar() + ggplot2.aes_string(x='CENTER_NAME') + ggplot2.theme(axis_text_x=ggplot2.element_text(angle=90, hjust=1))</p><p class="source-code">robjects.r.png('out.png', type='cairo-png')</p><p class="source-code">bar.plot()</p><p class="source-code">dev_off = robjects.r('dev.off')</p><p class="source-code">dev_off()</p></li>
</ol>
<p>The second line is a bit uninteresting but is an important piece of boilerplate code. One <a id="_idIndexMarker047"/>of the R functions that we <a id="_idIndexMarker048"/>will call has a parameter with a dot in its name. As Python function calls cannot have this, we must map the <strong class="source-inline">axis.text.x</strong> R parameter name to the <strong class="source-inline">axis_text_r</strong> Python name in the function theme. We monkey patch it (that is, we replace <strong class="source-inline">ggplot2.theme</strong> with a patched version of itself).</p>
<p>Then, we draw the chart itself. Note the declarative nature of <strong class="source-inline">ggplot2</strong> as we add features to the chart. First, we specify the <strong class="source-inline">seq_data</strong> DataFrame, then we use a histogram bar plot called <strong class="source-inline">geom_bar</strong>. Following this, we annotate the <strong class="source-inline">x</strong> variable (<strong class="source-inline">CENTER_NAME</strong>). Finally, we rotate the text of the <em class="italic">x-axis</em> by changing the theme. We finalize this by closing the R printing device.</p>
<ol>
<li value="8">Now, we can print the image in the Jupyter Notebook:<p class="source-code">Image(filename='out.png')</p></li>
</ol>
<p>The following chart is produced:</p>
<div>
<div class="IMG---Figure" id="_idContainer006">
<img alt="Figure 1.3 – The ggplot2-generated histogram of center names, which is responsible for sequencing the lanes of the human genomic data from the 1,000 Genomes Project " height="1386" src="image/B17942_01_003.jpg" width="1386"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.3 – The ggplot2-generated histogram of center names, which is responsible for sequencing the lanes of the human genomic data from the 1,000 Genomes Project</p>
<ol>
<li value="9">As a final <a id="_idIndexMarker049"/>example, we will now do a <a id="_idIndexMarker050"/>scatter plot of read and base counts for all of the sequenced lanes for Yoruban (<strong class="source-inline">YRI</strong>) and Utah residents with ancestry from Northern and Western Europe (<strong class="source-inline">CEU</strong>), using the Human 1,000 Genomes Project (the summary of the data of this project, which we will use thoroughly, can be seen in the <em class="italic">Working with modern sequence formats</em> recipe of <a href="B17942_03.xhtml#_idTextAnchor068"><em class="italic">Chapter 3</em></a>, <em class="italic">Next-Generation Sequencing</em>). Additionally, we are interested in the differences between the different types of sequencing (for instance, exome coverage, high coverage, and low coverage). First, we generate a DataFrame with just the <strong class="source-inline">YRI</strong> and <strong class="source-inline">CEU</strong> lanes, and limit the maximum base and read counts:<p class="source-code">robjects.r('yri_ceu &lt;- seq.data[seq.data$POPULATION %in% c("YRI", "CEU") &amp; seq.data$BASE_COUNT &lt; 2E9 &amp; seq.data$READ_COUNT &lt; 3E7, ]')</p><p class="source-code">yri_ceu = robjects.r('yri_ceu')</p></li>
<li>Now <a id="_idIndexMarker051"/>we are ready to plot:<p class="source-code">scatter = ggplot2.ggplot(yri_ceu) + ggplot2.aes_string(x='BASE_COUNT', y='READ_COUNT', shape='factor(POPULATION)', col='factor(ANALYSIS_GROUP)') + ggplot2.geom_point()</p><p class="source-code">robjects.r.png('out.png')</p><p class="source-code">scatter.plot()</p></li>
</ol>
<p>Hopefully, this <a id="_idIndexMarker052"/>example (please refer to the following screenshot) makes the power of the Grammar of Graphics approach clear. We will start by declaring the DataFrame and the type of chart in use (that is, the scatter plot implemented by <strong class="source-inline">geom_point</strong>).</p>
<p>Note how easy it is to express that the shape of each point depends on the <strong class="source-inline">POPULATION</strong> variable and that the color depends on the <strong class="source-inline">ANALYSIS_GROUP</strong> variable:</p>
<div>
<div class="IMG---Figure" id="_idContainer007">
<img alt="Figure 1.4 – The ggplot2-generated scatter plot with base and read counts for all sequencing lanes read; the color and shape of each dot reflects categorical data (population and the type of data sequenced) " height="972" src="image/B17942_01_004.jpg" width="972"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.4 – The ggplot2-generated scatter plot with base and read counts for all sequencing lanes read; the color and shape of each dot reflects categorical data (population and the type of data sequenced)</p>
<ol>
<li value="11">Because <a id="_idIndexMarker053"/>the R DataFrame is so close <a id="_idIndexMarker054"/>to <strong class="source-inline">pandas</strong>, it makes sense to convert between the two since that is supported by <strong class="source-inline">rpy2</strong>:<p class="source-code">import rpy2.robjects as ro</p><p class="source-code">from rpy2.robjects import pandas2ri</p><p class="source-code">from rpy2.robjects.conversion import localconverter </p><p class="source-code">with localconverter(ro.default_converter + pandas2ri.converter):</p><p class="source-code">  pd_yri_ceu = ro.conversion.rpy2py(yri_ceu)</p><p class="source-code">del pd_yri_ceu['PAIRED_FASTQ']</p><p class="source-code">with localconverter(ro.default_converter + pandas2ri.converter):</p><p class="source-code">  no_paired = ro.conversion.py2rpy(pd_yri_ceu)</p><p class="source-code">robjects.r.assign('no.paired', no_paired)</p><p class="source-code">robjects.r("print(colnames(no.paired))")</p></li>
</ol>
<p>We start <a id="_idIndexMarker055"/>by importing the necessary conversion module – <strong class="source-inline">rpy2</strong> provides many strategies to convert data from R into Python. Here, we <a id="_idIndexMarker056"/>are concerned with data frame conversion. We then convert the R DataFrame (note that we are converting <strong class="source-inline">yri_ceu</strong> in the R namespace, not the one on the Python namespace). We delete the column that indicates the name of the paired FASTQ file on the <strong class="source-inline">pandas</strong> DataFrame and copy it back to the R namespace. If you print the column names of the new R DataFrame, you will see that <strong class="source-inline">PAIRED_FASTQ</strong> is missing.</p>
<h2 id="_idParaDest-34"><a id="_idTextAnchor033"/>There’s more...</h2>
<p>It’s worth repeating that the advances in the Python software ecology are occurring at a breakneck pace. This means that if a certain functionality is not available today, it might be released sometime in the near future. So, if you are developing a new project, be sure to check for the very latest developments on the Python front before using functionality from an R package.</p>
<p>There are <a id="_idIndexMarker057"/>plenty of R packages for Bioinformatics in the Bioconductor project (<a href="http://www.bioconductor.org/">http://www.bioconductor.org/</a>). This should probably be your first port of call in the R world for bioinformatics functionalities. However, note that many R Bioinformatics packages are not on Bioconductor, so be sure to <a id="_idIndexMarker058"/>search the wider R packages on <strong class="bold">Comprehensive R Archive Network</strong> (<strong class="bold">CRAN</strong>) (refer to CRAN at <a href="http://cran.rproject.org/">http://cran.rproject.org/</a>).</p>
<p>There are plenty of plotting libraries for Python. Matplotlib is the most common library, but you also have a plethora of other choices. In the context of R, it’s worth noting that there is a <a id="_idIndexMarker059"/>ggplot2-like implementation for Python <a id="_idIndexMarker060"/>based on the Grammar of Graphics description language for charts, and – surprise, surprise – this is called <strong class="source-inline">ggplot</strong>! (<a href="http://yhat.github.io/ggpy/">http://yhat.github.io/ggpy/</a>).</p>
<h2 id="_idParaDest-35"><a id="_idTextAnchor034"/>See also</h2>
<p>To learn more about these topics, please refer to the following resources:</p>
<ul>
<li>There are plenty of tutorials and books on R; check the R web page (<a href="http://www.r-project.org/">http://www.r-project.org/</a>) for documentation.</li>
<li>For Bioconductor, check the documentation at <a href="http://manuals.bioinformatics.ucr.edu/home/R_BioCondManual">http://manuals.bioinformatics.ucr.edu/home/R_BioCondManual</a>.</li>
<li>If you work with NGS, you might also want to take look at high throughput sequence analysis with Bioconductor at <a href="http://manuals.bioinformatics.ucr.edu/home/ht-seq">http://manuals.bioinformatics.ucr.edu/home/ht-seq</a>.</li>
<li>The <strong class="source-inline">rpy</strong> library <a id="_idIndexMarker061"/>documentation is your Python gateway to R and can be found at <a href="https://rpy2.bitbucket.io/">https://rpy2.bitbucket.io/</a>.</li>
<li>The <em class="italic">Grammar of Graphics</em> approach is described in a book aptly named <em class="italic">The Grammar of Graphics</em>, by Leland Wilkinson, Springer.</li>
<li>In terms of data structures, similar functionality to R can be found in the <strong class="source-inline">pandas</strong> library. You can find some tutorials at <a href="http://pandas.pydata.org/pandas-docs/dev/tutorials.xhtml">http://pandas.pydata.org/pandas-docs/dev/tutorials.xhtml</a>. The book, <em class="italic">Python for Data Analysis</em>, by Wes McKinney, O’Reilly Media, is also an alternative to consider. In the next chapter, we will discuss pandas and use it throughout the book. </li>
</ul>
<h1 id="_idParaDest-36"><a id="_idTextAnchor035"/>Performing R magic with Jupyter</h1>
<p>Jupyter provides quite a few extra features compared to standard Python. Among those features, it provides a framework of <a id="_idIndexMarker062"/>extensible commands called <strong class="bold">magics</strong> (actually, this only works with the IPython kernel of Jupyter since it is actually an IPython feature, but <a id="_idIndexMarker063"/>that is the one we are concerned with). Magics <a id="_idIndexMarker064"/>allow you to extend the language in many useful ways. There are magic functions that you can use to deal with R. As you will see in our example, it makes R interfacing much easier and more declarative. This recipe will not introduce any new R functionalities, but hopefully, it will make it clear how IPython can be an important productivity boost for scientific computing in this regard.</p>
<h2 id="_idParaDest-37"><a id="_idTextAnchor036"/>Getting ready</h2>
<p>You will need to follow the previous <em class="italic">Getting ready</em> steps of the <em class="italic">Interfacing with R via rpy2</em> recipe. The notebook is <strong class="source-inline">Chapter01/R_magic.py</strong>. The notebook is more complete than the recipe presented here and includes more chart examples. For brevity, we will only concentrate on the fundamental constructs to interact with R using magics. If you are using Docker, you can use the following:</p>
<pre class="source-code">
docker run -ti -p 9875:9875 -v YOUR_DIRECTORY:/data tiagoantao/bioinformatics_r</pre>
<h2 id="_idParaDest-38"><a id="_idTextAnchor037"/>How to do it...</h2>
<p>This recipe is an aggressive simplification of the previous one because it illustrates the conciseness and elegance of R magics:</p>
<ol>
<li value="1">The first thing you need to do is load R magics and <strong class="source-inline">ggplot2</strong>:<p class="source-code">import rpy2.robjects as robjects</p><p class="source-code">import rpy2.robjects.lib.ggplot2 as ggplot2</p><p class="source-code">%load_ext rpy2.ipython</p></li>
</ol>
<p>Note that <strong class="source-inline">%</strong> starts an IPython-specific directive. Just as a simple example, you can write <strong class="source-inline">%R print(c(1, 2))</strong> onto a Jupyter cell.</p>
<p>Check out how easy it is to execute the R code without using the <strong class="source-inline">robjects</strong> package. Actually, <strong class="source-inline">rpy2</strong> is being used to look under the hood.</p>
<ol>
<li value="2">Let’s <a id="_idIndexMarker065"/>read the <strong class="source-inline">sequence.index</strong> file that <a id="_idIndexMarker066"/>was downloaded in the previous recipe:<p class="source-code">%%R</p><p class="source-code">seq.data &lt;- read.delim('sequence.index', header=TRUE, stringsAsFactors=FALSE)</p><p class="source-code">seq.data$READ_COUNT &lt;- as.integer(seq.data$READ_COUNT)</p><p class="source-code">seq.data$BASE_COUNT &lt;- as.integer(seq.data$BASE_COUNT)</p></li>
</ol>
<p>Then, you can specify that the entire cell should be interpreted as R code by using <strong class="source-inline">%%R</strong> (note the double <strong class="source-inline">%%</strong>).</p>
<ol>
<li value="3">We can now transfer the variable to the Python namespace:<p class="source-code">seq_data = %R seq.data</p><p class="source-code">print(type(seq_data))  # pandas dataframe!</p></li>
</ol>
<p>The type of the DataFrame is not a standard Python object, but a <strong class="source-inline">pandas</strong> DataFrame. This is a departure from previous versions of the R magic interface.</p>
<ol>
<li value="4">As we have a <strong class="source-inline">pandas</strong> DataFrame, we can operate on it quite easily using the <strong class="source-inline">pandas</strong> interface:<p class="source-code">my_col = list(seq_data.columns).index("CENTER_NAME")</p><p class="source-code">seq_data['CENTER_NAME'] = seq_data['CENTER_NAME'].apply(lambda` x: x.upper())</p></li>
<li>Let’s put this DataFrame back into the R namespace, as follows:<p class="source-code">%R -i seq_data</p><p class="source-code">%R print(colnames(seq_data))</p></li>
</ol>
<p>The <strong class="source-inline">-i</strong> argument informs the magic system that the variable that follows on the Python space is to be copied into the R namespace. The second line just shows that the DataFrame is indeed available in R. The name that we are using is different from the original – it’s <strong class="source-inline">seq_data</strong>, instead of <strong class="source-inline">seq.data</strong>.</p>
<ol>
<li value="6">Let’s do <a id="_idIndexMarker067"/>some final cleanup (for further details, see <a id="_idIndexMarker068"/>the previous recipe) and print the same bar chart as before:<p class="source-code">%%R</p><p class="source-code">bar &lt;- ggplot(seq_data) +  aes(factor(CENTER_NAME)) + geom_bar() + theme(axis.text.x = element_text(angle = 90, hjust = 1))</p><p class="source-code">print(bar)</p></li>
</ol>
<p>Additionally, the R magic system allows you to reduce code, as it changes the behavior of the interaction of R with IPython. For example, in the <strong class="source-inline">ggplot2</strong> code of the previous recipe, you do not need to use the <strong class="source-inline">.png</strong> and <strong class="source-inline">dev.off</strong> R functions, as the magic system will take care of this for you. When you tell R to print a chart, it will magically appear in your notebook or graphical console.</p>
<h2 id="_idParaDest-39"><a id="_idTextAnchor038"/>There’s more...</h2>
<p>The R magics have seemed to have changed quite a lot over time in terms of their interface. For example, I have updated the R code for the first edition of this book a few times. The current version of the DataFrame assignment returns <strong class="source-inline">pandas</strong> objects, which is a major change. </p>
<h2 id="_idParaDest-40"><a id="_idTextAnchor039"/>See also</h2>
<p>For more information, check out these links:</p>
<ul>
<li>For basic <a id="_idIndexMarker069"/>instructions on IPython magics, see <a href="https://ipython.readthedocs.io/en/stable/interactive/magics.xhtml">https://ipython.readthedocs.io/en/stable/interactive/magics.xhtml</a>.</li>
<li>A list <a id="_idIndexMarker070"/>of third-party extensions for IPython, including magic ones can be found at <a href="https://github.com/ipython/ipython/wiki/Extensions-Index">https://github.com/ipython/ipython/wiki/Extensions-Index</a>.</li>
</ul>
</div>
</div></body></html>