- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with Data and Statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most attractive features of Python for people who need to analyze
    data is the huge ecosystem of data manipulation and analysis packages, as well
    as the active community of data scientists working with Python. Python is easy
    to use, while also offering very powerful, fast libraries, which enables even
    relatively novice programmers to quickly and easily process vast sets of data.
    At the heart of many data science packages and tools is the pandas library. pandas
    provides two data container types that build on top of NumPy arrays and have good
    support for labels (other than simple integers). These data containers make working
    with large sets of data extremely easy.
  prefs: []
  type: TYPE_NORMAL
- en: Data and statistics are part of everything in the modern world. Python is leading
    the charge in trying to make sense of the vast quantity of data produced every
    day, and usually, this all starts with pandas – Python’s basic library for working
    with data. First, we’ll see some basic techniques for working with data using
    pandas. Then, we’ll discuss the basics of statistics, which will provide us with
    a systematic approach to understanding a whole population by looking at a small
    sample.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to leverage Python and pandas to work with
    large sets of data and perform statistical tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating Series and DataFrame objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading and storing data from a DataFrame
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating data in DataFrames
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plotting data from a DataFrame
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting descriptive statistics from a DataFrame
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding a population using sampling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing operations on grouped data in a DataFrame
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing hypotheses using t-tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing hypotheses using ANOVA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing hypotheses for non-parametric data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating interactive plots with Bokeh
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is statistics?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Statistics is the systematic study of data using mathematical – specifically,
    probability – theory. There are two major aspects to statistics. The first aspect
    of statistics is **summarizing data**. This is where we find numerical values
    that describe a set of data, including characteristics such as the center (mean
    or median) and spread (standard deviation or variance) of the data. These values
    are called **descriptive statistics**. What we’re doing here is fitting a probability
    distribution that describes the likelihood of a particular characteristic appearing
    in a population. Here, a *population* simply means a complete set of measurements
    of a particular characteristic – for example, the height of every person currently
    alive on Earth.
  prefs: []
  type: TYPE_NORMAL
- en: The second – and arguably more important – aspect of statistics is **inference**.
    Here, we try to estimate the distribution of data describing a population by computing
    numerical values on a relatively small sample of that population. Not only do
    we try to estimate the distribution of the population, but we also try to quantify
    how good our approximation is. This usually takes the form of a confidence interval.
    A confidence interval is a range of values where we are confident the true value
    lies given the data we have observed. We usually give 95% or 99% confidence intervals
    for estimated values.
  prefs: []
  type: TYPE_NORMAL
- en: Inference also includes tests for whether two or more sets of sampled data come
    from the same population. This is the area of **hypothesis testing**. Here, we
    compare the likely distributions of both sets of data to determine whether they
    are likely to be the same. Many hypothesis tests require that the data is a normal
    distribution or, more likely, that we can apply the *central limit theorem*. These
    tests are sometimes described as parametric tests and include t-tests and ANOVA.
    However, if your data is not sufficiently nice that the central limit theorem
    can help, then some tests do not require the assumption of normality. These are
    called non-parametric tests.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, we will mostly make use of the pandas library for data manipulation,
    which provides R-like data structures, such as `Series` and `DataFrame` objects,
    for storing, organizing, and manipulating data. We will also use the Bokeh data
    visualization library in the final recipe of this chapter. These libraries can
    be installed using your favorite package manager, such as `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We will also make use of the NumPy and SciPy packages.
  prefs: []
  type: TYPE_NORMAL
- en: The code for this chapter can be found in the `Chapter 06` folder of this book’s
    GitHub repository at [https://github.com/PacktPublishing/Applying-Math-with-Python-2nd-Edition/tree/main/Chapter%2006](https://github.com/PacktPublishing/Applying-Math-with-Python-2nd-Edition/tree/main/Chapter%2006).
  prefs: []
  type: TYPE_NORMAL
- en: Creating Series and DataFrame objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most data handling in Python is done using the pandas library, which builds
    on NumPy to provide R-like structures for holding data. These structures allow
    the easy indexing of rows and columns, using strings or other Python objects besides
    just integers. Once data is loaded into a pandas `DataFrame` or `Series`, it can
    be easily manipulated, just as if it were in a spreadsheet. This makes Python,
    when combined with pandas, a powerful tool for processing and analyzing data.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will see how to create new pandas `Series` and `DataFrame`
    objects and access items from them.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will import the pandas library as `pd` using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The NumPy package is `np`. We must also create a (seeded) random number generator
    from NumPy, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps outline how to create `Series` and `DataFrame` objects
    that hold data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create the random data that we will store in the `Series` and `DataFrame`
    objects:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, create a `Series` object that holds `diff_data`. We’ll print `Series`
    to produce a view of the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, create a `DataFrame` object with two columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the `DataFrame` object to produce a view of the data it holds:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The printed objects are as follows; the `Series` object is on the left and
    the `DataFrame` object is on the right:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: As expected, both `Series` and `DataFrame` contain 100 rows. Since the data
    in the series is of a single type – guaranteed by the fact that it is just a NumPy
    array – the data type is shown as `float64`. `DataFrame` has two columns, which
    may have different data types in general (although here, they both have `float64`).
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The pandas package provides the `Series` and `DataFrame` classes, which mirror
    the function and capabilities of their R counterparts. `Series` is used to store
    one-dimensional data, such as time series data, and `DataFrame` is used to store
    multidimensional data; you can think of a `DataFrame` object as a “spreadsheet.”
  prefs: []
  type: TYPE_NORMAL
- en: What separates `Series` from a simple NumPy `ndarray` is the way that `Series`
    indexes its items. A NumPy array is indexed by integers, which is also the default
    for a `Series` object. However, `Series` can be indexed by any hashable Python
    object, including strings and `datetime` objects. This makes `Series` useful for
    storing time series data. A `Series` can be created in several ways. In this recipe,
    we used a NumPy array, but any Python iterable, such as a list, can be used instead.
  prefs: []
  type: TYPE_NORMAL
- en: Each column in a `DataFrame` object is a series containing rows, just as in
    a traditional database or spreadsheet. In this recipe, the columns are given labels
    when the `DataFrame` object is constructed via the keys of the dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: The `DataFrame` and `Series` objects create a summary of the data they contain
    when printed. This includes column names, the number of rows and columns, and
    the first and last five rows of the frame (series). This is useful for quickly
    obtaining an overview of the object and the spread of data it contains.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The individual rows (records) of a `Series` object can be accessed using the
    usual index notation by providing the corresponding index. We can also access
    the rows by their numerical position using the special `iloc` property object.
    This allows us to access the rows by their numerical (integer) index, such as
    with Python lists or NumPy arrays.
  prefs: []
  type: TYPE_NORMAL
- en: The columns in a `DataFrame` object can be accessed using the usual index notation,
    providing the name of the column. The result of this is a `Series` object that
    contains the data from the selected column. `DataFrame` also provides two properties
    that can be used to access data. The `loc` attribute provides access to individual
    rows by their index, whatever this object may be. The `iloc` attribute provides
    access to the rows by numerical index, just as for the `Series` object.
  prefs: []
  type: TYPE_NORMAL
- en: You can provide selection criteria to `loc` (or just use index notation for
    the object) to select data. This includes a single label, a list of labels, a
    slice of labels, or a Boolean array (of an appropriate size). The `iloc` selection
    method accepts similar criteria.
  prefs: []
  type: TYPE_NORMAL
- en: There are other ways to select data from a `Series` or `DataFrame` object beyond
    the simple methods we describe here. For example, we can use the `at` attribute
    to access a single value at a specified row (and column) in the object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, a pandas `Series` or `DataFrame` is not sufficiently rich to describe
    the data because they are inherently low-dimensional. The `xarray` package builds
    upon the pandas interface and provides support for labeled multidimensional arrays
    (that is, NumPy arrays). We’ll learn about `xarray` in the *Loading and storing
    data from NetCDF files* recipe in [*Chapter 10*](B19085_10.xhtml#_idTextAnchor395).
    More information about `xarray` can be found in the documentation: [https://docs.xarray.dev/en/stable/index.html](https://docs.xarray.dev/en/stable/index.html).'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The pandas documentation contains a detailed description of the different ways
    to create and index a `DataFrame` or `Series` object: [https://pandas.pydata.org/docs/user_guide/indexing.html](https://pandas.pydata.org/docs/user_guide/indexing.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Loading and storing data from a DataFrame
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is fairly unusual to create a `DataFrame` object from the raw data in a Python
    session. In practice, the data will often come from an external source, such as
    an existing spreadsheet or CSV file, database, or API endpoint. For this reason,
    pandas provides numerous utilities for loading and storing data to file. Out of
    the box, pandas supports loading and storing data from CSV, Excel (`xls` or `xlsx`),
    JSON, SQL, Parquet, and Google BigQuery. This makes it very easy to import your
    data into pandas and then manipulate and analyze this data using Python.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to load and store data in a CSV file. The
    instructions will be similar for loading and storing data in other file formats.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will need to import the pandas package under the `pd` alias
    and the NumPy library as `np`. We must also create a default random number generator
    from NumPy using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Let’s learn how to store and then load data from a `DataFrame`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to store data in a file and then load the data back into
    Python:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we’ll create a sample `DataFrame` object using random data. Then, we
    will print this `DataFrame` object so that we can compare it to the data that
    we will read later:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will store the data in this `DataFrame` object in the `sample.csv` file
    by using the `to_csv` method on the `DataFrame` object. We will use the `index=False`
    keyword argument so that the index is not stored in the CSV file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can use the `read_csv` routine from pandas to read the `sample.csv`
    file into a new `DataFrame` object. We will print this object to show the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The two printed DataFrames are shown side by side. The `DataFrame` object from
    *step 1* is on the left and the `DataFrame` object from *step 3* is on the right:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: As we can see from the rows, these two DataFrames are identical.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The core of this recipe is the `read_csv` routine in pandas. This routine takes
    path- or file-like objects as an argument and reads the contents of the file as
    CSV data. We can customize the delimiter using the `sep` keyword argument, which
    is a comma (`,`) by default. There are also options to customize the column headers
    and customize the type of each column.
  prefs: []
  type: TYPE_NORMAL
- en: The `to_csv` method in a `DataFrame` or `Series` stores the contents in a CSV
    file. We used the `index` keyword argument here so that the indices are not printed
    into the file. This means that pandas will infer the index from the row number
    in the CSV file. This behavior is desirable if the data is indexed by integers,
    but this might not be the case if the data is indexed by times or dates, for example.
    We can also use this keyword argument to specify which column in the CSV file
    is the indexing column.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'See the pandas documentation for a list of supported file formats: [https://pandas.pydata.org/docs/reference/io.html](https://pandas.pydata.org/docs/reference/io.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Manipulating data in DataFrames
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we have data in a `DataFrame`, we often need to apply some simple transformations
    or filters to the data before we can perform any analysis. This could include,
    for example, filtering the rows that are missing data or applying a function to
    individual columns.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to perform some basic manipulation of `DataFrame`
    objects to prepare the data for analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will need the pandas package imported under the `pd` alias,
    the NumPy package imported under the `np` alias, and a default random number generator
    object from NumPy to be created using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Let’s learn how to perform some simple manipulations on data in a `DataFrame`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps illustrate how to perform some basic filtering and manipulations
    on a pandas `DataFrame`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will create a sample `DataFrame` using random data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will generate a new column from an existing column. This new column
    will hold `True` if the corresponding entry of the `"one"` column is greater than
    `0.5`, and `False` otherwise:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s create a new function that we will apply to our `DataFrame`. This
    function multiplies the row `"two"` value by the maximum of row `"one"` and `0.5`
    (there are more concise ways to write this function):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we will apply the previously defined function to each row in the DataFrame
    to generate a new column. We will also print the updated DataFrame for comparison
    later:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we have to filter out the rows in the DataFrame that contain a **Not
    a Number** (**NaN**) value. We will print the resulting DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output from the `print` command in *step 4* is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'There is a single NaN value visible in row 98\. As expected, we have 100 rows
    total and 5 columns of data. Now, we can compare this to the output of the `print`
    command in *step 6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: As expected, the number of rows has dropped by 12, since we have removed all
    the rows that contain a NaN value. (Notice that row 98 no longer contains NaN
    in column 3.)
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: New columns can be added to an existing `DataFrame` by simply assigning them
    to the new column index. However, some care needs to be taken here. In some situations,
    pandas will create a “view” of a `DataFrame` object rather than copying, and in
    this case, assigning it to a new column might not have the desired effect. This
    is discussed in the pandas documentation ([https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy)).
  prefs: []
  type: TYPE_NORMAL
- en: pandas `Series` objects (columns in a `DataFrame`) support rich comparison operators,
    such as equality and less than or greater than (in this recipe, we used the greater
    than operator). These comparison operators return a `Series` containing Boolean
    values corresponding to the positions at which the comparison was true and false.
    This can, in turn, be used to index the original `Series` and get just the rows
    where the comparison was true. In this recipe, we simply added this `Series` of
    Boolean values to the original `DataFrame`.
  prefs: []
  type: TYPE_NORMAL
- en: The `apply` method takes a function (or other callable function) and applies
    it to each column in the `DataFrame` object. In this recipe, we instead wanted
    to apply the function to each row, so we used the `axis=1` keyword argument to
    apply the function to each row in the `DataFrame` object. In either case, the
    function is provided with a `Series` object indexed by the rows (columns). We
    also applied a function to each row, which returned a value computed using the
    data from each row. In practice, this application would be quite slow if the `DataFrame`
    object contains a large number of rows. If possible, you should operate on the
    columns as a whole, using functions designed to operate on NumPy arrays, for better
    efficiency. This is especially true for performing simple arithmetic on values
    in columns of a `DataFrame`. Just like NumPy arrays, `Series` objects implement
    standard arithmetic operations, which can greatly improve the operation time for
    large DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: In the final step of this recipe, we used the `dropna` method to quickly select
    only the rows from the DataFrames that do not contain a NaN value. pandas uses
    NaN to represent missing data in a `DataFrame`, so this method selects the rows
    that don’t contain a missing value. This method returns a view to the original
    `DataFrame` object, but it can also modify the original `DataFrame` by passing
    the `inplace=True` keyword argument. As in this recipe, this is roughly equivalent
    to using the indexing notation to select rows using an indexing array containing
    Boolean values.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You should always be cautious when modifying original data directly since it
    might not be possible to return to this data to repeat your analysis later. If
    you do need to modify the data directly, you should make sure that it is either
    backed up or that the modifications do not remove data that you might need later.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most pandas routines deal with missing data (NaN) sensibly. However, if you
    do need to remove or replace missing data in a `DataFrame`, then there are several
    ways to do this. In this recipe, we used the `dropna` method to simply drop the
    rows from the DataFrames that are missing data. Instead, we could fill all the
    missing values with a specific value using the `fillna` method, or interpolate
    missing values using the surrounding values using the `interpolate` method.
  prefs: []
  type: TYPE_NORMAL
- en: More generally, we can use the `replace` method to replace specific (non-NaN)
    values with other values. This method can work with both numeric values and string
    values, including pattern-matching with regex.
  prefs: []
  type: TYPE_NORMAL
- en: The `DataFrame` class has many useful methods. We’ve only covered the very basic
    methods here, but there are two other methods that we should also mention. These
    are the `agg` method and the `merge` method.
  prefs: []
  type: TYPE_NORMAL
- en: The `agg` method aggregates the results of one or more operations over a given
    axis of the `DataFrame` object. This allows us to quickly produce summary information
    for each column (or row) by applying an aggregating function. The output is a
    `DataFrame` that contains the names of the functions applied as the rows, and
    the labels for the chosen axis (column labels, for instance) for the columns.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `merge` method performs a SQL-like join over two DataFrames. This will
    produce a new `DataFrame` that contains the result of the join. Various parameters
    can be passed to the `how` keyword argument to specify the type of merge to be
    performed, with the default being `inner`. The name of the column or index over
    which to perform the join should be passed to either the `on` keyword argument
    – if both `DataFrame` objects contain the same key – or to `left_on` and `right_on`.
    Here is a very simple example of a merge on DataFrames:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'This will produce a `DataFrame` that contains rows with `label`, `data1`, and
    `data2` corresponding to the rows from `df1` and `df2` that share the same label.
    Let’s print the three DataFrames to see the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Here, you can see that each combination of `data1` and `data2` values from `df1`
    and `df2`, respectively, with matching labels, have a row in `df3`. Moreover,
    the row with label `D` from `df2` is not used since there is no row with label
    `D` in `df1`.
  prefs: []
  type: TYPE_NORMAL
- en: Plotting data from a DataFrame
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As with many mathematical problems, one of the first steps to finding some way
    to visualize the problem and all the information is to formulate a strategy. For
    data-based problems, this usually means producing a plot of the data and visually
    inspecting it for trends, patterns, and the underlying structure. Since this is
    such a common operation, pandas provides a quick and simple interface for plotting
    data in various forms, using Matplotlib under the hood by default, directly from
    a `Series` or `DataFrame`.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to plot data directly from a `DataFrame` or
    `Series` to understand the underlying trends and structure.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will need the pandas library imported as `pd`, the NumPy
    library imported as `np`, the Matplotlib `pyplot` module imported as `plt`, and
    a default random number generator instance created using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to create a simple `DataFrame` using random data and produce
    plots of the data it contains:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a sample `DataFrame` using random data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we have to create a blank figure with two subplots ready for plotting:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We have to plot the `walk` column as a standard line graph. This can be done
    by using the `plot` method on the `Series` (column) object without additional
    arguments. We will force the plotting on `ax1` by passing the `ax=ax1` keyword
    argument:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we have to plot a histogram of the `diffs` column by passing the `kind="hist"`
    keyword argument to the `plot` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The resulting plots are shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Plot of the walk value and a histogram of differences from a
    DataFrame'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/6.1.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.1 – Plot of the walk value and a histogram of differences from a DataFrame
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the histogram of differences approximates a standard normal
    distribution (mean 0 and variance 1). The random walk plot shows the cumulative
    sum of the differences and oscillates (fairly symmetrically) above and below 0.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `plot` method on a `Series` (or a `DataFrame`) is a quick way to plot the
    data it contains against the row index. The `kind` keyword argument is used to
    control the type of plot that is produced, with a line plot being the default.
    There are lots of options for the plotting type, including `bar` for a vertical
    bar chart, `barh` for a horizontal bar chart, `hist` for a histogram (also seen
    in this recipe), `box` for a box plot, and `scatter` for a scatter plot. There
    are several other keyword arguments to customize the plot that it produces. In
    this recipe, we also provided the `title` keyword argument to add a title to each
    subplot.
  prefs: []
  type: TYPE_NORMAL
- en: Since we wanted to put both plots on the same figure side by side using subplots
    that we had already created, we used the `ax` keyword argument to pass in the
    respective axes handles to the plotting routine. Even if you let the `plot` method
    construct a figure, you may still need to use the `plt.show` routine to display
    the figure with certain settings.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can produce several common types of plots using the pandas interface. This
    includes, in addition to those mentioned in this recipe, scatter plots, bar plots
    (horizontal bars and vertical bars), area plots, pie charts, and box plots. The
    `plot` method also accepts various keyword arguments to customize the appearance
    of the plot.
  prefs: []
  type: TYPE_NORMAL
- en: Getting descriptive statistics from a DataFrame
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Descriptive statistics, or summary statistics, are simple values associated
    with a set of data, such as the mean, median, standard deviation, minimum, maximum,
    and quartile values. These values describe the location and spread of a dataset
    in various ways. The mean and median are measures of the center (location) of
    the data, and the other values measure the spread of the data from the mean and
    median. These statistics are vital for understanding a dataset and form the basis
    for many techniques for analysis.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to generate descriptive statistics for each
    column in a `DataFrame`.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we need the pandas package imported as `pd`, the NumPy package
    imported as `np`, the Matplotlib `pyplot` module imported as `plt`, and a default
    random number generator created using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps show how to generate descriptive statistics for each column
    in a `DataFrame`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will create some sample data that we can analyze:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will plot histograms of the data so that we can understand the distribution
    of the data in the `DataFrame` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To get a proper view of the distribution for the `bimodal` data, we will change
    the number of bins in the histogram to `20`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'pandas `DataFrame` objects have a method for getting several common descriptive
    statistics for each column. The `describe` method creates a new `DataFrame`, where
    the column headers are the same as from the original object and each row contains
    a different descriptive statistic:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We must also compute the *kurtosis* and add this to the new `DataFrame` object
    we just obtained. We must also print the descriptive statistics to the console
    to see what the values are:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we must add vertical lines to the histograms to illustrate the value
    of the mean in each case:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The resulting histograms are shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – Histograms of three sets of data with their mean values indicated'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/6.2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.2 – Histograms of three sets of data with their mean values indicated
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the mean is central to the normally distributed data (middle),
    but for the uniformly distributed data (left), the “mass” of the distribution
    is slightly more biased toward the lower values to the left of the mean. With
    the bimodal day (right), the mean line lies exactly between the two components
    of mass.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `describe` method returns a `DataFrame` with rows for the following descriptive
    statistics of the data: the count, mean, standard deviation, minimum value, 25%
    quartile, median (50% quartile), 75% quartile, and maximum value. The count is
    fairly self-explanatory, as are the minimum and maximum values. The mean and the
    median are two different *averages* of the data, which roughly represent the central
    value of the data. The definition of the mean should be familiar, as the sum of
    all values divided by the number of values. We can express this quantity using
    the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_06_001.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, the ![](img/Formula_06_002.png) values represent the data values and ![](img/Formula_06_003.png)
    is the number (count) of values. Here, we also adopt the common notation of the
    bar to represent the mean value. The median is the “middle value” when all the
    data is sorted (taking an average of the two middle values if there is an odd
    number of values). The quartile values at 25% and 75% are similarly defined, but
    taking the value at 25% or 75% of the way through the ordered values. You might
    also think of the minimum as the 0% quartile and the maximum as the 100% quartile.
  prefs: []
  type: TYPE_NORMAL
- en: '**Standard deviation** is a measure of the spread of the data from the mean
    and is related to another quantity that is frequently mentioned in statistics:
    the **variance**. The variance is the square of the standard deviation and is
    defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_06_004.png)'
  prefs: []
  type: TYPE_IMG
- en: You might also see ![](img/Formula_06_005.png) appear in the fraction here,
    which is a correction for **bias** when estimating population parameters from
    a sample. We will discuss population parameters and their estimation in the next
    recipe. The standard deviation, variance, quartiles, and maximum and minimum values
    describe the spread of the data. For example, if the maximum value is 5, the minimum
    value is 0, the 25% quartile is 2, and the 75% quartile is 4, then this indicates
    that most (at least 50% of the values, in fact) of the data is concentrated between
    2 and 4.
  prefs: []
  type: TYPE_NORMAL
- en: The *kurtosis* is a measure of how much the data is concentrated in the “tails”
    of the distribution (far from the mean). This is not as common as the other quantities
    we have discussed in this recipe, but it does appear in some analyses. We have
    included it here mostly as a demonstration of how to compute summary statistic
    values that do not appear in the `DataFrame` object returned from the `describe`
    method using the appropriately named method – here, `kurtosis`. There are, of
    course, separate methods for computing the mean (`mean`), standard deviation (`std`),
    and the other quantities from the `describe` method.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: When pandas computes the quantities described in this recipe, it will automatically
    ignore any “missing values” represented by NaN. This will also be reflected in
    the count reported in the descriptive statistics.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The third dataset that we included in our statistics illustrates the importance
    of looking at the data to make sure the values we have calculated make sense.
    Indeed, we compute the mean as approximately `2.9`, but looking at the histogram,
    it is clear that most of the data is relatively far from this value. We should
    always check whether the summary statistics that we calculate give an accurate
    summary of the data in our sample. Simply quoting the mean might give an inaccurate
    representation of the sample.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding a population using sampling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the central problems in statistics is to make estimations – and quantify
    how good these estimations are – of the distribution of an entire population given
    only a small (random) sample. A classic example is to estimate the average height
    of all the people in a country when measuring the height of a randomly selected
    sample of people. These kinds of problems are particularly interesting when the
    true population distribution, by which we usually mean the mean of the whole population,
    cannot feasibly be measured. In this case, we must rely on our knowledge of statistics
    and a (usually much smaller) randomly selected sample to estimate the true population
    mean and standard deviation, and also quantify how good our estimations are. It
    is the latter that is the source of confusion, misunderstanding, and misrepresentation
    of statistics in the wider world.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to estimate the population mean and give a
    **confidence interval** for these estimates.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we need the pandas package imported as `pd`, the `math` module
    from the Python standard library, and the SciPy `stats` module, imported using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: Let’s learn how to construct confidence intervals using the statistical routines
    from SciPy.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the following steps, we will give an estimation of the mean height of males
    in the United Kingdom, based on a randomly selected sample of 20 people:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must load our sample data into a pandas `Series`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we must compute the sample mean and standard deviation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we must compute the **standard error**, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We must compute the **critical values** for the confidence values we desire
    from the student t distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can compute the 95% and 99% confidence intervals for the true population
    mean using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE120]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The key to parameter estimation is normal distribution, which we discussed in
    [*Chapter 4*](B19085_04.xhtml#_idTextAnchor138), *Working with Randomness and
    Probability*. If we find the critical value of ![](img/Formula_06_006.png) for
    which the probability that a standard, normally distributed random number lies
    below this value ![](img/Formula_06_007.png) is 97.5%, then the probability that
    such a number lies between the values of ![](img/Formula_06_008.png) and ![](img/Formula_06_009.png)
    is 95% (2.5% in each tail). This critical value of ![](img/Formula_06_010.png)
    turns out to be 1.96, rounded to 2 decimal places. That is, we can be 95% sure
    that the value of a standard normally distributed random number lies between ![](img/Formula_06_011.png)
    and ![](img/Formula_06_012.png). Similarly, the critical value of 99% confidence
    is 2.58 (rounded to 2 decimal places).
  prefs: []
  type: TYPE_NORMAL
- en: If our sample is “large,” we could invoke the `stats.t.ppf` routine from the
    SciPy `stats` module.
  prefs: []
  type: TYPE_NORMAL
- en: The student t distribution is related to the normal distribution but has a parameter
    – the degree of freedom – that changes the shape of the distribution. As the number
    of degrees of freedom increases, the student t distribution will look more and
    more like a normal distribution. The point at which you consider the distributions
    to be sufficiently similar depends on your application and your data. A general
    rule of thumb says that a sample size of 30 is sufficient to invoke the central
    limit theorem and simply use the normal distribution, but it is by no means a
    good rule. You should be very careful when making deductions based on a sample,
    especially if the sample is very small compared to the total population.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have the critical values, the confidence interval for the true population
    mean can be computed by multiplying the critical value by the standard error of
    the sample and adding and subtracting this from the sample mean. The standard
    error is an approximation of the spread of the distribution of sample means of
    a given sample size from the true population mean. This is why we use the standard
    error to give the confidence interval for our estimation of the population mean.
    When we multiply the standard error by the critical value taken from the student
    t distribution (in this case), we obtain an estimate of the maximum difference
    between the observed sample mean and the true population mean at the given confidence
    level.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, that means that we are 95% certain that the mean height of UK
    males lies between 168.7 cm and 175.6 cm, and we are 99% certain that the mean
    height of UK males lies between 167.4 cm and 176.9 cm. Our sample was drawn from
    a population with a mean of 175.3 cm and a standard deviation of 7.2 cm. This
    true mean (175.3 cm) does indeed lie within both of our confidence intervals,
    but only just.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is a useful package called `uncertainties` for doing computations involving
    values with some uncertainty attached. See the *Accounting for uncertainty in
    calculations* recipe in [*Chapter 10*](B19085_10.xhtml#_idTextAnchor395), *Improving
    Your Productivity*, for more information.
  prefs: []
  type: TYPE_NORMAL
- en: Performing operations on grouped data in a DataFrame
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the great features of pandas DataFrames is the ability to group the data
    by the values in particular columns. For example, we might group assembly line
    data by the line ID and the shift ID. The ability to operate on this grouped data
    ergonomically is very important since data is often aggregated for analysis but
    needs to be grouped for preprocessing.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to perform operations on grouped data in a
    `DataFrame`. We’ll also take the opportunity to show how to operate on rolling
    windows of (grouped) data.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will need the NumPy library imported as `np`, the Matplotlib
    `pyplot` interface imported as `plt`, and the pandas library imported as `pd`.
    We’ll also need an instance of the default random number generator created as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we start, we also need to set up the Matplotlib plotting settings to
    change the plotting style in this recipe. We’re going to change the mechanism
    that cycles through the plotting style when multiple plots are produced on the
    same axes, which usually results in different colors. To do this, we’re going
    to change this to produce black lines with different line styles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s learn how to use the grouping features of pandas DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to learn how to perform operations on grouped data inside
    a pandas `DataFrame`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to generate some sample data in a `DataFrame`. For this example,
    we’re going to generate two label columns and one column of numerical data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE124]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE125]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE126]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, let’s add a new column that consists of the cumulative sum of the `"data"`
    column, grouped by the first label, `"label1"`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE128]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The first five rows of `df` are now as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see that the `"first_group"` column contains the cumulative sum
    for each of the labels in the `"label1"` column. For instance, the row 0 and row
    1 sums are just the value from the `"data"` column. The new entry in row 2 is
    the sum of the data in row 0 and row 2 since these are the first two rows with
    the label “`C`”.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s perform a grouping on both the `"label1"` and `"label2"` columns
    simultaneously:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can compute the rolling mean over consecutive entries within each group
    using the `transform` and `rolling` methods on the grouped data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE132]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE133]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE134]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The first five printed rows are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: 'As before, the first few rows all represent different groups, so the values
    in the `"second_group"` column are the same as the corresponding values in the
    `"data"` column. The value in row 4 is the mean of the data values in rows 3 and
    4\. The next five printed rows are those with the label `C`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see the rolling average and cumulative sums more clearly. All but
    the first row have the same labels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s plot the values of the `"first_group"` column grouped by the
    `"``label1"` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE138]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE139]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE140]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The resulting plot is shown in *Figure 6**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – Plot of cumulative sums by the label1 group'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/6.3.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.3 – Plot of cumulative sums by the label1 group
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that each of the groups has produced a distinct line on the
    plot. This is a quick and easy way to produce plots of grouped data from a `DataFrame`.
    (Remember that we changed the default style cycle in the *Getting ready* section
    to make the plot style more distinctive on the page.)
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `groupby` method creates a proxy for the DataFrame with an index generated
    from the requested columns. We can then perform operations on this proxy object.
    In this case, we used the `cumsum` method to generate the cumulative sum of the
    numerical values in the `"data"` column within each of the groups. We can use
    this approach to generate summary statistics of the grouped data in the same way.
    This is very useful for data exploration.
  prefs: []
  type: TYPE_NORMAL
- en: In the second part of this recipe, we grouped by two different label columns
    and computed a rolling average (with window length 2) on each group. Notice that
    we “wrap” this computation using the `transform` method rather than calling `rolling`
    directly on the grouped `DataFrame`. This is so that the result has the correct
    indexing to be put back into `df`. Otherwise, the output of `mean` will inherit
    the grouped index, and we will not be able to put the result into `df`. We used
    the `min_periods` optional argument on `rolling` to make sure that all rows had
    a value. Otherwise, the rows that appeared before the window size would be assigned
    NaN.
  prefs: []
  type: TYPE_NORMAL
- en: The final part of this recipe used the `plot` routine on the data grouped by
    `"label1"`. This is a fast and easy way to plot multiple streams of data from
    within the same `DataFrame` object. Unfortunately, it is a little difficult to
    customize the plotting in this case, although it can be done using the `rcparams`
    settings in Matplotlib.
  prefs: []
  type: TYPE_NORMAL
- en: Testing hypotheses using t-tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most common tasks in statistics is to test the validity of a hypothesis
    about the mean of a normally distributed population, given that you have collected
    sample data from that population. For example, in quality control, we might wish
    to test that the thickness of a sheet produced at a mill is 2 mm. To test this,
    we can randomly select sample sheets and measure the thickness to obtain our sample
    data. Then, we can use a `stats` module to compute a t statistic and a ![](img/Formula_06_017.png)
    value. If the ![](img/Formula_06_018.png) value is below 0.05, then we accept
    the null hypothesis with 5% significance (95% confidence). If the ![](img/Formula_06_019.png)
    value is larger than 0.05, then we must reject the null hypothesis in favor of
    our alternative hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to use a t-test to test whether the assumed
    population mean is valid given a sample.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe we will need the pandas package imported as `pd` and the SciPy
    `stats` module imported using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: Let’s learn how to perform t-tests using the SciPy `stats` module.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to use a t-test to test the validity of a proposed population
    mean given some sample data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must load the data into a pandas `Series`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE143]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE144]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE145]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE146]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE147]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE148]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE149]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s set the hypothesized population mean and the significance level
    that we will be testing at:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE151]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will use the `ttest_1samp` routine from the SciPy `stats` module to
    generate the t statistic and the ![](img/Formula_06_020.png) value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE153]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE154]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, let’s test whether the ![](img/Formula_06_020.png) value is smaller
    than the significance level we chose:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE156]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE157]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE158]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE159]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can conclude with 95% confidence that the mean of the population from which
    the data was sampled is not equal to 2\. (Given that most of the numbers shown
    in the sample are greater than 2, this isn’t much of a surprise.) We can be very
    confident that this is the case given how small the ![](img/Formula_06_020.png)
    value is here.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The t statistic is computed using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_06_023.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_06_024.png) is the hypothesized mean (from the null hypothesis),
    ![](img/Formula_06_025.png) is the sample mean, ![](img/Formula_06_026.png) is
    the sample standard deviation, and ![](img/Formula_06_027.png) is the size of
    the sample. The t statistic is an estimation of the difference between the observed
    sample mean and the hypothesized population mean, ![](img/Formula_06_028.png),
    normalized by the standard error. Assuming the population is normally distributed,
    the t statistic will follow a t distribution with ![](img/Formula_06_029.png)
    degrees of freedom. Looking at where the t statistic lies within the corresponding
    student t distribution gives us an idea of how likely it is that the sample mean
    we observed came from the population with the hypothesized mean. This is given
    in the form of a ![](img/Formula_06_030.png) value.
  prefs: []
  type: TYPE_NORMAL
- en: The ![](img/Formula_06_020.png) value is the probability of observing a more
    extreme value than the sample mean we have observed, given the assumption that
    the population mean is equal to ![](img/Formula_06_032.png). If the ![](img/Formula_06_033.png)
    value is smaller than the significance value we have chosen, then we cannot expect
    the true population mean to be the value, ![](img/Formula_06_034.png), that we
    assumed. In this case, we accept the alternative hypothesis that the true population
    norm is not equal to ![](img/Formula_06_035.png).
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The test that we demonstrated in this recipe is the most basic use of a t-test.
    Here, we compared the sample mean to a hypothesized population mean to decide
    whether it was reasonable that the mean of the whole population is this hypothesized
    value. More generally, we can use t-tests to compare two independent populations
    given samples taken from each using a **two-sample t-test**, or compare the populations
    where data is paired (in some way) using a **paired t-test**. This makes the t-test
    an important tool for a statistician.
  prefs: []
  type: TYPE_NORMAL
- en: Significance and confidence are two concepts that occur frequently in statistics.
    A statistically significant result has a high probability of being correct. In
    many contexts, we consider any result that has a probability of being wrong below
    a certain threshold (usually either 5% or 1%) to be statistically significant.
    Confidence is a quantification of how certain we are about a result. The confidence
    of a result is 1 minus the significance.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, the significance of a result is something that is often misused
    or misunderstood. To say that a result is statistically significant at 5% is to
    say that there is a 5% chance that we have wrongly accepted the null hypothesis.
    That is, if we repeated the same test on 20 other samples from the population,
    we would expect at least one of them to give the opposite result. That, however,
    is not to say that one of them is guaranteed to do so.
  prefs: []
  type: TYPE_NORMAL
- en: High significance indicates that we are more sure that the conclusion we have
    reached is correct, but it is certainly not a guarantee that this is indeed the
    case. The results found in this recipe are evidence for this; the sample that
    we used was drawn from a population with a mean of `2.5` and a standard deviation
    of `0.35`. (Some rounding was applied to the sample after creation, which will
    have altered the distribution slightly.) This is not to say that our analysis
    is wrong, or that the conclusion we reached from our sample is not the right one.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to remember that t-tests are only valid when the underlying
    populations follow a normal distribution, or at least approximately do so. If
    this is not the case, then you might need to use a non-parametric test instead.
    We will discuss this in the *Testing hypotheses for non-parametric* *data* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Testing hypotheses using ANOVA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Suppose we have designed an experiment that tests two new processes against
    the current process and we want to test whether the results of these new processes
    are different from the current process. In this case, we can use **Analysis of
    Variance** (**ANOVA**) to help us determine whether there are any differences
    between the mean values of the three sets of results (for this, we need to assume
    that each sample is drawn from a normal distribution with a common variance).
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to use ANOVA to compare multiple samples with
    one another.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we need the SciPy `stats` module. We will also need to create
    a default random number generator instance using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE160]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to perform a (one-way) ANOVA test to test for differences
    between three different processes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will create some sample data, which we will analyze:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE161]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE162]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE163]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will set the significance level for our test:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE164]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we will use the `f_oneway` routine from the SciPy `stats` module to generate
    the F-statistic and the ![](img/Formula_06_036.png) value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE165]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE166]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE167]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE168]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we must test whether the ![](img/Formula_06_020.png) value is sufficiently
    small to see whether we should accept or reject our null hypothesis that all mean
    values are equal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE169]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE170]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE171]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE172]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE173]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, the ![](img/Formula_06_038.png) value is so small (of order ![](img/Formula_06_039.png))
    that the difference is significant not only at 95% confidence (that is, ![](img/Formula_06_040.png))
    but also at 99% confidence (![](img/Formula_06_041.png)).
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ANOVA is a powerful technique for comparing multiple samples against one another
    simultaneously. It works by comparing the variation in the samples relative to
    the overall variation. ANOVA is especially powerful when comparing three or more
    samples since no cumulative error is incurred from running multiple tests. Unfortunately,
    if ANOVA detects that not all the mean values are equal, then there is no way
    from the test information to determine which sample(s) are significantly different
    from the others. For this, you would need to use an extra test to find the differences.
  prefs: []
  type: TYPE_NORMAL
- en: The `f_oneway` SciPy `stats` module routine performs a one-way ANOVA test –
    the test statistic generated in ANOVA follows an F-distribution. Again, the ![](img/Formula_06_018.png)
    value is the crucial piece of information coming from the test. We accept the
    null hypothesis if the ![](img/Formula_06_030.png) value is less than our predefined
    significance level (in this recipe, 5%) and reject the null hypothesis otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The ANOVA method is very flexible. The one-way ANOVA test that we presented
    here is the most simple case as there is only a single factor to test. A two-way
    ANOVA test can be used to test for differences between two different factors.
    This is useful in clinical trials of medicines, for example, where we test against
    a control measure but also measure the effects of gender (for instance) on the
    outcomes. Unfortunately, SciPy does not have a routine for performing two-way
    ANOVA in the `stats` module. You will need to use an alternative package, such
    as the `statsmodels` package.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously, ANOVA can only detect whether there are differences.
    It cannot detect where these differences occur if there are significant differences.
    For example, we can use Durnett’s test to test whether the other sample’s mean
    values differ from a control sample, or Tukey’s range test to test each group’s
    mean against every other group’s mean.
  prefs: []
  type: TYPE_NORMAL
- en: Testing hypotheses for non-parametric data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Both t-tests and ANOVA have a major drawback: the population that is being
    sampled must follow a normal distribution. In many applications, this is not too
    restrictive because many real-world population values follow a normal distribution,
    or some rules, such as the central limit theorem, allow us to analyze some related
    data. However, it is simply not true that all possible population values follow
    a normal distribution in any reasonable way. For these (thankfully, rare) cases,
    we need some alternative test statistics to use as replacements for t-tests and
    ANOVA.'
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will use a Wilcoxon rank-sum test and the Kruskal-Wallis
    test to test for differences between two (or more, in the latter case) populations.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will need the pandas package imported as `pd`, the SciPy
    `stats` module, and a default random number generator instance created using the
    following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE174]'
  prefs: []
  type: TYPE_PRE
- en: Let’s learn how to use the non-parametric hypothesis testing tools in SciPy
    `stats`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to compare the populations of two or more populations that
    are not normally distributed:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will generate some sample data to use in our analysis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE175]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE176]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE177]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will set the significance level that we will use in this analysis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE178]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we will use the `stats.kruskal` routine to generate the test statistic
    and the ![](img/Formula_06_038.png) value for the null hypothesis that the populations
    have the same median value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE179]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE180]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE181]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE182]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will use a conditional statement to print a statement about the outcome
    of the test:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE183]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE184]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE185]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE186]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE187]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we will use Wilcoxon rank-sum tests to obtain the ![](img/Formula_06_033.png)
    values for the comparisons between each pair of samples. The null hypothesis for
    these tests is that they are drawn from the same distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE188]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE189]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE190]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will use conditional statements to print out messages for those comparisons
    that indicate a significant difference:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE191]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE192]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE193]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE194]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE195]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE196]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE197]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE198]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE199]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE200]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE201]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE202]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE203]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE204]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE205]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE206]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE207]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE208]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: These printed lines show that our tests have detected significant differences
    between populations A and B and populations A and C, but not between populations
    B and C.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We say that data is non-parametric if the population from which the data was
    sampled does not follow a distribution that can be described by a small number
    of parameters. This usually means that the population is not normally distributed
    but is broader than this. In this recipe, we sampled from uniform distributions,
    but this is still a more structured example than we would generally have when
    non-parametric tests are necessary. Non-parametric tests can and should be used
    in any situation where we are not sure about the underlying distribution. The
    cost of doing this is that the tests are slightly less powerful.
  prefs: []
  type: TYPE_NORMAL
- en: The first step of any (real) analysis should be to plot a histogram of the data
    and inspect the distribution visually. If you draw a random sample from a normally
    distributed population, you might also expect the sample to be normally distributed
    (we have seen this several times in this book). If your sample shows the characteristic
    bell curve of a normal distribution, then it is fairly likely that the population
    is itself normally distributed. You might also use a `kind="kde"`. If you still
    aren’t sure whether the population is normal, you can apply a statistical test,
    such as D’Agostino’s K-squared test or Pearson’s Chi-squared test for normality.
    These two tests are combined into a single routine to test for normality called
    `normaltest` in the SciPy `stats` module, along with several other tests for normality.
  prefs: []
  type: TYPE_NORMAL
- en: The Wilcoxon rank-sum test is a non-parametric replacement for a two-sample
    t-test. Unlike the t-test, the rank-sum test does not compare the sample mean
    values to quantify whether the populations have different distributions. Instead,
    it combines the data of the samples and ranks them in order of size. The test
    statistic is generated from the sum of the ranks from the sample with the fewest
    elements. From here, as usual, we generate a ![](img/Formula_06_033.png) value
    for the null hypothesis that the two populations have the same distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The Kruskal-Wallis test is a non-parametric replacement for a one-way ANOVA
    test. Like the rank-sum test, it uses the ranking of the sample data to generate
    a test statistic and ![](img/Formula_06_030.png) values for the null hypothesis
    that all the populations have the same median value. As with one-way ANOVA, we
    can only detect whether all the populations have the same median, not where the
    differences lie. For this, we would have to use additional tests.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we used the Kruskal-Wallis test to determine whether there were
    any significant differences between the populations corresponding to our three
    samples. A difference was detected with a ![](img/Formula_06_018.png) value with
    a very small ![](img/Formula_06_020.png) value. We then used rank-sum tests to
    determine where significant differences occur between the populations. Here, we
    found that sample A is significantly different from samples B and C, but B is
    not significantly different from sample C. This is hardly surprising given the
    way that these samples were generated.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, since we have used multiple tests in this recipe, our overall
    confidence in our conclusions is not as high as we might expect it to be. We performed
    four tests with 95% confidence, which means our overall confidence in our conclusion
    is only approximately 81%. This is because errors aggregate over multiple tests,
    reducing the overall confidence. To correct this, we would have to adjust our
    significance threshold for each test, using the Bonferroni correction (or similar).
  prefs: []
  type: TYPE_NORMAL
- en: Creating interactive plots with Bokeh
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Test statistics and numerical reasoning are good for systematically analyzing
    sets of data. However, they don’t give us a good picture of the whole set of data
    like a plot would. Numerical values are definitive but can be difficult to understand,
    especially in statistics, whereas a plot instantly illustrates differences between
    sets of data and trends. For this reason, there is a large number of libraries
    for plotting data in even more creative ways. One particularly interesting package
    for producing plots of data is Bokeh, which allows us to create interactive plots
    in the browser by leveraging JavaScript libraries.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to use Bokeh to create an interactive plot
    that can be displayed in the browser.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will need the pandas package imported as `pd`, the NumPy
    package imported as `np`, an instance of the default random number generator constructed
    with the following code, and the `plotting` module from Bokeh, which we have imported
    under the `bk` alias:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE209]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'These steps show how to create an interactive plot in the browser using Bokeh:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create some sample data to plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE210]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE211]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE212]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we must specify the output file where the HTML code for the plot will
    be stored by using the `output_file` routine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE213]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we will create a new figure and set the title and axes labels, and set
    the ![](img/Formula_06_050.png)-axis type to `datetime` so that our date index
    will be correctly displayed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE214]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE215]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE216]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE217]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will add the data to the figure as a line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE218]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can use either the `show` routine or the `save` routine to save
    or update the HTML in the specified output file. We are using `show` here to cause
    the plot to open in the browser:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE219]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Bokeh plots are not static objects and are supposed to be interactive via the
    browser. The data as it will appear in the Bokeh plot has been recreated here,
    using `matplotlib` for comparison:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – Plot of time series data created using Matplotlib'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/6.4.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.4 – Plot of time series data created using Matplotlib
  prefs: []
  type: TYPE_NORMAL
- en: The real power of Bokeh is its ability to insert dynamic, interactive plots
    into web pages and documents (for example, Jupyter notebooks) so that the reader
    can look into the detail of the data that is plotted.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bokeh uses a JavaScript library to render a plot in a browser, using data provided
    by the Python backend. The advantage of this is that it can generate plots that
    a user can inspect for themselves. For instance, we can zoom in to see detail
    in the plot that might otherwise be hidden, or pan through the data naturally.
    The example given in this recipe is just a taster of what is possible using Bokeh.
  prefs: []
  type: TYPE_NORMAL
- en: The `figure` routine creates an object representing the plot, which we add elements
    to – such as a line through the data points – in the same way that we would add
    plots to a Matplotlib `Axes` object. In this recipe, we created a simple HTML
    file that contains JavaScript code to render the data. This HTML code is dumped
    to the specified file whenever we save or, as is in the recipe, call the `show`
    routine. In practice, the smaller the ![](img/Formula_06_033.png) value, the more
    confident we can be that the hypothesized population mean is correct.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The capabilities of Bokeh go far beyond what is described here. Bokeh plots
    can be embedded in files such as Jupyter notebooks, which are also rendered in
    the browser, or into existing websites. If you are using a Jupyter notebook, you
    should use the `output_notebook` routine instead of the `output_file` routine
    to print the plot directly into the notebook. It has a wide array of different
    plotting styles, supports sharing data between plots (data can be selected in
    one plot and highlighted in the other(s), for example), and supports streaming
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are a large number of textbooks on statistics and statistical theory.
    The following books are good references for the statistics covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mendenhall, W., Beaver, R., and Beaver, B. (2006), *Introduction To Probability
    And Statistics*. 12th ed., (Belmont, Calif.: Thomson Brooks/Cole).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Freedman, D., Pisani, R., and Purves, R. (2007), *Statistics*. New York: W.W.
    Norton.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The pandas documentation ([https://pandas.pydata.org/docs/index.html](https://pandas.pydata.org/docs/index.html))
    and the following pandas book serve as good references for working with pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: 'McKinney, W., (2017), *Python for Data Analysis*. 2nd ed., (Sebastopol: O’Reilly
    Media, Inc, US).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The SciPy documentation ([https://docs.scipy.org/doc/scipy/tutorial/stats.html](https://docs.scipy.org/doc/scipy/tutorial/stats.html))
    also contains detailed information about the statistics module that was used several
    times in this chapter.
  prefs: []
  type: TYPE_NORMAL
