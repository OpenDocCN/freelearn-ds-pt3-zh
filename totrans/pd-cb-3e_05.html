<html><head></head><body>
  <div id="_idContainer029" class="Basic-Text-Frame">
    <h1 class="chapterNumber">5</h1>
    <h1 id="_idParaDest-144" class="chapterTitle">Algorithms and How to Apply Them</h1>
    <p class="normal">In this book, we have already looked at a variety of ways to create pandas data structures and select/assign data within them and have subsequently seen how to store those structures in common formats. These features alone can make pandas a powerful tool in the realm of data exchange, but we are still just scratching the surface of what pandas can offer.</p>
    <p class="normal">A core component of data analysis and computing in general is the application of <em class="italic">algorithms</em>, which describe a sequence of steps the computer should take to process data. In their simplistic form, common data algorithms build upon basic arithmetic (for example, “sum this column”), but scale out to any sequence of steps that you may need for your custom calculations.</p>
    <p class="normal">As you will see in this chapter, pandas provides many common data algorithms out of the box, but also gives you a robust framework through which you can compose and apply your own algorithms. The algorithms pandas provides out of the box would be faster than anything you can write by hand in Python, and as you progress in your data journey, you will usually find that clever use of these algorithms can cover a vast amount of data processing needs.</p>
    <p class="normal">We are going to cover the following recipes in this chapter:</p>
    <ul>
      <li class="bulletList">Basic <code class="inlineCode">pd.Series</code> arithmetic</li>
      <li class="bulletList">Basic <code class="inlineCode">pd.DataFrame</code> arithmetic</li>
      <li class="bulletList">Aggregations</li>
      <li class="bulletList">Transformations</li>
      <li class="bulletList">Map</li>
      <li class="bulletList">Apply</li>
      <li class="bulletList">Summary statistics</li>
      <li class="bulletList">Binning algorithms</li>
      <li class="bulletList">One-hot encoding with <code class="inlineCode">pd.get_dummies</code></li>
      <li class="bulletList">Chaining with <code class="inlineCode">.pipe</code></li>
      <li class="bulletList">Selecting the lowest-budget movies from the top 100</li>
      <li class="bulletList">Calculating a trailing stop order price</li>
      <li class="bulletList">Finding the baseball players best at…</li>
      <li class="bulletList">Understanding which position scores the most per team</li>
    </ul>
    <h1 id="_idParaDest-145" class="heading-1">Basic pd.Series arithmetic</h1>
    <p class="normal">The easiest place to start when <a id="_idIndexMarker223"/>exploring pandas algorithms is with a <code class="inlineCode">pd.Series</code>, given it is also the most basic structure provided by the pandas library. Basic arithmetic will cover the operations of addition, subtraction, multiplication, and division, and, as you will see in this section, pandas offers two ways to perform these. The first approach allows pandas to work with the <code class="inlineCode">+</code>, <code class="inlineCode">-</code>, <code class="inlineCode">*</code>, and <code class="inlineCode">/</code> operators built into the Python language, which is an intuitive way for new users coming to the library to pick up the tool. However, to cover features specific to data analysis not covered by the Python language, and to support the <em class="italic">Chaining with .pipe</em> approach that we will cover later in this chapter, pandas also offers <code class="inlineCode">pd.Series.add</code>, <code class="inlineCode">pd.Series.sub</code>, <code class="inlineCode">pd.Series.mul</code>, and <code class="inlineCode">pd.Series.div</code>, respectively.</p>
    <p class="normal">The pandas library goes to great lengths to keep its API consistent across all data structures, so you will see that the knowledge from this section can be easily transferred over to the <code class="inlineCode">pd.DataFrame</code> structure, with the only difference being that a <code class="inlineCode">pd.Series</code> is one-dimensional while a <code class="inlineCode">pd.DataFrame</code> is two-dimensional.</p>
    <h2 id="_idParaDest-146" class="heading-2">How to do it</h2>
    <p class="normal">Let’s create a <a id="_idIndexMarker224"/>simple <code class="inlineCode">pd.Series</code> from a Python <code class="inlineCode">range</code> expression:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser = pd.Series(<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>), dtype=pd.Int64Dtype())
ser
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0    0
1    1
2    2
dtype: Int64
</code></code></pre>
    <p class="normal">To establish terminology, let’s briefly consider an expression like <code class="inlineCode">a + b</code>. In such an expression, we are using a <em class="italic">binary operator</em> (<code class="inlineCode">+</code>). The term <em class="italic">binary</em><em class="italic"><a id="_idIndexMarker225"/></em> refers to the fact that you need to add two things together for this expression to make sense, that is, it wouldn’t make sense to just have an expression like <code class="inlineCode">a +</code>. Those two “things” are technically considered <em class="italic">operands</em>; so, with <code class="inlineCode">a + b</code>, we have a left operand of <code class="inlineCode">a</code> and a right operand of <code class="inlineCode">b</code>.</p>
    <p class="normal">With one of the operands being a <code class="inlineCode">pd.Series</code>, the most basic algorithmic expression in pandas would encompass the other operand being a <em class="italic">scalar</em>, that is to say, just a single value. When that occurs, the scalar value is <em class="italic">broadcast</em> to each element of the <code class="inlineCode">pd.Series</code> to apply the algorithm.</p>
    <p class="normal">For example, if we<a id="_idIndexMarker226"/> wanted to add the number 42 to each and every element of our <code class="inlineCode">pd.Series</code>, we could simply express that as:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser + <span class="hljs-number">42</span>
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0    42
1    43
2    44
dtype: Int64
</code></code></pre>
    <p class="normal">The pandas library is able to take the addition expression and apply it to our <code class="inlineCode">pd.Series</code> in a <em class="italic">vectorized</em> manner (i.e., the number 42 gets applied to all values at once without requiring users to resort to a <code class="inlineCode">for</code> loop in Python).</p>
    <p class="normal">Subtraction may be expressed naturally using the <code class="inlineCode">-</code> operator:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser - <span class="hljs-number">42</span>
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0    -42
1    -41
2    -40
dtype: Int64
</code></code></pre>
    <p class="normal">Similarly, multiplication may be expressed with the <code class="inlineCode">*</code> operator:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser * <span class="hljs-number">2</span>
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0    0
1    2
2    4
dtype: Int64
</code></code></pre>
    <p class="normal">By now, you can probably surmise that division is expressed with the <code class="inlineCode">/</code> operator:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser / <span class="hljs-number">2</span>
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0    0.0
1    0.5
2    1.0
dtype: Float64
</code></code></pre>
    <p class="normal">It is also perfectly valid for the two operands to be a <code class="inlineCode">pd.Series</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser2 = pd.Series(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>, <span class="hljs-number">13</span>), dtype=pd.Int64Dtype())
ser + ser2
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0    10
1    12
2    14
dtype: Int64
</code></code></pre>
    <p class="normal">As mentioned <a id="_idIndexMarker227"/>in the introduction of this section, while the built-in Python operators are commonly used and viable in most cases, pandas still offers dedicated methods for <code class="inlineCode">pd.Series.add</code>, <code class="inlineCode">pd.Series.sub</code>, <code class="inlineCode">pd.Series.mul</code>, and <code class="inlineCode">pd.Series.div</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser1 = pd.Series([<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">3.</span>], dtype=pd.Float64Dtype())
ser2 = pd.Series([<span class="hljs-number">4.</span>, pd.NA, <span class="hljs-number">6.</span>], dtype=pd.Float64Dtype())
ser1.add(ser2)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0     5.0
1    &lt;NA&gt;
2     9.0
dtype: Float64
</code></code></pre>
    <p class="normal">The advantage of <code class="inlineCode">pd.Series.add</code> over the built-in operator is that it accepts an optional <code class="inlineCode">fill_value=</code> argument to handle missing data:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser1.add(ser2, fill_value=<span class="hljs-number">0.</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0    5.0
1    2.0
2    9.0
dtype: Float64
</code></code></pre>
    <p class="normal">Later in this chapter, you will also be introduced to chaining with <code class="inlineCode">.pipe</code>, which chains most naturally with the pandas methods and not with the built-in Python operators.</p>
    <h2 id="_idParaDest-147" class="heading-2">There’s more…</h2>
    <p class="normal">When both operands in<a id="_idIndexMarker228"/> your expression are <code class="inlineCode">pd.Series</code> objects together, it is important to note that pandas will align on the row labels. This alignment behavior is considered a feature, but can also be surprising to newcomers.</p>
    <p class="normal">To see why this matters, let’s start with two <code class="inlineCode">pd.Series</code> objects that have an identical row index. When we try to add these together, we get a rather unsurprising result:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser1 <span class="hljs-punctuation">=</span> pd.Series<span class="hljs-punctuation">(</span>range<span class="hljs-punctuation">(</span><span class="hljs-number">3</span><span class="hljs-punctuation">),</span> dtype<span class="hljs-punctuation">=</span>pd.Int64Dtype<span class="hljs-punctuation">())</span>
ser2 <span class="hljs-punctuation">=</span> pd.Series<span class="hljs-punctuation">(</span>range<span class="hljs-punctuation">(</span><span class="hljs-number">3</span><span class="hljs-punctuation">),</span> dtype<span class="hljs-punctuation">=</span>pd.Int64Dtype<span class="hljs-punctuation">())</span>
ser1 <span class="hljs-punctuation">+</span> ser2
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0    0
1    2
2    4
dtype: Int64
</code></code></pre>
    <p class="normal">But what happens when the row index values are not identical? A simple case may involve adding two <code class="inlineCode">pd.Series</code> objects together, where one <code class="inlineCode">pd.Series</code> uses a row index that is a subset of the other. You can see this with <code class="inlineCode">ser3</code> in the following code, which only has 2 values and uses the default <code class="inlineCode">pd.RangeIndex</code> with values of <code class="inlineCode">[0, 1]</code>. When added together with <code class="inlineCode">ser1</code>, we still get a 3-element <code class="inlineCode">pd.Series</code> in return, but values are only added where the row index labels can be aligned from both <code class="inlineCode">pd.Series</code> objects:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser3 <span class="hljs-punctuation">=</span> pd.Series<span class="hljs-punctuation">(</span>[<span class="hljs-number">2</span><span class="hljs-punctuation">,</span> <span class="hljs-number">4</span>]<span class="hljs-punctuation">,</span> dtype<span class="hljs-punctuation">=</span>pd.Int64Dtype<span class="hljs-punctuation">())</span>
ser1 <span class="hljs-punctuation">+</span> ser3
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0       2
1       5
2    &lt;NA&gt;
dtype: Int64
</code></code></pre>
    <p class="normal">Now let’s take a look at what <a id="_idIndexMarker229"/>happens when two <code class="inlineCode">pd.Series</code> objects of the same length get added together, but the row index values are different:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser4 <span class="hljs-punctuation">=</span> pd.Series<span class="hljs-punctuation">(</span>[<span class="hljs-number">2</span><span class="hljs-punctuation">,</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span> <span class="hljs-number">8</span>]<span class="hljs-punctuation">,</span> index<span class="hljs-punctuation">=</span>[<span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span> <span class="hljs-number">3</span>]<span class="hljs-punctuation">,</span> dtype<span class="hljs-punctuation">=</span>pd.Int64Dtype<span class="hljs-punctuation">())</span>
ser1 <span class="hljs-punctuation">+</span> ser4
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0    &lt;NA&gt;
1       3
2       6
3    &lt;NA&gt;
dtype: Int64
</code></code></pre>
    <p class="normal">For an even more extreme case, let’s consider the situation where one <code class="inlineCode">pd.Series</code> has row index values that are non-unique:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser5 <span class="hljs-punctuation">=</span> pd.Series<span class="hljs-punctuation">(</span>[<span class="hljs-number">2</span><span class="hljs-punctuation">,</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span> <span class="hljs-number">8</span>]<span class="hljs-punctuation">,</span> index<span class="hljs-punctuation">=</span>[<span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span>]<span class="hljs-punctuation">,</span> dtype<span class="hljs-punctuation">=</span>pd.Int64Dtype<span class="hljs-punctuation">())</span>
ser1 <span class="hljs-punctuation">+</span> ser5
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0       2
1       5
1       9
2    &lt;NA&gt;
dtype: Int64
</code></code></pre>
    <p class="normal">If you have a background in SQL, the behavior of pandas here is akin to a <code class="inlineCode">FULL OUTER JOIN</code> in a database. Every label from each row index gets included in the output, with pandas matching up the labels that can be seen in both <code class="inlineCode">pd.Series</code> objects. This can be directly replicated in a database like PostgreSQL:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code"><span class="hljs-keyword">WITH</span> ser1 <span class="hljs-keyword">AS</span> (
  <span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> (
    <span class="hljs-keyword">VALUES</span>
      (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>),
      (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
      (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)
   ) <span class="hljs-keyword">AS</span> t(index, val1)
),
ser5 <span class="hljs-keyword">AS</span> (
  <span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> (
    <span class="hljs-keyword">VALUES</span>
      (<span class="hljs-number">0</span>, <span class="hljs-number">2</span>),
      (<span class="hljs-number">1</span>, <span class="hljs-number">4</span>),
      (<span class="hljs-number">1</span>, <span class="hljs-number">8</span>)
   ) <span class="hljs-keyword">AS</span> t(index, val2)
)
<span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> ser1 <span class="hljs-keyword">FULL</span> <span class="hljs-keyword">OUTER</span> <span class="hljs-keyword">JOIN</span> ser5 <span class="hljs-keyword">USING</span>(index);
</code></code></pre>
    <p class="normal">If you were to run this snippet directly in PostgreSQL, you would get back the following result:</p>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">index | val1 | val2
------+------+------
    0 |    0 |    2
    1 |    1 |    8
    1 |    1 |    4
    2 |    2 |
(4 rows)
</code></code></pre>
    <p class="normal">Ignoring the ordering difference, you can see that the database gives us back all of the unique <code class="inlineCode">index</code> values from the combinations of <code class="inlineCode">[0, 1, 2]</code> and <code class="inlineCode">[0, 1, 1]</code>, alongside any associated <code class="inlineCode">val1</code> and <code class="inlineCode">val2</code> values. Even though <code class="inlineCode">ser1</code> only had one <code class="inlineCode">index</code> value of <code class="inlineCode">1</code>, that same value appeared twice in the <code class="inlineCode">index</code> column in <code class="inlineCode">ser5</code>. The <code class="inlineCode">FULL OUTER JOIN</code> therefore shows both <code class="inlineCode">val2</code> values from <code class="inlineCode">ser5</code> (<code class="inlineCode">4</code> and <code class="inlineCode">8</code>), while duplicating the <code class="inlineCode">val1</code> value originating from <code class="inlineCode">ser1</code> (<code class="inlineCode">1</code>).</p>
    <p class="normal">If you were to subsequently<a id="_idIndexMarker230"/> add <code class="inlineCode">val1</code> and <code class="inlineCode">val2</code> together in the database, you would get back a result that matches the output of <code class="inlineCode">ser1 + ser5</code>, sparing the fact that the database may choose a different order for its output:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code"><span class="hljs-keyword">WITH</span> ser1 <span class="hljs-keyword">AS</span> (
  <span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> (
    <span class="hljs-keyword">VALUES</span>
      (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>),
      (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
      (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)
   ) <span class="hljs-keyword">AS</span> t(index, val1)
),
ser5 <span class="hljs-keyword">AS</span> (
  <span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> (
    <span class="hljs-keyword">VALUES</span>
      (<span class="hljs-number">0</span>, <span class="hljs-number">2</span>),
      (<span class="hljs-number">1</span>, <span class="hljs-number">4</span>),
      (<span class="hljs-number">1</span>, <span class="hljs-number">8</span>)
   ) <span class="hljs-keyword">AS</span> t(index, val2)
)
<span class="hljs-keyword">SELECT</span> index, val1 <span class="hljs-operator">+</span> val2 <span class="hljs-keyword">AS</span> <span class="hljs-keyword">value</span> <span class="hljs-keyword">FROM</span> ser1 <span class="hljs-keyword">FULL</span> <span class="hljs-keyword">OUTER</span> <span class="hljs-keyword">JOIN</span> ser5 <span class="hljs-keyword">USING</span>(index);
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">index | value
------+-------
    0 |     2
    1 |     9
    1 |     5
    2 |
(4 rows)
</code></code></pre>
    <h1 id="_idParaDest-148" class="heading-1">Basic pd.DataFrame arithmetic</h1>
    <p class="normal">Having now covered basic <code class="inlineCode">pd.Series</code> arithmetic, you will find that the corresponding <code class="inlineCode">pd.DataFrame</code> arithmetic operations are practically <a id="_idIndexMarker231"/>identical, with the lone exception being that our algorithms now work in two dimensions instead of just one. In doing so, the pandas API makes it easy to interpret data regardless of its shape, and without requiring users to write loops to interact with data. This helps significantly reduce developer effort and helps you write faster code – a win-win for developers.</p>
    <h2 id="_idParaDest-149" class="heading-2">How it works</h2>
    <p class="normal">Let’s create a small 3x3 <code class="inlineCode">pd.DataFrame</code> using random numbers:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">np.random.seed(<span class="hljs-number">42</span>)
df = pd.DataFrame(
    np.random.randn(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>),
    columns=[<span class="hljs-string">"col1"</span>, <span class="hljs-string">"col2"</span>, <span class="hljs-string">"col3"</span>],
    index=[<span class="hljs-string">"row1"</span>, <span class="hljs-string">"row2"</span>, <span class="hljs-string">"row3"</span>],
).convert_dtypes(dtype_backend=<span class="hljs-string">"numpy_nullable"</span>)
df
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        col1         col2         col3
row1    0.496714    -0.138264     0.647689
row2    1.52303     -0.234153    -0.234137
row3    1.579213     0.767435    -0.469474
</code></code></pre>
    <p class="normal">Much like a <code class="inlineCode">pd.Series</code>, a <code class="inlineCode">pd.DataFrame</code> also supports built-in binary operators with a scalar <a id="_idIndexMarker232"/>argument. Here is a simplistic addition operation:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df + <span class="hljs-number">1</span>
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        col1        col2        col3
row1    1.496714    0.861736    1.647689
row2    2.52303     0.765847    0.765863
row3    2.579213    1.767435    0.530526
</code></code></pre>
    <p class="normal">And here is a simplistic multiplication operation:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df * <span class="hljs-number">2</span>
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        col1        col2          col3
row1    0.993428    -0.276529     1.295377
row2    3.04606     -0.468307    -0.468274
row3    3.158426     1.534869    -0.938949
</code></code></pre>
    <p class="normal">You can also perform arithmetic with a <code class="inlineCode">pd.Series</code>. By default, each row label in the <code class="inlineCode">pd.Series</code> is searched for and aligned against the columns of the <code class="inlineCode">pd.DataFrame</code>. To illustrate, let’s create a small <code class="inlineCode">pd.Series</code> whose index labels match the column labels of <code class="inlineCode">df</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser = pd.Series(
    [<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">0</span>],
    index=[<span class="hljs-string">"col1"</span>, <span class="hljs-string">"col2"</span>, <span class="hljs-string">"col3"</span>],
    dtype=pd.Int64Dtype(),
)
ser
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">col1    20
col2    10
col3     0
dtype: Int64
</code></code></pre>
    <p class="normal">If you were to try and add this to our <code class="inlineCode">pd.DataFrame</code>, it would take the value of <code class="inlineCode">col1</code> in the <code class="inlineCode">pd.Series</code> and add it to every element in the <code class="inlineCode">col1</code> column of the <code class="inlineCode">pd.DataFrame</code>, repeating for each index entry:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df + ser
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        col1         col2        col3
row1    20.496714    9.861736    0.647689
row2    21.52303     9.765847   -0.234137
row3    21.579213    10.767435  -0.469474
</code></code></pre>
    <p class="normal">In cases where the row labels of the <code class="inlineCode">pd.Series</code> do not match the column labels of the <code class="inlineCode">pd.DataFrame</code>, you may end up with missing data:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser = pd.Series(
    [<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">0</span>, <span class="hljs-number">42</span>],
    index=[<span class="hljs-string">"col1"</span>, <span class="hljs-string">"col2"</span>, <span class="hljs-string">"col3"</span>, <span class="hljs-string">"new_column"</span>],
    dtype=pd.Int64Dtype(),
)
ser + df
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        col1        col2        col3        new_column
row1    20.496714   9.861736    0.647689    NaN
row2    21.52303    9.765847    -0.234137   NaN
row3    21.579213   10.767435   -0.469474   NaN
</code></code></pre>
    <p class="normal">If you would <a id="_idIndexMarker233"/>like to control how <code class="inlineCode">pd.Series</code> and <code class="inlineCode">pd.DataFrame</code> align, you can use the <code class="inlineCode">axis=</code> parameter of methods like <code class="inlineCode">pd.DataFrame.add</code>, <code class="inlineCode">pd.DataFrame.sub</code>, <code class="inlineCode">pd.DataFrame.mul</code>, and <code class="inlineCode">pd.DataFrame.div</code>.</p>
    <p class="normal">Let’s see this in action by creating a new <code class="inlineCode">pd.Series</code> using row labels that align better with the row labels of our <code class="inlineCode">pd.DataFrame</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser = pd.Series(
    [<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">0</span>, <span class="hljs-number">42</span>],
    index=[<span class="hljs-string">"</span><span class="hljs-string">row1"</span>, <span class="hljs-string">"row2"</span>, <span class="hljs-string">"row3"</span>, <span class="hljs-string">"row4"</span>],
    dtype=pd.Int64Dtype(),
)
ser
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">row1    20
row2    10
row3     0
row4    42
dtype: Int64
</code></code></pre>
    <p class="normal">Specifying <code class="inlineCode">df.add(ser, axis=0)</code> will match up the row labels from both the <code class="inlineCode">pd.Series</code> and <code class="inlineCode">pd.DataFrame</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.add(ser, axis=<span class="hljs-number">0</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        col1        col2        col3
row1    20.496714   19.861736   20.647689
row2    11.52303    9.765847    9.765863
row3    1.579213    0.767435   -0.469474
row4    &lt;NA&gt;        &lt;NA&gt;        &lt;NA&gt;
</code></code></pre>
    <p class="normal">You can also use two <code class="inlineCode">pd.DataFrame</code> arguments as the operands of addition, subtraction, multiplication, and division. Here is how to multiply two <code class="inlineCode">pd.DataFrame</code> objects together:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df * df
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        col1       col2        col3
row1    0.246725   0.019117    0.4195
row2    2.31962    0.054828    0.05482
row3    2.493913   0.588956    0.220406
</code></code></pre>
    <p class="normal">Of course, when <a id="_idIndexMarker234"/>doing this, you still need to be aware of the index alignment rules – items are always aligned by label and not by position!</p>
    <p class="normal">Let’s create a new 3x3 <code class="inlineCode">pd.DataFrame</code> with different row and column labels to show this:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">np.random.seed(<span class="hljs-number">42</span>)
df2 = pd.DataFrame(np.random.randn(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))
df2 = df2.convert_dtypes(dtype_backend=<span class="hljs-string">"numpy_nullable"</span>)
df2
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">     0            1             2
0    0.496714     -0.138264     0.647689
1    1.52303      -0.234153    -0.234137
2    1.579213      0.767435    -0.469474
</code></code></pre>
    <p class="normal">Attempting to add this to our previous <code class="inlineCode">pd.DataFrame</code> will generate a row index with labels <code class="inlineCode">["row1", "row2", "row3", 0, 1, 2]</code> and a column index with labels <code class="inlineCode">["col1", "col2", "col3", 0, 1, 2]</code>. Because no labels could be aligned, everything comes back as a missing value:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df + df2
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        col1    col2    col3    0       1       2
row1    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;
row2    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;
row3    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;
0       &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;
1       &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;
2       &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;
</code></code></pre>
    <h1 id="_idParaDest-150" class="heading-1">Aggregations</h1>
    <p class="normal">Aggregations (also referred to as <em class="italic">reductions</em>) help you to reduce multiple values from a series of <a id="_idIndexMarker235"/>values down to a single value. Even if the technical term is new to you, you have no doubt encountered many aggregations in your data journey. Things like the <em class="italic">count</em> of records, the <em class="italic">sum</em> or sales, or the <em class="italic">average</em> price are all very common aggregations.</p>
    <p class="normal">In this recipe, we will explore many of the aggregations built into pandas, while also forming an understanding of how these aggregations are applied. Most analysis you will do throughout your data journey involves taking large datasets and aggregating the values therein into results that your audience can consume. Executives at most companies are not interested in receiving a data dump of transactions, they just want to know the sum, min, max, mean, and so on of values within those transactions. As such, effective use and application of aggregations is a key component to converting your complex data transformation pipelines into simple outputs that others can use and act upon.</p>
    <h2 id="_idParaDest-151" class="heading-2">How to do it</h2>
    <p class="normal">Many basic aggregations are implemented as methods directly on the <code class="inlineCode">pd.Series</code> object, which makes it trivial to calculate commonly desired outputs like the <code class="inlineCode">count</code>, <code class="inlineCode">sum</code>, <code class="inlineCode">max</code>, and so on.</p>
    <p class="normal">To kick off this recipe, let’s once again start with a <code class="inlineCode">pd.Series</code> containing random numbers:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">np.random.seed(<span class="hljs-number">42</span>)
ser = pd.Series(np.random.rand(<span class="hljs-number">10_000</span>), dtype=pd.Float64Dtype())
</code></code></pre>
    <p class="normal">The pandas library provides methods for many commonly used aggregations, like <code class="inlineCode">pd.Series.count</code>, <code class="inlineCode">pd.Series.mean</code>, <code class="inlineCode">pd.Series.std</code>, <code class="inlineCode">pd.Series.min</code>, <code class="inlineCode">pd.Series.max</code>, and <code class="inlineCode">pd.Series.sum</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code"><span class="hljs-built_in">print</span>(<span class="hljs-string">f"Count is: </span><span class="hljs-subst">{ser.count()}</span><span class="hljs-string">"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Mean value is: </span><span class="hljs-subst">{ser.mean()}</span><span class="hljs-string">"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Standard deviation is: </span><span class="hljs-subst">{ser.std()}</span><span class="hljs-string">"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Minimum value is: </span><span class="hljs-subst">{ser.</span><span class="hljs-built_in">min</span><span class="hljs-subst">()}</span><span class="hljs-string">"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Maximum value is: </span><span class="hljs-subst">{ser.</span><span class="hljs-built_in">max</span><span class="hljs-subst">()}</span><span class="hljs-string">"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Summation is: </span><span class="hljs-subst">{ser.</span><span class="hljs-built_in">sum</span><span class="hljs-subst">()}</span><span class="hljs-string">"</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">Count is: 10000
Mean value is: 0.49415955768429964
Standard deviation is: 0.2876301265269928
Minimum value is: 1.1634755366141114e-05
Maximum value is: 0.9997176732861306
Summation is: 4941.595576842997
</code></code></pre>
    <p class="normal">Instead of calling <a id="_idIndexMarker236"/>those methods directly, a more generic way to invoke these aggregations would be to use <code class="inlineCode">pd.Series.agg</code>, providing the name of the aggregation you would like to perform as a string:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code"><span class="hljs-built_in">print</span>(<span class="hljs-string">f"Count is: </span><span class="hljs-subst">{ser.agg(</span><span class="hljs-string">'count'</span><span class="hljs-subst">)}</span><span class="hljs-string">"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Mean value is: </span><span class="hljs-subst">{ser.agg(</span><span class="hljs-string">'mean'</span><span class="hljs-subst">)}</span><span class="hljs-string">"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Standard deviation is: </span><span class="hljs-subst">{ser.agg(</span><span class="hljs-string">'std'</span><span class="hljs-subst">)}</span><span class="hljs-string">"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Minimum value is: </span><span class="hljs-subst">{ser.agg(</span><span class="hljs-string">'min'</span><span class="hljs-subst">)}</span><span class="hljs-string">"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Maximum value is: </span><span class="hljs-subst">{ser.agg(</span><span class="hljs-string">'max'</span><span class="hljs-subst">)}</span><span class="hljs-string">"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Summation is: </span><span class="hljs-subst">{ser.agg(</span><span class="hljs-string">'sum'</span><span class="hljs-subst">)}</span><span class="hljs-string">"</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">Count is: 10000
Mean value is: 0.49415955768429964
Standard deviation is: 0.2876301265269928
Minimum value is: 1.1634755366141114e-05
Maximum value is: 0.9997176732861306
Summation is: 4941.595576842997
</code></code></pre>
    <p class="normal">An advantage using <code class="inlineCode">pd.Series.agg</code> is that it can perform multiple aggregations for you. For example, if you wanted to calculate the minimum and maximum of a field in one step, you could do this by providing a list to <code class="inlineCode">pd.Series.agg</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser.agg([<span class="hljs-string">"min"</span>, <span class="hljs-string">"max"</span>])
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">min    0.000012
max    0.999718
dtype: float64
</code></code></pre>
    <p class="normal">Aggregating a <code class="inlineCode">pd.Series</code> is straightforward because there is only one dimension to be aggregated. With a <code class="inlineCode">pd.DataFrame</code>, there are two possible dimensions to aggregate along, so you have a few more considerations as an end user of the library.</p>
    <p class="normal">To walk through this, let’s go ahead and create a <code class="inlineCode">pd.DataFrame</code> with random numbers:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">np.random.seed(<span class="hljs-number">42</span>)
df = pd.DataFrame(
    np.random.randn(<span class="hljs-number">10_000</span>, <span class="hljs-number">6</span>),
    columns=<span class="hljs-built_in">list</span>(<span class="hljs-string">"abcdef"</span>),
).convert_dtypes(dtype_backend=<span class="hljs-string">"numpy_nullable"</span>)
df
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">     a          b         c         d          e          f
0    0.496714  -0.138264  0.647689  1.523030  -0.234153  -0.234137
1    1.579213   0.767435 -0.469474  0.542560  -0.463418  -0.465730
2    0.241962  -1.913280 -1.724918 -0.562288  -1.012831   0.314247
3   -0.908024  -1.412304  1.465649 -0.225776   0.067528  -1.424748
4   -0.544383   0.110923 -1.150994  0.375698  -0.600639  -0.291694
…     …         …         …         …         …         …
9995  1.951254  0.324704  1.937021 -0.125083  0.589664   0.869128
9996  0.624062 -0.317340 -1.636983  2.390878 -0.597118   2.670553
9997 -0.470192  1.511932  0.718306  0.764051 -0.495094  -0.273401
9998 -0.259206  0.274769 -0.084735 -0.406717 -0.815527  -0.716988
9999  0.533743 -0.701856 -1.099044  0.141010 -2.181973  -0.006398
10000 rows × 6 columns
</code></code></pre>
    <p class="normal">By default, invoking an <a id="_idIndexMarker237"/>aggregation using a built-in method like <code class="inlineCode">pd.DataFrame.sum</code> will apply <em class="italic">along the columns</em>, meaning each column is individually aggregated. After that, pandas will display the result of each column’s aggregation as an entry in a <code class="inlineCode">pd.Series</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.<span class="hljs-built_in">sum</span>()
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">a    -21.365908
b     -7.963987
c    152.032992
d   -180.727498
e     29.399311
f     25.042078
dtype: Float64
</code></code></pre>
    <p class="normal">If you would like to<a id="_idIndexMarker238"/> aggregate data in each row, you can specify the <code class="inlineCode">axis=1</code> argument, with the caveat being that pandas is way more optimized for <code class="inlineCode">axis=0</code> operations, so this has a chance of being <em class="italic">significantly slower</em> than aggregating columns. Even still, it is a rather unique feature of pandas that can be useful when performance is not the main concern:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0       2.060878
1       1.490586
2      -4.657107
3      -2.437675
4      -2.101088
         ...   
9995     5.54669
9996     3.134053
9997     1.755601
9998    -2.008404
9999    -3.314518
Length: 10000, dtype: Float64
</code></code></pre>
    <p class="normal">Much like a <code class="inlineCode">pd.Series</code>, a <code class="inlineCode">pd.DataFrame</code> has a <code class="inlineCode">.agg</code> method, which can be used to apply multiple aggregations at once:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.agg([<span class="hljs-string">"min"</span>, <span class="hljs-string">"max"</span>])
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">      a         b         c         d         e         f
min  -4.295391 -3.436062 -3.922400 -4.465604 -3.836656 -4.157734
max   3.602415  3.745379  3.727833  4.479084  3.691625  3.942331
</code></code></pre>
    <h2 id="_idParaDest-152" class="heading-2">There’s more…</h2>
    <p class="normal">In the examples covered in the <em class="italic">How to do it</em> section, we passed functions as strings like <code class="inlineCode">min</code> and <code class="inlineCode">max</code> to <code class="inlineCode">.agg</code>. This is great for simple functions, but for more complex cases, you can also pass in callable arguments. Each callable should accept a single argument <code class="inlineCode">pd.Series</code> and reduce down to a scalar:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">mean_and_add_42</span>(<span class="hljs-params">ser: pd.Series</span>):
    <span class="hljs-keyword">return</span> ser.mean() + <span class="hljs-number">42</span>
<span class="hljs-keyword">def</span> <span class="hljs-title">mean_and_sub_42</span>(<span class="hljs-params">ser: pd.Series</span>):
    <span class="hljs-keyword">return</span> ser.mean() - <span class="hljs-number">42</span>
np.random.seed(<span class="hljs-number">42</span>)
ser = pd.Series(np.random.rand(<span class="hljs-number">10_000</span>), dtype=pd.Float64Dtype())
ser.agg([mean_and_add_42, mean_and_sub_42])
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">mean_and_add_42    42.49416
mean_and_sub_42   -41.50584
dtype: float64
</code></code></pre>
    <h1 id="_idParaDest-153" class="heading-1">Transformations</h1>
    <p class="normal">Contrary to <em class="italic">aggregations</em>, transformations<a id="_idIndexMarker239"/> do not reduce an array of values to a single value but, rather, maintain the shape of the calling object. This particular recipe may seem rather mundane coming from the previous section on aggregations, but transformations and aggregations will end up being very complementary tools to calculate things like the “% total of group” later in the cookbook.</p>
    <h2 id="_idParaDest-154" class="heading-2">How to do it</h2>
    <p class="normal">Let’s create a small <code class="inlineCode">pd.Series</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser = pd.Series([-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>], dtype=pd.Int64Dtype())
</code></code></pre>
    <p class="normal">Much like we saw with <code class="inlineCode">pd.Series.agg</code> before, <code class="inlineCode">pd.Series.transform</code> can accept a list of functions to apply. However, whereas <code class="inlineCode">pd.Series.agg</code> expected these functions to return a single value, <code class="inlineCode">pd.Series.transform</code> expects these functions to return a <code class="inlineCode">pd.Series</code> with the same index and shape:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">adds_one</span>(<span class="hljs-params">ser: pd.Series</span>) -&gt; pd.Series:
    <span class="hljs-keyword">return</span> ser + <span class="hljs-number">1</span>
ser.transform([<span class="hljs-string">"abs"</span>, adds_one])
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">     abs    adds_one
0    1      0
1    0      1
2    1      2
</code></code></pre>
    <p class="normal">Much like <code class="inlineCode">pd.DataFrame.agg</code> would <em class="italic">aggregate</em> each column by default, <code class="inlineCode">pd.DataFrame.transform</code> will <em class="italic">transform</em> each column by default. Let’s create a small <code class="inlineCode">pd.DataFrame</code> to see this in action:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df = pd.DataFrame(
    np.arange(-<span class="hljs-number">5</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>).reshape(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>)
).convert_dtypes(dtype_backend=<span class="hljs-string">"numpy_nullable"</span>)
df
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">     0    1    2
0   -5   -4   -3
1   -2   -1    0
2    1    2    3
</code></code></pre>
    <p class="normal">Sparing implementation details, calling something like <code class="inlineCode">df.transform("abs")</code> will apply the absolute value function to each column individually before piecing back together the result as a <code class="inlineCode">pd.DataFrame</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.transform(<span class="hljs-string">"abs"</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">     0    1    2
0    5    4    3
1    2    1    0
2    1    2    3
</code></code></pre>
    <p class="normal">If you were to <a id="_idIndexMarker240"/>pass multiple transformation functions to <code class="inlineCode">pd.DataFrame.transform</code>, you will end up with a <code class="inlineCode">pd.MultiIndex</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">add_42</span>(<span class="hljs-params">ser: pd.Series</span>):
    <span class="hljs-keyword">return</span> ser + <span class="hljs-number">42</span>
df.transform([<span class="hljs-string">"abs"</span>, add_42])
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">    0       1       2
    abs  add_42  abs  add_42  abs  add_42
0   5      37    4      38    3      39
1   2      40    1      41    0      42
2   1      43    2      44    3      45
</code></code></pre>
    <h2 id="_idParaDest-155" class="heading-2">There’s more…</h2>
    <p class="normal">As mentioned in the introduction to this recipe, transformations and aggregations can work naturally together alongside<a id="_idIndexMarker241"/> the <code class="inlineCode">GroupBy</code> concept, which will be covered in <em class="chapterRef">Chapter 8</em>, <em class="italic">Group By</em>. In particular, our <em class="italic">Group by basics</em> recipe will be helpful to compare/contrast aggregations to transformations and will highlight how transformations can be used to expressively and succinctly calculate “percent of group” calculations.</p>
    <h1 id="_idParaDest-156" class="heading-1">Map</h1>
    <p class="normal">The <code class="inlineCode">.agg</code> and <code class="inlineCode">.transform</code> methods we have seen so far apply to an entire <em class="italic">sequence</em> of values at once. Generally, in pandas, this is a good thing; it allows pandas to perform <em class="italic">vectorized</em> operations that are fast and computationally efficient.</p>
    <p class="normal">Still, sometimes, you as an end user may decide that you want to trade performance for customization or finer-grained<a id="_idIndexMarker242"/> control. This is where the <code class="inlineCode">.map</code> methods can come into the picture; <code class="inlineCode">.map</code> helps you apply functions individually to each element of your pandas object.</p>
    <h2 id="_idParaDest-157" class="heading-2">How to do it</h2>
    <p class="normal">Let’s assume we have a <code class="inlineCode">pd.Series</code> of data that mixes together both numbers and lists of numbers:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser = pd.Series([<span class="hljs-number">123.45</span>, [<span class="hljs-number">100</span>, <span class="hljs-number">113</span>], <span class="hljs-number">142.0</span>, [<span class="hljs-number">110</span>, <span class="hljs-number">113</span>, <span class="hljs-number">119</span>]])
ser
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0             123.45
1         [100, 113]
2              142.0
3    [110, 113, 119]
dtype: object
</code></code></pre>
    <p class="normal"><code class="inlineCode">.agg</code> or <code class="inlineCode">.transform</code> are not suitable here because we do not have a uniform data type – we really have to inspect each element to make a decision on how to handle it.</p>
    <p class="normal">For our analysis, let’s assume that when we encounter a number, we are happy to return the value as is. If we encounter a list of values, we want to average out all of the values within that list and return that. A function implementing this feature would look as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">custom_average</span>(<span class="hljs-params">value</span>):
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(value, <span class="hljs-built_in">list</span>):
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(value) / <span class="hljs-built_in">len</span>(value)
    <span class="hljs-keyword">return</span> value
</code></code></pre>
    <p class="normal">We can then apply this to each element of our <code class="inlineCode">pd.Series</code> using <code class="inlineCode">pd.Series.map</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser.<span class="hljs-built_in">map</span>(custom_average)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0    123.45
1    106.50
2    142.00
3    114.00
dtype: float64
</code></code></pre>
    <p class="normal">If we had a <code class="inlineCode">pd.DataFrame</code> containing<a id="_idIndexMarker243"/> this type of data, <code class="inlineCode">pd.DataFrame.map</code> would be able to apply this function just as well:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df = pd.DataFrame([
    [<span class="hljs-number">2.</span>, [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], <span class="hljs-number">3.</span>],
    [[<span class="hljs-number">4</span>, <span class="hljs-number">5</span>], <span class="hljs-number">5</span>, <span class="hljs-number">7.</span>],
    [<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5.5</span>]],
])
df
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">          0         1              2
0       2.0    [1, 2]            3.0
1    [4, 5]         5            7.0
2         1         4    [1, 1, 5.5]
</code></code></pre>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.<span class="hljs-built_in">map</span>(custom_average)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">       0      1     2
0    2.0    1.5   3.0
1    4.5    5.0   7.0
2    1.0    4.0   2.5
</code></code></pre>
    <h2 id="_idParaDest-158" class="heading-2">There’s more…</h2>
    <p class="normal">In the above example, instead of using <code class="inlineCode">pd.Series.map</code>, you could have also used <code class="inlineCode">pd.Series.transform</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser.transform(custom_average)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0    123.45
1    106.50
2    142.00
3    114.00
dtype: float64
</code></code></pre>
    <p class="normal">However, you would <em class="italic">not</em> get the same results with <code class="inlineCode">pd.DataFrame.transform</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.transform(custom_average)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">          0        1             2
0       2.0   [1, 2]           3.0
1    [4, 5]        5           7.0
2         1        4   [1, 1, 5.5]
</code></code></pre>
    <p class="normal">Why is this? Remember that <code class="inlineCode">.map</code> explicitly applies a function to each element, regardless of if you are working with a <code class="inlineCode">pd.Series</code> or <code class="inlineCode">pd.DataFrame</code>. <code class="inlineCode">pd.Series.transform</code> is also happy to apply a function to each element that it contains, but <code class="inlineCode">pd.DataFrame.transform</code> essentially loops over each column and passes that column as an argument to the callable arguments.</p>
    <p class="normal">Because our function is implemented as:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">custom_average</span>(<span class="hljs-params">value</span>):
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(value, <span class="hljs-built_in">list</span>):
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(value) / <span class="hljs-built_in">len</span>(value)
    <span class="hljs-keyword">return</span> value
</code></code></pre>
    <p class="normal">the <code class="inlineCode">isinstance(value, list)</code> check fails when passed a <code class="inlineCode">pd.Series</code> and you end up just returning the <code class="inlineCode">pd.Series</code> itself. If we tweak our function slightly:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">custom_average</span>(<span class="hljs-params">value</span>):
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(value, (pd.Series, pd.DataFrame)):
        <span class="hljs-keyword">raise</span> TypeError(<span class="hljs-string">"Received a pandas object - expected a single value!"</span>)
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(value, <span class="hljs-built_in">list</span>):
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(value) / <span class="hljs-built_in">len</span>(value)
    <span class="hljs-keyword">return</span> value
</code></code></pre>
    <p class="normal">then the behavior of <code class="inlineCode">pd.DataFrame.transform</code> becomes more clear:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.transform(custom_average)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">TypeError: Received a pandas object - expected a single value!
</code></code></pre>
    <p class="normal">While there may be conceptual overlap, generally, in your code, you should think of <code class="inlineCode">.map</code> as working element-wise, whereas <code class="inlineCode">.agg</code> and <code class="inlineCode">.transform</code> will try as best as they can to work with larger sequences of data at once.</p>
    <h1 id="_idParaDest-159" class="heading-1">Apply</h1>
    <p class="normal">Apply<a id="_idIndexMarker244"/> is a commonly used method, to the point that I would argue it is <em class="italic">overused</em>. The <code class="inlineCode">.agg</code>, <code class="inlineCode">.transform</code>, and <code class="inlineCode">.map</code> methods seen so far have relatively clear semantics (<code class="inlineCode">.agg</code> reduces, <code class="inlineCode">.transform</code> maintains shape, <code class="inlineCode">.map</code> applies functions element-wise), but when you reach for <code class="inlineCode">.apply</code>, you can mirror any of these. That flexibility may seem nice at first, but because <code class="inlineCode">.apply</code> leaves it up to pandas to <em class="italic">do the right thing</em>, you are typically better off picking the most explicit methods to avoid surprises.</p>
    <p class="normal">Even still, you will see a lot of code out in the wild (especially from users who did not read this book); so, understanding what it does and what its limitations are can be invaluable.</p>
    <h2 id="_idParaDest-160" class="heading-2">How to do it</h2>
    <p class="normal">Calling <code class="inlineCode">pd.Series.apply</code> will make <code class="inlineCode">.apply</code> act like <code class="inlineCode">.map</code> (i.e., the function gets applied to each individual element of the <code class="inlineCode">pd.Series</code>).</p>
    <p class="normal">Let’s take a look at a rather contrived function that prints out each element:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">debug_apply</span>(<span class="hljs-params">value</span>):
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Apply was called with value:\n</span><span class="hljs-subst">{value}</span><span class="hljs-string">"</span>)
</code></code></pre>
    <p class="normal">Funneling this through <code class="inlineCode">.apply</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser = pd.Series(<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>), dtype=pd.Int64Dtype())
ser.apply(debug_apply)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">Apply was called with value:
0
Apply was called with value:
1
Apply was called with value:
2
0    None
1    None
2    None
dtype: object
</code></code></pre>
    <p class="normal">gives exactly the same behavior as <code class="inlineCode">pd.Series.map</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser.<span class="hljs-built_in">map</span>(debug_apply)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">Apply was called with value:
0
Apply was called with value:
1
Apply was called with value:
2
0    None
1    None
2    None
dtype: object
</code></code></pre>
    <p class="normal"><code class="inlineCode">pd.Series.apply</code> works like a Python loop, calling the function for each element. Because our function returns nothing, our resulting <code class="inlineCode">pd.Series</code> is a like-indexed array of <code class="inlineCode">None</code> values.</p>
    <p class="normal">Whereas <code class="inlineCode">pd.Series.apply</code> works<a id="_idIndexMarker245"/> element-wise, <code class="inlineCode">pd.DataFrame.apply</code> works across each column as a <code class="inlineCode">pd.Series</code>. Let’s see this in action with a <code class="inlineCode">pd.DataFrame</code> of shape <code class="inlineCode">(3, 2)</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df = pd.DataFrame(
    np.arange(<span class="hljs-number">6</span>).reshape(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>),
    columns=<span class="hljs-built_in">list</span>(<span class="hljs-string">"ab"</span>),
).convert_dtypes(dtype_backend=<span class="hljs-string">"numpy_nullable"</span>)
df
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">      a     b
0     0     1
1     2     3
2     4     5
</code></code></pre>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.apply(debug_apply)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">Apply was called with value:
0    0
1    2
2    4
Name: a, dtype: Int64
Apply was called with value:
0    1
1    3
2    5
Name: b, dtype: Int64
a    None
b    None
dtype: object
</code></code></pre>
    <p class="normal">As you can see in the above output, the function was only called twice given the two columns of data, but it was applied three times with the <code class="inlineCode">pd.Series</code> that had three rows.</p>
    <p class="normal">Aside from how many<a id="_idIndexMarker246"/> times <code class="inlineCode">pd.DataFrame.apply</code> actually applies the function, the shape of the return value can vary between mirroring <code class="inlineCode">.agg</code> and <code class="inlineCode">.transform</code> functionality. Our preceding example is closer to a <code class="inlineCode">.agg</code> because it returns a single <code class="inlineCode">None</code> value, but if we returned the element we printed, we would get behavior more like a <code class="inlineCode">.transform</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">debug_apply_and_return</span>(<span class="hljs-params">value</span>):
    <span class="hljs-built_in">print</span>(value)
    <span class="hljs-keyword">return</span> value
df.apply(debug_apply_and_return)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0    0
1    2
2    4
Name: a, dtype: Int64
0    1
1    3
2    5
Name: b, dtype: Int64
      a    b
0     0    1
1     2    3
2     4    5
</code></code></pre>
    <p class="normal">If you find this confusing, you are not alone. Trusting pandas to <em class="italic">do the right thing</em> with <code class="inlineCode">.apply</code> can be a risky proposition; I strongly advise users exhaust all options with <code class="inlineCode">.agg</code>, <code class="inlineCode">.transform</code>, or <code class="inlineCode">.map</code> before reaching for <code class="inlineCode">.apply</code>.</p>
    <h1 id="_idParaDest-161" class="heading-1">Summary statistics</h1>
    <p class="normal">Summary statistics<a id="_idIndexMarker247"/> provide a quick way to understand the basic properties and distribution of the data. In this section, we introduce two powerful pandas methods: <code class="inlineCode">pd.Series.value_counts</code> and <code class="inlineCode">pd.Series.describe</code>, which can serve as useful starting points for exploration.</p>
    <h2 id="_idParaDest-162" class="heading-2">How to do it</h2>
    <p class="normal">The <code class="inlineCode">pd.Series.value_counts</code> method attaches frequency counts to each distinct data point, making it easy to see how often each value occurs. This is particularly useful for discrete data:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser = pd.Series([<span class="hljs-string">"a"</span>, <span class="hljs-string">"b"</span>, <span class="hljs-string">"c"</span>, <span class="hljs-string">"a"</span>, <span class="hljs-string">"c"</span>, <span class="hljs-string">"a"</span>], dtype=pd.StringDtype())
ser.value_counts()
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">a    3
c    2
b    1
Name: count, dtype: Int64
</code></code></pre>
    <p class="normal">For continuous data, <code class="inlineCode">pd.Series.describe</code> is a heap of calculations packaged together into one method call. Through invocation of this particular method, you can easily see the count, mean, minimum, and maximum, alongside a high-level distribution of your data:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser = pd.Series([<span class="hljs-number">0</span>, <span class="hljs-number">42</span>, <span class="hljs-number">84</span>], dtype=pd.Int64Dtype())
ser.describe()
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">count     3.0
mean     42.0
std      42.0
min       0.0
25% <span class="language-bash">     21.0</span>
50% <span class="language-bash">     42.0</span>
75% <span class="language-bash">     63.0</span>
max      84.0
dtype: Float64
</code></code></pre>
    <p class="normal">By default, we will see our distribution summarized through the 25%, 50%, 75%, and max (or 100%) quartiles. If your data analysis was focused on a more particular part of the distribution, you <a id="_idIndexMarker248"/>could control what this method presents back by providing a <code class="inlineCode">percentiles=</code> argument:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser.describe(percentiles=[<span class="hljs-number">.10</span>, <span class="hljs-number">.44</span>, <span class="hljs-number">.67</span>])
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">count      3.0
mean      42.0
std       42.0
min        0.0
10% <span class="language-bash">       8.4</span>
44% <span class="language-bash">     36.96</span>
50% <span class="language-bash">      42.0</span>
67% <span class="language-bash">     56.28</span>
max       84.0
dtype: Float64
</code></code></pre>
    <h1 id="_idParaDest-163" class="heading-1">Binning algorithms</h1>
    <p class="normal">Binning<a id="_idIndexMarker249"/> is the process of taking a continuous variable and categorizing it into discrete buckets. It can be useful to turn a potentially infinite amount of values into a finite amount of “bins” for your<a id="_idIndexMarker250"/> analysis.</p>
    <h2 id="_idParaDest-164" class="heading-2">How to do it</h2>
    <p class="normal">Let’s imagine we have collected survey data from users of a system. One of the survey questions asks users for their age, producing data that looks like:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df = pd.DataFrame([
    [<span class="hljs-string">"Jane"</span>, <span class="hljs-number">34</span>],
    [<span class="hljs-string">"John"</span>, <span class="hljs-number">18</span>],
    [<span class="hljs-string">"Jamie"</span>, <span class="hljs-number">22</span>],
    [<span class="hljs-string">"Jessica"</span>, <span class="hljs-number">36</span>],
    [<span class="hljs-string">"Jackie"</span>, <span class="hljs-number">33</span>],
    [<span class="hljs-string">"Steve"</span>, <span class="hljs-number">40</span>],
    [<span class="hljs-string">"Sam"</span>, <span class="hljs-number">30</span>],
    [<span class="hljs-string">"Stephanie"</span>, <span class="hljs-number">66</span>],
    [<span class="hljs-string">"Sarah"</span>, <span class="hljs-number">55</span>],
    [<span class="hljs-string">"Aaron"</span>, <span class="hljs-number">22</span>],
    [<span class="hljs-string">"Erin"</span>, <span class="hljs-number">28</span>],
    [<span class="hljs-string">"Elsa"</span>, <span class="hljs-number">37</span>],
], columns=[<span class="hljs-string">"name"</span>, <span class="hljs-string">"age"</span>])
df = df.convert_dtypes(dtype_backend=<span class="hljs-string">"numpy_nullable"</span>)
df.head()
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        name       age
0       Jane       34
1       John       18
2       Jamie      22
3       Jessica    36
4       Jackie     33
</code></code></pre>
    <p class="normal">Rather than treating each age as an individual number, we will use <code class="inlineCode">pd.cut</code> to place each record into an age group. As a first attempt, let’s pass our <code class="inlineCode">pd.Series</code> and the number of bins we would<a id="_idIndexMarker251"/> like to generate as arguments:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">pd.cut(df[<span class="hljs-string">"age"</span>], <span class="hljs-number">4</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0       (30.0, 42.0]
1     (17.952, 30.0]
2     (17.952, 30.0]
3       (30.0, 42.0]
4       (30.0, 42.0]
5       (30.0, 42.0]
6     (17.952, 30.0]
7       (54.0, 66.0]
8       (54.0, 66.0]
9     (17.952, 30.0]
10    (17.952, 30.0]
11      (30.0, 42.0]
Name: age, dtype: category
Categories (4, interval[float64, right]): [(17.952, 30.0] &lt; (30.0, 42.0] &lt; (42.0, 54.0] &lt; (54.0, 66.0]]
</code></code></pre>
    <p class="normal">This produces a <code class="inlineCode">pd.CategoricalDtype</code> with 4 distinct intervals – <code class="inlineCode">(17.952, 30.0]</code>, <code class="inlineCode">(30.0, 42.0]</code>, <code class="inlineCode">(42.0, 54.0]</code>, and <code class="inlineCode">(54.0, 66.0]</code>. Save some unexpected decimal places on the first bin, which starts at <code class="inlineCode">17.952</code>, these bins all cover an equidistant range of 12 years, which was derived from the fact that the maximum value (<code class="inlineCode">66</code>) minus the lowest value (<code class="inlineCode">18</code>) yields a total age gap of 48 years, which, when divided equally by 4, gives us the 12-year range for each bin.</p>
    <p class="normal">The age <code class="inlineCode">17.952</code> we see in<a id="_idIndexMarker252"/> the first bin may make sense to pandas internally for whatever algorithm it chose to determine the buckets, but it is ultimately uninteresting to us since we know we are dealing with whole numbers. Fortunately, this can be controlled via the <code class="inlineCode">precision=</code> keyword argument to remove any decimal places:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">pd.cut(df[<span class="hljs-string">"age"</span>], <span class="hljs-number">4</span>, precision=<span class="hljs-number">0</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0     (30.0, 42.0]
1     (18.0, 30.0]
2     (18.0, 30.0]
3     (30.0, 42.0]
4     (30.0, 42.0]
5     (30.0, 42.0]
6     (18.0, 30.0]
7     (54.0, 66.0]
8     (54.0, 66.0]
9     (18.0, 30.0]
10    (18.0, 30.0]
11    (30.0, 42.0]
Name: age, dtype: category
Categories (4, interval[float64, right]): [(18.0, 30.0] &lt; (30.0, 42.0] &lt; (42.0, 54.0] &lt; (54.0, 66.0]]
</code></code></pre>
    <p class="normal"><code class="inlineCode">pd.cut</code> does not limit us to producing equally sized bins like this. If, instead, we wanted to place each person into 10-year age buckets, we could provide those ranges as the second argument:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">pd.cut(df[<span class="hljs-string">"age"</span>], [<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>, <span class="hljs-number">40</span>, <span class="hljs-number">50</span>, <span class="hljs-number">60</span>, <span class="hljs-number">70</span>])
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0     (30, 40]
1     (10, 20]
2     (20, 30]
3     (30, 40]
4     (30, 40]
5     (30, 40]
6     (20, 30]
7     (60, 70]
8     (50, 60]
9     (20, 30]
10    (20, 30]
11    (30, 40]
Name: age, dtype: category
Categories (6, interval[int64, right]): [(10, 20] &lt; (20, 30] &lt; (30, 40] &lt; (40, 50] &lt; (50, 60] &lt; (60, 70]]
</code></code></pre>
    <p class="normal">However, this is a little too strict because it would not account for users over the age of 70. To handle that, we <a id="_idIndexMarker253"/>could change our last bin edge from <code class="inlineCode">70</code> to <code class="inlineCode">999</code> and treat it as a catch-all:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">pd.cut(df[<span class="hljs-string">"age"</span>], [<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>, <span class="hljs-number">40</span>, <span class="hljs-number">50</span>, <span class="hljs-number">60</span>, <span class="hljs-number">999</span>])
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0      (30, 40]
1      (10, 20]
2      (20, 30]
3      (30, 40]
4      (30, 40]
5      (30, 40]
6      (20, 30]
7     (60, 999]
8      (50, 60]
9      (20, 30]
10     (20, 30]
11     (30, 40]
Name: age, dtype: category
Categories (6, interval[int64, right]): [(10, 20] &lt; (20, 30] &lt; (30, 40] &lt; (40, 50] &lt; (50, 60] &lt; (60, 999]]
</code></code></pre>
    <p class="normal">In turn, this produced a label of <code class="inlineCode">(60, 999)</code>, which leaves something to be desired from a display perspective. If we are not happy with the default labels produced, we can control their output with the <code class="inlineCode">labels=</code> argument:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">pd.cut(
    df[<span class="hljs-string">"age"</span>],
    [<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>, <span class="hljs-number">40</span>, <span class="hljs-number">50</span>, <span class="hljs-number">60</span>, <span class="hljs-number">999</span>],
    labels=[<span class="hljs-string">"10-20"</span>, <span class="hljs-string">"20-30"</span>, <span class="hljs-string">"30-40"</span>, <span class="hljs-string">"40-50"</span>, <span class="hljs-string">"50-60"</span>, <span class="hljs-string">"60+"</span>],
)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0     30-40
1     10-20
2     20-30
3     30-40
4     30-40
5     30-40
6     20-30
7       60+
8     50-60
9     20-30
10    20-30
11    30-40
Name: age, dtype: category
Categories (6, object): ['10-20' &lt; '20-30' &lt; '30-40' &lt; '40-50' &lt; '50-60' &lt; '60+']
</code></code></pre>
    <p class="normal">However, our labels above are not <em class="italic">quite</em> right. Note that we provided both <code class="inlineCode">30-40</code> and <code class="inlineCode">40-50</code>, but what happens if someone is exactly 40 years old? What bin are they placed in?</p>
    <p class="normal">Fortunately, we can see <a id="_idIndexMarker254"/>this in our data already from <code class="inlineCode">Steve</code>, who perfectly matches this criteria. If you inspect the default bin he is placed in, it appears as <code class="inlineCode">(30, 40]</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.assign(age_bin=<span class="hljs-keyword">lambda</span> x: pd.cut(x[<span class="hljs-string">"age"</span>], [<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>, <span class="hljs-number">40</span>, <span class="hljs-number">50</span>, <span class="hljs-number">60</span>, <span class="hljs-number">999</span>]))
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        name        age     age_bin
0       Jane        34      (30, 40]
1       John        18      (10, 20]
2       Jamie       22      (20, 30]
3       Jessica     36      (30, 40]
4       Jackie      33      (30, 40]
5       Steve       40      (30, 40]
6       Sam         30      (20, 30]
7       Stephanie   66     (60, 999]
8       Sarah       55      (50, 60]
9       Aaron       22      (20, 30]
10      Erin        28      (20, 30]
11      Elsa        37      (30, 40]
</code></code></pre>
    <p class="normal">Binning, by default, is <em class="italic">right inclusive</em>, meaning each bin can be thought of as <em class="italic">up to and including</em> a particular value. If we wanted behavior that was <em class="italic">up to but not including</em>, we could control this with the <code class="inlineCode">right</code> argument:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.assign(
    age_bin=<span class="hljs-keyword">lambda</span> x: pd.cut(x[<span class="hljs-string">"age"</span>], [<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>, <span class="hljs-number">40</span>, <span class="hljs-number">50</span>, <span class="hljs-number">60</span>, <span class="hljs-number">999</span>], right=<span class="hljs-literal">False</span>)
)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        name      age   age_bin
0       Jane      34    [30, 40)
1       John      18    [10, 20)
2       Jamie     22    [20, 30)
3       Jessica   36    [30, 40)
4       Jackie    33    [30, 40)
5       Steve     40    [40, 50)
6       Sam       30    [30, 40)
7       Stephanie 66    [60, 999)
8       Sarah     55    [50, 60)
9       Aaron     22    [20, 30)
10      Erin      28    [20, 30)
11      Elsa      37    [30, 40)
</code></code></pre>
    <p class="normal">This changed the bin<a id="_idIndexMarker255"/> for <code class="inlineCode">Steve</code> from <code class="inlineCode">(30, 40]</code> to <code class="inlineCode">[40, 50)</code>. In the default string representation, the square bracket signifies the edge being <em class="italic">inclusive</em> of a particular value, whereas the parenthesis is <em class="italic">exclusive</em>.</p>
    <h1 id="_idParaDest-165" class="heading-1">One-hot encoding with pd.get_dummies</h1>
    <p class="normal">It is not uncommon in data <a id="_idIndexMarker256"/>analysis and machine learning applications to <a id="_idIndexMarker257"/>take data that is categorical in nature and convert it into a sequence of <code class="inlineCode">0/1</code> values, as the latter can be more easily interpreted by numeric algorithms. This process is often called <em class="italic">one-hot encoding</em>, and the outputs are typically referred to as <em class="italic">dummy indicators</em>.</p>
    <h2 id="_idParaDest-166" class="heading-2">How to do it</h2>
    <p class="normal">Let’s start with a small <code class="inlineCode">pd.Series</code> containing a discrete set of colors:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser = pd.Series([
    <span class="hljs-string">"green"</span>,
    <span class="hljs-string">"brown"</span>,
    <span class="hljs-string">"blue"</span>,
    <span class="hljs-string">"amber"</span>,
    <span class="hljs-string">"hazel"</span>,
    <span class="hljs-string">"</span><span class="hljs-string">amber"</span>,
    <span class="hljs-string">"green"</span>,
    <span class="hljs-string">"blue"</span>,
    <span class="hljs-string">"green"</span>,
], name=<span class="hljs-string">"eye_colors"</span>, dtype=pd.StringDtype())
ser
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">0    green
1    brown
2     blue
3    amber
4    hazel
5    amber
6    green
7     blue
8    green
Name: eye_colors, dtype: string
</code></code></pre>
    <p class="normal">Passing this<a id="_idIndexMarker258"/> as an argument to <code class="inlineCode">pd.get_dummies</code> will <a id="_idIndexMarker259"/>create a like-indexed <code class="inlineCode">pd.DataFrame</code> with a Boolean column for each color. Each row has one column with <code class="inlineCode">True</code> that maps it back to its original value; all other columns in the same row will be <code class="inlineCode">False</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">pd.get_dummies(ser)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        amber   blue    brown   green   hazel
0       False   False   False   True    False
1       False   False   True    False   False
2       False   True    False   False   False
3       True    False   False   False   False
4       False   False   False   False   True
5       True    False   False   False   False
6       False   False   False   True    False
7       False   True    False   False   False
8       False   False   False   True    False
</code></code></pre>
    <p class="normal">If we are not <a id="_idIndexMarker260"/>satisfied with the default column names, we <a id="_idIndexMarker261"/>can modify them by adding a prefix. A common convention in data modeling is to prefix a Boolean column with <code class="inlineCode">is_</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">pd.get_dummies(ser, prefix=<span class="hljs-string">"is"</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        is_amber  is_blue  is_brown  is_green  is_hazel
0       False     False    False     True      False
1       False     False    True      False     False
2       False     True     False     False     False
3       True      False    False     False     False
4       False     False    False     False     True
5       True      False    False     False     False
6       False     False    False     True      False
7       False     True     False     False     False
8       False     False    False     True      False
</code></code></pre>
    <h1 id="_idParaDest-167" class="heading-1">Chaining with .pipe</h1>
    <p class="normal">When<a id="_idIndexMarker262"/> writing pandas code, there are two major stylistic forms that <a id="_idIndexMarker263"/>developers follow. The first approach makes liberal use of variables throughout a program, whether that means creating new variables like:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df = pd.DataFrame(...)
df1 = do_something(df)
df2 = do_another_thing(df1)
df3 = do_yet_another_thing(df2)
</code></code></pre>
    <p class="normal">or simply reassigning to the same variable repeatedly:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df = pd.DataFrame(...)
df = do_something(df)
df = do_another_thing(df)
df = do_yet_another_thing(df)
</code></code></pre>
    <p class="normal">The alternative approach is to express your code as a <em class="italic">pipeline</em>, where each step accepts and returns a <code class="inlineCode">pd.DataFrame</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">(
    pd.DataFrame(...)
    .pipe(do_something)
    .pipe(do_another_thing)
    .pipe(do_yet_another_thing)
)
</code></code></pre>
    <p class="normal">With the <a id="_idIndexMarker264"/>variable-based approach, you must create multiple variables in your program, or change the state of a <code class="inlineCode">pd.DataFrame</code> at every reassignment. The pipeline approach, by contrast, does not create any new variables, nor does it change the state of <a id="_idIndexMarker265"/>your <code class="inlineCode">pd.DataFrame</code>.</p>
    <p class="normal">While the pipeline approach could theoretically be better handled by a query optimizer, pandas does not offer such a feature as of the time of writing, and it is hard to guess what that may look like in the future. As such, the choice between the two approaches makes almost no difference for performance; it is truly a matter of style.</p>
    <p class="normal">I encourage you to familiarize yourself with both approaches. You may at times find it easier to express your code as a pipeline; at other times, that may feel burdensome. There is no hard requirement to use one or the other, so you can mix and match the styles freely throughout your code.</p>
    <h2 id="_idParaDest-168" class="heading-2">How to do it</h2>
    <p class="normal">Let’s start with a very basic <code class="inlineCode">pd.DataFrame</code>. The columns and their contents are not important for now:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df = pd.DataFrame({
    <span class="hljs-string">"col1"</span>: pd.Series([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], dtype=pd.Int64Dtype()),
    <span class="hljs-string">"col2"</span>: pd.Series([<span class="hljs-string">"a"</span>, <span class="hljs-string">"b"</span>, <span class="hljs-string">"c"</span>], dtype=pd.StringDtype()),
})
df
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">      col1   col2
0     1      a
1     2      b
2     3      c
</code></code></pre>
    <p class="normal">Now let’s create some sample functions that will change the content of the columns. These functions should accept and return a <code class="inlineCode">pd.DataFrame</code>, which you can see from the code annotations:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">change_col1</span>(<span class="hljs-params">df: pd.DataFrame</span>) -&gt; pd.DataFrame:
    <span class="hljs-keyword">return</span> df.assign(col1=pd.Series([<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>], dtype=pd.Int64Dtype()))
<span class="hljs-keyword">def</span> <span class="hljs-title">change_col2</span>(<span class="hljs-params">df: pd.DataFrame</span>) -&gt; pd.DataFrame:
    <span class="hljs-keyword">return</span> df.assign(col2=pd.Series([<span class="hljs-string">"X"</span>, <span class="hljs-string">"Y"</span>, <span class="hljs-string">"Z"</span>], dtype=pd.StringDtype()))
</code></code></pre>
    <p class="normal">As mentioned in the introduction to this recipe, one of the most common ways to apply these functions would be to list them out as separate steps in our program, assigning the results of each step to a new variable along the way:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df2 = change_col1(df)
df3 = change_col2(df2)
df3
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">     col1   col2
0    4      X 
1    5      Y
2    6      Z
</code></code></pre>
    <p class="normal">If we wanted <a id="_idIndexMarker266"/>to avoid the use of intermediate variables altogether, we could have <a id="_idIndexMarker267"/>also tried to nest the function calls inside of one another:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">change_col2(change_col1(df))
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">      col1   col2
0     4      X
1     5      Y
2     6      Z
</code></code></pre>
    <p class="normal">However, that doesn’t make the code any more readable, especially given the fact that <code class="inlineCode">change_col1</code> is executed before <code class="inlineCode">change_col2</code>.</p>
    <p class="normal">By expressing this as a pipeline, we can avoid the use of variables and more easily express the order of operations being applied. To achieve this, we are going to reach for the <code class="inlineCode">pd.DataFrame.pipe</code> method:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.pipe(change_col1).pipe(change_col2)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        col1    col2
0       4       X
1       5       Y
2       6       Z
</code></code></pre>
    <p class="normal">As you can see, we have gotten back the same result as before, but without the use of variables and in a way that is arguably more readable.</p>
    <p class="normal">In case any of the functions you want to apply in a pipeline need to accept more arguments, <code class="inlineCode">pd.DataFrame.pipe</code> is able to forward them along for you. For instance, let’s see what happens if we add a new <code class="inlineCode">str_case</code> parameter to our <code class="inlineCode">change_col2</code> function:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Literal</span>
<span class="hljs-keyword">def</span> <span class="hljs-title">change_col2</span>(
<span class="hljs-params">        df: pd.DataFrame,</span>
<span class="hljs-params">        str_case: </span><span class="hljs-type">Literal</span><span class="hljs-params">[</span><span class="hljs-string">"upper"</span><span class="hljs-params">, </span><span class="hljs-string">"lower"</span><span class="hljs-params">]</span>
) -&gt; pd.DataFrame:
    <span class="hljs-keyword">if</span> str_case == <span class="hljs-string">"upper"</span>:
        values = [<span class="hljs-string">"X"</span>, <span class="hljs-string">"Y"</span>, <span class="hljs-string">"Z"</span>]
    <span class="hljs-keyword">else</span>:
        values = [<span class="hljs-string">"x"</span>, <span class="hljs-string">"y"</span>, <span class="hljs-string">"z"</span>]
    <span class="hljs-keyword">return</span> df.assign(col2=pd.Series(values, dtype=pd.StringDtype()))
</code></code></pre>
    <p class="normal">As you can<a id="_idIndexMarker268"/> see with <code class="inlineCode">pd.DataFrame.pipe</code>, you can simply pass that argument along<a id="_idIndexMarker269"/> as either a positional or keyword argument, just as if you were invoking the <code class="inlineCode">change_col2</code> function directly:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.pipe(change_col2, str_case=<span class="hljs-string">"lower"</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">       col1    col2
0      1       x
1      2       y
2      3       z
</code></code></pre>
    <p class="normal">To reiterate what we mentioned in the introduction to this recipe, there is little to no functional difference between these styles. I encourage you to learn them both as you will inevitably see code written both ways. For your own development, you may even find that mixing and matching the approaches works best.</p>
    <h1 id="_idParaDest-169" class="heading-1">Selecting the lowest-budget movies from the top 100</h1>
    <p class="normal">Now that we have<a id="_idIndexMarker270"/> covered many of the core pandas algorithms from a theoretical level, we can start looking at more “real world” datasets and touch on common ways to explore them.</p>
    <p class="normal">Top N analysis is a common technique whereby you filter your data based on how your data performs when measured by a single variable. Most analytics tools have the capability to help you filter your data to answer questions like <em class="italic">What are the top 10 customers by sales?</em> or, <em class="italic">What are the 10 products with the lowest inventory?</em>. When chained together, you can even form catchy news headlines such as <em class="italic">Out of the Top 100 Universities, These 5 Have the Lowest Tuition Fees</em>, or <em class="italic">From the Top 50 Cities to Live, These 10 Are the Most Affordable</em>.</p>
    <p class="normal">Given how common these types of analyses are, pandas offers built-in functionality to help you easily perform them. In this recipe, we will take a look at <code class="inlineCode">pd.DataFrame.nlargest</code> and <code class="inlineCode">pd.DataFrame.nsmallest</code> and see how we can use them together to answer a question like <em class="italic">From the top 100 movies, which had the lowest budget?</em>.</p>
    <h2 id="_idParaDest-170" class="heading-2">How to do it</h2>
    <p class="normal">Let’s start by reading in the movie dataset and selecting the columns <code class="inlineCode">movie_title</code>, <code class="inlineCode">imdb_score</code>, <code class="inlineCode">budget</code>, and <code class="inlineCode">gross</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df = pd.read_csv(
    <span class="hljs-string">"data/movie.csv"</span>,
    usecols=[<span class="hljs-string">"</span><span class="hljs-string">movie_title"</span>, <span class="hljs-string">"imdb_score"</span>, <span class="hljs-string">"budget"</span>, <span class="hljs-string">"gross"</span>],
    dtype_backend=<span class="hljs-string">"numpy_nullable"</span>,
)
df.head()
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">       gross          movie_title                          budget        imdb_score
0      760505847.0    Avatar                              237000000.0    7.9
1      309404152.0    Pirates of the Caribbean: At World's End  300000000.0    7.1
2      200074175.0    Spectre                             245000000.0    6.8
3      448130642.0    The Dark Knight Rises              250000000.0    8.5
4      &lt;NA&gt;           Star Wars: Episode VII - The Force Awakens  &lt;NA&gt;      7.1
</code></code></pre>
    <p class="normal">The <code class="inlineCode">pd.DataFrame.nlargest</code> method<a id="_idIndexMarker271"/> can be used to select the top 100 movies by <code class="inlineCode">imdb_score</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.nlargest(<span class="hljs-number">100</span>, <span class="hljs-string">"imdb_score"</span>).head()
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        gross        movie_title              budget      imdb_score
2725    &lt;NA&gt;         Towering Inferno         &lt;NA&gt;        9.5
1920    28341469.0   The Shawshank Redemption  25000000.0  9.3
3402    134821952.0  The Godfather            6000000.0   9.2
2779    447093.0     Dekalog                  &lt;NA&gt;        9.1
4312    &lt;NA&gt;         Kickboxer: Vengeance     17000000.0  9.1
</code></code></pre>
    <p class="normal">Now that we have the top 100 selected, we can chain in a call to <code class="inlineCode">pd.DataFrame.nsmallest</code> to return the five lowest-budget movies among those:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.nlargest(<span class="hljs-number">100</span>, <span class="hljs-string">"imdb_score"</span>).nsmallest(<span class="hljs-number">5</span>, <span class="hljs-string">"budget"</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        gross       movie_title              budget       imdb_score
4804    &lt;NA&gt;        Butterfly Girl           180000.0     8.7
4801    925402.0    Children of Heaven       180000.0     8.5
4706    &lt;NA&gt;        12 Angry Men             350000.0     8.9
4550    7098492.0   A Separation             500000.0     8.4
4636    133778.0    The Other Dream Team     500000.0     8.4
</code></code></pre>
    <h2 id="_idParaDest-171" class="heading-2">There’s more…</h2>
    <p class="normal">It is possible to pass a list of column names as the <code class="inlineCode">columns=</code> parameter of the <code class="inlineCode">pd.DataFrame.nlargest</code> and <code class="inlineCode">pd.DataFrame.nsmallest</code> methods. This would only be useful to break ties in the event that there were duplicate values sharing the <em class="italic">nth</em> ranked spot in the first column in the list.</p>
    <p class="normal">To see where this matters, let’s try to just select the top 10 movies by <code class="inlineCode">imdb_score</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.nlargest(<span class="hljs-number">10</span>, <span class="hljs-string">"imdb_score"</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        gross   movie_title     budget  imdb_score
2725    &lt;NA&gt;    Towering Inferno        &lt;NA&gt;     9.5
1920    28341469.0      The Shawshank Redemption        25000000.0     9.3
3402    134821952.0     The Godfather   6000000.0       9.2
2779    447093.0        Dekalog    &lt;NA&gt;    9.1
4312    &lt;NA&gt;    Kickboxer: Vengeance    17000000.0      9.1
66      533316061.0     The Dark Knight 185000000.0     9.0
2791    57300000.0      The Godfather: Part II     13000000.0      9.0
3415    &lt;NA&gt;    Fargo   &lt;NA&gt;    9.0
335     377019252.0     The Lord of the Rings: The Return of the King   94000000.0     8.9
1857    96067179.0      Schindler's List        22000000.0      8.9
</code></code></pre>
    <p class="normal">As you can see, the lowest <code class="inlineCode">imdb_score</code> from the top 10 is <code class="inlineCode">8.9</code>. However, there are more than 10 movies that have a score of <code class="inlineCode">8.9</code> and above:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df[df[<span class="hljs-string">"imdb_score"</span>] &gt;= <span class="hljs-number">8.9</span>]
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        gross   movie_title     budget  imdb_score
66      533316061.0     The Dark Knight 185000000.0      9.0
335     377019252.0     The Lord of the Rings: The Return of the King   94000000.0     8.9
1857    96067179.0      Schindler's List        22000000.0      8.9
1920    28341469.0      The Shawshank Redemption       25000000.0      9.3
2725    &lt;NA&gt;    Towering Inferno        &lt;NA&gt;    9.5
2779    447093.0        Dekalog &lt;NA&gt;    9.1
2791    57300000.0      The Godfather: Part II      13000000.0    9.0
3295    107930000.0     Pulp Fiction    8000000.0       8.9
3402    134821952.0     The Godfather   6000000.0       9.2
3415    &lt;NA&gt;    Fargo   &lt;NA&gt;    9.0
4312    &lt;NA&gt;    Kickboxer: Vengeance    17000000.0      9.1
4397    6100000.0       The Good, the Bad and the Ugly    1200000.0      8.9
4706    &lt;NA&gt;    12 Angry Men     350000.0      8.9
</code></code></pre>
    <p class="normal">The movies that were a part of the top 10 just happened to be the first two movies pandas came across with that score. However, you can use the <code class="inlineCode">gross</code> column as the tiebreaker:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.nlargest(<span class="hljs-number">10</span>, [<span class="hljs-string">"imdb_score"</span>, <span class="hljs-string">"gross"</span>])
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">        gross   movie_title     budget  imdb_score
2725    &lt;NA&gt;    Towering Inferno        &lt;NA&gt;     9.5
1920    28341469.0      The Shawshank Redemption        25000000.0      9.3
3402    134821952.0     The Godfather   6000000.0       9.2
2779    447093.0        Dekalog    &lt;NA&gt;    9.1
4312    &lt;NA&gt;    Kickboxer: Vengeance    17000000.0      9.1
66      533316061.0     The Dark Knight    185000000.0     9.0
2791    57300000.0      The Godfather: Part II    13000000.0        9.0
3415    &lt;NA&gt;    Fargo   &lt;NA&gt;    9.0
335     377019252.0     The Lord of the Rings: The Return of the King   94000000.0      8.9
3295    107930000.0     Pulp Fiction    8000000.0       8.9
</code></code></pre>
    <p class="normal">With that, you see that Pulp Fiction replaced Schindler’s List in our top 10 analysis, given that it grossed higher.</p>
    <h1 id="_idParaDest-172" class="heading-1">Calculating a trailing stop order price</h1>
    <p class="normal">There are many strategies to trade stocks. One basic type of trade that many investors employ is the <em class="italic">stop order</em>. A stop order<a id="_idIndexMarker272"/> is an order placed by an investor to buy or sell a stock that executes whenever the market price reaches a certain point. Stop orders are useful to both prevent huge losses and protect gains.</p>
    <p class="normal">In a <a id="_idIndexMarker273"/>typical stop order, the price does not change throughout the lifetime of the order. For instance, if you purchased a stock for $100 per share, you might want to set a stop order at $90 per share to limit your downside to 10%.</p>
    <p class="normal">A more advanced strategy would be to continually modify the sale price of the stop order to track the value of the stock if it increases in value. This is called a <em class="italic">trailing stop order</em>. Concretely, if the same $100 stock increases to $120, then a trailing stop order 10% below the current market value would move the sale price to $108.</p>
    <p class="normal">The trailing stop order never moves down and is always tied to the maximum value since the time of purchase. If the stock fell from $120 to $110, the stop order would still remain at $108. It would only increase if the price moved above $120.</p>
    <p class="normal">This recipe determines the trailing stop order price given an initial purchase price for any stock using the <code class="inlineCode">pd.Series.cummax</code> method and how <code class="inlineCode">pd.Series.cummin</code> could instead be used to handle short positions. We will also see how the <code class="inlineCode">pd.Series.idxmax</code> method can be used to identify the day the stop order would have been triggered.</p>
    <h2 id="_idParaDest-173" class="heading-2">How to do it</h2>
    <p class="normal">To get started, we will work with <a id="_idIndexMarker274"/>Nvidia (NVDA) stock and assume a purchase on the first trading day of 2020:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df = pd.read_csv(
    <span class="hljs-string">"data/NVDA.csv"</span>,
    usecols=[<span class="hljs-string">"Date"</span>, <span class="hljs-string">"Close"</span>],
    parse_dates=[<span class="hljs-string">"Date"</span>],
    index_col=[<span class="hljs-string">"Date"</span>],
    dtype_backend=<span class="hljs-string">"numpy_nullable"</span>,
)
df.head()
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">ValueError: not all elements from date_cols are numpy arrays
</code></code></pre>
    <p class="normal">In the pandas 2.2 series, there is a bug that prevents the preceding code block from running, instead throwing a <code class="inlineCode">ValueError</code>. If affected by this bug, you can alternatively run <code class="inlineCode">pd.read_csv</code> without the <code class="inlineCode">dtype_backend</code> argument, and add in a call to <code class="inlineCode">pd.DataFrame.convert_dtypes</code> instead:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df = pd.read_csv(
    <span class="hljs-string">"data/NVDA.csv"</span>,
    usecols=[<span class="hljs-string">"Date"</span>, <span class="hljs-string">"Close"</span>],
    parse_dates=[<span class="hljs-string">"Date"</span>],
    index_col=[<span class="hljs-string">"Date"</span>],
).convert_dtypes(dtype_backend=<span class="hljs-string">"numpy_nullable"</span>)
df.head() 
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">                      Close
Date
2020-01-02     59.977501
2020-01-03     59.017502
2020-01-06     59.264999
2020-01-07     59.982498
2020-01-08     60.095001
</code></code></pre>
    <p class="normal">For more information, see pandas bug issue <code class="inlineCode">#57930</code> (<a href="https://github.com/pandas-dev/pandas/issues/57930"><span class="url">https://github.com/pandas-dev/pandas/issues/57930</span></a>).</p>
    <p class="normal">Regardless of which path you took, be aware that <code class="inlineCode">pd.read_csv</code> returns a <code class="inlineCode">pd.DataFrame</code>, but for this analysis we will only need a <code class="inlineCode">pd.Series</code>. To perform that conversion, you can call <code class="inlineCode">pd.DataFrame.squeeze</code>, which will reduce the object from two to one dimension, if possible:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser = df.squeeze()
ser.head()
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">Date
2020-01-02    59.977501
2020-01-03    59.017502
2020-01-06    59.264999
2020-01-07    59.982498
2020-01-08    60.095001
Name: Close, dtype: float64
</code></code></pre>
    <p class="normal">With that, we can use the <code class="inlineCode">pd.Series.cummax</code> method to track the highest closing price seen to date:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser_cummax = ser.cummax()
ser_cummax.head()
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">Date
2020-01-02    59.977501
2020-01-03    59.977501
2020-01-06    59.977501
2020-01-07    59.982498
2020-01-08    60.095001
Name: Close, dtype: float64
</code></code></pre>
    <p class="normal">To create a trailing stop order that limits our downside to 10%, we can chain in a multiplication by <code class="inlineCode">0.9</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser.cummax().mul(<span class="hljs-number">0.9</span>).head()
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">Date
2020-01-02    53.979751
2020-01-03    53.979751
2020-01-06    53.979751
2020-01-07    53.984248
2020-01-08    54.085501
Name: Close, dtype: float64
</code></code></pre>
    <p class="normal">The <code class="inlineCode">pd.Series.cummax</code> method works by retaining the maximum value encountered up to and including the current value. Multiplying this series by 0.9, or whatever cushion you would like to use, creates the trailing stop order. In this particular example, NVDA increased in value, and thus, its trailing stop has also increased.</p>
    <p class="normal">On the flip side, let’s say we were pessimistic about NVDA stock during this timeframe, and we wanted to short the stock. However, we still wanted to put a stop order in place to limit the downside to a 10% increase in value.</p>
    <p class="normal">For this, we can<a id="_idIndexMarker275"/> simply replace our usage of <code class="inlineCode">pd.Series.cummax</code> with <code class="inlineCode">pd.Series.cummin</code> and multiply by <code class="inlineCode">1.1</code> instead of <code class="inlineCode">0.9</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">ser.cummin().mul(<span class="hljs-number">1.1</span>).head()
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">Date
2020-01-02    65.975251
2020-01-03    64.919252
2020-01-06    64.919252
2020-01-07    64.919252
2020-01-08    64.919252
Name: Close, dtype: float64
</code></code></pre>
    <h2 id="_idParaDest-174" class="heading-2">There’s more…</h2>
    <p class="normal">With our trailing stop orders calculated, we can easily determine the days where we would have fallen off of the cumulative maximum by more than our threshold:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">stop_prices = ser.cummax().mul(<span class="hljs-number">0.9</span>)
ser[ser &lt;= stop_prices]
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">Date
2020-02-24     68.320000
2020-02-25     65.512497
2020-02-26     66.912498
2020-02-27     63.150002
2020-02-28     67.517502
                 ...    
2023-10-27    405.000000
2023-10-30    411.609985
2023-10-31    407.799988
2023-11-01    423.250000
2023-11-02    435.059998
Name: Close, Length: 495, dtype: float64
</code></code></pre>
    <p class="normal">If we only cared to identify the very first day where we fell below the cumulative maximum, we could use the <code class="inlineCode">pd.Series.idxmax</code> method. This method works by first calculating the maximum value within a <code class="inlineCode">pd.Series</code>, and then returns the first-row index where that maximum was encountered:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">(ser &lt;= stop_prices).idxmax()
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">Timestamp('2020-02-24 00:00:00')
</code></code></pre>
    <p class="normal">The expression <code class="inlineCode">ser &lt;= stop_prices</code> gives back a Boolean <code class="inlineCode">pd.Series</code> containing <code class="inlineCode">True=/=False</code> values, with each <code class="inlineCode">True</code> record indicating where the stock price is at or below the stop price we already calculated. <code class="inlineCode">pd.Series.idxmax</code> will consider <code class="inlineCode">True</code> to be the maximum value in that <code class="inlineCode">pd.Series</code>; so, by returning the first index label where <code class="inlineCode">True</code> was seen as a value, it tells us the first day that our trailing stop order should have been triggered.</p>
    <p class="normal">This recipe gives us just a taste of how useful pandas may be for trading securities.</p>
    <h1 id="_idParaDest-175" class="heading-1">Finding the baseball players best at…</h1>
    <p class="normal">The American sport of baseball has long been a subject of intense analytical research, with data collection dating back to the early 1900s. For Major League baseball teams, advanced data analysis helps answer questions like <em class="italic">How much should I pay for X player?</em> and <em class="italic">What should I do in the game given the current state of things</em>?, For fans, that same data can be used as fodder for endless debates around <em class="italic">who is the greatest player ever</em>.</p>
    <p class="normal">For this recipe, we <a id="_idIndexMarker276"/>are going to use data that was collected from <a href="https://www.retrosheet.org"><span class="url">retrosheet.org</span></a>. Per the Retrosheet licensing requirements, you should be aware of the following legal disclaimer:</p>
    <div class="note">
      <p class="normal">The information used here was obtained free of charge and is copyrighted by Retrosheet. Interested parties <a id="_idIndexMarker277"/>may contact Retrosheet at <a href="https://www.retrosheet.org"><span class="url">www.retrosheet.org</span></a>.</p>
    </div>
    <p class="normal">From its raw form, the data was summarized to show the common baseball metrics for at bat (<code class="inlineCode">ab</code>), hits (<code class="inlineCode">h</code>), runs scored (<code class="inlineCode">r</code>), and home runs (<code class="inlineCode">hr</code>) for professional players in the years 2020–2023.</p>
    <h2 id="_idParaDest-176" class="heading-2">How to do it</h2>
    <p class="normal">Let’s start by reading in our summarized data and setting the <code class="inlineCode">id</code> column (which represents a unique player) as the index:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df = pd.read_parquet(
    <span class="hljs-string">"data/mlb_batting_summaries.parquet"</span>,
).set_index(<span class="hljs-string">"id"</span>)
df
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">                ab      r       h       hr
id 
abadf001        0       0       0       0
abboa001        0       0       0       0
abboc001        3       0       1       0
abrac001        847     116     208     20
abrea001        0       0       0       0
…               …       …       …       …
zimmk001        0       0       0       0
zimmr001        255     27      62      14
zubet001        1       0       0       0
zunig001        0       0       0       0
zunim001        572     82      111     41
2183 rows × 4 columns
</code></code></pre>
    <p class="normal">In baseball, it is rather<a id="_idIndexMarker278"/> rare for a player to dominate all statistical categories. Oftentimes, a player with a lot of home runs (<code class="inlineCode">hr</code>) will be more powerful and can hit the ball farther, but may do so less frequently than a player more specialized to collect a lot of hits (<code class="inlineCode">h</code>). With pandas, we are fortunate to not have to dive into each metric individually; a simple call to <code class="inlineCode">pd.DataFrame.idxmax</code> will look at each column, find the maximum value, and return the row index value associated with that maximum value for you:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.idxmax()
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">ab    semim001
r     freef001
h     freef001
hr    judga001
dtype: string
</code></code></pre>
    <p class="normal">As you can see, player <code class="inlineCode">semim001</code> (Marcus Semien) had the most at bats, <code class="inlineCode">freef001</code> (Freddie Freeman) had the most runs and hits, and <code class="inlineCode">judga001</code> (Aaron Judge) hit the most home runs in this timeframe.</p>
    <p class="normal">If you wanted to look deeper into how these great players performed across all categories, you could take the output of <code class="inlineCode">pd.DataFrame.idxmax</code>, subsequently call <code class="inlineCode">pd.Series.unique</code> on the values, and use that as a mask for the overall <code class="inlineCode">pd.DataFrame</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">best_players = df.idxmax().unique()
mask = df.index.isin(best_players)
df[mask]
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">          ab      r       h       hr
id
freef001  1849    368     590     81
judga001  1487    301     433    138
semim001  1979    338     521    100
</code></code></pre>
    <h2 id="_idParaDest-177" class="heading-2">There’s more…</h2>
    <p class="normal">For a nice visual enhancement to this data, you can use <code class="inlineCode">pd.DataFrame.style.highlight_max</code> to very specifically show which category these players were the best at:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df[mask].style.highlight_max()
</code></code></pre>
    <figure class="mediaobject"><img src="../Images/B31091_05_01.png" alt=""/></figure>
    <p class="packt_figref">Figure 5.1: Jupyter Notebook output of a DataFrame highlighting max value per column</p>
    <h1 id="_idParaDest-178" class="heading-1">Understanding which position scores the most per team</h1>
    <p class="normal">In baseball, teams<a id="_idIndexMarker279"/> are allowed 9 batters in a “lineup,” with 1 representing the first person to bat and 9 representing the last. Over the course of a game, teams cycle through batters in order, starting over with the first batter after the last has batted.</p>
    <p class="normal">Typically, teams place some of their best hitters toward the “top of the lineup” (i.e., lower number positions) to maximize the opportunity for them to come around and score. However, this does not always mean that the person who bats in position 1 will always be the first to score.</p>
    <p class="normal">In this recipe, we are going to look at all Major League baseball teams from 2000–2023 and find the position that scored the most runs for a team over each season.</p>
    <h2 id="_idParaDest-179" class="heading-2">How to do it</h2>
    <p class="normal">Much like we <a id="_idIndexMarker280"/>did in the <em class="italic">Finding the baseball players best at…</em> recipe, we are going to use data taken from <a href="https://www.retrosheet.org"><span class="url">retrosheet.org</span></a>. For this particular dataset, we are going to set the <code class="inlineCode">year</code> and <code class="inlineCode">team</code> columns in the row index, leaving the remaining columns to show the position in the batting order:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df = pd.read_parquet(
    <span class="hljs-string">"data/runs_scored_by_team.parquet"</span>,
).set_index([<span class="hljs-string">"year"</span>, <span class="hljs-string">"team"</span>])
df
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">           1    2    3    …    7    8    9
year  team
2000  ANA  124  107  100  …   77   76   54
      ARI  110  106  109  …   72   68   40
      ATL  113  125  124  …   77   74   39
      BAL  106  106   92  …   83   78   74
      BOS   99  107   99  …   75   66   62
…     …    …    …    …    …   …    …    …
2023  SLN  105   91   85  …   70   55   74
      TBA  121  120   93  …   78   95   98
      TEX  126  115   91  …   80   87   81
      TOR   91   97   85  …   64   70   79
      WAS  110   90   87  …   63   67   64
720 rows × 9 columns
</code></code></pre>
    <p class="normal">With <code class="inlineCode">pd.DataFrame.idxmax</code>, we can see for every year and team which position scored the most runs. However, with this dataset, the index label we would like <code class="inlineCode">pd.DataFrame.idxmax</code> to identify is actually in the columns and not the rows. Fortunately, pandas can still calculate this easily with the <code class="inlineCode">axis=1</code> argument:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.idxmax(axis=<span class="hljs-number">1</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">year  team
2000  ANA     1
      ARI     1
      ATL     2
      BAL     1
      BOS     4
            ...
2023  SLN     1
      TBA     1
      TEX     1
      TOR     2
      WAS     1
Length: 720, dtype: object
</code></code></pre>
    <p class="normal">From there, we can use <code class="inlineCode">pd.Series.value_counts</code> to understand the number of times a given position in the order represented the most runs scored for a team. We are also going to use the <code class="inlineCode">normalize=True</code> argument, which will give us a frequency instead of a total:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">df.idxmax(axis=<span class="hljs-number">1</span>).value_counts(normalize=<span class="hljs-literal">True</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">1    0.480556
2    0.208333
3    0.202778
4    0.088889
5    0.018056
6    0.001389
Name: proportion, dtype: float64
</code></code></pre>
    <p class="normal">Unsurprisingly, the<a id="_idIndexMarker281"/> first batter scored most frequently accounted for the most runs, doing so for 48% of the teams.</p>
    <h2 id="_idParaDest-180" class="heading-2">There’s more…</h2>
    <p class="normal">We might want to explore more and answer the question: <em class="italic">For teams where the first batter scored the most runs, who scored the second-most</em>?</p>
    <p class="normal">To calculate this, we can create a mask to filter on teams where the first batter scored the most, drop that column from our dataset, and then repeat with the same <code class="inlineCode">pd.DataFrame.idxmax</code> approach to identify the position next in line:</p>
    <pre class="programlisting code"><code class="hljs-code"><code class="hljs-code">mask = df.idxmax(axis=<span class="hljs-number">1</span>).eq(<span class="hljs-string">"1"</span>)
df[mask].drop(columns=[<span class="hljs-string">"1"</span>]).idxmax(axis=<span class="hljs-number">1</span>).value_counts(normalize=<span class="hljs-literal">True</span>)
</code></code></pre>
    <pre class="programlisting con"><code class="hljs-con"><code class="hljs-con">2    0.497110
3    0.280347
4    0.164740
5    0.043353
6    0.014451
Name: proportion, dtype: float64
</code></code></pre>
    <p class="normal">As you can see, if a team’s first batter does not lead the team in runs scored, the second batter ends up being the leader almost 50% of the time.</p>
    <h1 id="_idParaDest-181" class="heading-1">Join our community on Discord</h1>
    <p class="normal">Join our community’s Discord space for discussions with the authors and other readers:</p>
    <p class="normal"><a href="https://packt.link/pandas"><span class="url">https://packt.link/pandas</span></a></p>
    <p class="normal"><img src="../Images/QR_Code5040900042138312.png" alt=""/></p>
  </div>
</body></html>