- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying Streamlit Apps with Hugging Face and Heroku
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In *Chapter 5*, *Deploying Streamlit with Streamlit Community Cloud*, we learned
    how to deploy our Streamlit applications with Streamlit Community Cloud. Streamlit
    Community Cloud is quick, easy, and very effective for most applications. However,
    it does not have unlimited free computing resources available and is limited to
    1 GB of RAM per deployed app. If we want to have an app that uses more resources
    than that, we do not have that option.
  prefs: []
  type: TYPE_NORMAL
- en: This leads me to the other aspect to consider—the integration of Streamlit with
    Snowflake. The paid Streamlit offering is now within the Snowflake ecosystem.
    Though it might seem like a constraint, note that Snowflake enjoys immense popularity
    for a reason. If your company already uses Snowflake, this could be a great advantage
    to you. However, if you do not already use Snowflake, this chapter provides you
    with a couple other excellent options for deploying your resource-intensive or
    security-constrained applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'When Streamlit first was launched, and also when this book was first launched
    in the Fall of 2021, the deployment options available were sparse. Often the best
    option was to rent out server space from Amazon Web Services or Azure and set
    up all the configuration yourself. Thankfully with the massive success of the
    library the deployment options are much improved. This chapter will focus on three
    main sections:'
  prefs: []
  type: TYPE_NORMAL
- en: Choosing between Streamlit Community Cloud, Hugging Face, and Heroku
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying Streamlit apps on Hugging Face
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying Streamlit apps on Heroku
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here is a list of installments required for this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Heroku account**: Heroku is a popular platform that data scientists and software
    engineers use to host their applications, models, and **Application Programming
    Interfaces (APIs**), and is owned by Salesforce. To get a Heroku account, please
    head over to [https://signup.heroku.com](https://signup.heroku.com) to make your
    free account.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heroku Command-Line Interface** (**CLI**): To use Heroku effectively, we
    will need to download the Heroku CLI, which will allow us to run Heroku commands.
    To download this, please follow the instructions listed here: [https://devcenter.heroku.com/articles/heroku-cli](https://devcenter.heroku.com/articles/heroku-cli).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hugging Face account**: Hugging Face is a wonderful machine learning-focused
    platform, which we used in *Chapter 4*, *Machine Learning and AI with Streamlit*;
    to create an account head over to [https://huggingface.co/join](https://huggingface.co/join).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have the requirements, let’s begin!
  prefs: []
  type: TYPE_NORMAL
- en: Choosing between Streamlit Community Cloud, Hugging Face, and Heroku
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At a high level, whenever we are trying to deploy our Streamlit application
    such that users on the internet can see our applications, what we are really doing
    is renting a computer owned by someone else and giving that computer a set of
    instructions to start up our application. Choosing which platform to use is difficult
    to know how to do without either having a background in deploying systems or without
    trying each option out first, but there are a few heuristics that should help
    you out.
  prefs: []
  type: TYPE_NORMAL
- en: The two most important factors for this decision are the flexibility of the
    system and the time it takes to get up and running. Note that these two factors
    are often directly traded off with one another. If you are using Streamlit Community
    Cloud, you cannot say “I want this to run this on GPUs with 30 GiB of memory,”
    but in return, you get a wildly simple process where you can simply point Streamlit
    Community Cloud to your GitHub repository, and it will take care of all the other
    little decisions that need to be made. On the other hand, Hugging Face and Heroku
    give you more flexibility through paid options but take a bit more time to set
    up (as you will find out!).
  prefs: []
  type: TYPE_NORMAL
- en: In short, if you’re working with a platform already (Snowflake, Hugging Face,
    or Heroku), you should just work with the platform you’re already on. If you aren’t
    already using any of these, or are a hobbyist programmer, Streamlit Community
    Cloud is the best option.
  prefs: []
  type: TYPE_NORMAL
- en: If you need more compute and are working in the machine learning or natural
    language processing space, you should use Hugging Face. If you need more compute
    and want a more general platform with a broad set of integrations, Heroku is a
    great option for you.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started with Hugging Face!
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Streamlit with Hugging Face
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hugging Face offers an entire suite of products focused on machine learning
    and is especially used by machine learning engineers and folks in the natural
    language processing space. It gives developers the ability to easily use pre-trained
    models through its transformers library (which we already used!) but also create
    products that let developers host their own models, datasets, and even their own
    data apps through a product called Hugging Face Spaces. You can think of a Space
    as a place to deploy an app on the Hugging Face infrastructure, and it is quite
    easy to get started.
  prefs: []
  type: TYPE_NORMAL
- en: For this chapter, we’ll deploy the same Hugging Face app that we created in
    *Chapter 4*. We can deploy any of our Streamlit apps on Hugging Face, but I thought
    it would be more fitting to deploy that one!
  prefs: []
  type: TYPE_NORMAL
- en: To start, we need to go to [https://huggingface.co/spaces](https://huggingface.co/spaces)
    and click the button that says **Create new Space**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18444_08_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.1: Hugging Face login'
  prefs: []
  type: TYPE_NORMAL
- en: After logging in, we will get a few options. We can name our Space, choose a
    license, select the type of Space that we want (Gradio is another popular option
    for data apps and is owned by Hugging Face), choose the Space hardware (note the
    paid and free options), and set our Space as public or private. The screenshot
    below shows the options I have chosen (you can name the Space anything you’d like,
    but the rest of these should be the same).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18444_08_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.2: Hugging Face options'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, you should click the **Create Space** button at the bottom of the page.
    Once you have created the Space, you need to clone that Space on your personal
    computer using the following Git command, which I cloned inside the main Streamlit
    for Data Science GitHub repository that this book is in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that your repo is cloned, we need to create a file for our Streamlit app
    and another `requirements.txt` file to use to tell Hugging Face Spaces which libraries
    we need for our app, using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Within the `app.py` file, we can directly copy and paste the app we already
    created; the code is copied below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'And for our `requirements.txt` file, we just use three libraries, which we
    can add to the file like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the files in the right state, we just use Git to add, commit,
    and push the changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: When we push our changes from the command line, we will be asked to enter our
    Hugging Face username and password, and then if we go back to our **Hugging Face**
    tab, our app is hosted!
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18444_08_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.3: Hugging Face deployed app'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we go back to our code and look at the `README.md` file, we will notice
    that there are a bunch of useful configuration options, such as changing the emoji
    or the title. Hugging Face also allows us to specify other parameters like the
    Python version. The full documentation is in the link in your `README.md`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18444_08_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.4: Hugging Face deployed app code'
  prefs: []
  type: TYPE_NORMAL
- en: And that is it for deploying Streamlit apps on Hugging Face!
  prefs: []
  type: TYPE_NORMAL
- en: You can probably already notice some of the downsides of deploying on Hugging
    Face Spaces, which include a few more steps than Streamlit Community Cloud, and
    the large amount of real estate on apps that is taken by Hugging Face. Understandably,
    Hugging Face wants to make sure that anyone who sees your app knows that it is
    created using their product. They place a lot of their own branding and products
    at the top of your deployed app, which certainly negatively affects the app viewing
    experience. For other folks who are already using Hugging Face, this branding
    might be a big benefit as they can clone your Space and view popular Spaces and
    models, but for sending apps to non-ML colleagues or even friends, the branding
    is a downside of Spaces.
  prefs: []
  type: TYPE_NORMAL
- en: The other main downside of Hugging Face Spaces is that they are often a bit
    behind in the versions of Streamlit that they support. As of this writing, they
    are running Streamlit version 1.10.0, and the latest version of Streamlit is 1.16.0\.
    If you’re looking for the most recent Streamlit features, Hugging Face Spaces
    might not support them! This also is usually not a big deal for most Streamlit
    apps, but another factor to be aware of when choosing a platform.
  prefs: []
  type: TYPE_NORMAL
- en: I hope it is clear to you the strong benefits and mild disadvantages of using
    Hugging Face Spaces. Now let’s move over to Heroku!
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Streamlit with Heroku
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Heroku is a Platform as a Service owned by Salesforce, optimized as a generic
    compute platform that you can use for everything from websites to APIs to Streamlit
    apps. Because of this, you have many more options with Heroku than with either
    Streamlit Community Cloud or Hugging Face Spaces, but getting started takes more
    effort.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that Heroku has no free tier, so if you do not want to follow along
    (or if you are already happy with Streamlit Community Cloud or Hugging Face Spaces),
    feel free to just skip to the next chapter! The reason Heroku is included in this
    book is that I wanted to provide an option that had more capacity, supported the
    most recent Streamlit versions without much branding, and was easy to use. Heroku
    is the best platform on those metrics, so I’ll cover it below!
  prefs: []
  type: TYPE_NORMAL
- en: 'To deploy our Streamlit apps on Heroku, we need to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Set up and log in to Heroku.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Clone and configure our local repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy to Heroku.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s look at each of these steps in detail!
  prefs: []
  type: TYPE_NORMAL
- en: Setting up and logging in to Heroku
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the *Technical requirements* section of this chapter, we covered how to
    download Heroku and create an account. Now, we need to log in to our Heroku from
    our command line by running the following command and logging in when prompted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This will take us to the Heroku page, and once we log in, we will be good to
    go. This command will keep you logged in on your machine indefinitely, unless
    your password changes or you purposely log out of Heroku.
  prefs: []
  type: TYPE_NORMAL
- en: Cloning and configuring our local repository
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we need to change our directory to where the penguin machine learning
    app is located. My app folder is inside my `Documents` folder, so the following
    command takes me there, but your folder might be different:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If you do not already have the repository downloaded locally with a corresponding
    repository on GitHub, go ahead and stop by *Chapter 5*, *Deploying Streamlit with
    Streamlit Community Cloud*, to see how to get started with GitHub. Instead, you
    can also run the following command to download the repository locally from my
    personal GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: It is highly encouraged that you practice with your own GitHub repository, as
    this is much better practice than cloning an app from me to use to deploy to Heroku.
  prefs: []
  type: TYPE_NORMAL
- en: Now we need to create a Heroku app with a unique name for our app with the next
    command (the app will be deployed as this name with `.heroku.com` appended to
    the end of it). Mine will be `penguin-machine-learning`, but go ahead and pick
    your own!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have this, we need to explicitly make the connection between our Git
    repository and the Heroku app we have just created, which can be done with the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally, we are going to add two files to our repository that are needed
    to start up with Heroku, the `Procfile` file and the `streamlit_setup.sh` file.
    Heroku uses something called a `Procfile` as a way to declare which commands the
    app should perform when starting up, and also to tell Heroku what type of application
    this is. For our Heroku apps, we also need this `Procfile` to configure some setup
    for our app specific to Streamlit apps (such as the port configuration), and then
    also to run the `streamlit run` command to launch our app. Let’s start by creating
    the `streamlit_setup.sh` file using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can open this file with our text editor and put the following lines inside
    it, which creates our familiar `config.toml` file in the base directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we save this file, we need to create a `Procfile` that runs this `streamlit_setup.sh`
    file and then also runs our Streamlit app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Within the `Procfile` file we just created, we will next add the following
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have our Streamlit app all set up, our final step is to deploy it
    to Heroku!
  prefs: []
  type: TYPE_NORMAL
- en: Deploying to Heroku
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we deploy, we have a couple of new files on our app, so we need to add
    those to our Git repository using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'And now, our final step in this chapter is to push to Heroku, which we can
    do with this next command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This will kick off the Heroku build, and soon enough, we will see our Penguin
    app deployed to Heroku for anyone to go and view. The app we have been working
    on and just deployed can be found at the following link (with a screenshot attached!),
    [https://penguin-machine-learning.herokuapp.com/](https://penguin-machine-learning.herokuapp.com/),
    and the GitHub repository for this app can be found at [https://github.com/tylerjrichards/penguin_ml](https://github.com/tylerjrichards/penguin_ml).
    You can see the app in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Heroku App deployment ](img/B18444_08_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.5: Heroku app deployment'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, Heroku deployment is more difficult than Hugging Face Spaces
    or Streamlit Community Cloud but gives you the option to put more compute behind
    your app without adding Heroku branding. Heroku will also always support the most
    recent Streamlit features, which Hugging Face Spaces does not always do.
  prefs: []
  type: TYPE_NORMAL
- en: The big downside for Heroku (other than the increased difficulty) is that as
    of November 28^(th), 2022, Heroku no longer has a free tier, whereas Streamlit
    Community Cloud and Hugging Face Spaces both do. If you want the features, you
    have to pay for them!
  prefs: []
  type: TYPE_NORMAL
- en: And that covers deploying Streamlit with Heroku! As you can see, Streamlit Community
    Cloud handles the majority of these difficulties out of the box, so I would make
    an effort to make Streamlit Community Cloud work whenever possible. However, this
    section should have given you an appreciation for the true breadth of options
    and configuration controls in front of us when we use Hugging Face Spaces and
    Heroku, which may come in handy in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This has been by far the most technical of our chapters so far, so congratulations
    on making it through! Deploying applications is notoriously difficult and time-consuming,
    and requires skills from software engineering and DevOps, along with often requiring
    experience with version control software (such as Git) and UNIX-style commands
    and systems. This is part of the reason why Streamlit Community Cloud is such
    a crucial innovation, but in this chapter, we have learned how to push the edge
    of Streamlit deployment by renting our own virtual machines and deploying apps
    on Hugging Face Spaces and Heroku. We have also learned how to figure out what
    the right deployment strategy is before starting out, which will save hours or
    days of work (nothing is worse than finishing the deployment of an app and finding
    out you need to use another platform!).
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll move on to learning how to query from databases inside our Streamlit
    apps.
  prefs: []
  type: TYPE_NORMAL
- en: Learn more on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To join the Discord community for this book – where you can share feedback,
    ask questions to the author, and learn about new releases – follow the QR code
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/sl](https://packt.link/sl)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code13440134443835796.png)'
  prefs: []
  type: TYPE_IMG
