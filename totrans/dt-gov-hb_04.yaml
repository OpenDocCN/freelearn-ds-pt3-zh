- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Baseline Your Organization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A key component of measuring success is measuring your progress. To do that
    effectively, you need to know where you start from. In this chapter, you will
    learn the importance of defining a baseline, both for the organization at large
    and for individual projects. Next, you will learn how to capture a baseline and
    who to communicate it to. Finally, we will discuss how to ensure agreement on
    the baseline before beginning work.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many ways to baseline the organization to be able to measure your
    impact, but one of the most common is through the use of a data maturity model.
    Throughout the course of my last ten years in leading data transformations, one
    thing is for certain: having a strong baseline is beneficial not just for your
    stakeholders but also for you. It gives you an opportunity to demonstrate how
    much of an impact you’ve been able to drive through your tenure as the leader
    and the measurable progress of your team.'
  prefs: []
  type: TYPE_NORMAL
- en: We will discuss the need to provide discrete value for a solution or a product-by-product
    basis. There is also a need to be able to demonstrate the systematic evolution
    of data management maturity at an enterprise level. We will discuss why it is
    important to measure maturity, the various ways to measure maturity, how to involve
    stakeholders, how to regularly reassess to demonstrate progress, and the importance
    of strong communication. Do not make the mistake of underappreciating the importance
    of measuring progress at this level. It is one of the best ways to show your value
    and to measure progress over time.
  prefs: []
  type: TYPE_NORMAL
- en: What is a data management maturity model?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **data management maturity model** is a measurement framework used to assess
    the overall maturation of an organization’s management of its data. Said another
    way, it measures how well the company is managing data. The assessment provides
    a score by category, provides the aggregate maturity level of the company, and
    identifies areas for improvement. The maturity assessment is subjective. There
    are a series of ways to minimize the degree of subjectivity, which I will outline
    over the next several pages. Data management maturity models are broken down into
    different categories, and further broken down into levels of maturity against
    each of the categories, which helps minimize, but does not eliminate, the subjectivity.
  prefs: []
  type: TYPE_NORMAL
- en: 'A very simple (non-data) example would be to measure how grey something is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – Visual example of the degree of grey](img/B18846_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – Visual example of the degree of grey
  prefs: []
  type: TYPE_NORMAL
- en: In this example, none of these colors are wrong, they are simply progressively
    measuring the current state of the color from lightest grey to darkest grey. The
    current color simply tells us where we are. The delta, or variance, between the
    current color and the color we aim to be tells us how far apart we are, much like
    the data management maturity assessment measures the current state of data management.
    The level is not “wrong”, but it can tell us how far away from our optimal state
    we are. It also tells us how far we’ve come since our last assessment.
  prefs: []
  type: TYPE_NORMAL
- en: If this is your first data management maturity assessment, you are embarking
    on establishing a baseline. This is simply a snapshot of where the company is
    today. It’s important to frame this context for your stakeholders, who may need
    help to understand what a baseline means, not because they don’t understand maturity
    models, but because some may struggle with having a low score representing a low
    state of maturity. You will need to ensure they understand it’s simply a baseline
    and it will go up as you work together as partners.
  prefs: []
  type: TYPE_NORMAL
- en: This baseline will give the organization a sense of where it is today and can
    be used to compare against similar companies across the industry you operate in.
    For example, if you are a bank and your average data management maturity is 2.5,
    but the industry is averaging 3.5, you know you are behind your peer group.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Hint** **for success** |'
  prefs: []
  type: TYPE_TB
- en: '| Do not confuse a maturity model for a data strategy or a methodology. Methodologies
    are very useful (i.e., DAMA), but they define what a capability is, procedures
    to deploy it, and approaches to delivering data solutions. Maturity models aren’t
    plans to implement. They assess where you are on your data journey. |'
  prefs: []
  type: TYPE_TB
- en: Overview of process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we get into the details, let’s start with a preview of the data management
    maturity process. The process can be broken into 10 simple steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Define the scope of the assessment**: What data and processes will be included?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Assemble a team of stakeholders**: This team should include representatives
    from all levels of the organization, as well as from different departments.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Select a data management maturity model**: There are a number of different
    models available, so choose one that is appropriate for your organization’s needs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Execute the assessment and collect data**: This data can be collected through
    surveys, interviews, and document reviews.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Analyze the data**: Use the data to identify strengths and weaknesses in
    your organization’s data management practices.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Communicate results**: Inform all relevant parties of the results of the
    assessment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Develop a plan for improvement**: Based on your findings, develop a plan
    to improve your organization’s data management practices.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Implement the plan**: This may involve making changes to policies, procedures,
    or technology.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Monitor progress**: Track your progress and make adjustments to your plan
    as needed.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Reassess your maturity**: Periodically reassess your organization’s data
    management maturity to ensure that you are making progress.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Phases of a data management maturity assessment](img/B18846_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 – Phases of a data management maturity assessment
  prefs: []
  type: TYPE_NORMAL
- en: Over the course of this chapter, I will walk through each of these ten steps
    and explain how to navigate challenging situations for each. I’ll also share some
    of my lessons learned so you can avoid issues and have a great data management
    maturity assessment experience.
  prefs: []
  type: TYPE_NORMAL
- en: Why you should baseline data management maturity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While you are off [*Chapter 2*](B18846_02.xhtml#_idTextAnchor041), *Building
    a Coalition of Advocates*, and [*Chapter 3*](B18846_03.xhtml#_idTextAnchor057),
    *Building a High Performing Team*, you should also launch a data management maturity
    assessment (ideally, concurrently). This process will help you understand the
    company’s data maturity horizontally across the organization leveraging a standardized
    approach, which will help highlight any blind spots you or your team did not uncover
    and help identify any biases (unconscious or not) you may have had in assessing
    the company’s needs. Additionally, it will help identify areas where the stakeholders
    are aware of the maturity level for their areas or are unaware of the maturity
    level. This can help you build your relationship with your stakeholders by helping
    them understand the state of the union.
  prefs: []
  type: TYPE_NORMAL
- en: Foundational reasons to baseline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You will need to start by understanding and communicating the purpose of this
    assessment. Your communications will need to anchor on one basic question: Why
    are we doing it? There are five core reasons to execute a data maturity assessment
    to get you started:'
  prefs: []
  type: TYPE_NORMAL
- en: '**To establish understanding**: As mentioned, the most well-understood reason
    to complete a maturity assessment is to measure the state of data practices at
    the company. The first assessment establishes the baseline you need to gain a
    comprehensive and fair understanding of the state of the company. Every subsequent
    time you execute the assessment will measure progress (more on that later).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**To inform data strategy**: The outcome of the initial baseline will, in part,
    inform your data strategy. By taking inventory of where the company is with regard
    to data maturity, you will better understand what areas need improvement across
    the overall state of data governance. Note that just because an area is immature,
    does not mean you should put all your resources into improving it. See *#8* *Implement
    the Plan* on how to consider these results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**To assess information risk**: One of the key outcomes of the assessment is
    to grasp how significant the risk of the current state of data management/governance
    poses to the organization. If limited controls are in place, it’s worth investigating
    with the CISO to understand what protections exist for the data, if adequate data
    governance controls are not in place. You may have a serious problem on your hands
    if data governance is immature *and* information security is immature. The outcome
    of your assessment and the discussions with the CISO will be a key topic for your
    readout with senior management.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**To prioritize your solutions**: As you gather an understanding of the state
    of data management at your organization, you will begin to see where opportunities
    to improve exist. In my experience, there are often outliers of opportunity, meaning
    areas of inherent weakness in the data management of the company. For example,
    if metadata management is low, it may be clear that you need to seek out prioritizing
    a metadata management improvement program.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**To up-level the company’s understanding of the value of data**: One of the
    best benefits of the assessment is not necessarily the assessment itself but the
    conversation about data that comes alongside the assessment. You will find questions
    emerge from individuals you may not have had an engagement with previously because
    of this work. Embrace it. Even an adversarial colleague, when met with an open
    mind and a curious disposition, can prove to be fruitful. Encourage their questions
    and welcome the opportunity to educate, even in micro-moments throughout the assessment.
    Additionally, individuals may not realize how much they are gaining from their
    existing work. The entire process will drive a better understanding of how data
    is or is not used today.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be confident in why you are launching a baseline of your organization’s data
    maturity. It may feel unnatural to you, and perhaps to some of your stakeholders,
    to go through this process. To some, it may feel like an audit or a compliance
    exercise. You will have the maximum support and success in your baseline if you
    are clear about the *why* upfront.
  prefs: []
  type: TYPE_NORMAL
- en: Communicate with your stakeholders that this effort may feel uncomfortable or
    even hard to discuss the reality of where the company is and/or its function.
    Be clear about the results and what they will do for the company. What do you
    intend to do with them? Share openly that the outcome may feel uncomfortable and
    encourage the collective stakeholder group to embrace it. This is a stepping stone
    to driving change.
  prefs: []
  type: TYPE_NORMAL
- en: Executing a data management maturity assessment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Executing the assessment can be a bit of a nerve-wracking process. You are likely
    to encounter some great supporters and some less supportive stakeholders. It’s
    critical that you have a great value proposition and are able to explain why this
    benefits the stakeholder as an individual (what they will personally get out of
    the process), why it benefits their team, and why it benefits the company at large.
  prefs: []
  type: TYPE_NORMAL
- en: It may go without saying, but communication is the most important part of this
    process. Your primary responsibility is to remain unbiased, share information,
    translate to ensure understanding across the enterprise at the highest and lowest
    levels, and drive the assessment results to inform your strategy and ultimately
    the value of data at your organization.
  prefs: []
  type: TYPE_NORMAL
- en: '[#1] Defining the scope'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before you prepare to launch your assessment, you will need to define the scope
    of the assessment. Often, it can be tempting to say “all” and move on. However,
    there are options when it comes to defining the scope of your data management
    maturity assessment. There are three primary options to choose from, and you should
    consider what the best option is for your organization. It is a time commitment
    to conduct, both for you and your team and for your stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: Enterprise-wide
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most companies choose to do an enterprise-wide assessment. This is my recommendation,
    with very few exceptions (that I will outline). If your objective is to assess
    the state of data management for the company, you need to assess the entirety
    of the company to achieve this objective. This is also the best way to determine
    if you have areas of strengths or weaknesses that you need to take into account
    as you set up your program, deliver on transformation, and/or build capabilities
    for the organization at large.
  prefs: []
  type: TYPE_NORMAL
- en: When following the enterprise-wide approach, you should leverage the data domains
    that you defined in [*Chapter 2*](B18846_02.xhtml#_idTextAnchor041). This will
    give you a better understanding of which groups are stronger or have matured beyond
    others. Whether you report on this domain model is a separate consideration (see
    *Section 6*, *Communicating Results*).
  prefs: []
  type: TYPE_NORMAL
- en: '| **Hint** **for success** |'
  prefs: []
  type: TYPE_TB
- en: '| If you don’t assess the enterprise as a whole, you should not claim the outcome
    to be an “enterprise assessment”. I have seen this in a company; only about half
    of the company was included in the assessment, but the claim was made that it
    was an “enterprise” score. Unfortunately, once we baselined the entire company,
    the score was, in fact, much lower than previously reported. The groups who did
    not wish to participate previously had lower data maturity, thus, when they were
    baselined, the average score dropped. |'
  prefs: []
  type: TYPE_TB
- en: Pilot and data office
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you are struggling to gain support for this effort, you could select a single
    data domain to pilot the process with. As you work with this data domain, you
    will be able to work individually with this pilot data domain and build a deeper
    relationship with them. However, it is easier to become biased when assessing
    a single group.
  prefs: []
  type: TYPE_NORMAL
- en: While you assess the pilot data domain, you should also assess your own data
    office. This can be a somewhat humbling experience, as you might find that the
    pilot data domain has a stronger maturity level than your own data office does
    (been there!). This should not be a concern or something to shy away from. Remember
    this is simply a baseline by which to justify future investment. Embrace the baseline
    and use it to your advantage. Do not be afraid of a low score for your team or
    the pilot data domain.
  prefs: []
  type: TYPE_NORMAL
- en: Oftentimes, these early assessments shine a light on the weaknesses of the company’s
    data maturity and specifically highlight capabilities that need investment to
    drive adoption enterprise-wide (e.g., metadata management, reference data, lineage,
    etc.). The low score in the data office will highlight where the central data
    team needs to invest in the service of the data domains, such that consistent
    capabilities are built and then leveraged across the company. Embrace the opportunity
    to show how far you have to go.
  prefs: []
  type: TYPE_NORMAL
- en: Rolling assessment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A rolling assessment can be used if you are able to achieve buy-in for an enterprise-wide
    assessment but do not have the resourcing to drive an enterprise assessment concurrently.
    It’s a great option for high interest in the process but low resourcing to conduct
    such an assessment. It becomes very important to maintain strong consistency as
    you roll the assessment across the company. You and your team will become more
    efficient, and perhaps effective, at executing the assessment as you progress
    through the data domains; however, you must take extra care to ensure that the
    first team assessed and the last team assessed are given an equal experience and
    an equivalent assessment.
  prefs: []
  type: TYPE_NORMAL
- en: The following chart can be leveraged to show the scope of your assessment. Enter
    the data domains on the left side, including one row for the central data office.
    In the second column, enter whether that data domain is in scope for the assessment
    or not (only use this column if not all groups are included). In the third column,
    enter the baseline score. In the last column, enter the current score. You should
    consider the full chart to be internal to the data office unless you intend to
    publish the disaggregated results (see Section 6 Communicating Results).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – Example scoping model](img/B18846_04_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 – Example scoping model
  prefs: []
  type: TYPE_NORMAL
- en: '[#2] Identifying stakeholders'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next step in the data management maturity assessment is to identify who
    will be responsible, who will be accountable, who will be consulted, and who will
    be informed in the process. First, start by identifying the roles and groups before
    you assign names to the roles. This will help you create an evergreen approach
    you can maintain as people come and go from the company.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some additional tips for identifying the roles needed to participate
    in a data management maturity assessment:'
  prefs: []
  type: TYPE_NORMAL
- en: Consider the different departments and functions within the organization that
    are involved in data management.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify the people who have a vested interest in the success of the data management
    program.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Look for people who have a deep understanding of the company’s data assets and
    how they are used to support business decisions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Involve a mix of technical and non-technical people in the assessment. This
    will help to ensure that the assessment is comprehensive and that it gets the
    input of all the stakeholders.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Responsible
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The role responsible for executing the data management maturity assessment,
    from defining the methodology, execution, and reporting, is your head of data
    governance. This individual usually reports to the chief data and analytics officer
    and has responsibility for the assessment.
  prefs: []
  type: TYPE_NORMAL
- en: Accountable
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **chief data and analytics officer** (**CDAO**) is ultimately accountable
    for the company’s data management maturity assessment because they have the overall
    responsibility for data management within the organization. Since the CDAO is
    also responsible for driving data-driven decision-making throughout the organization,
    the data management maturity assessment is a critical tool for the CDAO to understand
    the current state of data management within the organization and identify areas
    for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: 'The assessment will help the CDAO to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Identify gaps in data management processes and procedures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assess the maturity of data governance policies and practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluate the quality of data assets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify opportunities to improve data-driven decision-making
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The CDAO can then use the results of the assessment to develop a plan for improving
    data management within the organization. This plan should be aligned with the
    company’s overall business strategy and should be communicated to all stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: By taking accountability for the company’s data management maturity assessment,
    the CDAO can ensure that data is managed effectively and that the organization
    is able to derive maximum value from its data assets.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the reasons mentioned, the CDAO is also accountable for the company’s
    data management maturity assessment because they have the authority to make changes
    to data management processes and procedures. This is important because the assessment
    may identify areas where data management needs to be improved. The CDAO can then
    use its authority to implement changes that will help the organization achieve
    a higher level of data maturity.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the CDAO is accountable for the company’s data management maturity
    assessment because they are the public face of data management within the organization.
    They are responsible for communicating the importance of data management to the
    rest of the organization and for ensuring that data management is a priority.
    The data management maturity assessment is a valuable tool for the CDAO to use
    to communicate the importance of data management and to demonstrate the value
    that data can bring to the organization.
  prefs: []
  type: TYPE_NORMAL
- en: Consulted
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following groups of individuals should be consulted during the data management
    maturity assessment, both for broad context and for scoring purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data domain executives**: The data domain executives are responsible for
    data management within their data domains, so they should be consulted to get
    their perspective on the current state of data management and to identify areas
    for improvement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Business data stewards**: Data stewards are responsible for ensuring the
    quality and accuracy of data, so they should be consulted to get their input on
    the data quality and governance processes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data analysts**: Data analysts use data to make business decisions, so they
    should be consulted to get their perspective on the usability of data and the
    effectiveness of data-driven decision-making.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Business users**: Business users are the ones who ultimately need to use
    data, so they should be consulted to get their input on the data that is available
    to them and the challenges they face in using data.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Technical data stewards**: IT staff are responsible for the infrastructure
    that supports data management, so they should be consulted to get their input
    on the data management systems and processes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition to these key stakeholders, it is also important to consult with
    a variety of other people to gather context and examples of both successes and
    failures of data management, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Subject matter experts who have deep knowledge of the company’s data assets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: People who have experience with data management best practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: People who have been involved in previous data management initiatives
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By consulting with a variety of people, you can get a comprehensive view of
    the company’s data management maturity and identify areas for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Informed
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As a part of the data management maturity assessment, you should inform several
    groups along the way. Ahead of the assessment, you should inform your data domain
    executives and the enterprise data committee. You need their support and buy-in
    for the assessment, so they can set the expectation with participants to prioritize
    the effort.
  prefs: []
  type: TYPE_NORMAL
- en: Upon completion of the assessment, you will want to go back to the data domain
    executives and enterprise data committee to inform them regarding the results
    and what will come next. Additionally, you should inform the C-Suite and the board
    of directors of the results so that they understand the needs of the company and
    can assist with funding and prioritizing any follow-up transformational work required
    in the data management space.
  prefs: []
  type: TYPE_NORMAL
- en: '[#3] Selecting a data management maturity model'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before you get started, you will need to select the data management maturity
    model that is appropriate for your organization. There are several different models
    that exist with pros and cons that you can choose from, or you can choose to create
    your own. If your company has never done a data management maturity assessment
    before, I strongly recommend you select a widely used model, as it will help you
    to defend the criteria and the process overall. If your company is no stranger
    to data management maturity and has found that a more customized model may suit
    your needs better, then (and only then) you could create your maturity model.
  prefs: []
  type: TYPE_NORMAL
- en: Common industry models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data management maturity models are frameworks that organizations can use to
    assess their current data management practices and identify areas for improvement.
    These models typically define a set of stages or levels of maturity, with each
    stage representing a successively higher level of sophistication in data management
    practices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the most common data management maturity models include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The **Data Management Maturity Model** (**DMMM**) by the **Data Management Association**
    (**DAMA**) (retired in 2021)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Data Governance Maturity Model** (**DGMM**) by the IBM Data Governance
    Council
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Data Management Capability Model** (**DCAM**) by the EDM Council, is a
    non-profit organization that promotes the use of data management best practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Gartner IT Score for Data and Analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Stanford Data Governance Maturity Model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The TDWI Data Management Maturity Model and Assessment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, most consulting firms have their own proprietary models. The risk
    in using a consulting firm’s proprietary model is that they are proprietary. Often,
    the company will require an engagement (i.e., funding) to continue to use the
    model over time. If you intend to execute your assessment over a series of years,
    this may not be the most cost-effective option for you and your company.
  prefs: []
  type: TYPE_NORMAL
- en: The model I’ve used the most is the DMMM model from DAMA, but it was retired
    in 2021\. DMMM was replaced by DCAM. DCAM is more comprehensive than DMMM, and
    based on conversations I have had with other CDAOs, DCAM seems to be the choice
    of data maturity model for companies who had previously been using DMMM. My recommendation
    is to select a model that resonates closest with your company’s needs and stick
    with it so that you can establish a consistent comparison of maturity over time.
  prefs: []
  type: TYPE_NORMAL
- en: Building your own model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although less common, one approach could be to create your own model or blend
    models from various programs to fit your needs. It’s critical to ensure you have
    a strong methodology heading into this approach, as you will need to be able to
    explain why your model is designed the way it is, especially in instances where
    someone or some team is scored low. I have seen situations where the team that
    scores low attacks the homegrown model versus looking at the results, and you
    need to be prepared for that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how to build your own model:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Define the scope of your model**: Consider which aspects or areas of data
    management you will want to assess.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Identify the thresholds for each level of maturity**: Consider what specific
    criteria are required for each level to be achieved. The stages in a data management
    maturity model may vary, but common stages include:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Ad hoc**: Data is managed in a reactive and ad hoc manner. There is no formal
    data management strategy or plan.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Basic**: Data is managed in a more structured manner, but there is still
    no formal data management strategy or plan.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Repeatable**: Data management processes are documented and repeatable. There
    is still no formal data management strategy or plan, but there is a commitment
    to improving data management capabilities.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Defined**: Data management processes are well-defined and documented. There
    is a formal data management strategy and plan in place.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Managed**: Data management processes are actively managed and monitored.
    There is a strong commitment to improving data management capabilities.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Optimized**: Data management processes are optimized for efficiency and effectiveness.
    There is a continuous improvement process in place for data management.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Develop an assessment tool**: Consider how you might capture this information.
    The tool could be a checklist, an interview guide/questionnaire, or something
    more sophisticated. It should collect the data needed to produce the results of
    the assessment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[#4] Execute the assessment and collect data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we’ve gone through what a data management maturity model is, you’ve
    selected the participants, and you’ve selected (or designed) your data management
    maturity model, it’s time to put the assessment to work. Let’s execute the assessment!
  prefs: []
  type: TYPE_NORMAL
- en: Use case - gaming the system
  prefs: []
  type: TYPE_NORMAL
- en: Be mindful of *who* is executing the assessment.
  prefs: []
  type: TYPE_NORMAL
- en: At one of my previous companies, we executed an enterprise data management maturity
    assessment. At the time, the company had federated data offices established in
    each major division, plus a central data office. To conduct the assessment, each
    data officer (both federated and central) was given an assessment to score themselves.
    Seemingly efficient process, right?
  prefs: []
  type: TYPE_NORMAL
- en: '*Wrong*.'
  prefs: []
  type: TYPE_NORMAL
- en: Heading into the assessment, we knew which data offices had been established
    longer, had more resources and funding, and were more mature. But the results
    did not match the reality. Why?
  prefs: []
  type: TYPE_NORMAL
- en: Because funding was decentralized, some data officers used the assessment to
    game the results. This means they purposefully scored their maturity lower so
    they could use the results to advocate for additional funding for their data programs,
    despite being more mature than their peer data offices. What that looked like
    in aggregate was that the company overall was less mature than it really was,
    and the data offices with higher maturity scored lower than those with lower maturity.
    Further, some data officers over-scored their programs to demonstrate impact and
    progress. This is equally as bad, as it suggests the data office was more mature
    and had less work to do to build reliable, trustworthy data assets.
  prefs: []
  type: TYPE_NORMAL
- en: This invalidated the results, confused management, and ultimately undermined
    the credibility of the data management maturity assessment, along with the data
    officers individually.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, we had to redo the assessment and hire a third party to conduct
    the assessment independently. This allowed the company to have an objective assessment,
    with results it could trust. Because of the way the first assessment played out,
    we had to conduct many interviews and collect evidence to support the assessment.
    We also added a layer of credible challenges by asking each data officer about
    what they knew from their peers to help validate the results and highlight any
    gaps in the interviews.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing to launch
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As you prepare to launch your assessment, I recommend you communicate a few
    different ways to ensure your stakeholders know what to expect. In your enterprise
    data committee and enterprise data council meetings, be sure to present on this
    topic well in advance of the annual exercise. In your enterprise data committee,
    I recommend a pitch deck that includes the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: What is a data management maturity model?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why is it important to assess maturity? What are the benefits to the company,
    data office, and data domains?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What will be done with the information?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How will they be engaged?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What do they need from the data team?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the timeline of the assessment? How will we validate the results?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When will we report the results? To whom?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the time commitment you expect for each type of persona in the RACI?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Communicating expectations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before you launch, you will need to set expectations about what this is, why
    you need to do the assessment, what you will do with the results, and why this
    process will benefit the stakeholders involved. You should also communicate the
    expectations to the individuals who are participating in the assessment. They
    need to understand what to expect during the assessment, what they should plan
    for from a time commitment perspective, what will be done with results, and why
    this process matters to them (as well as the company). Individuals involved will
    need to know what is coming and what will be required of them. Communication will
    become one of the most important parts of the assessment process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example email you can send to your stakeholders kicking off the assessment:'
  prefs: []
  type: TYPE_NORMAL
- en: Sample maturity assessment announcement email
  prefs: []
  type: TYPE_NORMAL
- en: 'To: All business data stewards; technical data stewards'
  prefs: []
  type: TYPE_NORMAL
- en: 'CC: Data domain executives, enterprise data committee members, chief data and
    analytics officer, and individuals conducting the assessment'
  prefs: []
  type: TYPE_NORMAL
- en: 'Subject: Announcing the enterprise data management maturity assessment'
  prefs: []
  type: TYPE_NORMAL
- en: Dear stakeholders,
  prefs: []
  type: TYPE_NORMAL
- en: 'In the coming weeks, we will be launching an enterprise-wide data management
    maturity assessment. We have selected an assessment model to measure our company’s
    progress against stated maturity levels across a series of data management dimensions.
    We have selected the industry-leading assessment model: DCAM. You can read more
    about the model here: [https://edmcouncil.org/frameworks/dcam/](https://edmcouncil.org/frameworks/dcam/).'
  prefs: []
  type: TYPE_NORMAL
- en: To support this effort, we are asking for two hours of your time over the next
    eight weeks. The first hour will be used to interview you and your teammates about
    the current state of data management in your area of the company. There are no
    wrong answers. We are simply taking a pulse of where we stand. There may be a
    request for supporting materials from that initial conversation, which we will
    send in writing following the first meeting.
  prefs: []
  type: TYPE_NORMAL
- en: The second meeting will include a read-out of the results of your first meeting
    against our maturity model and will give you the opportunity to ask questions,
    challenge any of our assumptions, and edit to ensure we have the most appropriate
    score going into the aggregation process company-wide.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we will share the results with the enterprise data committee, the executive
    team, and, in aggregate, the board of directors. Your division’s individual scores
    will not be shared—only at the company level. We will share the materials with
    you in advance, so you can see transparently what is being communicated. The results
    of the assessment will help with future funding, prioritization, and identifying
    where we can improve our data capabilities enterprise-wide in order to serve you
    better.
  prefs: []
  type: TYPE_NORMAL
- en: Thank you in advance for your support of this important annual event. We are
    happy to answer any questions you might have. Meetings will be coming from our
    chief data and analytics officer’s calendar in the coming days.
  prefs: []
  type: TYPE_NORMAL
- en: Sincerely,
  prefs: []
  type: TYPE_NORMAL
- en: Head of data governance
  prefs: []
  type: TYPE_NORMAL
- en: CDAO Office
  prefs: []
  type: TYPE_NORMAL
- en: How to launch the data management maturity assessment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a great opportunity to both assess the current state and educate the
    stakeholders you engage with about the goals and objectives of a data management
    program. You can use this process to educate them on the core components while
    you also assess the state of maturity. Pay extra attention to the language you
    use. For example, not everyone will know what technical metadata is, but if you
    educate them on the term, they may understand it and be able to better share their
    understanding of the state of maturity for metadata management within their division.
  prefs: []
  type: TYPE_NORMAL
- en: By using these assessment sessions as dual purpose, you may be able to engage
    the stakeholders more fully in the conversation and use it to build your rapport
    with them. The more you can do in person, the better. You can use a workshop-style
    setting to bring common groups together. I have found this approach to be particularly
    helpful because it gives teams the opportunity to come together when they otherwise
    wouldn’t.
  prefs: []
  type: TYPE_NORMAL
- en: Who you need to include
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As mentioned, your assessment should target those closest to the data; business
    data stewards and technical data stewards. You may want to include a wide variety
    of individuals from across the organization, especially if the roles of business
    data stewards and technical data stewards are not yet formalized. At the very
    minimum, you should have a representative from every department with some additional
    focus from groups such as information technology and finance where there is heavier
    involvement in data.
  prefs: []
  type: TYPE_NORMAL
- en: Who you don’t need to include
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You may run into instances where you have individuals seemingly crawling out
    of the woodwork to join your workshops. It is OK to share and state clearly who
    was selected and why. You do not want to run into a situation where every data
    person in the company is included or you will struggle to complete your workshop
    in the time allocated. Stick to having a business data steward and a technical
    data steward from each data domain included in your assessment. If others want
    their voice heard, encourage them to speak to their data domain’s representative
    ahead of the workshop.
  prefs: []
  type: TYPE_NORMAL
- en: Workshop versus one-on-one sessions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Depending on your stakeholders, you may want to consider whether it is best
    to schedule workshops or one-on-one sessions with them (or a combination). Ideally,
    you should conduct workshops as the default. They create the most inclusive environment
    and limit bias in the process. However, there are some specific instances where
    you may want to conduct a one-on-one session. See the following table for the
    rationale for both:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Workshop** | **One-on-one sessions** |'
  prefs: []
  type: TYPE_TB
- en: '| Should be the defaultCan help others hear ideas from each otherHelps remove
    biasDrives consistency | Best for adversarial individualsCan be used ahead of
    the workshop to help gain support of less supportive individualsCan be used for
    extremely supportive individuals to help them understand the importance of their
    role in helping to guide a positive workshop |'
  prefs: []
  type: TYPE_TB
- en: Execute one-on-ones
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you are conducting one-on-one workshops with those you need to bring on
    board with the process, you should do that ahead of the workshops. You may want
    to take time to explain the why and listen to what their concerns are. Common
    concerns include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Wanting their individual results and not supporting aggregation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fear of a low score
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fear of management’s perception of their maturity
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Not being included
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Not being elevated to a data domain executive
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Not being represented fairly
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Be sure to hear them out and do your best to calm any nerves, explain why, and
    always use transparency. Facts matter in these situations.
  prefs: []
  type: TYPE_NORMAL
- en: Executing the workshop(s)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Your workshop needs to be executed very well. You should not cut corners in
    preparing the workshop and should facilitate your attendees. Remember to reiterate
    that a maturity model is simply a tool that you use to assess how well your company
    has done in using data to drive business outcomes. Most models break down into
    areas of focus or capabilities and provide a scoring approach to determine how
    mature the company or division is within that area of focus or capability.
  prefs: []
  type: TYPE_NORMAL
- en: Sample agenda
  prefs: []
  type: TYPE_NORMAL
- en: Welcome and introductions *[welcome the attendees and take time to do introductions
    for* *all participants]*
  prefs: []
  type: TYPE_NORMAL
- en: 'Aligning purpose: why are we here? *[Explain the purpose of the assessment
    and what the attendees can expect from* *the session]*'
  prefs: []
  type: TYPE_NORMAL
- en: What the assessment is
  prefs: []
  type: TYPE_NORMAL
- en: Why we are conducting the assessment
  prefs: []
  type: TYPE_NORMAL
- en: Allow time for brief questions
  prefs: []
  type: TYPE_NORMAL
- en: Explain why this is beneficial for attendees
  prefs: []
  type: TYPE_NORMAL
- en: Explain why this is beneficial for the company
  prefs: []
  type: TYPE_NORMAL
- en: 'Goals and outcomes: what will we achieve together?'
  prefs: []
  type: TYPE_NORMAL
- en: Topical discussion and assessment exercise
  prefs: []
  type: TYPE_NORMAL
- en: Scoring
  prefs: []
  type: TYPE_NORMAL
- en: Data office’s next steps
  prefs: []
  type: TYPE_NORMAL
- en: Gathering example documents (avoid saying “evidence”, as this can feel like
    an audit and may change the tone of the conversation)
  prefs: []
  type: TYPE_NORMAL
- en: Aggregating scores
  prefs: []
  type: TYPE_NORMAL
- en: 'Attendee next steps: explain what will come next, when, and how they will be
    engaged going forward'
  prefs: []
  type: TYPE_NORMAL
- en: Thanks and adjourn
  prefs: []
  type: TYPE_NORMAL
- en: Bonus outcomes
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As a result of conducting the maturity assessments in a workshop style, you
    will be able to gather additional outcomes that, while not the intention of the
    maturity assessment, will aid in your overall business case development and inform
    your strategy and initiatives going forward. Some bonus outcomes include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Ideas for opportunity
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ideas for initiatives
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Identifying common themes
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Identifying troubled areas
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Community building
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[#5] Analyzing the data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that you’ve completed the workshop, the next step in the process is to analyze
    the data and prepare to communicate the results. As a part of this step, you have
    both quantitative and qualitative data to analyze. Both are valuable in this exercise.
  prefs: []
  type: TYPE_NORMAL
- en: The numbers – quantitative data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Arguably the easiest part of analyzing the data is looking at the scores themselves
    in isolation. Having collected the scores during the workshops, you need to add
    these scores into a common template and conduct a simple average to measure the
    company’s aggregated data management maturity score. The average score is what
    you will use to report your results to the enterprise data committee, the executive
    team (C-suite), and the board of directors. The business data stewards and technical
    data stewards should also receive this information in advance of the executive
    communication plan.
  prefs: []
  type: TYPE_NORMAL
- en: The context – qualitative data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This analysis is more subjective and needs to be treated with care to ensure
    bias does not creep into the analysis. As you assess, please keep in mind the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Be objective**: Avoid making any assumptions or jumping to conclusions with
    your analysis. Imagine defending these results to stakeholders. Will your conclusions
    hold up? Use this thought process to help credibly challenge your assessment or
    that of your team.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Be realistic**: Don’t expect to nail the assessment of the qualitative data
    overnight. This will be iterative and require back and forth with your participants
    to ensure you’ve captured their insights properly. Expect this in your timeline.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Be collaborative**: You will need to involve your stakeholders in this part
    of the analysis. You will ensure that your qualitative data is represented fairly
    and that no one is surprised when it comes time for the communication process.
    Try phrases such as “I think I heard you say ____, can you confirm that for me?”
    It will help build trust in the results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Be iterative**: As you work on consolidating the findings and reporting on
    the results, you should expect to come back to the results again as you plan for
    improvement initiatives. Expect to iterate now and when you conduct next year’s
    assessment. Keep the documents accessible for reference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To analyze the data coming out of the assessment, take the following steps
    in sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Identify key findings**: Start by listing out all the key findings you heard
    during the assessment process.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Group findings into themes**: Are you seeing a pattern of issues related
    to customer identifier data being low quality across groups? Lack of tooling?
    Group these types of findings into common buckets/themes to identify where you
    have consistency across data domains.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Compare findings to the maturity model**: Look at these qualitative findings
    against the model. Align them into each topical area so you can see where you
    have specific areas that need improvement that may influence your scores.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Compare findings across data domains**: Now assess these same themes across
    data domains. Are particular domains lower? These qualitative results are helpful
    during improvement conversations. It may be that a domain hasn’t had any investment,
    or perhaps they were not aware of the central capabilities available to them.
    These qualitative data points are great for debriefing conversations and ongoing
    maturity planning.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Look for root causes**: Is there a common reason why the qualitative results
    are what they are? Causation can be helpful when reporting results. Executives
    will likely want to know why the results are what they are. This is a good area
    to focus energy on, if possible.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Prioritize findings**: Not every finding or comment is created equal. Focus
    on the findings that are the most impactful for your company’s success in achieving
    its broader strategy to maximize impact and align on outcomes.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Develop your plan for improvement**: You should gather at least a top-five
    list of what you believe the company needs to focus on going forward as a result
    of the assessment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Alignment and agreement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following steps speak to the alignment and agreement portion of the data
    management maturity assessment. The execution of the assessment itself is a challenge
    at times, but the hard work comes in alignment. It’s critical that you gain the
    support of your stakeholders to ensure that they will buy into the results, support
    the implementation plan, and partner with you on your data strategy.
  prefs: []
  type: TYPE_NORMAL
- en: '[#6] Communicate the results'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you have the results of your data maturity assessment, you will need to
    decide how you want to communicate your results. You have options, and there are
    pros and cons to how you execute this step. You can make the decision on how to
    communicate these results yourself, as CDAO, or you could employ your enterprise
    data committee to make this decision collectively. Either can work in your favor
    equally (I have seen both work well in different companies/industries).
  prefs: []
  type: TYPE_NORMAL
- en: Communicating disaggregated results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Your first option is to communicate results by division. Communicating by division
    means giving the marketing division the marketing score, the sales division the
    sales score, engineering the engineering score, etc. Your stakeholders will most
    likely advocate for their own results because they feel more connected to their
    own scores versus their scores rolled up with the rest of the company. However,
    this is not my recommendation. In my experience across multiple companies, this
    disaggregation reporting approach generally leads to the separation of the data
    community, data funding, and capabilities. This leads to duplication of capabilities,
    disconnected results, and increased costs. There are only a couple of very limited
    reasons why I would recommend disaggregated results:'
  prefs: []
  type: TYPE_NORMAL
- en: '**You have no central team**: This can be a good option when you do not have
    much of a team in place to help guide the company individually and you need to
    allow them to move the ball forward in the interim while you establish your team
    and hire leaders.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**You have no data strategy**: When the company is in its infancy regarding
    developing a data strategy, reporting disaggregated results can show how disparate
    the results are across the organization. However, use caution. Sometimes this
    backfires and can result in individual groups (especially strong/mature ones)
    advocating for the company to work together on enterprise efforts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pros
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The pros for disaggregated results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stakeholder preference**: Stakeholders most likely will want their own score
    so they can feel ownership of the result and action it independent of others'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Accountability**: Stakeholders feel more accountable and thus may accept
    the results'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bias to action**: Teams may decide to take action right away, and they can
    because they know exactly what their teams’ weaknesses are and what they can do
    to move it forward'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cons
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The cons for disaggregated results are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stakeholder disbelief**: The stakeholders may not believe the result without
    seeing the details, especially if it’s a mismatch with their expectations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gaming the system**: When disaggregated results are shared, individual teams
    may be incentivized to overstate their maturity when they are looking to show
    off their maturity or understate their maturity if they are seeking funding.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lack of collaboration**: Teams are not incentivized to work together to improve
    the scores when they have access to their own individual scores. They are now
    incentivized to improve their own area and not work together across the company.
    This can result in teams investing in their own capabilities instead of investing
    together toward company-wide capabilities, which are usually more cost-effective
    and efficient.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Communicating aggregated results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Your second option is to communicate a company aggregated score. Communicating
    at the company level only means that individual divisions will *not* receive individual
    scores and only the aggregated company score is disclosed. Be aware: some teams
    may agree to this and like the rationale only to attempt to disclose their score
    off the record after the fact. This approach only works if you maintain the aggregated
    score and do not disclose the individual team’s scores. You can and should disclose
    what the individual teams need to work on where there are outliers (i.e., specific
    areas of weakness); however, the company score is just that. It’s the score for
    the company as a whole.'
  prefs: []
  type: TYPE_NORMAL
- en: Pros
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Company view**: Providing exclusively aggregated results drives the organization
    to accept that this score is a reflection of how well the company is doing in
    managing data and thus can unify the company to take action collectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Partnership**: Aggregated results can drive divisions to work together to
    raise the bar vs. working in silos.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learning**: Teams are motivated to share and learn from one another so that
    best practices can be driven across the company.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cons
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Individual team accountability**: Teams may not feel like they need to take
    action and they can rely on the greater organization to lift the scores.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Existing capabilities could atrophy**: By leaning more on the central team,
    if you do not carefully communicate the importance of existing capabilities, decentralized
    teams may not carry forward their existing capabilities, which can lead to a dip
    in short-term data management maturity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Program baseline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to the enterprise data management maturity assessment, you can perform
    an isolated maturity assessment for a specific program. This can be a great starting
    point for companies who are not ready to assess an overall company-wide assessment
    or in situations where they want to evaluate the lift provided by the data investment
    in a large transformational program.
  prefs: []
  type: TYPE_NORMAL
- en: You would execute the same steps, only against the program scope instead of
    across the entire data domain construct. You may desire to supplement this assessment
    by baselining data quality as well to measure the trustworthiness of the data
    ahead of program implementation and again at the end of the deployment to show
    the measured improvement for specific systems, data sets, or processes.
  prefs: []
  type: TYPE_NORMAL
- en: '[#7] Develop a plan'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you finalize your communication plan, you should concurrently begin to work
    internally on your data office team, as well as with your stakeholders to develop
    a plan for improvement. This plan should focus on the high-priority findings you
    identified and come with assigned owners, timelines, and funding needs.
  prefs: []
  type: TYPE_NORMAL
- en: Bring your stakeholders along with you as you craft this plan. This is a super
    topic for a data community of practice or a data steward working group to develop
    together. I recommend prioritizing the common themes that came up during the assessment
    that benefit the whole of the data community, along with any glaring issues that
    impact customers, are a violation of law or contractual obligations, or have major
    ethical implications. Address any legal or contractual obligations in partnership
    with your in-house legal team and chief privacy officer.
  prefs: []
  type: TYPE_NORMAL
- en: Aside from major issues, focusing on building capabilities that will support
    the masses inside your organization is a great place to start. For example, if
    you have several concerns about low visibility into where data is coming from
    or going and the quality of the data, you may want to start with deploying a metadata
    management program alongside a data quality initiative. As you read *Part 2* of
    this book, we will dive into the specifics of these capabilities in detail.
  prefs: []
  type: TYPE_NORMAL
- en: While you are developing the plan, consider what capabilities will have the
    biggest impact and focus on why they will have the impact. For example, if your
    stakeholders mentioned concerns about low-quality and low-trust data, define what
    good-quality data would allow them to do. Why will high-quality, trustworthy data
    matter? This seems like a potentially obvious question, but try getting really
    specific. What will the stakeholders be able to do once they have this high-quality
    data that they can’t today? Will it impact revenue? How? Can you measure it? How
    can you measure it? These answers will help you define exactly what you need to
    deliver and how to message it for buy-in at the top levels of the organization.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have identified what you will do, who will drive it, when you will
    deliver it, and how you will measure success, build this into a program plan.
    This plan can be, and should be, part of your communication to your enterprise
    data committee, C-suite, and potentially board (depending on how much interest
    they have in your data program). You will use this for *steps 8*, *9*, and *10*.
  prefs: []
  type: TYPE_NORMAL
- en: '[#8] Implement the plan'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Assuming you are successful in securing buy-in and funding for the plan you
    developed in *step 7*, you will execute the plan. Bring your stakeholders along
    on the journey by using your data steward working groups and enterprise data committee
    to report on iterative progress, results during delivery (i.e., quick wins), issues,
    risks, and how you are progressing against measured results.
  prefs: []
  type: TYPE_NORMAL
- en: As you deliver, do not be shy about claiming results. If you are seeing business
    impacts, don’t just mark the milestone as complete and move on; ask the business
    user (not your data steward, the end user) to share a story about how they are
    experiencing the results of your deployment in their day-to-day business. Did
    they have lower customer attrition as a result of your data management deployment?
    Measure it and report it!
  prefs: []
  type: TYPE_NORMAL
- en: '[#9] Monitor progress'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you implement the plan you developed in *step 8*, you should build in metrics
    to measure progress. For example, if one of the solutions you and your team are
    delivering is to catalog 500 data assets in your enterprise data catalog, you
    should create a scorecard to track that metric over the course of your program.
    As you deliver, the number of assets cataloged divided by 500 should give you
    a percentage of completion that you can then report to your stakeholders and executive
    team.
  prefs: []
  type: TYPE_NORMAL
- en: Reporting and monitoring progress is also a good way to keep everyone aligned
    on what you defined as success at the onset of the program. Scope creep is a very
    real risk to data programs because data is everywhere. There is also a risk of
    how data “feels” to stakeholders, and thus measuring and monitoring data initiatives
    is an important way to ground the improvement in facts vs. feelings.
  prefs: []
  type: TYPE_NORMAL
- en: The result of monitoring progress can also help build confidence in the team’s
    delivery, which can be used for future funding, even ahead of final delivery.
    You can show that the investment to date is driving progress as agreed, and use
    that story to secure additional funding for the next initiative.
  prefs: []
  type: TYPE_NORMAL
- en: 'Report on a regular basis in a transparent fashion. You should bake measured
    results into all data-related projects and programs to show the impact of investing
    in data maturity for the company. As you reassess your maturity (see step #10),
    you can correlate the impact of these program investments to the uplift of your
    data management maturity scores over time. Win-win!'
  prefs: []
  type: TYPE_NORMAL
- en: '[#10] Reassess your maturity'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Frequency of reassessment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You should develop a plan for reassessment. I find it most useful to decide
    on a pattern of reassessment and stick to it. It drives more credibility and consistency
    in the results, which translates into better buy-in enterprise-wide.
  prefs: []
  type: TYPE_NORMAL
- en: 'I’m a big fan of an annual assessment as the default timeline. There may be
    situations where you would vary from this frequency:'
  prefs: []
  type: TYPE_NORMAL
- en: '**New acquisition**: If your company is acquiring new organizations, you may
    want to require a light version of the assessment within 90 days of the transaction
    being completed and then ramp the acquisition into the standard process from there.
    This will highlight areas of weakness that may need rapid focus as the acquisition
    adjusts to the organization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spin out**: If your company is going through a divestiture, you may need
    to execute a special purpose assessment as a part of due diligence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Significant change**: If a division has made a significant investment in
    data, completed a major program, or has gone through a major restructuring, it
    may want a special purpose assessment to show the uplift as a measure of success.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring success
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you reflect upon the data management maturity assessment, you should consider
    how you measure the success of your assessment. Some considerations include the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Did all of your stakeholders participate?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Did you achieve buy-in of the results?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many questions did you receive from the executive team?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Was the board interested in your progress?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have scores improved over time? By how much?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may also consider the amount of time it takes to conduct the assessment
    year over year to determine if your team is becoming more efficient at conducting
    the assessment and/or if the stakeholders are more engaged in the process (be
    careful in how you set up duration metrics to account for these two).
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the assessment, what matters is how your company uses the information.
    If the assessment is conducted and then lands on the preverbal shelf until next
    time, it’s likely a paper exercise and not one of value. Consider basing your
    value on how the assessment is used to feed additional investment, the dialog
    about data that ensues, and how your data community is engaging with one another.
    It’s a great process to drive conversation, build community, and drive awareness
    of what trustworthy data can do to improve the value of your company.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is important to ensure when you conduct this baseline, you do it well. Your
    credibility will be, in part, established by how transparent your baselining process
    is conducted. Ensuring that you communicate the methodology and the plans for
    sharing the results and to whom up front will help your stakeholders buy into
    the process. Be candid about the maturity of your team also. By being pragmatic
    about this process, you can gain credibility to help you design the program you
    need to lead for your company. Conducting this baseline of your organization is
    a great launching point by which to establish a credible and critical seat at
    the proverbial executive table. Take the time to do this well and thoroughly.
  prefs: []
  type: TYPE_NORMAL
