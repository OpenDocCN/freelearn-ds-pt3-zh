["```py\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n    nls97.set_index(\"personid\", inplace=True) \n    ```", "```py\n    feature_cols = ['satverbal','satmath','gpascience',\n      'gpaenglish','gpamath','gpaoverall']\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(nls97[feature_cols],\\\n      nls97[['wageincome20']], test_size=0.3, random_state=0) \n    ```", "```py\n    nls97.shape[0] \n    ```", "```py\n    8984 \n    ```", "```py\n    X_train.info() \n    ```", "```py\n    <class 'pandas.core.frame.DataFrame'>\n    Index: 6288 entries, 639330 to 166002\n    Data columns (total 6 columns):\n     #   Column      Non-Null Count  Dtype \n    ---  ------      --------------  ----- \n     0   satverbal   1010 non-null   float64\n     1   satmath     1010 non-null   float64\n     2   gpascience  4022 non-null   float64\n     3   gpaenglish  4086 non-null   float64\n     4   gpamath     4076 non-null   float64\n     5   gpaoverall  4237 non-null   float64\n    dtypes: float64(6)\n    memory usage: 343.9 KB \n    ```", "```py\n    y_train.info() \n    ```", "```py\n    <class 'pandas.core.frame.DataFrame'>\n    Index: 6288 entries, 639330 to 166002\n    Data columns (total 1 columns):\n     #   Column        Non-Null Count  Dtype \n    ---  ------        --------------  ----- \n     0   wageincome20  3652 non-null   float64\n    dtypes: float64(1)\n    memory usage: 98.2 KB \n    ```", "```py\n    X_test.info() \n    ```", "```py\n    <class 'pandas.core.frame.DataFrame'>\n    Index: 2696 entries, 624557 to 201518\n    Data columns (total 6 columns):\n     #   Column      Non-Null Count  Dtype \n    ---  ------      --------------  ----- \n     0   satverbal   396 non-null    float64\n     1   satmath     397 non-null    float64\n     2   gpascience  1662 non-null   float64\n     3   gpaenglish  1712 non-null   float64\n     4   gpamath     1690 non-null   float64\n     5   gpaoverall  1767 non-null   float64\n    dtypes: float64(6)\n    memory usage: 147.4 KB \n    ```", "```py\n    y_test.info() \n    ```", "```py\n    <class 'pandas.core.frame.DataFrame'>\n    Index: 2696 entries, 624557 to 201518\n    Data columns (total 1 columns):\n     #   Column        Non-Null Count  Dtype \n    ---  ------        --------------  ----- \n     0   wageincome20  1549 non-null   float64\n    dtypes: float64(1)\n    memory usage: 42.1 KB \n    ```", "```py\n    import pandas as pd\n    import feature_engine.selection as fesel\n    from sklearn.model_selection import train_test_split\n    nls97 = pd.read_csv(\"data/nls97g.csv\",low_memory=False)\n    nls97.set_index(\"personid\", inplace=True)\n    ltpoland = pd.read_csv(\"data/ltpoland.csv\")\n    ltpoland.set_index(\"station\", inplace=True)\n    ltpoland.dropna(inplace=True) \n    ```", "```py\n    feature_cols = ['satverbal','satmath','gpascience',\n      'gpaenglish','gpamath','gpaoverall']\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(nls97[feature_cols],\\\n      nls97[['wageincome20']], test_size=0.3, random_state=0) \n    ```", "```py\n    X_train.corr() \n    ```", "```py\n     satverbal  satmath  gpascience  \\\n    satverbal        1.00     0.74        0.42  \n    satmath          0.74     1.00        0.47  \n    gpascience       0.42     0.47        1.00  \n    gpaenglish       0.44     0.44        0.67  \n    gpamath          0.36     0.50        0.62  \n    gpaoverall       0.40     0.48        0.79  \n                gpaenglish  gpamath  gpaoverall \n    satverbal         0.44     0.36        0.40 \n    satmath           0.44     0.50        0.48 \n    gpascience        0.67     0.62        0.79 \n    gpaenglish        1.00     0.61        0.84 \n    gpamath           0.61     1.00        0.76 \n    gpaoverall        0.84     0.76        1.00 \n    ```", "```py\ntr = fesel.DropCorrelatedFeatures(variables=None, method='pearson', threshold=0.75)\ntr.fit(X_train)\nX_train_tr = tr.transform(X_train)\nX_test_tr = tr.transform(X_test)\nX_train_tr.info() \n```", "```py\n<class 'pandas.core.frame.DataFrame'>\nIndex: 6288 entries, 639330 to 166002\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   satverbal   1010 non-null   float64\n 1   satmath     1010 non-null   float64\n 2   gpascience  4022 non-null   float64\n 3   gpaenglish  4086 non-null   float64\n 4   gpamath     4076 non-null   float64\ndtypes: float64(5)\nmemory usage: 294.8 KB \n```", "```py\n    feature_cols = ['year','month','latabs','latitude','elevation',\n      'longitude','country']\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(ltpoland[feature_cols],\\\n      ltpoland[['temperature']], test_size=0.3, random_state=0)\n    X_train.sample(5, random_state=99) \n    ```", "```py\n     year  month  latabs  latitude  elevation  longitude   country\n    station                                   \n    SIEDLCE    2023     11      52        52        152         22   Poland\n    OKECIE     2023      6      52        52        110         21   Poland\n    BALICE     2023      1      50        50        241         20   Poland\n    BALICE     2023      7      50        50        241         20   Poland\n    BIALYSTOK  2023     11      53        53        151         23   Poland \n    ```", "```py\n    X_train.year.value_counts() \n    ```", "```py\n    year\n    2023    84\n    Name: count, dtype: int64 \n    ```", "```py\n    X_train.country.value_counts() \n    ```", "```py\n    country\n    Poland    84\n    Name: count, dtype: int64 \n    ```", "```py\n    (X_train.latitude!=X_train.latabs).sum() \n    ```", "```py\n    0 \n    ```", "```py\n    tr = fesel.DropConstantFeatures()\n    tr.fit(X_train)\n    X_train_tr = tr.transform(X_train)\n    X_test_tr = tr.transform(X_test)\n    X_train_tr.head() \n    ```", "```py\n     month  latabs  latitude  elevation  longitude\n    station                                                \n    OKECIE         1      52        52        110         21\n    LAWICA         8      52        52         94         17\n    LEBA          11      55        55          2         18\n    SIEDLCE       10      52        52        152         22\n    BIALYSTOK     11      53        53        151         23 \n    ```", "```py\n    tr = fesel.DropDuplicateFeatures()\n    tr.fit(X_train_tr)\n    X_train_tr = tr.transform(X_train_tr)\n    X_train_tr.head() \n    ```", "```py\n     month  latabs  elevation  longitude\n    station                                      \n    OKECIE         1      52        110         21\n    LAWICA         8      52         94         17\n    LEBA          11      55          2         18\n    SIEDLCE       10      52        152         22\n    BIALYSTOK     11      53        151         23 \n    ```", "```py\n    import pandas as pd\n    from feature_engine.encoding import OneHotEncoder\n    from sklearn.preprocessing import OrdinalEncoder\n    from sklearn.model_selection import train_test_split\n    nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n    nls97.set_index(\"personid\", inplace=True) \n    ```", "```py\nfeature_cols = ['gender','maritalstatus','colenroct99']\nnls97demo = nls97[['wageincome20'] + feature_cols].dropna()\nX_demo_train, X_demo_test, y_demo_train, y_demo_test =  \\\n  train_test_split(nls97demo[feature_cols],\\\n  nls97demo[['wageincome20']], test_size=0.3, random_state=0) \n```", "```py\n    pd.get_dummies(X_demo_train,\n      columns=['gender','maritalstatus'], dtype=float).\\\n      head(2).T \n    ```", "```py\n     606986             764231\n    colenroct99      3\\. 4-year college    1\\. Not enrolled\n    gender_Female                    1                  0\n    gender_Male                      0                  1\n    maritalstatus_Divorced           0                  0\n    maritalstatus_Married            0                  1\n    maritalstatus_Never-married      1                  0\n    maritalstatus_Separated          0                  0\n    maritalstatus_Widowed            0                  0 \n    ```", "```py\n    pd.get_dummies(X_demo_train,\n      columns=['gender','maritalstatus'], dtype=float,\n      drop_first=True).head(2).T \n    ```", "```py\n     606986           764231\n    colenroct99           3\\. 4-year college  1\\. Not enrolled\n    gender_Male                           0                1\n    maritalstatus_Married                 0                1\n    maritalstatus_Never-married           1                0\n    maritalstatus_Separated               0                0\n    maritalstatus_Widowed                 0                0 \n    ```", "```py\n    ohe = OneHotEncoder(drop_last=True,\n      variables=['gender','maritalstatus'])\n    ohe.fit(X_demo_train)\n    X_demo_train_ohe = ohe.transform(X_demo_train)\n    X_demo_test_ohe = ohe.transform(X_demo_test)\n    X_demo_train_ohe.filter(regex='gen|mar', axis=\"columns\").head(2).T \n    ```", "```py\n     606986   764231\n    gender_Female                   1        0\n    maritalstatus_Never-married     1        0\n    maritalstatus_Married           0        1\n    maritalstatus_Divorced          0        0\n    maritalstatus_Separated         0        0 \n    ```", "```py\n    X_demo_train.colenroct99.\\\n      sort_values().unique() \n    ```", "```py\n    array(['1\\. Not enrolled', '2\\. 2-year college ', '3\\. 4-year college'],\n          dtype=object) \n    ```", "```py\n    X_demo_train.head() \n    ```", "```py\n     gender  maritalstatus        colenroct99\n    606986  Female  Never-married  3\\. 4-year college\n    764231    Male        Married    1\\. Not enrolled\n    673419    Male  Never-married  3\\. 4-year college\n    185535    Male        Married    1\\. Not enrolled\n    903011    Male  Never-married    1\\. Not enrolled \n    ```", "```py\n    oe = OrdinalEncoder(categories=\\\n      [X_demo_train.colenroct99.sort_values().\\\n       unique()])\n    colenr_enc = \\\n      pd.DataFrame(oe.fit_transform(X_demo_train[['colenroct99']]),\n        columns=['colenroct99'], index=X_demo_train.index)\n    X_demo_train_enc = \\\n      X_demo_train[['gender','maritalstatus']].\\\n      join(colenr_enc) \n    ```", "```py\n    X_demo_train_enc.head() \n    ```", "```py\n     gender  maritalstatus  colenroct99\n    606986  Female  Never-married            2\n    764231    Male        Married            0\n    673419    Male  Never-married            2\n    185535    Male        Married            0\n    903011    Male  Never-married            0 \n    ```", "```py\n    X_demo_train.colenroct99.value_counts().\\\n      sort_index() \n    ```", "```py\n     colenroct99\n    1\\. Not enrolled       2843\n    2\\. 2-year college      137\n    3\\. 4-year college      324\n    Name: count, dtype: int64 \n    ```", "```py\n    X_demo_train_enc.colenroct99.value_counts().\\\n      sort_index() \n    ```", "```py\n     colenroct99\n    0              2843\n    1               137\n    2               324\n    Name: count, dtype: int64 \n    ```", "```py\n    import pandas as pd\n    from feature_engine.encoding import OneHotEncoder\n    from category_encoders.hashing import HashingEncoder\n    from sklearn.model_selection import train_test_split\n    covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n    feature_cols = ['location','population',\n        'aged_65_older','life_expectancy','region']\n    covidtotals = covidtotals[['total_cases'] + feature_cols].dropna()\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(covidtotals[feature_cols],\\\n      covidtotals[['total_cases']], test_size=0.3, random_state=0) \n    ```", "```py\nX_train.region.value_counts() \n```", "```py\nregion\nEastern Europe     15\nWestern Europe     15\nWest Asia          12\nSouth America      11\nCentral Africa     10\nEast Asia           9\nCaribbean           9\nOceania / Aus       9\nWest Africa         7\nSouthern Africa     7\nCentral Asia        6\nSouth Asia          6\nEast Africa         5\nCentral America     5\nNorth Africa        4\nNorth America       1\nName: count, dtype: int64 \n```", "```py\n    ohe = OneHotEncoder(top_categories=6, variables=['region'])\n    covidtotals_ohe = ohe.fit_transform(covidtotals)\n    covidtotals_ohe.filter(regex='location|region',\n      axis=\"columns\").sample(5, random_state=2).T \n    ```", "```py\n     31        157        2     170     78\n    location                Bulgaria  Palestine  Algeria  Russia  Ghana\n    region_Eastern Europe          1          0        0       1      0\n    region_Western Europe          0          0        0       0      0\n    region_West Africa             0          0        0       0      1\n    region_West Asia               0          1        0       0      0\n    region_East Asia               0          0        0       0      0\n    region_Caribbean               0          0        0       0      0 \n    ```", "```py\n    X_train['region2'] = X_train.region\n    he = HashingEncoder(cols=['region'], n_components=6)\n    X_train_enc = he.fit_transform(X_train)\n    X_train_enc.\\\n     groupby(['col_0','col_1','col_2','col_3','col_4',\n       'col_5','region2']).\\\n     size().reset_index(name=\"count\") \n    ```", "```py\n     col_0  col_1  col_2  col_3  col_4  col_5          region2  count\n    0      0      0      0      0      0      1        Caribbean      9\n    1      0      0      0      0      0      1   Central Africa     10\n    2      0      0      0      0      0      1      East Africa      5\n    3      0      0      0      0      0      1     North Africa      4\n    4      0      0      0      0      1      0  Central America      5\n    5      0      0      0      0      1      0   Eastern Europe     15\n    6      0      0      0      0      1      0    North America      1\n    7      0      0      0      0      1      0    Oceania / Aus      9\n    8      0      0      0      0      1      0  Southern Africa      7\n    9      0      0      0      0      1      0        West Asia     12\n    10     0      0      0      0      1      0   Western Europe     15\n    11     0      0      0      1      0      0     Central Asia      6\n    12     0      0      0      1      0      0        East Asia      9\n    13     0      0      0      1      0      0       South Asia      6\n    14     0      0      1      0      0      0      West Africa      7\n    15     1      0      0      0      0      0    South America     11 \n    ```", "```py\n    import pandas as pd\n    from feature_engine import transformation as vt\n    from sklearn.model_selection import train_test_split\n    import matplotlib.pyplot as plt\n    from scipy import stats\n    covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n    feature_cols = ['location','population',\n        'aged_65_older','life_expectancy','region']\n    covidtotals = covidtotals[['total_cases'] + feature_cols].dropna()\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(covidtotals[feature_cols],\\\n      covidtotals[['total_cases']], test_size=0.3, random_state=0) \n    ```", "```py\n    y_train.total_cases.skew() \n    ```", "```py\n    6.092053479609332 \n    ```", "```py\n    plt.hist(y_train.total_cases)\n    plt.title(\"Total COVID-19 Cases (in millions)\")\n    plt.xlabel('Cases')\n    plt.ylabel(\"Number of Countries\")￼\n    plt.show() \n    ```", "```py\n    tf = vt.LogTransformer(variables = ['total_cases'])\n    y_train_tf = tf.fit_transform(y_train)\n    y_train_tf.total_cases.skew() \n    ```", "```py\n    0.09944093918837159 \n    ```", "```py\n    plt.hist(y_train_tf.total_cases)\n    plt.title(\"Total COVID-19 Cases (log transformation)\")\n    plt.xlabel('Cases')\n    plt.ylabel(\"Number of Countries\")\n    plt.show() \n    ```", "```py\n    tf = vt.BoxCoxTransformer(variables = ['total_cases'])\n    y_train_tf = tf.fit_transform(y_train)\n    y_train_tf.total_cases.skew() \n    ```", "```py\n    0.010531307863482307 \n    ```", "```py\n    plt.hist(y_train_tf.total_cases)\n    plt.title(\"Total COVID-19 Cases (Box Cox transformation)\")\n    plt.xlabel('Cases')\n    plt.ylabel(\"Number of Countries\")\n    plt.show() \n    ```", "```py\nstats.boxcox(y_train.total_cases)[1] \n```", "```py\n-0.020442184436288167 \n```", "```py\n    import pandas as pd\n    from feature_engine.discretisation import EqualFrequencyDiscretiser as efd\n    from feature_engine.discretisation import EqualWidthDiscretiser as ewd\n    from sklearn.preprocessing import KBinsDiscretizer\n    from sklearn.model_selection import train_test_split\n    covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n    feature_cols = ['location','population',\n        'aged_65_older','life_expectancy','region']\n    covidtotals = covidtotals[['total_cases'] + feature_cols].dropna()\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(covidtotals[feature_cols],\\\n      covidtotals[['total_cases']], test_size=0.3, random_state=0) \n    ```", "```py\n    y_train['total_cases_group'] = \\\n      pd.qcut(y_train.total_cases, q=10,\n      labels=[0,1,2,3,4,5,6,7,8,9])\n    y_train.total_cases_group.value_counts().\\\n      sort_index() \n    ```", "```py\n     total_cases_group\n    0    14\n    1    13\n    2    13\n    3    13\n    4    13\n    5    13\n    6    13\n    7    13\n    8    13\n    9    13\n    Name: count, dtype: int64 \n    ```", "```py\n    def runtransform(bt, dftrain, dftest):\n      bt.fit(dftrain)\n      train_bins = bt.transform(dftrain)\n      test_bins = bt.transform(dftest)\n      return train_bins, test_bins \n    ```", "```py\n    y_train.drop(['total_cases_group'], axis=1, inplace=True)\n    bintransformer = efd(q=10, variables=['total_cases'])\n    y_train_bins, y_test_bins = runtransform(bintransformer, y_train, y_test)\n    y_train_bins.total_cases.value_counts().sort_index() \n    ```", "```py\n     total_cases\n    0    14\n    1    13\n    2    13\n    3    13\n    4    13\n    5    13\n    6    13\n    7    13\n    8    13\n    9    13\n    Name: count, dtype: int64 \n    ```", "```py\n    bintransformer = ewd(bins=10, variables=['total_cases'])\n    y_train_bins, y_test_bins = runtransform(bintransformer, y_train, y_test)\n    y_train_bins.total_cases.value_counts().sort_index() \n    ```", "```py\n     total_cases\n    0    122\n    1      2\n    2      3\n    3      2\n    4      1\n    9      1\n    Name: count, dtype: int64 \n    ```", "```py\n    y_train_bins = y_train_bins.\\\n      rename(columns={'total_cases':'total_cases_group'}).\\\n      join(y_train)\n    y_train_bins.groupby(\"total_cases_group\")[\"total_cases\"].\\\n      agg(['min','max']) \n    ```", "```py\n     min           max\n    total_cases_group                     \n    0                      5,085     8,633,769\n    1                 11,624,000    13,980,340\n    2                 23,774,451    26,699,442\n    3                 37,519,960    38,437,756\n    4                 45,026,139    45,026,139\n    9                 99,329,249    99,329,249 \n    ```", "```py\n    kbins = KBinsDiscretizer(n_bins=10, encode='ordinal',\n      strategy='kmeans', subsample=None)\n    y_train_bins = \\\n      pd.DataFrame(kbins.fit_transform(y_train),\n      columns=['total_cases'], index=y_train.index)\n    y_train_bins.total_cases.value_counts().sort_index() \n    ```", "```py\n     total_cases\n    0    57\n    1    19\n    2    25\n    3    10\n    4    11\n    5     2\n    6     3\n    7     2\n    8     1\n    9     1\n    Name: count, dtype: int64 \n    ```", "```py\n    y_train.total_cases.agg(['skew','kurtosis']) \n    ```", "```py\n    skew        6.092\n    kurtosis   45.407\n    Name: total_cases, dtype: float64 \n    ```", "```py\n    y_train_bins.total_cases.agg(['skew','kurtosis']) \n    ```", "```py\n    skew       1.504\n    kurtosis   2.281\n    Name: total_cases, dtype: float64 \n    ```", "```py\n    y_train_bins.rename(columns={'total_cases':'total_cases_bin'}, inplace=True)\n    y_train.join(y_train_bins).\\\n      groupby(['total_cases_bin'])['total_cases'].\\\n      agg(['min','max','size']) \n    ```", "```py\n     min        max  size\n    total_cases_bin                           \n    0                    5,085    272,010    57\n    1                  330,417    834,470    19\n    2                  994,037  2,229,538    25\n    3                2,465,545  4,536,733    10\n    4                5,269,967  8,633,769    11\n    5               11,624,000 13,980,340     2\n    6               23,774,451 26,699,442     3\n    7               37,519,960 38,437,756     2\n    8               45,026,139 45,026,139     1\n    9               99,329,249 99,329,249     1 \n    ```", "```py\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n    covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n    feature_cols = ['population','total_deaths',\n        'aged_65_older','life_expectancy']\n    covidtotals = covidtotals[['total_cases'] + feature_cols].dropna()\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(covidtotals[feature_cols],\\\n      covidtotals[['total_cases']], test_size=0.3, random_state=0) \n    ```", "```py\n    scaler = MinMaxScaler()\n    X_train_mms = pd.DataFrame(scaler.fit_transform(X_train),\n      columns=X_train.columns, index=X_train.index)\n    X_train_mms.describe() \n    ```", "```py\n     population  total_deaths  aged_65_older  life_expectancy\n    count          131.00        131.00         131.00           131.00\n    mean             0.03          0.05           0.34             0.65\n    std              0.13          0.14           0.28             0.23\n    min              0.00          0.00           0.00             0.00\n    25%              0.00          0.00           0.11             0.54\n    50%              0.01          0.01           0.24             0.69\n    75%              0.02          0.03           0.60             0.81\n    max              1.00          1.00           1.00             1.00 \n    ```", "```py\n    scaler = StandardScaler()\n    X_train_ss = pd.DataFrame(scaler.fit_transform(X_train),\n      columns=X_train.columns, index=X_train.index)\n    X_train_ss.describe() \n    ```", "```py\n     population  total_deaths  aged_65_older  life_expectancy\n    count         131.00        131.00         131.00           131.00\n    mean           -0.00         -0.00          -0.00             0.00\n    std             1.00          1.00           1.00             1.00\n    min            -0.28         -0.39          -1.24            -2.79\n    25%            -0.26         -0.38          -0.84            -0.48\n    50%            -0.22         -0.34          -0.39             0.18\n    75%            -0.09         -0.15           0.93             0.67\n    max             7.74          6.95           2.37             1.51 \n    ```", "```py\n    scaler = RobustScaler()\n    X_train_rs = pd.DataFrame(scaler.fit_transform(X_train),\n      columns=X_train.columns, index=X_train.index)\n    X_train_rs.describe() \n    ```", "```py\n     population    total_deaths    aged_65_older    life_expectancy\n    count         131.00          131.00           131.00             131.00\n    mean            1.29            1.51             0.22              -0.16\n    std             5.81            4.44             0.57               0.87\n    min            -0.30           -0.20            -0.48              -2.57\n    25%            -0.22           -0.16            -0.26              -0.58\n    50%             0.00            0.00             0.00               0.00\n    75%             0.78            0.84             0.74               0.42\n    max            46.09           32.28             1.56               1.15 \n    ```"]