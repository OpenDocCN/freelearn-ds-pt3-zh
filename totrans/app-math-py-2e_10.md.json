["```py\npython3.10 -m pip install pint uncertainties netCDF4 xarray pandas scikit-learn geopandas geoplot jupyter papermill cerberus cython\n```", "```py\npython3.10 -m pip install dask[complete]\n```", "```py\nimport pint\n```", "```py\n    ureg = pint.UnitRegistry(system=\"mks\")\n    ```", "```py\n    distance = 5280 * ureg.feet\n    ```", "```py\n    print(distance.to(\"miles\"))\n    ```", "```py\n    print(distance.to_base_units())\n    ```", "```py\n    print(distance.to_base_units().to_compact())\n    ```", "```py\n0.9999999999999999 mile\n1609.3439999999998 meter\n1.6093439999999999 kilometer\n```", "```py\n    @ureg.wraps(ureg.meter, ureg.second)\n    ```", "```py\n    def calc_depth(dropping_time):\n    ```", "```py\n        # s = u*t + 0.5*a*t*t\n    ```", "```py\n        # u = 0, a = 9.81\n    ```", "```py\n        return 0.5*9.81*dropping_time*dropping_time\n    ```", "```py\n    depth = calc_depth(0.05 * ureg.minute)\n    ```", "```py\n    print(\"Depth\", depth)\n    ```", "```py\n    # Depth 44.144999999999996 meter\n    ```", "```py\nfrom uncertainties import ufloat, umath\n```", "```py\n    seconds = ufloat(3.0, 0.4)\n    ```", "```py\n    print(seconds)      # 3.0+/-0.4\n    ```", "```py\n    depth = 0.5*9.81*seconds*seconds\n    ```", "```py\n    print(depth)      # 44+/-12\n    ```", "```py\n    other_depth = ufloat(44, 12)\n    ```", "```py\n    time = umath.sqrt(2.0*other_depth/9.81)\n    ```", "```py\n    print(\"Estimated time\", time)\n    ```", "```py\n    # Estimated time 3.0+/-0.4\n    ```", "```py\nimport pint\nfrom uncertainties import ufloat\nureg = pint.UnitRegistry(system=\"mks\")\ng = 9.81*ureg.meters / ureg.seconds ** 2\nseconds = ufloat(3.0, 0.4) * ureg.seconds\ndepth = 0.5*g*seconds**2\nprint(depth)\n```", "```py\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\nimport xarray as xr\n```", "```py\n    dates = pd.date_range(\"2020-01-01\", periods=365, name=\"date\")\n    ```", "```py\n    locations = list(range(25))\n    ```", "```py\n    steps = rng.normal(0, 1, size=(365,25))\n    ```", "```py\n    accumulated = np.add.accumulate(steps)\n    ```", "```py\n    data_array = xr.Dataset({\n    ```", "```py\n        \"steps\": ((\"date\", \"location\"), steps),\n    ```", "```py\n        \"accumulated\": ((\"date\", \"location\"), accumulated)     },\n    ```", "```py\n        {\"location\": locations, \"date\": dates}\n    ```", "```py\n    )\n    ```", "```py\n<xarray.Dataset>\nDimensions: (date: 365, location: 25)\nCoordinates:\n* location (location) int64 0 1 2 3 4 5 6 7 8 ... 17 18 19 20 21 22 23 24\n* date (date) datetime64[ns] 2020-01-01 2020-01-02 ... 2020-12-30\nData variables:\nsteps (date, location) float64 geoplot.pointplot(cities, ax=ax, fc=\"r\", marker=\"2\")\nax.axis((-180, 180, -90, 90))-1.424 1.264 ... -0.4547 -0.4873\naccumulated (date, location) float64 -1.424 1.264 -0.8707 ... 8.935 -3.525\n```", "```py\n    means = data_array.mean(dim=\"location\")\n    ```", "```py\n    fig, ax = plt.subplots()\n    ```", "```py\n    means[\"accumulated\"].to_dataframe().plot(ax=ax)\n    ```", "```py\n    ax.set(title=\"Mean accumulated values\", \n    ```", "```py\n        xlabel=\"date\", ylabel=\"value\")\n    ```", "```py\n    data_array.to_netcdf(\"data.nc\")\n    ```", "```py\n    new_data = xr.load_dataset(\"data.nc\")\n    ```", "```py\n    print(new_data)\n    ```", "```py\n<xarray.Dataset>\nDimensions: (date: 365, location: 25)\nCoordinates:\n            * location (location) int64 0 1 2 3 4 5 6 7 8 ... 17 18 19 20 21 22 23 24\n            * date (date) datetime64[ns] 2020-01-01 2020-01-02 ... 2020-12-30\nData variables:\n            steps (date, location) float64 -1.424 1.264 ... -0.4547 -0.4873\n            accumulated (date, location) float64 -1.424 1.264 -0.8707 ... 8.935 -3.525\n```", "```py\nimport geopandas\nimport geoplot\nimport matplotlib.pyplot as plt\n```", "```py\n    world = geopandas.read_file(\n    ```", "```py\n        geopandas.datasets.get_path(\"naturalearth_lowres\")\n    ```", "```py\n    )\n    ```", "```py\n    cities = geopandas.read_file(\n    ```", "```py\n        geopandas.datasets.get_path(\"naturalearth_cities\")\n    ```", "```py\n    )\n    ```", "```py\n    fig, ax = plt.subplots()\n    ```", "```py\n    geoplot.polyplot(world, ax=ax, alpha=0.7)\n    ```", "```py\n    geoplot.pointplot(cities, ax=ax, fc=\"k\", marker=\"2\")\n    ```", "```py\n    ax.axis((-180, 180, -90, 90))\n    ```", "```py\n    import matplotlib.pyplot as plt\n    ```", "```py\n    from numpy.random import default_rng\n    ```", "```py\n    rng = default_rng(12345)\n    ```", "```py\n    uniform_data = rng.uniform(-5, 5, size=(2, 100))\n    ```", "```py\n    fig, ax = plt.subplots(tight_layout=True)\n    ```", "```py\n    ax.scatter(uniform_data[0, :], uniform_data[1, :])\n    ```", "```py\n    ax.set(title=\"Scatter plot\", xlabel=\"x\", ylabel=\"y\")\n    ```", "```py\n    papermill --kernel python3 sample.ipynb output.ipynb\n    ```", "```py\njupyter kernelspec list\n```", "```py\nimport csv\nimport cerberus\n```", "```py\n    float_schema = {\"type\": \"float\", \"coerce\": float, \n    ```", "```py\n        \"min\": -1.0, \"max\": 1.0}\n    ```", "```py\n    item_schema = {\n    ```", "```py\n        \"type\": \"dict\",\n    ```", "```py\n        \"schema\": {\n    ```", "```py\n            \"id\": {\"type\": \"string\"},\n    ```", "```py\n            \"number\": {\"type\": \"integer\",\n    ```", "```py\n            \"coerce\": int},\n    ```", "```py\n        \"lower\": float_schema,\n    ```", "```py\n        \"upper\": float_schema,\n    ```", "```py\n        }\n    ```", "```py\n    }\n    ```", "```py\n    schema = {\n    ```", "```py\n        \"rows\": {\n    ```", "```py\n            \"type\": \"list\",\n    ```", "```py\n            \"schema\": item_schema\n    ```", "```py\n        }\n    ```", "```py\n    }\n    ```", "```py\n    validator = cerberus.Validator(schema)\n    ```", "```py\n    with open(\"sample.csv\") as f:\n    ```", "```py\n        dr = csv.DictReader(f)\n    ```", "```py\n        document = {\"rows\": list(dr)}\n    ```", "```py\n    validator.validate(document)\n    ```", "```py\n    errors = validator.errors[\"rows\"][0]\n    ```", "```py\n    for row_n, errs in errors.items():\n    ```", "```py\n                print(f\"row {row_n}: {errs}\")\n    ```", "```py\nrow 11: [{'lower': ['min value is -1.0']}]\nrow 18: [{'number': ['must be of integer type',      \"field 'number' cannot be coerced: invalid literal for int() with base 10: 'None'\"]}]\nrow 32: [{'upper': ['min value is -1.0']}]\nrow 63: [{'lower': ['max value is 1.0']}]\n```", "```py\n# mandelbrot/python_mandel.py\nimport numpy as np\ndef in_mandel(cx, cy, max_iter):\n    x = cx\n    y = cy\n    for i in range(max_iter):\n        x2 = x**2\n        y2 = y**2\n        if (x2 + y2) >= 4:\n            return i\n        y = 2.0*x*y + cy\n        x = x2 - y2 + cx\n    return max_iter\ndef compute_mandel(N_x, N_y, N_iter):\n    xlim_l = -2.5\n    xlim_u = 0.5\n    ylim_l = -1.2\n    ylim_u = 1.2\n    x_vals = np.linspace(xlim_l, xlim_u,\n        N_x, dtype=np.float64)\ny_vals = np.linspace(ylim_l, ylim_u,\n        N_y, dtype=np.float64)\n    height = np.empty((N_x, N_y), dtype=np.int64)\n    for i in range(N_x):\n        for j in range(N_y):\n        height[i, j] = in_mandel(\n\t\t    x_vals[i], y_vals[j], N_iter)\n    return height\n```", "```py\n    # mandelbrot/cython_mandel.pyx\n    ```", "```py\n    import numpy as np\n    ```", "```py\n    cimport numpy as np\n    ```", "```py\n    cimport cython\n    ```", "```py\n    ctypedef Py_ssize_t Int\n    ```", "```py\n    ctypedef np.float64_t Double\n    ```", "```py\n    cdef int in_mandel(Double cx, Double cy, int max_iter):\n    ```", "```py\n        cdef Double x = cx\n    ```", "```py\n        cdef Double y = cy\n    ```", "```py\n        cdef Double x2, y2\n    ```", "```py\n        cdef Int i\n    ```", "```py\n        for i in range(max_iter):\n    ```", "```py\n            x2 = x**2\n    ```", "```py\n            y2 = y**2\n    ```", "```py\n            if (x2 + y2) >= 4:\n    ```", "```py\n                return i\n    ```", "```py\n            y = 2.0*x*y + cy\n    ```", "```py\n            x = x2 - y2 + cx\n    ```", "```py\n        return max_iter\n    ```", "```py\n    @cython.boundscheck(False)\n    ```", "```py\n    @cython.wraparound(False)\n    ```", "```py\n    def compute_mandel(int N_x, int N_y, int N_iter):\n    ```", "```py\n        cdef double xlim_l = -2.5\n    ```", "```py\n        cdef double xlim_u = 0.5\n    ```", "```py\n        cdef double ylim_l = -1.2\n    ```", "```py\n        cdef double ylim_u = 1.2\n    ```", "```py\n        cdef np.ndarray x_vals = np.linspace(xlim_l,\n    ```", "```py\n            xlim_u, N_x, dtype=np.float64)\n    ```", "```py\n        cdef np.ndarray y_vals = np.linspace(ylim_l,\n    ```", "```py\n            ylim_u, N_y, dtype=np.float64)\n    ```", "```py\n        cdef np.ndarray height = np.empty(\n    ```", "```py\n            (N_x, N_y),dtype=np.int64)\n    ```", "```py\n        cdef Int i, j\n    ```", "```py\n        for i in range(N_x):\n    ```", "```py\n            for j in range(N_y):\n    ```", "```py\n                height[i, j] = in_mandel(\n    ```", "```py\n                    xx_vals[i], y_vals[j], N_iter)\n    ```", "```py\n            return height\n    ```", "```py\n    # mandelbrot/setup.py\n    ```", "```py\n    import numpy as np\n    ```", "```py\n    from setuptools import setup, Extension\n    ```", "```py\n    from Cython.Build import cythonize\n    ```", "```py\n    hybrid = Extension(\n    ```", "```py\n        \"hybrid_mandel\",\n    ```", "```py\n        sources=[\"python_mandel.py\"],\n    ```", "```py\n        include_dirs=[np.get_include()],\n    ```", "```py\n        define_macros=[(\"NPY_NO_DEPRECATED_API\",\n    ```", "```py\n            \"NPY_1_7_API_VERSION\")]\n    ```", "```py\n    )\n    ```", "```py\n    cython = Extension(\n    ```", "```py\n        \"cython_mandel\",\n    ```", "```py\n        sources=[\"cython_mandel.pyx\"],\n    ```", "```py\n        include_dirs=[np.get_include()],\n    ```", "```py\n        define_macros=[(\"NPY_NO_DEPRECATED_API\",\n    ```", "```py\n            \"NPY_1_7_API_VERSION\")]\n    ```", "```py\n    )\n    ```", "```py\n    extensions = [hybrid, cython]\n    ```", "```py\n    setup(\n    ```", "```py\n        ext_modules = cythonize(\n    ```", "```py\n            extensions, compiler_directives={\n    ```", "```py\n    \t\t    \"language_level\": \"3\"}),\n    ```", "```py\n    )\n    ```", "```py\n    python3.8 setup.py build_ext --inplace\n    ```", "```py\n    # run.py\n    ```", "```py\n    from time import time\n    ```", "```py\n    from functools import wraps\n    ```", "```py\n    import matplotlib.pyplot as plt\n    ```", "```py\n    from mandelbrot.python_mandel import compute_mandel\n    ```", "```py\n                as compute_mandel_py\n    ```", "```py\n    from mandelbrot.hybrid_mandel import compute_mandel\n    ```", "```py\n                as compute_mandel_hy\n    ```", "```py\n    from mandelbrot.cython_mandel import compute_mandel\n    ```", "```py\n                as compute_mandel_cy\n    ```", "```py\n    def timer(func, name):\n    ```", "```py\n    \t@wraps(func)\n    ```", "```py\n    \tdef wrapper(*args, **kwargs):\n    ```", "```py\n    \t\tt_start = time()\n    ```", "```py\n    \t\tval = func(*args, **kwargs)\n    ```", "```py\n    \t\tt_end = time()\n    ```", "```py\n    \t\tprint(f\"Time taken for {name}:\n    ```", "```py\n    \t\t\t{t_end - t_start}\")\n    ```", "```py\n    \t\treturn val\n    ```", "```py\n    \treturn wrapper\n    ```", "```py\n    mandel_py = timer(compute_mandel_py, \"Python\")\n    ```", "```py\n    mandel_hy = timer(compute_mandel_hy, \"Hybrid\")\n    ```", "```py\n    mandel_cy = timer(compute_mandel_cy, \"Cython\")\n    ```", "```py\n    Nx = 320\n    ```", "```py\n    Ny = 240\n    ```", "```py\n    steps = 255\n    ```", "```py\n    mandel_py(Nx, Ny, steps)\n    ```", "```py\n    mandel_hy(Nx, Ny, steps)\n    ```", "```py\n    vals = mandel_cy(Nx, Ny, steps)\n    ```", "```py\n    fig, ax = plt.subplots()\n    ```", "```py\n    ax.imshow(vals.T, extent=(-2.5, 0.5, -1.2, 1.2))\n    ```", "```py\n    plt.show()\n    ```", "```py\nTime taken for Python: 11.399756908416748\nTime taken for Hybrid: 10.955225229263306\nTime taken for Cython: 0.24534869194030762\n```", "```py\nimport dask.dataframe as dd\n```", "```py\n    data = dd.read_csv(\"sample.csv\", dtype={\n    ```", "```py\n        \"number\":\"object\"})\n    ```", "```py\n    sum_data = data.lower + data.upper\n    ```", "```py\n    print(sum_data)\n    ```", "```py\nDask Series Structure:\nnpartitions=1\n             float64\n                               ...\ndtype: float64\nDask Name: add, 4 graph layers\n```", "```py\n    result = sum_data.compute()\n    ```", "```py\n    print(result.head())\n    ```", "```py\n0      -0.911811\n1       0.947240\n2      -0.552153\n3      -0.429914\n4       1.229118\ndtype:  float64\n```", "```py\n    means = data[[\"lower\", \"upper\"]].mean().compute()\n    ```", "```py\n    print(means)\n    ```", "```py\nlower -0.060393\nupper -0.035192\ndtype: float64\n```", "```py\nfrom sklearn.metrics import ConfusionMatrixDisplay, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\n```", "```py\nrng = np.random.default_rng(12345)\n```", "```py\ndef get_data():\n\tpermute = rng.permutation(200)\n\tdata = np.vstack([\n\t\trng.normal((1.0, 2.0, -3.0), 1.0,\n\t\tsize=(50, 3)),\n\t\trng.normal((-1.0, 1.0, 1.0), 1.0,\n\t\tsize=(50, 3)),\n\t\trng.normal((0.0, -1.0, -1.0), 1.0,\n\t\tsize=(50, 3)),\n\t\trng.normal((-1.0, -1.0, -2.0), 1.0,\n\t\tsize=(50, 3))\n\t\t])\n\tlabels = np.hstack(\n\t\t[[1]*50, [2]*50, [3]*50,[4]*50])\n\tX = pd.DataFrame(\n\t\tnp.take(data, permute, axis=0),\n\t\tcolumns=[\"A\", \"B\", \"C\"])\n\ty = pd.Series(np.take(labels, permute, axis=0))\n\treturn X, y\n```", "```py\n    data, labels = get_data()\n    ```", "```py\n    data.to_csv(\"data.csv\")\n    ```", "```py\n    labels.to_csv(\"labels.csv\")\n    ```", "```py\n    X_train, X_test, y_train, y_test = train_test_split(\n    ```", "```py\n        data,labels, test_size=0.2, random_state=23456)\n    ```", "```py\n    X_train.index.to_series().to_csv(\"train_index.csv\",\n    ```", "```py\n        index=False, header=False)\n    ```", "```py\n    X_test.index.to_series().to_csv(\"test_index.csv\",\n    ```", "```py\n        index=False, header=False)\n    ```", "```py\n    classifier = DecisionTreeClassifier(random_state=34567)\n    ```", "```py\n    classifer.fit(X_train, y_train)\n    ```", "```py\n    feat_importance = pd.DataFrame(\n    ```", "```py\n    \tclassifier.feature_importances_,\n    ```", "```py\n    \tindex=classifier.feature_names_in_,\n    ```", "```py\n    \tcolumns=[\"Importance\"])\n    ```", "```py\n    feat_importance.to_csv(\"feature_importance.csv\")\n    ```", "```py\n    train_predictions = classifier.predict(X_train)\n    ```", "```py\n    test_predictions = classifier.predict(X_test)\n    ```", "```py\n    pd.Series(train_predictions,index=X_train.index,\n    ```", "```py\n        name=\"Predicted label\").to_csv(\n    ```", "```py\n    \t\t\"train_predictions.csv\")\n    ```", "```py\n    pd.Series(test_predictions,index=X_test.index,\n    ```", "```py\n        name=\"Predicted label\").to_csv(\n    ```", "```py\n    \t\t\"test_predictions.csv\")\n    ```", "```py\n    fig, (ax1, ax2) = plt.subplots(1, 2, tight_layout=True)\n    ```", "```py\n    ax1.set_title(\"Confusion matrix for training data\")\n    ```", "```py\n    ax2.set_title(\"Confusion matrix for test data\")\n    ```", "```py\n    ConfusionMatrixDisplay.from_predictions(\n    ```", "```py\n    \ty_train, train_predictions,\n    ```", "```py\n    \tax=ax1 cmap=\"Greys\", colorbar=False)\n    ```", "```py\n    ConfusionMatrixDisplay.from_predictions(\n    ```", "```py\n    \ty_test, test_predictions,\n    ```", "```py\n    \tax=ax2 cmap=\"Greys\", colorbar=False)\n    ```", "```py\n    print(f\"Train accuracy {accuracy_score(y_train, train_predictions)}\",\n    ```", "```py\n    \tf\"Test accuracy {accuracy_score(y_test, test_predictions)}\",\n    ```", "```py\n    \tsep=\"\\n\")\n    ```", "```py\n    # Train accuracy 1.0\n    ```", "```py\n    # Test accuracy 0.65\n    ```", "```py\nfrom pathlib import Path\nfrom datetime import datetime\nRESULTS_OUT = Path(datetime.now().isoformat())\n...\nresults.to_csv(RESULTS_OUT / \"name.csv\")\n```"]