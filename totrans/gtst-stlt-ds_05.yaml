- en: '*Chapter 4*: Using Machine Learning with Streamlit'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A very common situation data scientists find themselves in is at the end of
    the model creation process, not knowing exactly how to convince non-data scientists
    that their model is worthwhile. They might have performance metrics from their
    model or some static visualizations but have no easy way to allow others to interact
    with their model.
  prefs: []
  type: TYPE_NORMAL
- en: Before Streamlit, there were a couple of other options, the most popular being
    creating a full-fledged app in Flask or Django or turning their model into an
    **Application Programming Interface** (**API**) and pointing developers toward
    it. These are great options but tend to be time-consuming and suboptimal for valuable
    use cases such as prototyping an app.
  prefs: []
  type: TYPE_NORMAL
- en: The incentives on teams are a little misaligned here. A data scientist wants
    to create the best models for their teams, but if they need to take a day or two
    (or, if they have experience, a few hours) of work to turn their model into a
    Flask or Django app, it doesn't make much sense to build this out until they think
    they are nearly complete with the modeling process. The benefit of Streamlit is
    that it helps us turn this arduous process into a frictionless app creation experience.
    In this chapter, we'll go over how to create **Machine Learning** (**ML**) prototypes
    in Streamlit, how to add user interaction to your ML apps, and also how to understand
    the ML results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, the following topics are covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The standard ML workflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting penguin species
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilizing a pre-trained ML model in Streamlit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training models inside Streamlit apps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding ML results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The standard ML workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first step to creating an app that uses ML is the ML model itself. There
    are dozens of popular workflows for creating your own ML models. It''s likely
    you might have your own already! There are two parts of this process to consider:'
  prefs: []
  type: TYPE_NORMAL
- en: The generation of the ML model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The use of the ML model in production
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the plan is to train a model once and then use this model in our Streamlit
    app, the best method is to create this model outside of Streamlit (for example,
    in a Jupyter notebook or in a standard Python file) first, and then use this model
    within the app.
  prefs: []
  type: TYPE_NORMAL
- en: If the plan is to use the user input to train the model inside our app, then
    we can no longer create the model outside of Streamlit and instead will need to
    run the model training within the Streamlit app.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by building our ML models outside of Streamlit and move on to
    training our models inside of Streamlit apps after.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting penguin species
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The dataset that we will primarily use in this chapter is the same Palmer''s
    Penguins dataset that we used in [*Chapter 1*](B16864_01_Final_VK_ePub.xhtml#_idTextAnchor014),
    *An Introduction to Streamlit*. As is typical, we will create a new folder that
    will house our new Streamlit app and accompanying code. The following code creates
    this new folder within our `streamlit_apps` folder and copies the data from our
    `penguin_app` folder. If you haven''t downloaded the Palmer''s Penguins data yet,
    please follow the instructions in the *The Setup: Palmer''s Penguins* section
    in [*Chapter 2*](B16864_02_Final_VK_ePub.xhtml#_idTextAnchor024), *Uploading,
    Downloading, and Manipulating Data*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As you may have noticed in the preceding code, there are two Python files here,
    one to create the ML model (`penguins_ml.py`) and the second to create the Streamlit
    app (`penguins_streamlit.py`). We will start with the `penguins_ml.py` file, and
    once we have a model we are happy with, we will move on to the `penguins_streamlit.py`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You can also opt to create the model in a Jupyter notebook, which is less reproducible
    by design (as cells can be run out of order) but is still incredibly popular.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s get re-familiarized with the `penguins.csv` dataset. The following code
    will read the dataset and print out the first five rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code, when we run our Python file `penguins_ml.py`
    in the terminal, will look something like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – First five penguins'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16864_04_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.1 – First five penguins
  prefs: []
  type: TYPE_NORMAL
- en: For this app, we are going to attempt to create an app that will help researchers
    in the wild know what species of penguin they are looking at. It will predict
    the species of the penguin given some measurements of the bill, flippers, and
    body mass, and knowledge about the sex and location of the penguin.
  prefs: []
  type: TYPE_NORMAL
- en: 'This next section is not an attempt to make the best ML model possible, but
    just to create something as a quick prototype for our Streamlit app that we can
    iterate off of. So in that light, we are going to drop our few rows with null
    values, and not use the `year` variable in our features as it does not fit with
    our use case. We will need to define our features and output variables, and do
    one-hot-encoding (or as pandas calls it, creating dummy variables for our text
    columns) on our features, and factorize our output variable (turn it from a string
    into a number). The following code should get our dataset in a better spot to
    run through a classification algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now when we run our Python file `penguins_ml.py` again, we see the output and
    feature variables separated, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Output variables'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16864_04_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.2 – Output variables
  prefs: []
  type: TYPE_NORMAL
- en: Now, we want to create a classification model using a subset (in this case,
    80%) of our data, and get the accuracy of said model. The following code runs
    through those steps using a random forest model, but you can use other classification
    algorithms if you would like. Again, the point here is to get a quick prototype
    to show to the penguin researchers for feedback!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have a pretty good model for predicting the species of penguins! Our
    last step in the model generating process is to save the two parts of this model
    that we need the most – the model itself and the `uniques` variable, which maps
    the factorized output variable to the species name that we recognize. To the previous
    code, we will add a few lines that will save these objects as pickle files (files
    that turn a Python object into something we can save directly and import easily
    from another Python file such as our Streamlit app). More specifically, the `open()`
    function creates two pickle files, the `pickle.dump()` function writes our Python
    files to said files, and the `close()` function closes the files. The `wb` in
    the `open()` function stands for *write bytes*, which tells Python that we want
    to write, not read, to this file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We now have two more files in our `penguin_ml` folder, a file called `random_forest_penguin.pickle`,
    which contains our model, and `output_penguin_.pickle`, which has the mapping
    between penguin species and the output of our model. This is it for the `penguins_ml.py`
    function! We can move on to our Streamlit app.
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing a pre-trained ML model in Streamlit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have our model, we want to load it (along with our mapping function
    as well) into Streamlit. In our file, `penguins_streamlit.py`, that we created
    before, we will again use the `pickle` library to load our files using the following
    code. We use the same functions as before, but instead of `wb`, we use the `rb`
    parameter, which stands for *read bytes*. To make sure these are the same Python
    objects that we used before, we will use the `st.write()` function that we are
    so familiar with already to check:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As with our previous Streamlit apps, we run the following code in the terminal
    to run our app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have our random forest classifier, along with the penguin mapping! Our
    next step is to add Streamlit functions to get the user input. In our app, we
    used island, bill length, bill depth, flipper length, body mass, and sex to predict
    the penguin species, so we will need to get each of these from our user. For island
    and sex, we know which options were in our dataset already and want to avoid having
    to parse through user text, so we will use `selectbox`. For the other data, we
    just need to make sure that the user has input a positive number, so we will use
    the `st.number_input()` function and make the minimum value `0`. The following
    code takes these inputs in and prints them out on our Streamlit app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code should make the following app. Try it out and see if it
    works by changing the values and seeing if the output changes as well. Streamlit
    is designed so that, by default, each time a value is changed, the entire app
    reruns. The following screenshot shows the app live, with some values that I''ve
    changed. We can either change numeric values with the (**+** and **-**) buttons
    on the right-hand side, or we can just enter the values manually:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – Model inputs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16864_04_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.3 – Model inputs
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we have all our inputs, and we also have our model. The next step is to
    format the data into the same format as our preprocessed data, for example, our
    model does not have one variable called `sex` but instead has two variables called
    `sex_female` and `sex_male`. Once our data is in the right shape, we can call
    the `predict` function and map the prediction to our original species list to
    see how our model functions. The following code does exactly this, and also adds
    some basic titles and instructions to the app to make it more usable. This app
    is rather long, so I will break it up into multiple sections for readability,
    starting with adding instructions and a title to our app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have an app with our title and instructions for the user. The next step
    is to get the user inputs as we did before. We also need to put our `sex` and
    `island` variables into the correct format, as discussed before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'All of our data is in the correct format! The last step here is using the `predict()`
    function on our model with our new data, which this final section takes care of:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Now our app should look like the following screenshot. I have added some example
    values to the inputs, but you should play around with changing the data to see
    if you can make the species change!
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4 – Full Streamlit prediction'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16864_04_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.4 – Full Streamlit prediction
  prefs: []
  type: TYPE_NORMAL
- en: We now have a full Streamlit app that utilizes our pre-trained ML model, takes
    user input, and outputs the prediction. Next, we will discuss how to train models
    directly within Streamlit apps!
  prefs: []
  type: TYPE_NORMAL
- en: Training models inside Streamlit apps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Often, we may want to have the user input change how our model is trained. We
    may want to accept data from the user or ask the user what features they would
    like to use, or even allow the user to pick the type of machine learning algorithm
    they would like to use. All of these options are feasible in Streamlit, and in
    this section, we will cover the basics around using user input to affect the training
    process. As we discussed in the section above, if a model is going to be trained
    only once, it is probably best to train the model outside of Streamlit and import
    the model into Streamlit. But what if, in our example, the penguin researchers
    have the data stored locally, or do not know how to retrain the model but have
    the data in the correct format already? In cases like these, we can add the `st.file_uploader()`
    option and include a method for these users to input their own data, and get a
    custom model deployed for them without having to write any code. The following
    code will add a user option to accept data and will use the preprocessing/training
    code that we originally had in `penguins_ml.py` to make a unique model for this
    user. It is important to note here that this will only work if the user has data
    in the exact same format and style that we used, which may be unlikely. One other
    potential add-on here is to show the user what format the data needs to be in
    for this app to correctly train a model as expected!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This first section imports the libraries that we need, adds the title – as
    we have used before, and adds the `file_uploader()` function. What happens, however,
    when the user has yet to upload a file? We can set the default to load our random
    forest model if there is no penguin file, as shown in the next section of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The next problem we need to solve is how to take in the user''s data, clean
    it, and train a model based on it. Luckily, we can reuse the model training code
    that we have already created and put it within our `else` statement in the next
    code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We have now created our model within the app and need to get the inputs from
    the user for our prediction. This time, however, we can make an improvement on
    what we have done before. As of now, each time a user changes an input in our
    app, the entire Streamlit app will rerun. We can use the `st.form()` and `st.submit_form_button()`
    functions to wrap the rest of our user inputs in and allow the user to change
    all of the inputs and submit the entire form at once instead of multiple times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the inputs with our new form, we need to create our prediction
    and write the prediction to the user, as shown in the next block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'And there we go! We now have a Streamlit app that allows the user to input
    their own data and trains a model based on their data and outputs the results,
    as shown in the next screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 – Penguin classifier predictions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16864_04_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.5 – Penguin classifier predictions
  prefs: []
  type: TYPE_NORMAL
- en: There are potential improvements here, such as through using caching functions
    (explored in [*Chapter 2*](B16864_02_Final_VK_ePub.xhtml#_idTextAnchor024), *Uploading,
    Downloading, and Manipulating Data*), as one example. Apps like these where users
    bring their own data are significantly harder to build, especially without a universal
    data format. It is more common as of this writing to see Streamlit apps that show
    off impressive ML models and use cases rather than apps that build them directly
    in-app (especially with more computationally expensive model training). As we
    mentioned before, Streamlit developers often will provide references to the required
    data format before asking for user input in the form of a dataset. However, this
    option of allowing users to bring their own data is available and practical, especially
    to allow for quick iterations on model building.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding ML results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, our app might be useful, but often just showing a result is not good
    enough for a data app. We also should show some explanation as to why they got
    the result that they did! In order to do this, we can include in the output of
    the app that we have already made a section that helps users understand the model
    better.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, random forest models already have a built-in feature importance method
    derived from the set of individual decision trees that make up the random forest.
    We can edit our `penguins_ml.py` file to graph this importance, and then call
    that image from within our Streamlit app. We could also graph this directly from
    within our Streamlit app, but it is more efficient to make this graph once in
    `penguins_ml.py` instead of every time our Streamlit app reloads (which is every
    time a user changes a user input!). The following code edits our `penguins_ml.py`
    file and adds the feature importance graph, saving it to our folder. We also call
    the `tight_layout()` feature, which helps format our graph better and makes sure
    we avoid any labels getting cut off. This set of code is long, and the top half
    of the file remains unchanged, so only the section on library importing and data
    cleaning has been omitted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now when we rerun `pengiuns_ml.py`, we should see a file called `feature_importance.png`,
    which we can call from our Streamlit app. Let''s do that now! We can use the `st.image()`
    function to load an image from our `png` and print it to our penguin app. The
    following code adds our image to the Streamlit app and also improves our explanations
    around the prediction we made. Because of the length of this code block, we will
    just show the new code from the point where we start to predict using the user''s
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the bottom of your Streamlit app should look like the following screenshot
    (note: your string might be slightly different based on your inputs).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 – Feature importance screenshot'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16864_04_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.6 – Feature importance screenshot
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see, bill length, bill depth, and flipper length are the most important
    variables according to our random forest model. A final option for explaining
    how our model works is to plot the distributions of each of these variables by
    species, and also plot some vertical lines representing the user input. Ideally,
    the user can begin to understand the underlying data holistically, and therefore
    will understand the predictions that come from the model as well. To do this,
    we will need to actually import the data into our Streamlit app, which we have
    not done previously. The following code imports the penguin data we used to build
    the model, and plots three histograms (for *bill length*, *bill depth*, and *flipper
    length*) along with the user input as a vertical line, starting from the model
    explanation section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have set up our app for the histograms, we can use the `displot()`
    function in the Seaborn visualization library to create our three histograms for
    our most important variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code should create the app shown in the following figure, which
    is our app in its final form. For viewing ease, we will just show the first histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 – Bill Length by Species'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16864_04_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.6 – Bill Length by Species
  prefs: []
  type: TYPE_NORMAL
- en: As always, the completed and final code can be found at [https://github.com/tylerjrichards/Getting-Started-with-Streamlit-for-Data-Science](https://github.com/tylerjrichards/Getting-Started-with-Streamlit-for-Data-Science).
    That completes this section. We have now created a fully formed Streamlit app
    that takes a pre-built model and user input and outputs both the result of the
    prediction and an explanation of the output as well.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we learned some ML basics: how to take a pre-built ML model
    and use it within Streamlit, how to create our own models from within Streamlit,
    and also how to use user input to understand and iterate on ML models. Hopefully,
    at the end of this chapter, you feel comfortable with each of these. We will dive
    into the world of deploying Streamlit using Streamlit sharing next!'
  prefs: []
  type: TYPE_NORMAL
