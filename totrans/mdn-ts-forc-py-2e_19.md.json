["```py\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import LSTM\nhorizon = 12\nmodels = [LSTM(h=horizon,\n               max_steps=500,\n               scaler_type='standard',\n               encoder_hidden_size=64,\n               decoder_hidden_size=64,),\n          ]\nnf = NeuralForecast(models=models, freq='M')\nnf.fit(df=Y_df)\nY_hat_df = nf.predict() \n```", "```py\nmodel_interpretable = model_untuned.models[0]\ndataset, *_ = TimeSeriesDataset.from_df(df = training_df, id_col='LCLid',time_col='timestamp',target_col='energy_consumption')\ny_hat = model_interpretable.decompose(dataset=dataset) \n```", "```py\npooling_sizes = np.exp2(\n    np.round(np.linspace(0.49, np.log2(prediction_length / 2), n_stacks))\n)\npooling_sizes = [int(x) for x in pooling_sizes[::-1]]\ndownsample_frequencies = [\n    min(prediction_length, int(np.power(x, 1.5))) for x in pooling_sizes\n] \n```", "```py\n# calculating the FFT of Query and Key\nq_fft = torch.fft.rfft(queries.permute(0, 2, 3, 1).contiguous(), dim=-1)\nk_fft = torch.fft.rfft(keys.permute(0, 2, 3, 1).contiguous(), dim=-1)\n# Multiplying the FFT of Query with Conjugate FFT of Key\nres = q_fft * torch.conj(k_fft) \n```", "```py\ncorr = torch.fft.irfft(res, dim=-1) \n```", "```py\n# Declare nn.Linear for each channel\nlayers = nn.ModuleList([nn.Linear(context_window, forecast_horizon) for _ in range(n_timeseries)])\n## Forward Method ##\n# Now use these layers once you get the input (Batch, Context Length, Channel)\nforecast = [layers[i](input[:,:,i]) for i in range(n_timeseries)] \n```", "```py\n# Declare nn.Linear for each channel, trend and seasonality separately\ntrend_layers = nn.ModuleList([nn.Linear(context_window, forecast_horizon) for _ in range(n_timeseries)])\nseasonality_layers = nn.ModuleList([nn.Linear(context_window, forecast_horizon) for _ in range(n_timeseries)])\n## Forward Method ##\n# Now use these layers once you get the input (Batch, Context Length, Channel)\n# series_decomp is a function extracting trend using moving aveages\ntrend, seasonality = series_decomp(input)\ntrend_forecast = [trend_layers[i]( trend[:,:,i]) for i in range(n_timeseries)]\nseasonality_forecast = [seasonality_layers[i]( seasonality [:,:,i]) for i in range(n_timeseries)]\nforecast = [trend_forecast[i] + seasonality_forecast[i] for i in range(n_timeseries)] \n```", "```py\n# Declare nn.Linear for each channel\nlayers = nn.ModuleList([nn.Linear(context_window, forecast_horizon) for _ in range(n_timeseries)])\n## Forward Method ##\n# Extract the last value once you get the input (Batch, Context Length, Channel)\n# Get the last value of time series\nlast_value = sample_data[:,-1:,:]\n# Normalize the time series\nnorm_ts = sample_data - last_value\n# Use the linear layers\noutput = [layers[i](norm_ts[:,:,i]) for i in range(n_timeseries)]\n# Add back the last value\nforecast = [o + last_value[:,:,i] for i, o in enumerate(output)] \n```", "```py\nraw_predictions, x = best_model.predict(val_dataloader, mode=\"raw\", return_x=True)\ninterpretation = best_model.interpret_output(raw_predictions, reduction=\"sum\") \n```", "```py\nbest_model.plot_interpretation(interpretation) \n```"]