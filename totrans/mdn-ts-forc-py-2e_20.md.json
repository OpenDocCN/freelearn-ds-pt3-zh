["```py\nlevel = 95  # Confidence levels\nqs = [50 - level / 2, 50 + level / 2] # Quantiles \n```", "```py\nimport numpy as np\ndef coverage(y_true, lower_bounds, upper_bounds):\n    \"\"\"\n    Calculate the coverage of prediction intervals.\n\n    Parameters:\n    y_true (array-like): True values.\n    lower_bounds (array-like): Lower bounds of prediction intervals.\n    upper_bounds (array-like): Upper bounds of prediction intervals.\n\n    Returns:\n    float: Coverage metric.\n    \"\"\"\n    y_true = np.array(y_true)\n    lower_bounds = np.array(lower_bounds)\n    upper_bounds = np.array(upper_bounds)\n    # Check if true values fall within the prediction intervals\n    coverage = np.mean((y_true >= lower_bounds) & (y_true <= upper_bounds))\n    return coverage \n```", "```py\ndef average_length(lower_bounds, upper_bounds):\n    \"\"\"\n    Calculate the average length of prediction intervals.\n\n    Parameters:\n    lower_bounds (array-like): Lower bounds of prediction intervals.\n    upper_bounds (array-like): Upper bounds of prediction intervals.\n\n    Returns:\n    float: Average length of prediction intervals.\n    \"\"\"\n    lower_bounds = np.array(lower_bounds)\n    upper_bounds = np.array(upper_bounds)\n\n    # Calculate the length of each prediction interval\n    lengths = upper_bounds - lower_bounds\n    # Calculate the average length\n    average_length = np.mean(lengths)\n    return average_length \n```", "```py\nfrom ngboost import NGBRegressor\nfrom ngboost.distns import Normal\n# Training the model\nngb = NGBRegressor(Dist=Normal).fit(X_train, Y_train) \n```", "```py\ny_pred = ngb.predict(X_val) \n```", "```py\ny_pred_dists = ngb.pred_dist(X_val) \n```", "```py\ny_pred_dists[0:5].params \n```", "```py\ny_pred_lower, y_pred_upper = y_pred_dists.dist.interval(0.95) \n```", "```py\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import LSTM\nfrom neuralforecast.losses.pytorch import DistributionLoss \n```", "```py\nhorizon = 48\nlevels = [80, 90]\nlstm_config = dict(input_size=3*horizon, encoder_hidden_size=8, decoder_hidden_size=8) \n```", "```py\nmodels = [\n    LSTM(\n        h=horizon,\n        loss=DistributionLoss(distribution=\"StudentT\", level=levels),\n        alias=\"LSTM_StudentT\",\n        **lstm_config\n    ),\n    LSTM(\n        h=horizon,\n        loss=DistributionLoss(distribution=\"Normal\", level=levels),\n        alias=\"LSTM_Normal\",\n        **lstm_config\n    ),\n]\n# Setting freq=1 because the ds column is not date, but instead a sequentially increasing number\nnf = NeuralForecast(models=models, freq=1) \n```", "```py\nnf.fit(df=Y_train_df) \n```", "```py\nY_hat_df = nf.predict() \n```", "```py\ndef quantile_loss(q, y, y_hat_q):\n    \"\"\" Calculate the quantile loss for a given quantile.\n    Args:\n    q (float): The quantile to be evaluated, e.g., 0.5 for median.\n    y (float): The target value.\n    y_hat_q (float): The quantile forecast.\n    \"\"\"\n    error = y - y_hat_q\n    return np.maximum(q * error, (q - 1) * error) \n```", "```py\nparams = {\n    'objective': 'quantile',\n    'metric': 'quantile',\n    'max_depth': 4,\n    'num_leaves': 15,\n    'learning_rate': 0.1,\n    'n_estimators': 100,\n    'boosting_type': 'gbdt'\n}\n# converting levels to quantiles\n# For 90% Confidence - 0.05 for lower, 0.5 for median, and 0.95 for upper\nquantiles = [0.5] + sum([level_to_quantiles(l) for l in levels], []) \n```", "```py\n# Training a model each for the quantiles\nquantile_models = {}\nfor q in quantiles:\n    model = LGBMRegressor(alpha=q, **params)\n    model = model.fit(X_train, Y_train)\n    quantile_models[q] = model \n```", "```py\n# Point Forecast using the 0.5 quantile model\ny_pred = quantile_models[0.5].predict(X_val)\n# Prediction Intervals using the 0.1 and 0.9 quantile models\ny_pred_lower = quantile_models[0.1].predict(X_val)\ny_pred_upper = quantile_models[0.9].predict(X_val) \n```", "```py\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import LSTM\nfrom neuralforecast.losses.pytorch import MQLoss \n```", "```py\nhorizon = 48\nlevels = [80, 90]\nlstm_config = dict(input_size=3*horizon) \n```", "```py\nmodels = [LSTM(h=horizon, loss=MQLoss(level=levels), **lstm_config)]\n# Setting freq=1 because the ds column is not date, but instead a sequentially increasing number\nnf = NeuralForecast(models=models, freq=1) \n```", "```py\nnf.fit(df=Y_train_df) \n```", "```py\nY_hat_df = nf.predict() \n```", "```py\nclass DNonLinear(BaseWindows):\n    def __init__(\n        self,\n        # Inherited hyperparameters with no defaults\n        h,\n        input_size,\n        # Model specific hyperparameters\n        # Window over which the moving average operates for trend extraction\n        moving_avg_window=3,\n        dropout=0.1,\n        # Inhereted hyperparameters with defaults\n        ...\n        **trainer_kwargs,\n    ):\n        super(DropoutDNonLinear, self).__init__(\n            h=h,\n            ...\n            **trainer_kwargs,\n        )\n        # Model specific hyperparameters\n        self.moving_avg_window = moving_avg_window\n        self.dropout = dropout\n        # Model initialization to follow \n```", "```py\n # Defining a decomposition Layer\n        self.decomp = SeriesDecomp(self.moving_avg_window)\n        # Defining a non-linear trend predictor with dropout\n        self.non_linear_block = nn.Sequential(\n            nn.Dropout(self.dropout),\n            nn.Linear(self.input_size, 100),\n            nn.ReLU(),\n            nn.Dropout(self.dropout),\n            nn.Linear(100, 100),\n            nn.ReLU(),\n            nn.Dropout(self.dropout),\n            nn.Linear(100, self.h),\n        )\n        # Defining a linear trend predictor with dropout\n        self.linear_trend = nn.Sequential(\n            nn.Dropout(self.dropout),\n            nn.Linear(self.input_size, self.h),\n        )\n        # Defining a seasonality predictor with dropout\n        self.seasonality = nn.Sequential(\n            nn.Dropout(self.dropout),\n            nn.Linear(self.input_size, self.h),\n        ) \n```", "```py\n def forward(self, windows_batch):\n        # Parse windows_batch\n        insample_y = windows_batch[\n            \"insample_y\"\n        ].clone()  # --> (batch_size, input_size)\n        seasonal_init, trend_init = self.decomp(\n            insample_y\n        )  # --> (batch_size, input_size)\n        # Non-linear block\n        non_linear_part = self.non_linear_block(\n            insample_y\n        )  # --> (batch_size, horizon)\n        # Linear trend block\n        trend_part = self.linear_trend(trend_init)  # --> (batch_size, horizon)\n        # Seasonality block\n        seasonal_part = self.seasonality(\n            seasonal_init\n        )  # --> (batch_size, horizon)\n        # Combine the components\n        forecast = (\n            trend_part + seasonal_part + non_linear_part\n        )  # --> (batch_size, horizon)\n        # Map the forecast to the domain of the target\n        forecast = self.loss.domain_map(forecast)\n        return forecast \n```", "```py\ndef enable_dropout(model):\n    \"\"\"Function to enable the dropout layers during test-time\"\"\"\n    for m in model.modules():\n        if m.__class__.__name__.startswith(\"Dropout\"):\n            m.train() \n```", "```py\nclass MCDropoutDNonLinear(DNonLinear):\n    def predict_step(self, batch, batch_idx):\n        enable_dropout(self)\n        pred_samples = []\n        # num_samples and levels will be saved to the model in MCNeuralForecast predict method\n        for i in range(self.num_samples):\n            y_hat = super().predict_step(batch, batch_idx)\n            pred_samples.append(y_hat)\n        # Stack the samples\n        pred_samples = torch.stack(pred_samples, dim=0)\n        # Calculate the median and the quantiles\n        y_hat = [pred_samples.quantile(0.5, dim=0)]\n        if self.levels is not None:\n            for l in self.levels:\n                lo, hi = level_to_quantiles(l)\n                y_hat_lo = pred_samples.quantile(lo, dim=0)\n                y_hat_hi = pred_samples.quantile(hi, dim=0)\n                y_hat.extend([y_hat_lo, y_hat_hi])\n        # Stack the results\n        y_hat = torch.stack(y_hat, dim=-1)\n        return y_hat \n```", "```py\nclass MCNeuralForecast(NeuralForecast):\n    def __init__(self, num_samples, levels=None, **kwargs):\n        super().__init__(**kwargs)\n        self.num_samples = num_samples\n        self.levels = levels\n    def predict(\n        self,\n        df=None,\n        static_df=None,\n        futr_df=None,\n        sort_df=True,\n        verbose=False,\n        engine=None,\n        **data_kwargs,\n    ):\n        # Adding model columns to loss output names\n        # Necessary hack to get the quantiles and format it correctly\n        for model in self.models:\n            model.loss.output_names = [\"-median\"]\n            for l in list(self.levels):\n                model.loss.output_names.append(f\"-lo-{l}\")\n                model.loss.output_names.append(f\"-hi-{l}\")\n            # Setting the number of samples and levels in the model\n            model.num_samples = self.num_samples\n            model.levels = self.levels\n        return super().predict(\n            df, static_df, futr_df, sort_df, verbose, engine, **data_kwargs\n        ) \n```", "```py\nhorizon = len(Y_test_df.ds.unique()) # 48\nlevels = [80, 90]\nmodel = MCDropoutDNonLinear (\n    h= horizon,\n    input_size=WINDOW,\n    moving_avg_window=horizon*3,\n    dropout=0.1,\n    max_steps=500,\n    early_stop_patience_steps=5,\n)\nmcnf = MCNeuralForecast(models=[model], freq=1, num_samples=100, levels=levels)\nmcnf.fit(Y_train_df, val_size= horizon, verbose=True) \n```", "```py\nY_hat_df = mcnf.predict()\nY_hat_df = Y_hat_df.reset_index() \n```", "```py\n# 1: Get conformal scores\nn = calib_y.shape[0]\ncal_smx = model.predict_proba(calib_x) # shape (n, n_classes)\n# scores from the softmax score for the correct class\ncal_scores = 1 - cal_smx[np.arange(n), calib_y] # shape (n,)\n# 2: Get adjusted quantile\nalpha = 0.1  # Confidence level (1 - alpha)\nq_level = np.ceil((n + 1) * (1 - alpha)) / n\nqhat = np.quantile(cal_scores, q_level, method='higher')\n# 3: Form prediction sets\nval_smx = model.predict_proba(test_x)\nprediction_sets = val_smx >= (1 - qhat) \n```", "```py\n# 1: Get conformal scores\ncalib_preds = model.predict(calib_x)\ncal_scores = np.abs(calib_y - calib_preds)\n# 2: Get adjusted quantile\nqhat = … # Exactly the same as classification\n# 3: Form prediction intervals\ntest_preds = model.predict(test_x)\nlower_bounds = test_preds - qhat\nupper_bounds = test_preds + qhat \n```", "```py\ndef calculate_scores(self, Y_calib_df):\n    Y_calib_df = Y_calib_df.copy()\n    Y_calib_df[\"calib_scores\"] = np.abs(Y_calib_df[\"y\"] - Y_calib_df[self.model])\n    return Y_calib_df \n```", "```py\ndef get_quantile(self, Y_calib_df):\n    def get_qhat(Y_calib_df):\n        n_cal = len(Y_calib_df)\n        q_level = np.ceil((n_cal + 1) * (1 - self.alpha)) / n_cal\n        return np.quantile(\n                Y_calib_df[\"calib_scores\"].values, q_level, method=\"higher\"\n            )\n    return Y_calib_df.groupby(\n\"unique_id\").apply(get_qhat).to_dict() \n```", "```py\ndef calc_prediction_interval(self, Y_test_df, q_hat):\n    return (\n            Y_test_df[self.model] - Y_test_df[\"unique_id\"].map(q_hat),\n            Y_test_df[self.model] + Y_test_df[\"unique_id\"].map(q_hat),\n        ) \n```", "```py\nfrom src.conformal.conformal_predictions import ConformalPrediction\nY_calib_df, Y_test_df = prediction_dict['LSTM']\n# Y_calib_df & Y_test_df have forecasts in column named \"LSTM\"\ncp = ConformalPrediction(model=\"LSTM\", level=level)\n# Calibrating the model\ncp.fit(Y_calib_df=Y_calib_df)\n# Generating Prediction intervals\nY_test_df_cp = cp.predict(Y_test_df=Y_test_df) \n```", "```py\n>> cp.method_name\n'Vanilla Conformal Prediction (CP) \n```", "```py\ndef calculate_scores(self, Y_calib_df):\n    Y_calib_df = Y_calib_df.copy()\n    lower_bounds = Y_calib_df[self.lower_quantile_model]\n    upper_bounds = Y_calib_df[self.upper_quantile_model]\n    Y_calib_df[\"calib_scores\"] = np.maximum(\n            lower_bounds - Y_calib_df[\"y\"], Y_calib_df[\"y\"] - upper_bounds\n        )\n    return Y_calib_df \n```", "```py\ndef calc_prediction_interval(self, Y_test_df, q_hat):\n    return (\n            Y_test_df[self.lower_quantile_model] - Y_test_df[\"unique_id\"].map(q_hat),\n            Y_test_df[self.upper_quantile_model] + Y_test_df[\"unique_id\"].map(q_hat),\n        ) \n```", "```py\nfrom src.conformal.conformal_predictions import ConformalizedQuantileRegression\nY_calib_df, Y_test_df = prediction_dict['LSTM_QR']\n# Forecast in column \"LSTM_QR\"\ncp = ConformalizedQuantileRegression(model=\"LSTM_QR\", level=level)\ncp.fit(Y_calib_df=Y_calib_df)\nY_test_df_cqr = cp.predict(Y_test_df=Y_test_df) \n```", "```py\nfrom scipy.stats import norm\ndef calculate_standard_deviation(upper_bound, point_prediction, confidence_level):\n    # Calculate the Z-value from the confidence level\n    z_value = norm.ppf((1 + confidence_level) / 2)\n    # Calculate the standard deviation\n    sigma = (upper_bound - point_prediction) / z_value\n\n    return sigma\ndef reverse_engineer_sd(X, model_tag, level):\n    X[\"std\"] = calculate_standard_deviation(\n        X[f\"{model_tag}-hi-{level}\"], X[model_tag], level / 100\n    )\n    return X \n```", "```py\nY_calib_df = reverse_engineer_sd(Y_calib_df, \"LSTM_Normal\", level)\nY_test_df = reverse_engineer_sd(Y_test_df, \"LSTM_Normal\", level) \n```", "```py\nclass ConformalizedUncertaintyEstimates(ConformalPrediction):\n    def __init__(\n        self,\n        model: str,\n        uncertainty_model: str,\n        level: Optional[float] = None,\n        alias: str = None,\n    ):\n        super().__init__(model, level, alias)\n        self.method = \"Conformalized Uncertainty Intervals\"\n        self._mthd = \"CUE\"\n        self.uncertainty_model = uncertainty_model \n```", "```py\ndef calculate_scores(self, Y_calib_df):\n    Y_calib_df = Y_calib_df.copy()\n        uncertainty = Y_calib_df[self.uncertainty_model]\n    Y_calib_df[\"calib_scores\"] = (\n            np.abs(Y_calib_df[\"y\"] - Y_calib_df[self.model]) / uncertainty\n        )\n    return Y_calib_df \n```", "```py\ndef calc_prediction_interval(self, Y_test_df, q_hat:\n    uncertainty = Y_test_df[self.uncertainty_model]\n    return (\n            Y_test_df[self.model] - uncertainty * Y_test_df[\"unique_id\"].map(q_hat),\n            Y_test_df[self.model] + uncertainty * Y_test_df[\"unique_id\"].map(q_hat),\n        ) \n```", "```py\nfrom src.conformal.conformal_predictions import ConformalizedUncertaintyEstimates\n# We have saved uncertainty estimates in \"std\"\ncp = ConformalizedUncertaintyEstimates(model=\"LSTM_Normal\", uncertainty_model=\"std\", level=level)\ncp.fit(Y_calib_df=Y_calib_df)\nY_test_df_pdf = cp.predict(Y_test_df=Y_test_df) \n```", "```py\nclass WeightedConformalPredictor:\n    def __init__(\n        self,\n        conformal_predictor: ConformalPrediction,\n        K: int,\n        weight_strategy: str,\n        custom_weights: list = None,\n        decay_factor: float = 0.5,\n    ):\n    … \n```", "```py\ndef fit(self, Y_calib_df):\n    self.calib_df = self.conformal_predictor.calculate_scores(\n            Y_calib_df.sort_values([\"unique_id\", \"ds\"])\n        ) \n```", "```py\ndef predict(self, Y_test_df):\n    # Groupby unique_id\n    …   \n    # Calculate quantiles for each unique_id\n    self.q_hat = {}\n    for unique_id, group in grouped_calib:\n        # Take the last K timesteps\n        group = group.iloc[-self.K :]\n        scores = group[\"calib_scores\"].values\n        # Calculate weights based on the last K timesteps\n        total_timesteps = len(scores)\n        weights = self._calculate_weight(total_timesteps)\n        normalized_weights = weights / weights.sum()\n        # Calculate quantile for the current unique_id\n        quantile = self.get_weighted_quantile(\n                scores, normalized_weights, self.conformal_predictor.alpha\n            )\n        self.q_hat[unique_id] = quantile\n    # Calculate prediction intervals using the underlying conformal predictor's method\n    lo, hi = self.conformal_predictor.get_prediction_interval_names()\n    Y_test_df[lo], Y_test_df[hi] = (\n self.conformal_predictor.calc_prediction_interval(Y_test_df, self.q_hat)\n        )\n    return Y_test_df \n```", "```py\nfrom src.conformal.conformal_predictions import WeightedConformalPredictor\nY_calib_df, Y_test_df = prediction_dict['LSTM']\n# Defining an underlying conformal predictor\ncp = ConformalPrediction(model=\"LSTM\", level=level)\n# using the defined conformal predictor in weighted version\nweighted_cp = WeightedConformalPredictor(\n    conformal_predictor=cp,\n    K=50,\n    weight_strategy=\"uniform\",\n)\nweighted_cp.fit(Y_calib_df=Y_calib_df)\nY_test_df_wcp = weighted_cp.predict(Y_test_df=Y_test_df) \n```", "```py\nfrom src.conformal.conformal_predictions import OnlineWeightedConformalPredictor\ncp = ConformalPrediction(model=\"LSTM\", level=level)\nonline_weighted_cp = OnlineWeightedConformalPredictor(\n    conformal_predictor=cp,\n    K=50,\n    weight_strategy=\"uniform\",\n)\nonline_weighted_cp.fit(Y_calib_df=Y_calib_df)\njoblib.dump(online_weighted_cp, \"path/to/saved/file.pkl\") \n```", "```py\n# Loading the saved model\nonline_weighted_cp = joblib.load(\"path/to/saved/file.pkl\")\n# current timestep data = current\n# past timestep actuals = last_timestep_actuals\nprediction = online_weighted_cp.predict_one(current_test)\n# updating the calibration data using the last timestep actuals\nonline_weighted_cp.update(last_timestep_actuals) \n```", "```py\nY_test_df_wcpo = online_weighted_cp.offline_predict(Y_test_df=Y_test_df) \n```", "```py\nclass OnlineAdaptiveConformalInference:\n    def __init__(\n        self,\n        conformal_predictor: ConformalPrediction,\n        gamma: float = 0.005,\n        update_method: str = \"simple\",\n        momentum_bw: float = 0.95,\n        per_unique_id: bool = True,\n    ):\n        … \n```", "```py\ndef fit(self, Y_calib_df):\n    \"\"\"\n    Fit the conformal predictor model with calibration data.\n    \"\"\"\n    self.calib_df = self.conformal_predictor.calculate_scores(Y_calib_df)\n    self.scores_by_id = (\n        self.calib_df.groupby(\"unique_id\")[\"calib_scores\"].apply(list).to_dict()\n    )\n    # Some more code to initialize necessary data structures     \n    …\n    return self \n```", "```py\ndef predict_one(self, current_test):\n    unique_ids = current_test[\"unique_id\"].unique()\n    predictions = []\n    for unique_id in unique_ids:\n        group_scores = self.scores_by_id.get(unique_id, [])\n        if group_scores:\n            # Determine the appropriate alpha to use\n            alpha = (\n                self.alphat[unique_id]\n                if self.per_unique_id\n                else self.alphat_global\n            )\n            # Calculate quantile for the current unique_id\n            self.q_hat = {\n                unique_id: np.quantile(group_scores, 1 - alpha, method=\"higher\")\n            }\n            # Calculating prediction intervals using conformal_predictor\n            …\n            current_test[lo] = lower.values\n            current_test[hi] = upper.values\n            # Storing most recent prediction\n            …\n        # Collecting and returning concatenated predictions\n        … \n```", "```py\ndef update(self, new_data):\n    new_scores = self.conformal_predictor.calculate_scores(new_data)\n    for unique_id, score in zip(\n        new_scores[\"unique_id\"], new_scores[\"calib_scores\"]\n    ):\n        # Updating score trajectory with new score\n    …\n        # Retrieve stored predictions and calculate adapt_err\n        if self.per_unique_id:\n            lower, upper = self.predictions[unique_id]\n            actual_y = new_data.loc[new_data[\"unique_id\"] == unique_id, \"y\"].values[0]\n            adapt_err = int(actual_y < lower or actual_y > upper)\n            # Update alpha updates the alpha using simple or momentum method\n            self.update_alpha(unique_id, adapt_err)\n        else:\n            # Do the same update at a global error-pooled way \n```", "```py\nfrom src.conformal.conformal_predictions import OnlineAdaptiveConformalInference\ncp = ConformalPrediction(model=\"LSTM\", level=level)\naci_cp = OnlineAdaptiveConformalInference(\n    conformal_predictor=cp,\n    gamma=0.005,\n    update_method=\"simple\",\n)\naci_cp.fit(Y_calib_df=Y_calib_df)\njoblib.dump(aci_cp, \"path/to/saved/file.pkl\") \n```", "```py\n# Loading the saved model\naci_cp = joblib.load(\"path/to/saved/file.pkl\")\n# current timestep data = current\n# past timestep actuals = last_timestep_actuals\nprediction = aci_cp.predict_one(current_test)\n# updating the calibration data using the last timestep actuals\naci_cp.update(last_timestep_actuals) \n```", "```py\nY_test_df_aci = aci_cp.offline_predict(Y_test_df=Y_test_df) \n```"]