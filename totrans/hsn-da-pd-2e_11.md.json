["```py\nlogin_attempt_simulator\n|-- __init__.py\n|-- login_attempt_simulator.py\n`-- utils.py\n```", "```py\n\"\"\"Utility functions for the login attempt simulator.\"\"\"\nimport ipaddress\nimport itertools\nimport json\nimport random\nimport string\n```", "```py\ndef make_user_base(out_file):\n    \"\"\"Generate a user base and save it to a file.\"\"\"\n    with open(out_file, 'w') as user_base:\n        for first, last in itertools.product(\n            string.ascii_lowercase, \n            ['smith', 'jones', 'kim', 'lopez', 'brown']\n        ): # makes 130 accounts\n            user_base.write(first + last + '\\n')\n        # adds 3 more accounts\n        for account in ['admin', 'master', 'dba']: \n            user_base.write(account + '\\n')\n```", "```py\ndef get_valid_users(user_base_file):\n    \"\"\"Read in users from the user base file.\"\"\"\n    with open(user_base_file, 'r') as file:\n        return [user.strip() for user in file.readlines()]\n```", "```py\ndef random_ip_generator():\n    \"\"\"Randomly generate a fake IP address.\"\"\"\n    try:\n        ip_address = ipaddress.IPv4Address('%d.%d.%d.%d' %\n            tuple(random.randint(0, 255) for _ in range(4))\n        )\n    except ipaddress.AddressValueError:\n        ip_address = random_ip_generator()\n    return str(ip_address) if ip_address.is_global \\\n        else random_ip_generator()\n```", "```py\ndef assign_ip_addresses(user_list):\n    \"\"\"Assign users 1-3 fake IP addresses.\"\"\"\n    return {\n        user: [\n            random_ip_generator()\n            for _ in range(random.randint(1, 3))\n        ] for user in user_list\n    }\n```", "```py\ndef save_user_ips(user_ip_dict, file):\n    \"\"\"Save the user-IP address mapping to a JSON file.\"\"\"\n    with open(file, 'w') as file:\n        json.dump(user_ip_dict, file)\ndef read_user_ips(file):\n    \"\"\"Read in the JSON file of the user-IP address mapping.\"\"\"\n    with open(file, 'r') as file:\n        return json.loads(file.read())\n```", "```py\n\"\"\"Simulator of login attempts from valid users and hackers.\"\"\"\nimport calendar\nimport datetime as dt\nfrom functools import partial\nimport math\nimport random\nimport string\nimport numpy as np\nimport pandas as pd\nfrom .utils import random_ip_generator, read_user_ips\n```", "```py\nclass LoginAttemptSimulator:\n    \"\"\"Simulate login attempts from valid users + attackers.\"\"\"\n    ATTEMPTS_BEFORE_LOCKOUT = 3\n    ACCOUNT_LOCKED = 'error_account_locked'\n    WRONG_USERNAME = 'error_wrong_username'\n    WRONG_PASSWORD = 'error_wrong_password'\n```", "```py\n    def __init__(self, user_base_json_file, start, end=None, *,\n                 attacker_success_probs=[.25, .45],\n                 valid_user_success_probs=[.87, .93, .95],\n                 seed=None):\n        # user, ip address dictionary\n        self.user_base = read_user_ips(user_base_json_file)\n        self.users = [user for user in self.user_base.keys()]\n        self.start = start\n        self.end = end if end else self.start + \\\n            dt.timedelta(days=random.uniform(1, 50))\n        self.hacker_success_likelihoods = \\\n            attacker_success_probs\n        self.valid_user_success_likelihoods = \\\n            valid_user_success_probs\n        self.log = pd.DataFrame(columns=[\n            'datetime', 'source_ip', 'username',\n            'success', 'failure_reason'\n        ])\n        self.hack_log = \\\n            pd.DataFrame(columns=['start', 'end', 'source_ip'])\n        self.locked_accounts = []\n        # set seeds for random numbers from random and numpy:\n        random.seed(seed)\n        np.random.seed(seed)\n```", "```py\n    def _record(self, when, source_ip, username, success, \n                failure_reason):\n        \"\"\"\n        Record the outcome of a login attempt.\n        Parameters:\n            - when: The datetime of the event.\n            - source_ip: IP address the attempt came from.\n            - username: The username used in the attempt.\n            - success: Whether the attempt succeeded (Boolean).\n            - failure_reason: Reason for the failure.\n        Returns: \n            None, the `log` attribute is updated.\n        \"\"\"\n        self.log = self.log.append({\n            'datetime': when, \n            'source_ip': source_ip, \n            'username': username, \n            'success': success, \n            'failure_reason': failure_reason\n        }, ignore_index=True)\n```", "```py\n    def _attempt_login(self, when, source_ip, username,\n                       username_accuracy, success_likelihoods):\n        \"\"\"\n        Simulates a login attempt, allowing for account\n        lockouts, and recording the results.\n        Parameters:\n            - when: The datetime to start trying.\n            - source_ip: IP address the attempt came from. \n            - username: The username being used in the attempt.\n            - username_accuracy: Prob. username is correct.\n            - success_likelihoods: List of probabilities that \n              password is correct (one per attempt).\n        Returns:\n            The datetime after trying.\n        \"\"\"\n        current = when\n        recorder = partial(self._record, source_ip=source_ip)\n        if random.random() > username_accuracy:\n            correct_username = username\n            username = self._distort_username(username)\n        if username not in self.locked_accounts:\n            tries = len(success_likelihoods)\n            for i in range(\n                min(tries, self.ATTEMPTS_BEFORE_LOCKOUT)\n            ):\n                current += dt.timedelta(seconds=1)\n                if username not in self.users:\n                    recorder(\n                        when=current, username=username, \n                        success=False,\n                        failure_reason=self.WRONG_USERNAME\n                    )\n                    if random.random() <= username_accuracy:\n                        username = correct_username\n                    continue\n                if random.random() <= success_likelihoods[i]:\n                    recorder(\n                        when=current, username=username,\n                        success=True, failure_reason=None\n                    )\n                    break\n                else:\n                    recorder(\n                        when=current, username=username, \n                        success=False,\n                        failure_reason=self.WRONG_PASSWORD\n                    )\n            else:\n                if tries >= self.ATTEMPTS_BEFORE_LOCKOUT \\\n                and username in self.users:\n                    self.locked_accounts.append(username)\n        else:\n            recorder(\n                when=current, username=username, success=False,\n                failure_reason=self.ACCOUNT_LOCKED\n            )\n            if random.random() >= .5: # unlock account randomly\n                self.locked_accounts.remove(username)\n        return current\n```", "```py\n    def _hacker_attempts_login(self, when, source_ip,\n                               username):\n        \"\"\"Simulates a login attempt from an attacker.\"\"\"\n        return self._attempt_login(\n            when=when, source_ip=source_ip, username=username,\n            username_accuracy=random.gauss(mu=0.35, sigma=0.5),\n            success_likelihoods=self.hacker_success_likelihoods\n        )\n    def _valid_user_attempts_login(self, when, username):\n        \"\"\"Simulates a login attempt from a valid user.\"\"\"\n        return self._attempt_login(\n            when=when, username=username,\n            source_ip=random.choice(self.user_base[username]),\n            username_accuracy=\\\n                random.gauss(mu=1.01, sigma=0.01),\n            success_likelihoods=\\\n                self.valid_user_success_likelihoods\n        )\n```", "```py\n    @staticmethod\n    def _distort_username(username):\n        \"\"\"\n        Alters the username to allow for wrong username login \n        failures. Randomly removes a letter or replaces a \n        letter in a valid username.\n        \"\"\"\n        username = list(username)\n        change_index = random.randint(0, len(username) - 1)\n        if random.random() < .5: # remove random letter\n            username.pop(change_index)\n        else: # randomly replace a single letter\n            username[change_index] = \\\n                random.choice(string.ascii_lowercase)\n        return ''.join(username)\n```", "```py\n    @staticmethod\n    def _valid_user_arrivals(when):\n        \"\"\"\n        Static method for simulating Poisson process of \n        arrivals (users wanting to log in). Lambda for the \n        Poisson varies depending upon the day and time of week.\n        \"\"\"\n        is_weekday = when.weekday() not in (\n            calendar.SATURDAY, calendar.SUNDAY\n        )\n        late_night = when.hour < 5 or when.hour >= 11\n        work_time = is_weekday \\\n                    and (when.hour >= 9 or when.hour <= 17)\n        if work_time:\n# hours 9-5 on work days get higher lambda \n            poisson_lambda = random.triangular(1.5, 5, 2.75)\n        elif late_night:\n            # hours in middle of night get lower lambda\n            poisson_lambda = random.uniform(0.0, 5.0)\n        else:\n            poisson_lambda = random.uniform(1.5, 4.25)\n        hourly_arrivals = np.random.poisson(poisson_lambda)\n        interarrival_times = np.random.exponential(\n            1/poisson_lambda, size=hourly_arrivals\n        )\n        return hourly_arrivals, interarrival_times\n```", "```py\n    def _hack(self, when, user_list, vary_ips):\n        \"\"\"\n        Simulate an attack by a random hacker.\n        Parameters:\n            - when: The datetime to start the attack.\n            - user_list: The list of users to try to hack.\n            - vary_ips: Whether or not to vary the IP address.\n        Returns:\n            Initial IP address and the end time for recording.\n        \"\"\"\n        hacker_ip = random_ip_generator()\n        random.shuffle(user_list)\n        for user in user_list:\n            when = self._hacker_attempts_login(\n                when=when, username=user,\n                source_ip=random_ip_generator() if vary_ips \\\n                    else hacker_ip\n            )\n        return hacker_ip, when\n```", "```py\n    def simulate(self, *, attack_prob, try_all_users_prob,\n                 vary_ips):\n        \"\"\"\n        Simulate login attempts.\n        Parameters:\n            - attack_probs: Probability of attack in given hour\n            - try_all_users_prob: Prob. hacker will try to \n              guess credentials for all users vs random subset.\n            - vary_ips: Whether to vary the IP address.\n        \"\"\"\n        hours_in_date_range = math.floor(\n            (self.end - self.start).total_seconds() / 60 / 60\n        )\n        for offset in range(hours_in_date_range + 1):\n            current = self.start + dt.timedelta(hours=offset)\n            # simulate hacker\n            if random.random() < attack_prob:\n                attack_start = current \\\n                    + dt.timedelta(hours=random.random())\n                source_ip, end_time = self._hack(\n                    when=attack_start,\n                    user_list=self.users if \\\n                        random.random() < try_all_users_prob \\\n                        else random.sample(\nself.users, \n                            random.randint(0, len(self.users))\n                    ),\n                    vary_ips=vary_ips\n                )\n                self.hack_log = self.hack_log.append(\n                    dict(\n                        start=attack_start, end=end_time, \n                        source_ip=source_ip\n                    ), ignore_index=True\n                )\n            # simulate valid users\n            hourly_arrivals, interarrival_times = \\\n                self._valid_user_arrivals(current)\n            random_user = random.choice(self.users)\n            random_ip = \\\n                random.choice(self.user_base[random_user])\n            for i in range(hourly_arrivals):\n                current += \\\n                    dt.timedelta(hours=interarrival_times[i])\n                current = self._valid_user_attempts_login(\n                    current, random_user\n                )\n```", "```py\n    @staticmethod\n    def _save(data, filename, sort_column):\n        \"\"\"Sort data by the datetime and save to a CSV file.\"\"\"\n        data.sort_values(sort_column)\\\n            .to_csv(filename, index=False)\n    def save_log(self, filename):\n        \"\"\"Save the login attempts log to a CSV file.\"\"\"\n        self._save(self.log, filename, 'datetime')\n    def save_hack_log(self, filename):\n        \"\"\"Save the record of the attacks to a CSV file.\"\"\"\n        self._save(self.hack_log, filename, 'start')\n```", "```py\n\"\"\"Package for simulating login data.\"\"\"\nfrom .login_attempt_simulator import LoginAttemptSimulator\n```", "```py\n\"\"\"Script for simulating login attempts.\"\"\"\nimport argparse\nimport datetime as dt\nimport os\nimport logging\nimport random\nimport login_attempt_simulator as sim\n```", "```py\n# Logging configuration\nFORMAT = '[%(levelname)s] [ %(name)s ] %(message)s'\nlogging.basicConfig(level=logging.INFO, format=FORMAT)\nlogger = logging.getLogger(os.path.basename(__file__))\n```", "```py\ndef get_simulation_file_path(path_provided, directory,\n                             default_file):\n    \"\"\"Get filepath, make directory if necessary.\"\"\"\n    if path_provided:\n        file = path_provided\n    else:\n        if not os.path.exists(directory):\n            os.mkdir(directory)\n        file = os.path.join(directory, default_file)\n    return file\ndef get_user_base_file_path(path_provided, default_file):\n    \"\"\"Get the path for a user_data directory file.\"\"\"\n    return get_simulation_file_path(\n        path_provided, 'user_data', default_file\n    )\ndef get_log_file_path(path_provided, default_file):\n    \"\"\"Get the path for a logs directory file.\"\"\"\n    return get_simulation_file_path(\n        path_provided, 'logs', default_file\n    )\n```", "```py\nif __name__ == '__main__':\n    # command-line argument parsing\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        'days', type=float,\n        help='number of days to simulate from start'\n    )\n    parser.add_argument(\n        'start_date', type=str,\n        help=\"datetime to start in the form 'YYYY-MM-DD(...)'\"\n    )\n    parser.add_argument(\n'-m', '--make', action='store_true', \n        help='make user base'\n    )\n    parser.add_argument(\n'-s', '--seed', type=int, \n        help='set a seed for reproducibility'\n    )\n    parser.add_argument(\n'-u', '--userbase', \n        help='file to write the user base to'\n    )\n    parser.add_argument(\n'-i', '--ip', \n        help='file to write user-IP address map to'\n    )\n    parser.add_argument(\n        '-l', '--log', help='file to write the attempt log to'\n    )\n    parser.add_argument(\n'-hl', '--hacklog', \n        help='file to write the hack log to'\n    )\n```", "```py\n    args = parser.parse_args()\n```", "```py\n    user_ip_mapping_file = \\\n        get_user_base_file_path(args.ip, 'user_ips.json')\n    if args.make:\n        logger.warning(\n            'Creating new user base, mapping IP addresses.'\n        )\n        user_base_file = get_user_base_file_path(\n            args.userbase, 'user_base.txt'\n        )\n        # seed the creation of user base\n        random.seed(args.seed)\n        # create usernames and write to file\n        sim.utils.make_user_base(user_base_file)\n        # create 1 or more IP addresses per user, save mapping \n        valid_users = sim.utils.get_valid_users(user_base_file)\n        sim.utils.save_user_ips(\n            sim.utils.assign_ip_addresses(valid_users), \n            user_ip_mapping_file\n        )\n```", "```py\n    try:\n        start = \\\n            dt.datetime(*map(int, args.start_date.split('-')))\n    except TypeError:\n        logger.error('Start date must be in \"YYYY-MM-DD\" form')\n        raise\n    except ValueError:\n        logger.warning(\n            f'Could not interpret {args.start_date}, '\n            'using January 1, 2020 at 12AM as start instead'\n        )\n        start = dt.datetime(2020, 1, 1)\n    end = start + dt.timedelta(days=args.days)\n```", "```py\ntry clause and multiple except clauses. We can specify how to handle specific errors occurring during code execution (called except clause. In this case, we have the logger object print a more helpful message for the user, and then re-raise the same exception (because we don't intend to handle it) by simply writing raise. This ends the program—the user can then try again with valid input. Try triggering this exception to see how much more useful this is. One thing to keep in mind, though, is that order matters—be sure to handle specific exceptions before having a general except clause; otherwise, the code specific to each exception type will never trigger. Also, note that using except without providing a specific exception will catch everything, even exceptions not meant to be caught.\n```", "```py\n    try:\n        logger.info(f'Simulating {args.days} days...')\n        simulator = sim.LoginAttemptSimulator(\n            user_ip_mapping_file, start, end, seed=args.seed\n        )\n        simulator.simulate(\n            attack_prob=0.1, try_all_users_prob=0.2, \n            vary_ips=False\n        )\n        # save logs\n        logger.info('Saving logs')\n        simulator.save_hack_log(\n            get_log_file_path(args.hacklog, 'attacks.csv')\n        )\n        simulator.save_log(\n            get_log_file_path(args.log, 'log.csv')\n        )\n        logger.info('All done!')\n    except:\n        logger.error('Oops! Something went wrong...')\n        raise\n```", "```py\n(book_env) $ python3 simulate.py -h\nusage: simulate.py [-h] [-m] [-s SEED] [-u USERBASE] [-i IP] \n                   [-l LOG] [-hl HACKLOG]\n                   days start_date\npositional arguments:\n  days                  number of days to simulate from start\n  start_date            datetime to start in the form \n                        'YYYY-MM-DD' or 'YYYY-MM-DD-HH'\noptional arguments:\n  -h, --help            show this help message and exit\n  -m, --make            make user base\n  -s SEED, --seed SEED  set a seed for reproducibility\n  -u USERBASE, --userbase USERBASE\n                        file to write the user base to\n  -i IP, --ip IP        file to write the user-IP address \n                        map to\n  -l LOG, --log LOG     file to write the attempt log to\n  -hl HACKLOG, --hacklog HACKLOG\n                        file to write the hack log to\n```", "```py\n(book_env) $ python3 simulate.py -ms 0 30 '2018-11-01'\n[WARNING] [ simulate.py ] Creating new user base and mapping IP addresses to them.\n[INFO] [ simulate.py ] Simulating 30.0 days...\n[INFO] [ simulate.py ] Saving logs\n[INFO] [ simulate.py ] All done!\n```", "```py\n# leave off the .py\n(book_env) $ python3 -m simulate -ms 0 30 \"2018-11-01\"\n```", "```py\n>>> %matplotlib inline\n>>> import matplotlib.pyplot as plt\n>>> import numpy as np\n>>> import pandas as pd\n>>> import seaborn as sns\n>>> log = pd.read_csv(\n...     'logs/log.csv', index_col='datetime', parse_dates=True\n... )\n```", "```py\n>>> attacks = pd.read_csv(\n...     'logs/attacks.csv',\n...     converters={\n...         'start': np.datetime64, \n...         'end': np.datetime64\n...     }\n... ) # make start and end columns datetimes but not the index\n```", "```py\n>>> attacks.shape, log.shape\n((72, 3), (12836, 4))\n>>> attacks.source_ip.nunique() / log.source_ip.nunique()\n0.22018348623853212\n```", "```py\n>>> log.assign(attempts=1).attempts.resample('1H').sum()\\\n...     .plot(figsize=(15, 5), title='hourly attempts')\\\n...     .set(xlabel='datetime', ylabel='attempts')\n```", "```py\n>>> log.source_ip.value_counts().describe()\ncount    327.000000\nmean      39.253823\nstd       69.279330\nmin        1.000000\n25%        5.000000\n50%       10.000000\n75%       22.500000\nmax      257.000000\nName: source_ip, dtype: float64\n```", "```py\n>>> fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n>>> log.source_ip.value_counts()\\\n...     .plot(kind='box', ax=axes[0]).set_ylabel('attempts')\n>>> log.source_ip.value_counts()\\\n...     .plot(kind='hist', bins=50, ax=axes[1])\\\n...     .set_xlabel('attempts')\n>>> fig.suptitle('Attempts per IP Address')\n```", "```py\n>>> num_hackers = attacks.source_ip.nunique()\n>>> log.source_ip.value_counts().index[:num_hackers]\\\n...     .isin(attacks.source_ip).sum() / num_hackers\n0.8888888888888888\n```", "```py\n>>> log.assign(attempts=1).groupby('source_ip').attempts\\\n...     .resample('1H').sum().unstack().mean()\\\n...     .plot(\n...         figsize=(15, 5), \n...         title='average hourly attempts per IP address'\n...     ).set_ylabel('average hourly attempts per IP address')\n```", "```py\n>>> log[log.source_ip.isin(attacks.source_ip)]\\\n...     .success.value_counts(normalize=True)\nFalse    0.831801\nTrue     0.168199\nName: success, dtype: float64\n```", "```py\n>>> log[~log.source_ip.isin(attacks.source_ip)]\\\n...     .success.value_counts(normalize=True)\nTrue     0.873957\nFalse    0.126043\nName: success, dtype: float64\n```", "```py\n>>> pd.crosstab(\n...     index=pd.Series(\n...         log.source_ip.isin(attacks.source_ip),\n...         name='is_hacker'\n...     ), columns=log.failure_reason\n... )\n```", "```py\n>>> log.assign(attempts=1).groupby('username').attempts\\\n...     .resample('1H').sum().unstack().mean()\\\n...     .plot(figsize=(15, 5),\n...           title='average hourly attempts per user')\\\n...     .set_ylabel('average hourly attempts per user')\n```", "```py\n>>> pivot = log.pivot_table(\n...     values='success', index=log.source_ip, \n...     columns=log.failure_reason.fillna('success'), \n...     aggfunc='count', fill_value=0\n... )\n>>> pivot.insert(0, 'attempts', pivot.sum(axis=1))\n>>> pivot = pivot.sort_values('attempts', ascending=False)\\\n...     .assign(\n...         success_rate=lambda x: x.success / x.attempts,\n...         error_rate=lambda x: 1 - x.success_rate\n...     )\n>>> pivot.head()\n```", "```py\n>>> log.groupby('source_ip').agg(dict(username='nunique'))\\\n...     .username.value_counts().describe()\ncount     53.000000\nmean       6.169811\nstd       34.562505\nmin        1.000000\n25%        1.000000\n50%        1.000000\n75%        2.000000\nmax      253.000000\nName: username, dtype: float64\n```", "```py\n>>> pivot.plot(\n...     kind='scatter', x='attempts', y='success', alpha=0.25,\n...     title='successes vs. attempts by IP address' \n... )\n```", "```py\n>>> ax = pivot.plot(\n...     kind='scatter', x='attempts', y='success', alpha=0.25, \n...     title='successes vs. attempts by IP address'\n... )\n>>> plt.axvline(\n...     125, label='sample boundary',\n...     color='red', linestyle='--'\n... )\n>>> plt.legend(loc='lower right')\n```", "```py\n>>> fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n>>> for ax in axes:\n...     sns.scatterplot(\n...         y=pivot.success, x=pivot.attempts, \n...         hue=pivot.assign(\n...             is_hacker=\\\n...                 lambda x: x.index.isin(attacks.source_ip)\n...         ).is_hacker,\n...         ax=ax, alpha=0.5\n...     ) \n...     for spine in ['top', 'right']: # make less boxy\n...         ax.spines[spine].set_visible(False)\n>>> axes[1].set_xscale('log')\n>>> plt.suptitle('successes vs. attempts by IP address')\n```", "```py\n>>> pivot[['attempts', 'success']].plot(\n...     kind='box', subplots=True, figsize=(10, 3),\n...     title='stats per IP address'\n... )\n```", "```py\n>>> hourly_ip_logs = log.assign(\n...     failures=lambda x: np.invert(x.success)\n... ).groupby('source_ip').resample('1H').agg({\n...     'username': 'nunique', 'success': 'sum', \n...     'failures': 'sum'\n... }).assign(\n...     attempts=lambda x: x.success + x.failures,\n...     success_rate=lambda x: x.success / x.attempts,\n...     failure_rate=lambda x: 1 - x.success_rate\n... ).dropna().reset_index()\n```", "```py\n>>> def get_baselines(hourly_ip_logs, func, *args, **kwargs):\n...     \"\"\"\n...     Calculate hourly bootstrapped statistic per column.\n...\n...     Parameters:\n...         - hourly_ip_logs: Data to sample from.\n...         - func: Statistic to calculate.\n...         - args: Additional positional arguments for `func`\n...         - kwargs: Additional keyword arguments for `func`\n...\n...     Returns: \n...         `DataFrame` of hourly bootstrapped statistics\n...     \"\"\"\n...     if isinstance(func, str):\n...         func = getattr(pd.DataFrame, func)\n...\n...     return hourly_ip_logs.assign(\n...         hour=lambda x: x.datetime.dt.hour\n...     ).groupby('hour').apply(\n...         lambda x: x\\\n...             .sample(10, random_state=0, replace=True)\\\n...             .pipe(func, *args, **kwargs, numeric_only=True)\n...     )\n```", "```py\nrandom_state is used with sample() for reproducibility; however, in practice, we will probably not want to always pick the same rows.\n```", "```py\n>>> averages = get_baselines(hourly_ip_logs, 'mean')\n>>> averages.shape\n(24, 7)\n```", "```py\n>>> averages.nlargest(6, 'failure_rate')\n```", "```py\n>>> def trim(x, quantile):\n...     \"\"\"\n...     Remove rows with entries for the username, attempts, \n...     or failure_rate columns above a given quantile.\n...     \"\"\"\n...     mask = (\n...         (x.username <= x.username.quantile(quantile)) &\n...         (x.attempts <= x.attempts.quantile(quantile)) &\n...         (x.failure_rate\n...          <= x.failure_rate.quantile(quantile))\n...     )\n...     return x[mask]\n```", "```py\n>>> trimmed_hourly_logs = hourly_ip_logs\\\n...     .assign(hour=lambda x: x.datetime.dt.hour)\\\n...     .groupby('hour').apply(lambda x: trim(x, 0.95))\\\n...     .drop(columns='hour').reset_index().iloc[:,2:]\n```", "```py\n>>> averages = get_baselines(trimmed_hourly_logs, 'mean')\n>>> averages.iloc[[19, 23, 3, 11, 14, 16]]\n```", "```py\n>>> def pct_change_threshold(hourly_ip_logs, baselines,\n...                          pcts=None):\n...     \"\"\"\n...     Return flagged IP addresses based on thresholds.\n...\n...     Parameters:\n...         - hourly_ip_logs: Aggregated data per IP address.\n...         - baselines: Hourly baselines per column in data.\n...         - pcts: Dictionary of custom percentages per column \n...           for calculating upper bound thresholds\n...           (baseline * pct). If not provided, pct will be 1\n...\n...     Returns: `Series` containing the IP addresses flagged.\n...     \"\"\"\n...     pcts = {} if not pcts else pcts\n...\n...     return hourly_ip_logs.assign(\n...         hour=lambda x: x.datetime.dt.hour\n...     ).join(\n...         baselines, on='hour', rsuffix='_baseline'\n...     ).assign(\n...         too_many_users=lambda x: x.username_baseline \\\n...             * pcts.get('username', 1) <= x.username,\n...         too_many_attempts=lambda x: x.attempts_baseline \\\n...             * pcts.get('attempts', 1) <= x.attempts,\n...         high_failure_rate=lambda x: \\\n...             x.failure_rate_baseline \\\n...             * pcts.get('failure_rate', 1) <= x.failure_rate\n...     ).query(\n...         'too_many_users and too_many_attempts '\n...         'and high_failure_rate'\n...     ).source_ip.drop_duplicates()\n```", "```py\n>>> pct_from_mean_ips = pct_change_threshold(\n...     hourly_ip_logs, averages, \n...     {key: 1.25 for key in [\n...         'username', 'attempts', 'failure_rate'\n...     ]}\n... )\n```", "```py\n>>> pct_from_mean_ips.nunique()\n73\n```", "```py\n>>> def tukey_fence_test(trimmed_data, logs, k, pct=None):\n...     \"\"\"\n...     See which IP addresses get flagged with a Tukey fence \n...     with multiplier k and optional percent differences.\n...  \n...     Parameters: \n...         - trimmed_data: Data for calculating the baselines\n...         - logs: The data to test\n...         - k: The multiplier for the IQR\n...         - pct: Dictionary of percentages per column for use \n...                with `pct_change_threshold()`\n...\n...     Returns: \n...         `pandas.Series` of flagged IP addresses\n...     \"\"\"\n...     q3 = get_baselines(trimmed_data, 'quantile', .75)\\\n...         .drop(columns=['hour'])\n...\n...     q1 = get_baselines(trimmed_data, 'quantile', .25)\\\n...         .drop(columns=['hour'])\n...\n...     iqr = q3 - q1\n...     upper_bound = (q3 + k * iqr).reset_index()\n...\n...     return pct_change_threshold(logs, upper_bound, pct)\n```", "```py\n>>> tukey_fence_ips = tukey_fence_test(\n...     trimmed_hourly_logs, hourly_ip_logs, k=3\n... )\n```", "```py\n>>> tukey_fence_ips.nunique()\n83\n```", "```py\n>>> def z_score_test(trimmed_data, logs, cutoff):\n...     \"\"\"\n...     See which IP addresses get flagged with a Z-score\n...     greater than or equal to a cutoff value.\n...\n...     Parameters: \n...         - trimmed_data: Data for calculating the baselines\n...         - logs: The data to test\n...         - cutoff: Flag row when z_score >= cutoff\n...\n...     Returns: \n...         `pandas.Series` of flagged IP addresses\n...     \"\"\"\n...     std_dev = get_baselines(trimmed_data, 'std')\\\n...         .drop(columns=['hour'])\n...     averages = get_baselines(trimmed_data, 'mean')\\\n...         .drop(columns=['hour'])\n...\n...     return logs.assign(hour=lambda x: x.datetime.dt.hour)\\\n...         .join(std_dev.join(\n...             averages, lsuffix='_std', rsuffix='_mean'\n...         ), on='hour')\\\n...         .assign(\n...             too_many_users=lambda x: (\n...                 x.username - x.username_mean\n...             )/x.username_std >= cutoff,\n...             too_many_attempts=lambda x: (\n...                 x.attempts - x.attempts_mean\n...             )/x.attempts_std >= cutoff,\n...             high_failure_rate=lambda x: (\n...                 x.failure_rate - x.failure_rate_mean\n...             )/x.failure_rate_std >= cutoff\n...         ).query(\n...             'too_many_users and too_many_attempts '\n...             'and high_failure_rate'\n...         ).source_ip.drop_duplicates()\n```", "```py\n>>> z_score_ips = \\\n...     z_score_test(trimmed_hourly_logs, hourly_ip_logs, 3)\n```", "```py\n>>> z_score_ips.nunique()\n62\n```", "```py\n>>> def evaluate(alerted_ips, attack_ips, log_ips):\n...     \"\"\"\n...     Calculate true positives (TP), false positives (FP),\n...     true negatives (TN), and false negatives (FN) for \n...     IP addresses flagged as suspicious.\n...\n...     Parameters:\n...         - alerted_ips: `Series` of flagged IP addresses\n...         - attack_ips: `Series` of attacker IP addresses\n...         - log_ips: `Series` of all IP addresses seen\n...\n...     Returns:\n...         Tuple of the form (TP, FP, TN, FN)\n...     \"\"\"\n...     tp = alerted_ips.isin(attack_ips).sum()\n...     tn = np.invert(np.isin(\n...         log_ips[~log_ips.isin(alerted_ips)].unique(),\n...         attack_ips\n...     )).sum()\n...     fp = np.invert(alerted_ips.isin(attack_ips)).sum()\n...     fn = np.invert(attack_ips.isin(alerted_ips)).sum()\n...     return tp, fp, tn, fn\n```", "```py\n>>> from functools import partial\n>>> scores = partial(\n...     evaluate, attack_ips=attacks.source_ip,\n...     log_ips=pivot.index\n... )\n```", "```py\n>>> tp, fp, tn, fn = scores(pct_from_mean_ips)\n>>> fp / (fp + tn), fp / (fp + tp)\n(0.00392156862745098, 0.0136986301369863)\n```", "```py\n>>> fn / (fn + tp), fn / (fn + tn)\n(0.0, 0.0)\n```", "```py\n>>> def classification_stats(tp, fp, tn, fn):\n...     \"\"\"Calculate metrics\"\"\"\n...     return {\n...         'FPR': fp / (fp + tn), 'FDR': fp / (fp + tp),\n...         'FNR': fn / (fn + tp), 'FOR': fn / (fn + tn)\n...     }\n```", "```py\n>>> classification_stats(tp, fp, tn, fn)\n{'FPR': 0.00392156862745098, 'FDR': 0.0136986301369863,\n 'FNR': 0.0, 'FOR': 0.0}\n```", "```py\n>>> medians = get_baselines(hourly_ip_logs, 'median')\n>>> pct_from_median_ips = pct_change_threshold(\n...     hourly_ip_logs, medians, \n...     {key: 1.25 for key in\n...      ['username', 'attempts', 'failure_rate']}\n... )\n```", "```py\n>>> tp, fp, tn, fn = scores(pct_from_median_ips)\n>>> classification_stats(tp, fp, tn, fn)\n{'FPR': 0.00784313725490196, 'FDR': 0.02702702702702703,\n 'FNR': 0.0, 'FOR': 0.0}\n```", "```py\n>>> pd.DataFrame({\n...     method: classification_stats(*scores(ips))\n...     for method, ips in {\n...         'means': pct_from_mean_ips,\n...         'medians': pct_from_median_ips,\n...         'Tukey fence': tukey_fence_ips,\n...         'Z-scores': z_score_ips\n...     }.items()\n... })\n```"]