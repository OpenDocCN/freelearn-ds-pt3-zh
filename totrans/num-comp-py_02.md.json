["```py\n>>> import pandas as pd \n>>> hrattr_data = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\") \n\n>>> print (hrattr_data.head()) \n```", "```py\n>>> hrattr_data['Attrition_ind'] = 0 \n>>> hrattr_data.loc[hrattr_data['Attrition'] =='Yes', 'Attrition_ind'] = 1 \n```", "```py\n>>> dummy_busnstrvl = pd.get_dummies(hrattr_data['BusinessTravel'], prefix='busns_trvl') \n>>> dummy_dept = pd.get_dummies(hrattr_data['Department'], prefix='dept') \n>>> dummy_edufield = pd.get_dummies(hrattr_data['EducationField'], prefix='edufield') \n>>> dummy_gender = pd.get_dummies(hrattr_data['Gender'], prefix='gend') \n>>> dummy_jobrole = pd.get_dummies(hrattr_data['JobRole'], prefix='jobrole') \n>>> dummy_maritstat = pd.get_dummies(hrattr_data['MaritalStatus'], prefix='maritalstat')  \n>>> dummy_overtime = pd.get_dummies(hrattr_data['OverTime'], prefix='overtime')  \n```", "```py\n>>> continuous_columns = ['Age','DailyRate','DistanceFromHome', 'Education', 'EnvironmentSatisfaction','HourlyRate','JobInvolvement','JobLevel','JobSatisfaction', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked','PercentSalaryHike',  'PerformanceRating', 'RelationshipSatisfaction','StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear','WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion','YearsWithCurrManager'] \n\n>>> hrattr_continuous = hrattr_data[continuous_columns] \n```", "```py\n>>> hrattr_data_new = pd.concat([dummy_busnstrvl, dummy_dept, dummy_edufield, dummy_gender, dummy_jobrole, dummy_maritstat, dummy_overtime, hrattr_continuous, hrattr_data['Attrition_ind']],axis=1) \n```", "```py\n# Train and Test split \n>>> from sklearn.model_selection import train_test_split \n>>> x_train,x_test,y_train,y_test = train_test_split( hrattr_data_new.drop (['Attrition_ind'], axis=1),hrattr_data_new['Attrition_ind'],   train_size = 0.7, random_state=42) \n```", "```py\nhrattr_data = read.csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")   \nstr(hrattr_data);summary(hrattr_data)   \nhrattr_data$Attrition_ind = 0;   \nhrattr_data$Attrition_ind[   hrattr_data$Attrition==\"Yes\"]=1   \nhrattr_data$Attrition_ind=   as.factor(hrattr_data$Attrition_ind)   \n\nremove_cols = c(\"EmployeeCount\",\"EmployeeNumber\",\"Over18\",   \"StandardHours\",\"Attrition\")   \nhrattr_data_new =   hrattr_data[,!(names(hrattr_data) %in% remove_cols)]   \n\nset.seed(123)   \nnumrow = nrow(hrattr_data_new)   \ntrnind = sample(1:numrow,size =   as.integer(0.7*numrow))   \ntrain_data =   hrattr_data_new[trnind,]   \ntest_data = hrattr_data_new[-trnind,]   \n # Code for calculating   precision, recall for 0 and 1 categories and # at overall level which   will be used in all the classifiers in # later sections   \nfrac_trzero =   (table(train_data$Attrition_ind)[[1]])/nrow(train_data)   \nfrac_trone =   (table(train_data$Attrition_ind)[[2]])/nrow(train_data)   \n\nfrac_tszero =   (table(test_data$Attrition_ind)[[1]])/nrow(test_data)   \nfrac_tsone = (table(test_data$Attrition_ind)[[2]])/nrow(test_data)   \n\nprec_zero <-   function(act,pred){  tble = table(act,pred)   \nreturn( round(   tble[1,1]/(tble[1,1]+tble[2,1]),4))}   \n\nprec_one <-   function(act,pred){ tble = table(act,pred)   \nreturn( round(   tble[2,2]/(tble[2,2]+tble[1,2]),4))}   \n\nrecl_zero <-   function(act,pred){tble = table(act,pred)   \nreturn( round(   tble[1,1]/(tble[1,1]+tble[1,2]),4))}   \n\nrecl_one <-   function(act,pred){ tble = table(act,pred)   \nreturn( round(   tble[2,2]/(tble[2,2]+tble[2,1]),4))}   \n\naccrcy <-   function(act,pred){ tble = table(act,pred)   \nreturn(   round((tble[1,1]+tble[2,2])/sum(tble),4))} \n```", "```py\n# Decision Tree Classifier \n>>> from sklearn.tree import DecisionTreeClassifier \n```", "```py\n >>> dt_fit = DecisionTreeClassifier(criterion=\"gini\", max_depth=5,min_samples_split=2,  min_samples_leaf=1,random_state=42) \n>>> dt_fit.fit(x_train,y_train) \n\n>>> print (\"\\nDecision Tree - Train Confusion  Matrix\\n\\n\", pd.crosstab(y_train, dt_fit.predict(x_train),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))    \n>>> from sklearn.metrics import accuracy_score, classification_report    \n>>> print (\"\\nDecision Tree - Train accuracy\\n\\n\",round(accuracy_score (y_train, dt_fit.predict(x_train)),3)) \n>>> print (\"\\nDecision Tree - Train Classification Report\\n\", classification_report(y_train, dt_fit.predict(x_train))) \n\n>>> print (\"\\n\\nDecision Tree - Test Confusion Matrix\\n\\n\",pd.crosstab(y_test, dt_fit.predict(x_test),rownames = [\"Actuall\"],colnames = [\"Predicted\"])) \n>>> print (\"\\nDecision Tree - Test accuracy\",round(accuracy_score(y_test, dt_fit.predict(x_test)),3)) \n>>> print (\"\\nDecision Tree - Test Classification Report\\n\", classification_report( y_test, dt_fit.predict(x_test))) \n```", "```py\n# Decision Trees using C5.0   package   \nlibrary(C50)   \ndtree_fit = C5.0(train_data[-31],train_data$Attrition_ind,costs   = NULL,control = C5.0Control(minCases = 1))   \nsummary(dtree_fit)   \ntr_y_pred = predict(dtree_fit,   train_data,type = \"class\")   \nts_y_pred =   predict(dtree_fit,test_data,type = \"class\")   \ntr_y_act =   train_data$Attrition_ind;ts_y_act = test_data$Attrition_ind   \n\ntr_tble =   table(tr_y_act,tr_y_pred)   \nprint(paste(\"Train   Confusion Matrix\"))   \nprint(tr_tble)   \ntr_acc =   accrcy(tr_y_act,tr_y_pred)   \ntrprec_zero =   prec_zero(tr_y_act,tr_y_pred);    \ntrrecl_zero =   recl_zero(tr_y_act,tr_y_pred)   \ntrprec_one =   prec_one(tr_y_act,tr_y_pred);    \ntrrecl_one =   recl_one(tr_y_act,tr_y_pred)   \ntrprec_ovll = trprec_zero *frac_trzero   + trprec_one*frac_trone   \ntrrecl_ovll = trrecl_zero   *frac_trzero + trrecl_one*frac_trone   \n\nprint(paste(\"Decision Tree   Train accuracy:\",tr_acc))   \nprint(paste(\"Decision Tree   - Train Classification Report\"))   \nprint(paste(\"Zero_Precision\",trprec_zero,\"Zero_Recall\",trrecl_zero))   \nprint(paste(\"One_Precision\",trprec_one,\"One_Recall\",trrecl_one))   \nprint(paste(\"Overall_Precision\",round(trprec_ovll,4),\"Overall_Recall\",   \nround(trrecl_ovll,4)))   \n ts_tble =   table(ts_y_act,ts_y_pred)   \nprint(paste(\"Test   Confusion Matrix\"))   \nprint(ts_tble)   \n\nts_acc =   accrcy(ts_y_act,ts_y_pred)   \ntsprec_zero =   prec_zero(ts_y_act,ts_y_pred); tsrecl_zero = recl_zero(ts_y_act,ts_y_pred)   \ntsprec_one =   prec_one(ts_y_act,ts_y_pred); tsrecl_one = recl_one(ts_y_act,ts_y_pred)   \n\ntsprec_ovll = tsprec_zero *frac_tszero   + tsprec_one*frac_tsone   \ntsrecl_ovll = tsrecl_zero   *frac_tszero + tsrecl_one*frac_tsone   \n\nprint(paste(\"Decision Tree   Test accuracy:\",ts_acc))   \nprint(paste(\"Decision Tree   - Test Classification Report\"))   \nprint(paste(\"Zero_Precision\",tsprec_zero,\"Zero_Recall\",tsrecl_zero))   \nprint(paste(\"One_Precision\",tsprec_one,\"One_Recall\",tsrecl_one))   \nprint(paste(\"Overall_Precision\",round(tsprec_ovll,4),   \n\"Overall_Recall\",round(tsrecl_ovll,4))) \n```", "```py\n>>> dummyarray = np.empty((6,10))\n>>> dt_wttune = pd.DataFrame(dummyarray)\n```", "```py\n>>> dt_wttune.columns = [\"zero_wght\",\"one_wght\",\"tr_accuracy\", \"tst_accuracy\", \"prec_zero\",\"prec_one\", \"prec_ovll\", \"recl_zero\",\"recl_one\",\"recl_ovll\"] \n```", "```py\n>>> zero_clwghts = [0.01,0.1,0.2,0.3,0.4,0.5] \n\n>>> for i in range(len(zero_clwghts)): \n...    clwght = {0:zero_clwghts[i],1:1.0-zero_clwghts[i]} \n...    dt_fit = DecisionTreeClassifier(criterion=\"gini\",  max_depth=5,               ... min_samples_split=2, min_samples_leaf=1,random_state=42,class_weight = clwght) \n...    dt_fit.fit(x_train,y_train) \n...    dt_wttune.loc[i, 'zero_wght'] = clwght[0]        \n...    dt_wttune.loc[i, 'one_wght'] = clwght[1]      \n...    dt_wttune.loc[i, 'tr_accuracy'] = round(accuracy_score(y_train, dt_fit.predict( x_train)),3)     \n...    dt_wttune.loc[i, 'tst_accuracy'] = round(accuracy_score(y_test,dt_fit.predict( x_test)),3)     \n\n...    clf_sp = classification_report(y_test,dt_fit.predict(x_test)).split() \n...    dt_wttune.loc[i, 'prec_zero'] = float(clf_sp[5])    \n...    dt_wttune.loc[i, 'prec_one'] = float(clf_sp[10])    \n...    dt_wttune.loc[i, 'prec_ovll'] = float(clf_sp[17])    \n\n...    dt_wttune.loc[i, 'recl_zero'] = float(clf_sp[6])    \n...    dt_wttune.loc[i, 'recl_one'] = float(clf_sp[11])    \n...    dt_wttune.loc[i, 'recl_ovll'] = float(clf_sp[18]) \n...    print (\"\\nClass Weights\",clwght,\"Train accuracy:\",round(accuracy_score( y_train,dt_fit.predict(x_train)),3),\"Test accuracy:\",round(accuracy_score(y_test, dt_fit.predict(x_test)),3)) \n...    print (\"Test Confusion Matrix\\n\\n\",pd.crosstab(y_test,dt_fit.predict( x_test),rownames = [\"Actuall\"],colnames = [\"Predicted\"])) \n```", "```py\n#Decision Trees using C5.0   package - Error Costs   \nlibrary(C50)   \nclass_zero_wgt =   c(0.01,0.1,0.2,0.3,0.4,0.5)   \n\nfor (cwt in class_zero_wgt){   \n  cwtz = cwt   \n  cwto = 1-cwtz   \n  cstvr = cwto/cwtz     \n  error_cost <- matrix(c(0,   1, cstvr, 0), nrow = 2)     \n  dtree_fit = C5.0(train_data[-31],train_data$Attrition_ind, \n costs = error_cost,control = C5.0Control(  minCases =   1))   \n  summary(dtree_fit)     \n  tr_y_pred =   predict(dtree_fit, train_data,type = \"class\")   \n  ts_y_pred =   predict(dtree_fit,test_data,type = \"class\")   \n\n  tr_y_act =   train_data$Attrition_ind;   \n  ts_y_act =   test_data$Attrition_ind   \n  tr_acc =   accrcy(tr_y_act,tr_y_pred)   \n  ts_acc =   accrcy(ts_y_act,ts_y_pred)     \n\n  print(paste(\"Class   weights\",\"{0:\",cwtz,\"1:\",cwto,\"}\",   \n              \"Decision   Tree Train accuracy:\",tr_acc,   \n              \"Decision   Tree Test accuracy:\",ts_acc))   \n  ts_tble =   table(ts_y_act,ts_y_pred)   \n  print(paste(\"Test   Confusion Matrix\"))   \n  print(ts_tble)    \n} \n```", "```py\n# Bagging Classifier \n>>> from sklearn.tree import DecisionTreeClassifier\n>>> from sklearn.ensemble import BaggingClassifier\n```", "```py\n>>> dt_fit = DecisionTreeClassifier(criterion=\"gini\", max_depth=5,min_samples_split=2, min_samples_leaf=1,random_state=42,class_weight = {0:0.3,1:0.7}) \n```", "```py\n>>> bag_fit = BaggingClassifier(base_estimator= dt_fit,n_estimators=5000, max_samples=0.67, \n...              max_features=1.0,bootstrap=True, \n...              bootstrap_features=False, n_jobs=-1,random_state=42) \n\n>>> bag_fit.fit(x_train, y_train) \n\n>>> print (\"\\nBagging - Train Confusion Matrix\\n\\n\",pd.crosstab(y_train, bag_fit.predict(x_train),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))       \n>>> print (\"\\nBagging- Train accuracy\",round(accuracy_score(y_train, bag_fit.predict(x_train)),3))  \n>>> print (\"\\nBagging  - Train Classification Report\\n\",classification_report(y_train, bag_fit.predict(x_train))) \n\n>>> print (\"\\n\\nBagging - Test Confusion Matrix\\n\\n\",pd.crosstab(y_test, bag_fit.predict(x_test),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))       \n>>> print (\"\\nBagging - Test accuracy\",round(accuracy_score(y_test, bag_fit.predict(x_test)),3)) \n>>> print (\"\\nBagging - Test Classification Report\\n\",classification_report(y_test, bag_fit.predict(x_test)))\n```", "```py\n# Bagging Classifier - using   Random forest package but all variables selected   \nlibrary(randomForest)   \nset.seed(43)   \nrf_fit = randomForest(Attrition_ind~.,data   = train_data,mtry=30,maxnodes= 64,classwt = c(0.3,0.7), ntree=5000,nodesize =   1)   \ntr_y_pred = predict(rf_fit,data   = train_data,type = \"response\")   \nts_y_pred =   predict(rf_fit,newdata = test_data,type = \"response\")   \ntr_y_act = train_data$Attrition_ind;ts_y_act   = test_data$Attrition_ind   \n\ntr_tble =   table(tr_y_act,tr_y_pred)   \nprint(paste(\"Train   Confusion Matrix\"))   \nprint(tr_tble)   \ntr_acc =   accrcy(tr_y_act,tr_y_pred)   \ntrprec_zero =   prec_zero(tr_y_act,tr_y_pred); trrecl_zero = recl_zero(tr_y_act,tr_y_pred)   \ntrprec_one =   prec_one(tr_y_act,tr_y_pred);    \ntrrecl_one =   recl_one(tr_y_act,tr_y_pred)   \ntrprec_ovll = trprec_zero   *frac_trzero + trprec_one*frac_trone   \ntrrecl_ovll = trrecl_zero   *frac_trzero + trrecl_one*frac_trone   \nprint(paste(\"Random Forest   Train accuracy:\",tr_acc))   \nprint(paste(\"Random Forest   - Train Classification Report\"))   \nprint(paste(\"Zero_Precision\",trprec_zero,\"Zero_Recall\",trrecl_zero))   \nprint(paste(\"One_Precision\",trprec_one,\"One_Recall\",trrecl_one))   \nprint(paste(\"Overall_Precision\",round(trprec_ovll,4),\"Overall_Recall\",   \nround(trrecl_ovll,4)))   \n\nts_tble =   table(ts_y_act,ts_y_pred)   \nprint(paste(\"Test   Confusion Matrix\"))   \nprint(ts_tble)   \nts_acc =   accrcy(ts_y_act,ts_y_pred)   \ntsprec_zero =   prec_zero(ts_y_act,ts_y_pred); tsrecl_zero = recl_zero(ts_y_act,ts_y_pred)   \ntsprec_one =   prec_one(ts_y_act,ts_y_pred);    \ntsrecl_one =   recl_one(ts_y_act,ts_y_pred)   \ntsprec_ovll = tsprec_zero   *frac_tszero + tsprec_one*frac_tsone   \ntsrecl_ovll = tsrecl_zero   *frac_tszero + tsrecl_one*frac_tsone   \nprint(paste(\"Random Forest   Test accuracy:\",ts_acc))   \nprint(paste(\"Random Forest   - Test Classification Report\"))   \nprint(paste(\"Zero_Precision\",tsprec_zero,\"Zero_Recall\",tsrecl_zero))   \nprint(paste(\"One_Precision\",tsprec_one,\"One_Recall\",tsrecl_one))   \nprint(paste(\"Overall_Precision\",round(tsprec_ovll,4),\"Overall_Recall\",   \nround(tsrecl_ovll,4))) \n```", "```py\n# Random Forest Classifier \n>>> from sklearn.ensemble import RandomForestClassifier \n```", "```py\n>>> rf_fit = RandomForestClassifier(n_estimators=5000,criterion=\"gini\", max_depth=5, min_samples_split=2,bootstrap=True,max_features='auto',random_state=42, min_samples_leaf=1,class_weight = {0:0.3,1:0.7}) \n>>> rf_fit.fit(x_train,y_train)        \n\n>>> print (\"\\nRandom Forest - Train Confusion Matrix\\n\\n\",pd.crosstab(y_train, rf_fit.predict(x_train),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))       \n>>> print (\"\\nRandom Forest - Train accuracy\",round(accuracy_score(y_train, rf_fit.predict(x_train)),3)) \n>>> print (\"\\nRandom Forest  - Train Classification Report\\n\",classification_report( y_train, rf_fit.predict(x_train))) \n\n>>> print (\"\\n\\nRandom Forest - Test Confusion Matrix\\n\\n\",pd.crosstab(y_test, rf_fit.predict(x_test),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))       \n>>> print (\"\\nRandom Forest - Test accuracy\",round(accuracy_score(y_test, rf_fit.predict(x_test)),3)) \n>>> print (\"\\nRandom Forest - Test Classification Report\\n\",classification_report( y_test, rf_fit.predict(x_test))) \n```", "```py\n# Plot of Variable importance by mean decrease in gini \n>>> model_ranks = pd.Series(rf_fit.feature_importances_,index=x_train.columns, name='Importance').sort_values(ascending=False, inplace=False) \n>>> model_ranks.index.name = 'Variables' \n>>> top_features = model_ranks.iloc[:31].sort_values(ascending=True,inplace=False) \n>>> import matplotlib.pyplot as plt \n>>> plt.figure(figsize=(20,10)) \n>>> ax = top_features.plot(kind='barh') \n>>> _ = ax.set_title(\"Variable Importance Plot\") \n>>> _ = ax.set_xlabel('Mean decrease in Variance') \n>>> _ = ax.set_yticklabels(top_features.index, fontsize=13) \n```", "```py\n# Random Forest   \nlibrary(randomForest)   \nset.seed(43)   \nrf_fit =   randomForest(Attrition_ind~.,data = train_data,mtry=6, maxnodes= 64,classwt =   c(0.3,0.7),ntree=5000,nodesize = 1)   \ntr_y_pred = predict(rf_fit,data   = train_data,type = \"response\")   \nts_y_pred =   predict(rf_fit,newdata = test_data,type = \"response\")   \ntr_y_act =   train_data$Attrition_ind;ts_y_act = test_data$Attrition_ind   \ntr_tble =   table(tr_y_act,tr_y_pred)   \nprint(paste(\"Train   Confusion Matrix\"))   \nprint(tr_tble)   \ntr_acc =   accrcy(tr_y_act,tr_y_pred)   \ntrprec_zero = prec_zero(tr_y_act,tr_y_pred);   trrecl_zero = recl_zero(tr_y_act,tr_y_pred)   \ntrprec_one =   prec_one(tr_y_act,tr_y_pred); trrecl_one = recl_one(tr_y_act,tr_y_pred)   \ntrprec_ovll = trprec_zero   *frac_trzero + trprec_one*frac_trone   \ntrrecl_ovll = trrecl_zero   *frac_trzero + trrecl_one*frac_trone   \n\nprint(paste(\"Random Forest   Train accuracy:\",tr_acc))   \nprint(paste(\"Random Forest   - Train Classification Report\"))   \nprint(paste(\"Zero_Precision\",trprec_zero,\"Zero_Recall\",trrecl_zero))   \nprint(paste(\"One_Precision\",trprec_one,\"One_Recall\",trrecl_one))   \nprint(paste(\"Overall_Precision\",round(trprec_ovll,4),\"Overall_Recall\",round(trrecl_ovll,4)))   \nts_tble =   table(ts_y_act,ts_y_pred)   \nprint(paste(\"Test   Confusion Matrix\"))   \nprint(ts_tble)   \nts_acc =   accrcy(ts_y_act,ts_y_pred)   \ntsprec_zero = prec_zero(ts_y_act,ts_y_pred);   tsrecl_zero = recl_zero(ts_y_act,ts_y_pred)   \ntsprec_one =   prec_one(ts_y_act,ts_y_pred); tsrecl_one = recl_one(ts_y_act,ts_y_pred)   \ntsprec_ovll = tsprec_zero   *frac_tszero + tsprec_one*frac_tsone   \ntsrecl_ovll = tsrecl_zero   *frac_tszero + tsrecl_one*frac_tsone   \n\nprint(paste(\"Random Forest   Test accuracy:\",ts_acc))   \nprint(paste(\"Random Forest   - Test Classification Report\"))   \nprint(paste(\"Zero_Precision\",tsprec_zero,\"Zero_Recall\",tsrecl_zero))   \nprint(paste(\"One_Precision\",tsprec_one,\"One_Recall\",tsrecl_one))   \nprint(paste(\"Overall_Precision\",round(tsprec_ovll,4),\"Overall_Recall\",round(tsrecl_ovll,4)))   \n```", "```py\n# Random Forest Classifier - Grid Search \n>>> from sklearn.pipeline import Pipeline \n>>> from sklearn.model_selection import train_test_split,GridSearchCV \n\n>>> pipeline = Pipeline([ ('clf',RandomForestClassifier(criterion='gini',class_weight = {0:0.3,1:0.7}))]) \n```", "```py\n>>> parameters = { \n...         'clf__n_estimators':(2000,3000,5000), \n...         'clf__max_depth':(5,15,30), \n...         'clf__min_samples_split':(2,3), \n...         'clf__min_samples_leaf':(1,2)  } \n\n>>> grid_search = GridSearchCV(pipeline,parameters,n_jobs=-1,cv=5,verbose=1, scoring='accuracy') \n>>> grid_search.fit(x_train,y_train) \n\n>>> print ('Best Training score: %0.3f' % grid_search.best_score_) \n>>> print ('Best parameters set:') \n>>> best_parameters = grid_search.best_estimator_.get_params()  \n>>> for param_name in sorted(parameters.keys()): \n...     print ('\\t%s: %r' % (param_name, best_parameters[param_name])) \n\n>>> predictions = grid_search.predict(x_test) \n\n>>> print (\"Testing accuracy:\",round(accuracy_score(y_test, predictions),4)) \n>>> print (\"\\nComplete report of Testing data\\n\",classification_report(y_test, predictions)) \n```", "```py\n>>> print (\"\\n\\nRandom Forest Grid Search- Test Confusion Matrix\\n\\n\",pd.crosstab( y_test, predictions,rownames = [\"Actuall\"],colnames = [\"Predicted\"]))      \n```", "```py\n# Grid Search - Random Forest   \nlibrary(e1071)   \nlibrary(randomForest)   \nrf_grid =   tune(randomForest,Attrition_ind~.,data = train_data,classwt =   c(0.3,0.7),ranges = list( mtry = c(5,6),   \n  maxnodes = c(32,64), ntree =   c(3000,5000), nodesize = c(1,2)   \n),   \ntunecontrol =   tune.control(cross = 5) )   \nprint(paste(\"Best   parameter from Grid Search\"))   \nprint(summary(rf_grid))   \nbest_model = rf_grid$best.model   \ntr_y_pred=predict(best_model,data   = train_data,type =\"response\")   \nts_y_pred=predict(best_model,newdata   = test_data,type= \"response\")   \n\ntr_y_act =   train_data$Attrition_ind;   \nts_y_act= test_data$Attrition_ind   \n\ntr_tble =   table(tr_y_act,tr_y_pred)   \nprint(paste(\"Random Forest   Grid search Train Confusion Matrix\"))   \nprint(tr_tble)   \ntr_acc =   accrcy(tr_y_act,tr_y_pred)   \ntrprec_zero =   prec_zero(tr_y_act,tr_y_pred); trrecl_zero = recl_zero(tr_y_act,tr_y_pred)   \ntrprec_one =   prec_one(tr_y_act,tr_y_pred); trrecl_one = recl_one(tr_y_act,tr_y_pred)   \ntrprec_ovll = trprec_zero   *frac_trzero + trprec_one*frac_trone   \ntrrecl_ovll = trrecl_zero   *frac_trzero + trrecl_one*frac_trone   \n\nprint(paste(\"Random Forest   Grid Search Train accuracy:\",tr_acc))   \nprint(paste(\"Random Forest   Grid Search - Train Classification Report\"))   \nprint(paste(\"Zero_Precision\",trprec_zero,\"Zero_Recall\",trrecl_zero))   \nprint(paste(\"One_Precision\",trprec_one,\"One_Recall\",trrecl_one))   \nprint(paste(\"Overall_Precision\",round(trprec_ovll,4),\"Overall_Recall\",round(trrecl_ovll,4)))   \n\nts_tble =   table(ts_y_act,ts_y_pred)   \nprint(paste(\"Random Forest   Grid search Test Confusion Matrix\"))   \nprint(ts_tble)   \nts_acc =   accrcy(ts_y_act,ts_y_pred)   \ntsprec_zero =   prec_zero(ts_y_act,ts_y_pred); tsrecl_zero = recl_zero(ts_y_act,ts_y_pred)   \ntsprec_one =   prec_one(ts_y_act,ts_y_pred); tsrecl_one = recl_one(ts_y_act,ts_y_pred)   \ntsprec_ovll = tsprec_zero   *frac_tszero + tsprec_one*frac_tsone   \ntsrecl_ovll = tsrecl_zero   *frac_tszero + tsrecl_one*frac_tsone   \n\nprint(paste(\"Random Forest   Grid Search Test accuracy:\",ts_acc))   \nprint(paste(\"Random Forest   Grid Search - Test Classification Report\"))   \nprint(paste(\"Zero_Precision\",tsprec_zero,\"Zero_Recall\",tsrecl_zero))   \nprint(paste(\"One_Precision\",tsprec_one,\"One_Recall\",tsrecl_one))   \nprint(paste(\"Overall_Precision\",round(tsprec_ovll,4),\"Overall_Recall\",round(tsrecl_ovll,4)))\n```", "```py\n# Adaboost Classifier \n>>> from sklearn.tree import DecisionTreeClassifier \n>>> from sklearn.ensemble import AdaBoostClassifier \n```", "```py\n>>> dtree = DecisionTreeClassifier(criterion='gini',max_depth=1) \n```", "```py\n>>>adabst_fit = AdaBoostClassifier(base_estimator= dtree,n_estimators=5000,learning_rate=0.05,random_state=42)\n\n>>>adabst_fit.fit(x_train, y_train)\n>>>print (\"\\nAdaBoost - Train Confusion Matrix\\n\\n\", pd.crosstab(y_train, adabst_fit.predict(x_train), rownames = [\"Actuall\"],colnames = [\"Predicted\"]))\n>>>print (\"\\nAdaBoost - Train accuracy\",round(accuracy_score(y_train,adabst_fit.predict(x_train)), 3))\n>>>print (\"\\nAdaBoost  - Train Classification Report\\n\",classification_report(y_train,adabst_fit.predict(x_train)))\n```", "```py\n# Adaboost classifier using   C5.0 with trails included for boosting   \nlibrary(C50)   \nclass_zero_wgt = 0.3   \nclass_one_wgt = 1-class_zero_wgt   \ncstvr =   class_one_wgt/class_zero_wgt   \nerror_cost <- matrix(c(0, 1,   cstvr, 0), nrow = 2)   \n# Fitting Adaboost model     \nada_fit = C5.0(train_data[-31],train_data$Attrition_ind,costs   = error_cost, trails = 5000,control = C5.0Control(minCases = 1))   \nsummary(ada_fit)   \n\ntr_y_pred = predict(ada_fit,   train_data,type = \"class\")   \nts_y_pred =   predict(ada_fit,test_data,type = \"class\")   \n\ntr_y_act =   train_data$Attrition_ind;ts_y_act = test_data$Attrition_ind   \n\ntr_tble = table(tr_y_act,tr_y_pred)   \nprint(paste(\"AdaBoost -   Train Confusion Matrix\"))   \nprint(tr_tble)   \ntr_acc =   accrcy(tr_y_act,tr_y_pred)   \ntrprec_zero =   prec_zero(tr_y_act,tr_y_pred); trrecl_zero = recl_zero(tr_y_act,tr_y_pred)   \ntrprec_one =   prec_one(tr_y_act,tr_y_pred); trrecl_one = recl_one(tr_y_act,tr_y_pred)   \ntrprec_ovll = trprec_zero   *frac_trzero + trprec_one*frac_trone   \ntrrecl_ovll = trrecl_zero   *frac_trzero + trrecl_one*frac_trone   \nprint(paste(\"AdaBoost   Train accuracy:\",tr_acc))   \nprint(paste(\"AdaBoost -   Train Classification Report\"))   \nprint(paste(\"Zero_Precision\",trprec_zero,\"Zero_Recall\",trrecl_zero))   \nprint(paste(\"One_Precision\",trprec_one,\"One_Recall\",trrecl_one))   \nprint(paste(\"Overall_Precision\",round(trprec_ovll,4),\"Overall_Recall\",round(trrecl_ovll,4)))   \n\nts_tble =   table(ts_y_act,ts_y_pred)   \nprint(paste(\"AdaBoost -   Test Confusion Matrix\"))   \nprint(ts_tble)   \n\nts_acc =   accrcy(ts_y_act,ts_y_pred)   \ntsprec_zero =   prec_zero(ts_y_act,ts_y_pred); tsrecl_zero = recl_zero(ts_y_act,ts_y_pred)   \ntsprec_one =   prec_one(ts_y_act,ts_y_pred); tsrecl_one = recl_one(ts_y_act,ts_y_pred)   \n\ntsprec_ovll = tsprec_zero   *frac_tszero + tsprec_one*frac_tsone   \ntsrecl_ovll = tsrecl_zero   *frac_tszero + tsrecl_one*frac_tsone   \n\nprint(paste(\"AdaBoost Test   accuracy:\",ts_acc))   \nprint(paste(\"AdaBoost -   Test Classification Report\"))   \nprint(paste(\"Zero_Precision\",tsprec_zero,\"Zero_Recall\",tsrecl_zero))   \nprint(paste(\"One_Precision\",tsprec_one,\"One_Recall\",tsrecl_one))   \nprint(paste(\"Overall_Precision\",round(tsprec_ovll,4),\"Overall_Recall\",round(tsrecl_ovll,4)))   \n```", "```py\n# Gradientboost Classifier\n>>> from sklearn.ensemble import GradientBoostingClassifier\n```", "```py\n>>> gbc_fit = GradientBoostingClassifier (loss='deviance', learning_rate=0.05, n_estimators=5000, min_samples_split=2, min_samples_leaf=1, max_depth=1, random_state=42 ) \n\n```", "```py\n>>> gbc_fit.fit(x_train,y_train) \n>>> print (\"\\nGradient Boost - Train Confusion Matrix\\n\\n\",pd.crosstab(y_train, gbc_fit.predict(x_train),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))\n>>> print (\"\\nGradient Boost - Train accuracy\",round(accuracy_score(y_train, gbc_fit.predict(x_train)),3))\n>>> print (\"\\nGradient Boost - Train Classification Report\\n\",classification_report( y_train, gbc_fit.predict(x_train)))\n\n>>> print (\"\\n\\nGradient Boost - Test Confusion Matrix\\n\\n\",pd.crosstab(y_test, gbc_fit.predict(x_test),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))\n>>> print (\"\\nGradient Boost - Test accuracy\",round(accuracy_score(y_test, gbc_fit.predict(x_test)),3)) >>> print (\"\\nGradient Boost - Test Classification Report\\n\",classification_report( y_test, gbc_fit.predict(x_test)))\n```", "```py\n# Gradient boosting\nlibrary(gbm)\n\nlibrary(caret)\nset.seed(43)\n# Giving weights to all the observations in a way that total #weights will \nbe euqal 1\nmodel_weights <- ifelse(train_data$Attrition_ind == \"0\",\n (1/table(train_data$Attrition_ind)[1]) * 0.3,\n (1/table(train_data$Attrition_ind)[2]) * 0.7)\n# Setting parameters for GBM\ngrid <- expand.grid(n.trees = 5000, interaction.depth = 1, shrinkage = .04, n.minobsinnode = 1)\n# Fitting the GBM model\ngbm_fit <- train(Attrition_ind ~ ., data = train_data, method = \"gbm\", weights = model_weights,\n tuneGrid=grid,verbose = FALSE)\n# To print variable importance plot\nsummary(gbm_fit)\n\ntr_y_pred = predict(gbm_fit, train_data,type = \"raw\")\nts_y_pred = predict(gbm_fit,test_data,type = \"raw\")\ntr_y_act = train_data$Attrition_ind;ts_y_act = test_data$Attrition_ind\n\ntr_tble = table(tr_y_act,tr_y_pred)\nprint(paste(\"Gradient Boosting - Train Confusion Matrix\"))\nprint(tr_tble)\n\ntr_acc = accrcy(tr_y_act,tr_y_pred)\ntrprec_zero = prec_zero(tr_y_act,tr_y_pred); trrecl_zero = \nrecl_zero(tr_y_act,tr_y_pred)\ntrprec_one = prec_one(tr_y_act,tr_y_pred); trrecl_one = recl_one(tr_y_act,tr_y_pred)\n\ntrprec_ovll = trprec_zero *frac_trzero + trprec_one*frac_trone\ntrrecl_ovll = trrecl_zero *frac_trzero + trrecl_one*frac_trone\n\nprint(paste(\"Gradient Boosting Train accuracy:\",tr_acc))\nprint(paste(\"Gradient Boosting - Train Classification Report\"))\nprint(paste(\"Zero_Precision\",trprec_zero,\"Zero_Recall\",trrecl_zero))\nprint(paste(\"One_Precision\",trprec_one,\"One_Recall\",trrecl_one))\nprint(paste(\"Overall_Precision\",round(trprec_ovll,4),\"Overall_Recall\",round(trrecl_ovll,4)))\n\nts_tble = table(ts_y_act,ts_y_pred)\nprint(paste(\"Gradient Boosting - Test Confusion Matrix\"))\nprint(ts_tble)\nts_acc = accrcy(ts_y_act,ts_y_pred)\ntsprec_zero = prec_zero(ts_y_act,ts_y_pred); tsrecl_zero = \nrecl_zero(ts_y_act,ts_y_pred)\ntsprec_one = prec_one(ts_y_act,ts_y_pred); tsrecl_one = recl_one(ts_y_act,ts_y_pred)\ntsprec_ovll = tsprec_zero *frac_tszero + tsprec_one*frac_tsone\ntsrecl_ovll = tsrecl_zero *frac_tszero + tsrecl_one*frac_tsone\nprint(paste(\"Gradient Boosting Test accuracy:\",ts_acc))\nprint(paste(\"Gradient Boosting - Test Classification Report\"))\nprint(paste(\"Zero_Precision\",tsprec_zero,\"Zero_Recall\",tsrecl_zero))\nprint(paste(\"One_Precision\",tsprec_one,\"One_Recall\",tsrecl_one))\nprint(paste(\"Overall_Precision\",round(tsprec_ovll,4),\"Overall_Recall\",round(tsrecl_ovll,4)))\n\n# Use the following code for performing cross validation on data - At the moment commented though\n#fitControl <- trainControl(method = \"repeatedcv\", number = 4, repeats = 4)\n# gbmFit1 <- train(Attrition_ind ~ ., data = train_data,\nmethod = # \"gbm\", trControl = fitControl,tuneGrid=grid,verbose = FALSE)\n```", "```py\n# Xgboost Classifier\n>>> import xgboost as xgb\n>>> xgb_fit = xgb.XGBClassifier(max_depth=2, n_estimators=5000, \nlearning_rate=0.05)\n>>> xgb_fit.fit(x_train, y_train)\n\n>>> print (\"\\nXGBoost - Train Confusion Matrix\\n\\n\",pd.crosstab(y_train, xgb_fit.predict(x_train),rownames = [\"Actuall\"],colnames = [\"Predicted\"])) \n>>> print (\"\\nXGBoost - Train accuracy\",round(accuracy_score(y_train, xgb_fit.predict(x_train)),3))\n>>> print (\"\\nXGBoost  - Train Classification Report\\n\",classification_report(y_train, xgb_fit.predict(x_train)))\n>>> print (\"\\n\\nXGBoost - Test Confusion Matrix\\n\\n\",pd.crosstab(y_test, xgb_fit.predict(x_test),rownames = [\"Actuall\"],colnames = [\"Predicted\"])) \n>>> print (\"\\nXGBoost - Test accuracy\",round(accuracy_score(y_test, xgb_fit.predict(x_test)),3))\n>>> print (\"\\nXGBoost - Test Classification Report\\n\",classification_report(y_test, xgb_fit.predict(x_test)))\n```", "```py\n# Xgboost Classifier\nlibrary(xgboost); library(caret)\n\nhrattr_data = read.csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")\nstr(hrattr_data); summary(hrattr_data)\n# Target variable creation\nhrattr_data$Attrition_ind = 0;\nhrattr_data$Attrition_ind[hrattr_data$Attrition==\"Yes\"]=1\n\n# Columns to be removed due to no change in its value across observations\nremove_cols = c(\"EmployeeCount\",\"EmployeeNumber\",\"Over18\",\"StandardHours\",\"Attrition\")\nhrattr_data_new = hrattr_data[,!(names(hrattr_data) %in% remove_cols)] \n# List of  variables with continuous values \ncontinuous_columns = c('Age','DailyRate', 'DistanceFromHome', 'Education', 'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction','MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears',  'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager')\n\n# list of categorical variables\nohe_feats = c('BusinessTravel', 'Department', 'EducationField','Gender','JobRole', 'MaritalStatus', 'OverTime')\n\n# one-hot-encoding categorical features\ndummies <- dummyVars(~ BusinessTravel+Department+ EducationField+Gender+JobRole+MaritalStatus+OverTime, data = hrattr_data_new)\ndf_all_ohe <- as.data.frame(predict(dummies, newdata = hrattr_data_new))\n\n# Cleaning column names and replace . with _\n\ncolClean <- function(x){ colnames(x) <- gsub(\"\\\\.\", \"_\", colnames(x)); x }\ndf_all_ohe = colClean(df_all_ohe)\n\nhrattr_data_new$Attrition_ind = as.integer(hrattr_data_new$Attrition_ind)\n\n# Combining both continuous and dummy variables from categories\nhrattr_data_v3 = cbind(df_all_ohe,hrattr_data_new [,(names(hrattr_data_new) %in% continuous_columns)], hrattr_data_new$Attrition_ind)\n\nnames(hrattr_data_v3)[52] = \"Attrition_ind\"\n\n# Train and Test split based on 70% and 30%\nset.seed(123)\nnumrow = nrow(hrattr_data_v3)\ntrnind = sample(1:numrow,size = as.integer(0.7*numrow))\ntrain_data = hrattr_data_v3[trnind,]\ntest_data = hrattr_data_v3[-trnind,]\n\n# Custom functions for calculation of Precision and Recall\nfrac_trzero = (table(train_data$Attrition_ind)[[1]])/nrow(train_data)\nfrac_trone = (table(train_data$Attrition_ind)[[2]])/nrow(train_data)\n\nfrac_tszero = (table(test_data$Attrition_ind)[[1]])/nrow(test_data)\nfrac_tsone = (table(test_data$Attrition_ind)[[2]])/nrow(test_data)\nprec_zero <- function(act,pred){  tble = table(act,pred)\nreturn( round( tble[1,1]/(tble[1,1]+tble[2,1]),4)  ) }\n\nprec_one <- function(act,pred){ tble = table(act,pred)\nreturn( round( tble[2,2]/(tble[2,2]+tble[1,2]),4)   ) }\n\nrecl_zero <- function(act,pred){tble = table(act,pred)\nreturn( round( tble[1,1]/(tble[1,1]+tble[1,2]),4)   ) }\n\nrecl_one <- function(act,pred){ tble = table(act,pred)\nreturn( round( tble[2,2]/(tble[2,2]+tble[2,1]),4)  ) }\n\naccrcy <- function(act,pred){ tble = table(act,pred)\nreturn( round((tble[1,1]+tble[2,2])/sum(tble),4)) }\n\ny = train_data$Attrition_ind\n\n# XGBoost Classifier Training\nxgb <- xgboost(data = data.matrix(train_data[,-52]),label = y,eta = 0.04,max_depth = 2, nround=5000, subsample = 0.5, colsample_bytree = 0.5, seed = 1, eval_metric = \"logloss\", objective = \"binary:logistic\",nthread = 3)\n\n# XGBoost value prediction on train and test data\ntr_y_pred_prob <- predict(xgb, data.matrix(train_data[,-52]))\ntr_y_pred <- as.numeric(tr_y_pred_prob > 0.5)\nts_y_pred_prob <- predict(xgb, data.matrix(test_data[,-52]))\nts_y_pred <- as.numeric(ts_y_pred_prob > 0.5)\ntr_y_act = train_data$Attrition_ind;ts_y_act = test_data$Attrition_ind\ntr_tble = table(tr_y_act,tr_y_pred)\n\n# XGBoost Metric predictions on Train Data\nprint(paste(\"Xgboost - Train Confusion Matrix\"))\nprint(tr_tble)\ntr_acc = accrcy(tr_y_act,tr_y_pred)\ntrprec_zero = prec_zero(tr_y_act,tr_y_pred); trrecl_zero = recl_zero(tr_y_act,tr_y_pred)\ntrprec_one = prec_one(tr_y_act,tr_y_pred); trrecl_one = recl_one(tr_y_act,tr_y_pred)\ntrprec_ovll = trprec_zero *frac_trzero + trprec_one*frac_trone\ntrrecl_ovll = trrecl_zero *frac_trzero + trrecl_one*frac_trone\n\nprint(paste(\"Xgboost Train accuracy:\",tr_acc))\nprint(paste(\"Xgboost - Train Classification Report\"))\nprint(paste(\"Zero_Precision\",trprec_zero,\"Zero_Recall\",trrecl_zero))\nprint(paste(\"One_Precision\",trprec_one,\"One_Recall\",trrecl_one))\nprint(paste(\"Overall_Precision\",round(trprec_ovll,4),\"Overall_Recall\",round(trrecl_ovll,4)))\n\n# XGBoost Metric predictions on Test Data\nts_tble = table(ts_y_act,ts_y_pred)\nprint(paste(\"Xgboost - Test Confusion Matrix\"))\nprint(ts_tble)\nts_acc = accrcy(ts_y_act,ts_y_pred)\ntsprec_zero = prec_zero(ts_y_act,ts_y_pred); tsrecl_zero = recl_zero(ts_y_act,ts_y_pred)\ntsprec_one = prec_one(ts_y_act,ts_y_pred); tsrecl_one = recl_one(ts_y_act,ts_y_pred)\ntsprec_ovll = tsprec_zero *frac_tszero + tsprec_one*frac_tsone\ntsrecl_ovll = tsrecl_zero *frac_tszero + tsrecl_one*frac_tsone\n\nprint(paste(\"Xgboost Test accuracy:\",ts_acc))\nprint(paste(\"Xgboost - Test Classification Report\"))\nprint(paste(\"Zero_Precision\",tsprec_zero,\"Zero_Recall\",tsrecl_zero))\nprint(paste(\"One_Precision\",tsprec_one,\"One_Recall\",tsrecl_one))\nprint(paste(\"Overall_Precision\",round(tsprec_ovll,4),\"Overall_Recall\",round(tsrecl_ovll,4)))\n```", "```py\n#Ensemble of Ensembles - by fitting various classifiers\n>>> clwght = {0:0.3,1:0.7}\n\n# Classifier 1 – Logistic Regression\n>>> from sklearn.linear_model import LogisticRegression\n>>> clf1_logreg_fit = LogisticRegression(fit_intercept=True,class_weight=clwght)\n>>> clf1_logreg_fit.fit(x_train,y_train)\n\n>>> print (\"\\nLogistic Regression for Ensemble - Train Confusion Matrix\\n\\n\",pd.crosstab( y_train, clf1_logreg_fit.predict(x_train),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))\n>>> print (\"\\nLogistic Regression for Ensemble - Train accuracy\",round( accuracy_score(y_train,clf1_logreg_fit.predict(x_train)),3))\n>>> print (\"\\nLogistic Regression for Ensemble - Train Classification Report\\n\", classification_report(y_train,clf1_logreg_fit.predict(x_train)))\n>>> print (\"\\n\\nLogistic Regression for Ensemble - Test Confusion Matrix\\n\\n\",pd.crosstab( y_test,clf1_logreg_fit.predict(x_test),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))     >\n>> print (\"\\nLogistic Regression for Ensemble - Test accuracy\",round( accuracy_score(y_test,clf1_logreg_fit.predict(x_test)),3))\n>>> print (\"\\nLogistic Regression for Ensemble - Test Classification Report\\n\", classification_report( y_test,clf1_logreg_fit.predict(x_test)))\n\n# Classifier 2 – Decision Tree\n>>> from sklearn.tree import DecisionTreeClassifier\n>>> clf2_dt_fit = DecisionTreeClassifier(criterion=\"gini\", max_depth=5, min_samples_split=2, min_samples_leaf=1, random_state=42, class_weight=clwght)\n>>> clf2_dt_fit.fit(x_train,y_train)\n\n>>> print (\"\\nDecision Tree for Ensemble - Train Confusion Matrix\\n\\n\",pd.crosstab( y_train, clf2_dt_fit.predict(x_train),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))\n>>> print (\"\\nDecision Tree for Ensemble - Train accuracy\", round(accuracy_score( y_train,clf2_dt_fit.predict(x_train)),3))\n>>> print (\"\\nDecision Tree for Ensemble - Train Classification Report\\n\", classification_report(y_train,clf2_dt_fit.predict(x_train)))\n>>> print (\"\\n\\nDecision Tree for Ensemble - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, clf2_dt_fit.predict(x_test),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))\n>>> print (\"\\nDecision Tree for Ensemble - Test accuracy\",round(accuracy_score(y_test, clf2_dt_fit.predict(x_test)),3))\n\n>>> print (\"\\nDecision Tree for Ensemble - Test Classification Report\\n\", classification_report(y_test, clf2_dt_fit.predict(x_test)))\n\n# Classifier 3 – Random Forest\n>>> from sklearn.ensemble import RandomForestClassifier\n>>> clf3_rf_fit = RandomForestClassifier(n_estimators=10000, criterion=\"gini\", max_depth=6, min_samples_split=2,min_samples_leaf=1,class_weight = clwght)\n>>> clf3_rf_fit.fit(x_train,y_train)\n\n>>> print (\"\\nRandom Forest for Ensemble - Train Confusion Matrix\\n\\n\", pd.crosstab(y_train, clf3_rf_fit.predict(x_train),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))\n>>> print (\"\\nRandom Forest for Ensemble - Train accuracy\",round(accuracy_score( y_train,clf3_rf_fit.predict(x_train)),3))\n>>> print (\"\\nRandom Forest for Ensemble - Train Classification Report\\n\", classification_report(y_train,clf3_rf_fit.predict(x_train))) \n>>> print (\"\\n\\nRandom Forest for Ensemble - Test Confusion Matrix\\n\\n\",pd.crosstab( y_test, clf3_rf_fit.predict(x_test),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))     \n>>> print (\"\\nRandom Forest for Ensemble - Test accuracy\",round(accuracy_score( y_test,clf3_rf_fit.predict(x_test)),3))\n>>> print (\"\\nRandom Forest for Ensemble - Test Classification Report\\n\", classification_report(y_test,clf3_rf_fit.predict(x_test))) \n# Classifier 4 – Adaboost classifier\n>>> from sklearn.ensemble import AdaBoostClassifier\n>>> clf4_dtree = DecisionTreeClassifier(criterion='gini',max_depth=1,class_weight = clwght)\n>>> clf4_adabst_fit = AdaBoostClassifier(base_estimator= clf4_dtree,\n                n_estimators=5000,learning_rate=0.05,random_state=42)\n>>> clf4_adabst_fit.fit(x_train, y_train)\n>>> print (\"\\nAdaBoost for Ensemble  - Train Confusion Matrix\\n\\n\",pd.crosstab(y_train, clf4_adabst_fit.predict(x_train),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))     \n>>> print (\"\\nAdaBoost for Ensemble   - Train accuracy\",round(accuracy_score(y_train, clf4_adabst_fit.predict(x_train)),3))\n>>> print (\"\\nAdaBoost for Ensemble   - Train Classification Report\\n\", classification_report(y_train,clf4_adabst_fit.predict(x_train)))\n>>> print (\"\\n\\nAdaBoost for Ensemble   - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, clf4_adabst_fit.predict(x_test),rownames = [\"Actuall\"],colnames = [\"Predicted\"]))     \n>>> print (\"\\nAdaBoost for Ensemble   - Test accuracy\",round(accuracy_score(y_test, clf4_adabst_fit.predict(x_test)),3))\n>>> print (\"\\nAdaBoost for Ensemble  - Test Classification Report\\n\", classification_report(y_test, clf4_adabst_fit.predict(x_test)))\n```", "```py\n>> ensemble = pd.DataFrame() \n```", "```py\n>>> ensemble[\"log_output_one\"] = pd.DataFrame(clf1_logreg_fit.predict_proba( x_train))[1]\n>>> ensemble[\"dtr_output_one\"] = pd.DataFrame(clf2_dt_fit.predict_proba(x_train))[1]\n>>> ensemble[\"rf_output_one\"] = pd.DataFrame(clf3_rf_fit.predict_proba(x_train))[1]\n>>> ensemble[\"adb_output_one\"] = pd.DataFrame(clf4_adabst_fit.predict_proba( x_train))[1]\n>>> ensemble = pd.concat([ensemble,pd.DataFrame(y_train).reset_index(drop = True )],axis=1)\n\n# Fitting meta-classifier\n>>> meta_logit_fit =  LogisticRegression(fit_intercept=False)\n>>> meta_logit_fit.fit(ensemble[['log_output_one', 'dtr_output_one', 'rf_output_one', 'adb_output_one']],ensemble['Attrition_ind'])\n>>> coefs =  meta_logit_fit.coef_\n>>> ensemble_test = pd.DataFrame()\n>>> ensemble_test[\"log_output_one\"] = pd.DataFrame(clf1_logreg_fit.predict_proba( x_test))[1]\n>>> ensemble_test[\"dtr_output_one\"] = pd.DataFrame(clf2_dt_fit.predict_proba( x_test))[1] \n>>> ensemble_test[\"rf_output_one\"] = pd.DataFrame(clf3_rf_fit.predict_proba( x_test))[1]\n>>> ensemble_test[\"adb_output_one\"] = pd.DataFrame(clf4_adabst_fit.predict_proba( x_test))[1]\n>>> coefs =  meta_logit_fit.coef_\n>>> ensemble_test = pd.DataFrame()\n>>> ensemble_test[\"log_output_one\"] = pd.DataFrame(clf1_logreg_fit.predict_proba( x_test))[1]\n>>> ensemble_test[\"dtr_output_one\"] = pd.DataFrame(clf2_dt_fit.predict_proba( x_test))[1]\n>>> ensemble_test[\"rf_output_one\"] = pd.DataFrame(clf3_rf_fit.predict_proba( x_test))[1]\n>>> ensemble_test[\"adb_output_one\"] = pd.DataFrame(clf4_adabst_fit.predict_proba( x_test))[1]\n>>> print (\"\\n\\nEnsemble of Models - Test Confusion Matrix\\n\\n\",pd.crosstab( ensemble_test['Attrition_ind'],ensemble_test['all_one'],rownames = [\"Actuall\"], colnames = [\"Predicted\"])) \n>>> print (\"\\nEnsemble of Models - Test accuracy\",round(accuracy_score (ensemble_test['Attrition_ind'],ensemble_test['all_one']),3))\n>>> print (\"\\nEnsemble of Models - Test Classification Report\\n\", classification_report( ensemble_test['Attrition_ind'], ensemble_test['all_one']))\n```", "```py\n>>> coefs = meta_logit_fit.coef_\n>>> print (\"Co-efficients for LR, DT, RF and AB are:\",coefs)\n```", "```py\n# Ensemble of Ensembles with different type of Classifiers setwd \n(\"D:\\\\Book writing\\\\Codes\\\\Chapter 4\") \n\nhrattr_data = read.csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\") \nstr(hrattr_data) \nsummary(hrattr_data) \n\nhrattr_data$Attrition_ind = 0; hrattr_data$Attrition_ind[hrattr_data$Attrition==\"Yes\"]=1 \nhrattr_data$Attrition_ind = as.factor(hrattr_data$Attrition_ind) \n\nremove_cols = c (\"EmployeeCount\",\"EmployeeNumber\",\"Over18\",  \"StandardHours\",\"Attrition\")\nhrattr_data_new = hrattr_data[,!(names(hrattr_data) %in% remove_cols)]\n\nset.seed(123)\nnumrow = nrow(hrattr_data_new)\ntrnind = sample(1:numrow,size = as.integer(0.7*numrow))\ntrain_data = hrattr_data_new[trnind,]\ntest_data = hrattr_data_new[-trnind,]\n\n# Ensemble of Ensembles with different type of Classifiers train_data$Attrition_ind = as.factor(train_data$Attrition_ind)\n\n# Classifier 1 - Logistic Regression\nglm_fit = glm(Attrition_ind ~.,family = \"binomial\",data = train_data) glm_probs = predict(glm_fit,newdata = train_data,type = \"response\")\n\n# Classifier 2 - Decision Tree classifier\nlibrary(C50) \ndtree_fit = C5.0(train_data[-31],train_data$Attrition_ind,\n control = C5.0Control(minCases = 1))\ndtree_probs = predict(dtree_fit,newdata = train_data,type = \"prob\")[,2]\n\n# Classifier 3 - Random Forest\nlibrary(randomForest)\nrf_fit = randomForest(Attrition_ind~., data = train_data,mtry=6,maxnodes= 64,ntree=5000,nodesize = 1)\nrf_probs = predict(rf_fit,newdata = train_data,type = \"prob\")[,2]\n\n# Classifier 4 - Adaboost\nada_fit = C5.0(train_data[-31],train_data$Attrition_ind,trails = 5000,control = C5.0Control(minCases = 1))\nada_probs = predict(ada_fit,newdata = train_data,type = \"prob\")[,2]\n\n# Ensemble of Models\nensemble = data.frame(glm_probs,dtree_probs,rf_probs,ada_probs)\nensemble = cbind(ensemble,train_data$Attrition_ind)\nnames(ensemble)[5] = \"Attrition_ind\"\nrownames(ensemble) <- 1:nrow(ensemble)\n\n# Meta-classifier on top of individual classifiers\nmeta_clf = glm(Attrition_ind~.,data = ensemble,family = \"binomial\")\nmeta_probs = predict(meta_clf, ensemble,type = \"response\")\n\nensemble$pred_class = 0\nensemble$pred_class[meta_probs>0.5]=1\n\n# Train confusion and accuracy metrics\ntr_y_pred = ensemble$pred_class\ntr_y_act = train_data$Attrition_ind;ts_y_act = test_data$Attrition_ind\ntr_tble = table(tr_y_act,tr_y_pred)\nprint(paste(\"Ensemble - Train Confusion Matrix\"))\nprint(tr_tble)\n\ntr_acc = accrcy(tr_y_act,tr_y_pred)\nprint(paste(\"Ensemble Train accuracy:\",tr_acc))\n\n# Now verifing on test data\nglm_probs = predict(glm_fit,newdata = test_data,type = \"response\")\ndtree_probs = predict(dtree_fit,newdata = test_data,type = \"prob\")[,2]\nrf_probs = predict(rf_fit,newdata = test_data,type = \"prob\")[,2]\nada_probs = predict(ada_fit,newdata = test_data,type = \"prob\")[,2]\n\nensemble_test = data.frame(glm_probs,dtree_probs,rf_probs,ada_probs)\nensemble_test = cbind(ensemble_test,test_data$Attrition_ind)\nnames(ensemble_test)[5] = \"Attrition_ind\"\n\nrownames(ensemble_test) <- 1:nrow(ensemble_test)\nmeta_test_probs = predict(meta_clf,newdata = ensemble_test,type = \"response\")\nensemble_test$pred_class = 0\nensemble_test$pred_class[meta_test_probs>0.5]=1\n\n# Test confusion and accuracy metrics\nts_y_pred = ensemble_test$pred_class\nts_tble = table(ts_y_act,ts_y_pred)\nprint(paste(\"Ensemble - Test Confusion Matrix\"))\nprint(ts_tble)\n\nts_acc = accrcy(ts_y_act,ts_y_pred)\nprint(paste(\"Ensemble Test accuracy:\",ts_acc))\n```", "```py\n# Ensemble of Ensembles - by applying bagging on simple classifier \n>>> from sklearn.tree import DecisionTreeClassifier \n>>> from sklearn.ensemble import BaggingClassifier \n>>> from sklearn.ensemble import AdaBoostClassifier \n>>> clwght = {0:0.3,1:0.7}\n```", "```py\n>>> eoe_dtree = DecisionTreeClassifier(criterion='gini',max_depth=1,class_weight = clwght)\n```", "```py\n>>> eoe_adabst_fit = AdaBoostClassifier(base_estimator= eoe_dtree, n_estimators=500,learning_rate=0.05,random_state=42) \n>>> eoe_adabst_fit.fit(x_train, y_train) \n\n>>> print (\"\\nAdaBoost - Train Confusion Matrix\\n\\n\",pd.crosstab(y_train, eoe_adabst_fit.predict(x_train),rownames = [\"Actuall\"],colnames = [\"Predicted\"])) \n>>> print (\"\\nAdaBoost - Train accuracy\",round(accuracy_score(y_train, eoe_adabst_fit.predict(x_train)),3)) \n>>> print (\"\\nAdaBoost - Train Classification Report\\n\",classification_report(y_train, eoe_adabst_fit.predict(x_train))) \n\n>>> print (\"\\n\\nAdaBoost - Test Confusion Matrix\\n\\n\",pd.crosstab(y_test, eoe_adabst_fit.predict(x_test),rownames = [\"Actuall\"],colnames = [\"Predicted\"])) \n>>> print (\"\\nAdaBoost - Test accuracy\",round(accuracy_score(y_test, eoe_adabst_fit.predict(x_test)),3)) \n>>> print (\"\\nAdaBoost - Test Classification Report\\n\",classification_report(y_test, eoe_adabst_fit.predict(x_test)))\n```", "```py\n>>> bag_fit = BaggingClassifier(base_estimator= eoe_adabst_fit,n_estimators=50,\nmax_samples=1.0,max_features=1.0, bootstrap=True,\nbootstrap_features=False,n_jobs=-1,random_state=42) \n>>> bag_fit.fit(x_train, y_train) \n>>> print (\"\\nEnsemble of AdaBoost - Train Confusion Matrix\\n\\n\",pd.crosstab( y_train,bag_fit.predict(x_train),rownames = [\"Actuall\"],colnames = [\"Predicted\"])) \n>>> print (\"\\nEnsemble of AdaBoost - Train accuracy\",round(accuracy_score(y_train, bag_fit.predict(x_train)),3))\n>>> print (\"\\nEnsemble of AdaBoost - Train Classification Report\\n\", classification_report( y_train,bag_fit.predict(x_train))) \n\n>>> print (\"\\n\\nEnsemble of AdaBoost - Test Confusion Matrix\\n\\n\",pd.crosstab(y_test, bag_fit.predict(x_test),rownames = [\"Actuall\"],colnames = [\"Predicted\"])) \n>>> print (\"\\nEnsemble of AdaBoost - Test accuracy\",round(accuracy_score(y_test,bag_fit.predict(x_test)),3)) \n>>> print (\"\\nEnsemble of AdaBoost - Test Classification Report\\n\", classification_report(y_test,bag_fit.predict(x_test)))\n```"]