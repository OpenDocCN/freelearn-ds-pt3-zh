- en: Chapter 4. Profiling and Optimization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章：性能分析与优化
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Evaluating the time taken by a statement in IPython
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 IPython 中评估语句所花费的时间
- en: Profiling your code easily with cProfile and IPython
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 cProfile 和 IPython 轻松分析代码
- en: Profiling your code line-by-line with line_profiler
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `line_profiler` 逐行分析代码的性能
- en: Profiling the memory usage of your code with memory_profiler
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `memory_profiler` 分析代码的内存使用情况
- en: Understanding the internals of NumPy to avoid unnecessary array copying
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 NumPy 的内部机制，以避免不必要的数组复制
- en: Using stride tricks with NumPy
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 NumPy 的跨步技巧
- en: Implementing an efficient rolling average algorithm with stride tricks
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用跨步技巧实现高效的滚动平均算法
- en: Making efficient array selections in NumPy
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 NumPy 中进行高效的数组选择
- en: Processing huge NumPy arrays with memory mapping
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用内存映射处理超大的 NumPy 数组
- en: Manipulating large arrays with HDF5 and PyTables
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 HDF5 和 PyTables 操作大数组
- en: Manipulating large heterogeneous tables with HDF5 and PyTables
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 HDF5 和 PyTables 操作大规模异构数据表
- en: Introduction
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: Although Python is generally known (a bit unfairly) as a *slow* language, it
    is possible to achieve very good performance with the right methods. This is the
    objective of this chapter and the next. This chapter describes how to evaluate
    (**profile**) what makes a program slow, and how this information can be used
    to **optimize** the code and make it more efficient. The next chapter will deal
    with more advanced high-performance computing methods that should only be tackled
    when the methods described here are not sufficient.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Python 通常被认为是（有点不公平地）*较慢*的语言，但通过使用正确的方法，实际上可以实现非常好的性能。这就是本章和下一章的目标。本章将介绍如何评估（**分析**）程序变慢的原因，以及如何利用这些信息来**优化**代码，使其更加高效。下一章将讨论一些更高级的高性能计算方法，只有在本章中描述的方法不足以解决问题时才应采用。
- en: 'The recipes of this chapter are organized into three parts:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的内容分为三个部分：
- en: '**Time and memory profiling**: Evaluating the performance of code'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间和内存性能分析**：评估代码的性能'
- en: '**NumPy optimization**: Using NumPy more efficiently, particularly with large
    arrays'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NumPy 优化**：更高效地使用 NumPy，特别是在处理大数组时'
- en: '**Memory mapping with arrays**: Implementing memory mapping techniques for
    out-of-core computations on huge arrays, notably with the HDF5 file format'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存映射与数组**：为超大数组的外存计算实现内存映射技术，特别是使用 HDF5 文件格式'
- en: Evaluating the time taken by a statement in IPython
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 IPython 中评估语句所花费的时间
- en: The `%timeit` magic and the `%%timeit` cell magic (that applies to an entire
    code cell) allow you to quickly evaluate the time taken by one or several Python
    statements. For more extensive profiling, you may need to use more advanced methods
    presented in the next recipes.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`%timeit` 魔法命令和 `%%timeit` 单元格魔法命令（适用于整个代码单元）允许你快速评估一个或多个 Python 语句所花费的时间。对于更全面的性能分析，你可能需要使用本章后续介绍的更高级方法。'
- en: How to do it...
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'We are going to estimate the time taken to calculate the sum of the inverse
    squares of all positive integer numbers up to a given `n`:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将估算计算所有正整数的倒数平方和，直到给定的 `n` 所需的时间：
- en: 'Let''s define `n`:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义 `n`：
- en: '[PRE0]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s time this computation in pure Python:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在纯 Python 中计时这段计算：
- en: '[PRE1]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, let''s use the `%%timeit` cell magic to time the same computation written
    on two lines:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们使用 `%%timeit` 单元格魔法命令来计时将相同的计算分成两行代码：
- en: '[PRE2]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, let''s time the NumPy version of this computation:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们计时使用 NumPy 版本的计算：
- en: '[PRE3]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: How it works...
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `%timeit` command accepts several optional parameters. One such parameter
    is the number of statement evaluations. By default, this number is chosen automatically
    so that the `%timeit` command returns within a few seconds. However, this number
    can be specified directly with the `-r` and `-n` parameters. Type `%timeit?` in
    IPython to get more information.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`%timeit` 命令接受多个可选参数。其中一个参数是语句评估的次数。默认情况下，这个次数会自动选择，以确保 `%timeit` 命令在几秒钟内返回。然而，你也可以通过
    `-r` 和 `-n` 参数直接指定这个次数。在 IPython 中输入 `%timeit?` 以获取更多信息。'
- en: The `%%timeit` cell magic also accepts an optional setup statement in the first
    line (on the same line as `%%timeit`), which is executed but not timed. All variables
    created in this statement are available inside the cell.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`%%timeit` 单元格魔法命令还接受一个可选的设置语句（位于 `%%timeit` 的同一行），该语句会被执行，但不计时。所有在此语句中创建的变量都可以在单元格内部使用。'
- en: There's more...
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: If you are not in an IPython interactive session, you can use `timeit.timeit()`.
    This function, defined in Python's `timeit` module, benchmarks a Python statement
    stored in a string. IPython's `%timeit` magic command is a convenient wrapper
    around `timeit()`, useful in an interactive session. For more information on the
    `timeit` module, refer to [https://docs.python.org/3/library/timeit.html](https://docs.python.org/3/library/timeit.html).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不在 IPython 交互式会话中，可以使用 `timeit.timeit()`。这个函数定义在 Python 的 `timeit` 模块中，用于基准测试存储在字符串中的
    Python 语句。IPython 的 `%timeit` 魔法命令是 `timeit()` 的一个方便封装，适用于交互式会话。有关 `timeit` 模块的更多信息，请参阅
    [https://docs.python.org/3/library/timeit.html](https://docs.python.org/3/library/timeit.html)。
- en: See also
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: The *Profiling your code easily with cProfile and IPython* recipe
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 cProfile 和 IPython 轻松分析代码* 配方'
- en: The *Profiling your code line-by-line with line_profiler* recipe
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*逐行分析代码性能的 line_profiler 配方*'
- en: Profiling your code easily with cProfile and IPython
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 cProfile 和 IPython 轻松分析你的代码
- en: The `%timeit` magic command is often helpful, yet a bit limited when you need
    detailed information about what takes most of the execution time in your code.
    This magic command is meant for **benchmarking** (comparing the execution times
    of different versions of a function) rather than **profiling** (getting a detailed
    report of the execution time, function by function).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`%timeit` 魔法命令通常很有用，但当你需要详细了解代码中哪些部分占用了最多执行时间时，它的功能略显有限。这个魔法命令更适用于**基准测试**（比较不同版本函数的执行时间），而不是**性能分析**（获取按函数细分的执行时间报告）。'
- en: Python includes a profiler named `cProfile` that breaks down the execution time
    into the contributions of all called functions. IPython provides convenient ways
    to leverage this tool in an interactive session.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Python 包含一个名为 `cProfile` 的性能分析器，可以将执行时间分解为所有调用函数的贡献。IPython 提供了在交互式会话中方便使用此工具的方法。
- en: How to do it...
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: IPython offers the `%prun` line magic and the `%%prun` cell magic to easily
    profile one or multiple lines of code. The `%run` magic command also accepts a
    `-p` flag to run a Python script under the control of the profiler. These commands
    accept a lot of options, and you may want to take a look at their documentation
    with `%prun?` and `%run?`.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: IPython 提供了 `%prun` 行魔法命令和 `%%prun` 单元格魔法命令，可以轻松地分析一行或多行代码的性能。`%run` 魔法命令也接受
    `-p` 标志，用于在性能分析器的控制下运行 Python 脚本。这些命令有许多选项，你可能希望查看它们的文档，可以通过 `%prun?` 和 `%run?`
    进行查询。
- en: In this example, we will profile a numerical simulation of random walks starting
    at the origin. We will cover these kinds of simulations in more detail in [Chapter
    13](ch13.html "Chapter 13. Stochastic Dynamical Systems"), *Stochastic Dynamical
    Systems*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将分析一个从原点开始的随机漫步数值模拟。我们将在 [第13章](ch13.html "第13章：随机动力学系统") 中更详细地介绍这些类型的模拟，*随机动力学系统*。
- en: 'Let''s import NumPy and matplotlib:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入 NumPy 和 matplotlib：
- en: '[PRE4]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let''s create a function generating random +1 and -1 values in an array:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个生成随机 +1 和 -1 值的函数，并将其存储在数组中：
- en: '[PRE5]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now, let's write the simulation code in a cell starting with `%%prun` in order
    to profile the entire simulation. The various options allow us to save the report
    in a file and to sort the first 10 results by cumulative time. We will explain
    these options in more detail in the *How it works…* section.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们在一个以 `%%prun` 开头的单元格中编写模拟代码，以便分析整个模拟过程的性能。各种选项允许我们将报告保存到文件中，并按累计时间对前 10
    个结果进行排序。我们将在 *原理介绍* 部分更详细地解释这些选项。
- en: '[PRE6]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The profiling report has been saved in a text file named `prun0`. Let''s display
    it (the following output is a stripped down version that fits on this page):'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 性能分析报告已保存为名为 `prun0` 的文本文件。让我们展示一下它（以下输出是经过简化的版本，以适应本页面）：
- en: '[PRE7]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here, we observe the time taken by the different functions involved, directly
    or indirectly, in our code.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们观察了在代码中直接或间接涉及的不同函数的执行时间。
- en: 'If we run the exact same simulation with 500 iterations instead of 50, we obtain
    the following results:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们将模拟的迭代次数从 50 增加到 500，那么运行相同的模拟，我们将得到以下结果：
- en: '[PRE8]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can observe that the number of iterations has a big influence on the relative
    performance cost of the involved functions (notably `cumsum` here).
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以观察到，迭代次数对涉及的函数（特别是 `cumsum` 函数）的相对性能开销有很大影响。
- en: How it works...
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 原理介绍...
- en: Python's profiler creates a detailed report of the execution time of our code,
    function by function. Here, we can observe the number of calls of the functions
    `histogram`, `cumsum`, `step`, `sort`, and `rand`, and the total time spent in
    those functions during the code's execution. Internal functions are also profiled.
    For each function, we get the total number of calls, the total and cumulative
    times, and their per-call counterparts (division by `ncalls`). The **total time**
    represents how long the interpreter stays in a given function, *excluding* the
    time spent in calls to subfunctions. The **cumulative time** is similar but *includes*
    the time spent in calls to subfunctions. The filename, function name, and line
    number are displayed in the last column.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Python 的性能分析器会生成关于我们代码执行时间的详细报告，按函数进行分类。在这里，我们可以观察到 `histogram`、`cumsum`、`step`、`sort`
    和 `rand` 函数的调用次数，以及在代码执行过程中这些函数的总时间。内部函数也会被分析。对于每个函数，我们会得到总调用次数、总时间和累积时间，以及每次调用的对应值（通过
    `ncalls` 除以总值）。**总时间**表示解释器在某个函数中停留的时间，*不包括*在调用子函数时所花费的时间。**累积时间**类似，但*包括*在调用子函数时所花费的时间。文件名、函数名和行号会显示在最后一列。
- en: The `%prun` and `%%prun` magic commands accept multiple optional options (type
    `%prun?` for more details). In the example, `-s` allows us to **sort** the report
    by a particular column, `-q` to suppress (**quell**) the pager output (which is
    useful when we want to integrate the output in a notebook), `-l` to **limit**
    the number of lines displayed or to filter the results by function name (which
    is useful when we are interested in a particular function), and `-T` to save the
    report in a **text** file. In addition, we can choose to save (**dump**) the binary
    report in a file with `-D`, or to **return** it in IPython with `-r`. This database-like
    object contains all information about the profiling and can be analyzed through
    Python's `pstats` module.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`%prun` 和 `%%prun` 魔法命令接受多个可选参数（输入 `%prun?` 查看详细信息）。在示例中，`-s` 允许我们按特定列**排序**报告，`-q`
    用于抑制（**抑制**）分页器输出（当我们想将输出整合到笔记本中时很有用），`-l` 用于**限制**显示的行数或按函数名筛选结果（当我们关注某个特定函数时非常有用），`-T`
    用于将报告保存为**文本**文件。此外，我们还可以选择使用 `-D` 保存（**转储**）二进制报告到文件中，或者使用 `-r` 在 IPython 中**返回**报告。这个类似数据库的对象包含所有分析信息，可以通过
    Python 的 `pstats` 模块进行分析。'
- en: Note
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Every profiler brings its own overhead that can bias the profiling results (**probe
    effect**). In other words, a profiled program may run significantly slower than
    a non-profiled program. That's a point to keep in mind.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 每个性能分析器都有其自身的开销，可能会影响分析结果（**探测效应**）。换句话说，一个被分析过的程序可能比未分析的程序运行得慢得多。这一点需要记住。
- en: '"Premature optimization is the root of all evil"'
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: “过早的优化是万恶之源”
- en: As Donald Knuth's well-known quote suggests, optimizing code prematurely is
    generally considered a bad practice. Code optimization should only be conducted
    when it's really needed, that is, when the code is really too slow in normal situations.
    Additionally, we should know exactly where we need to optimize your code; typically,
    the vast majority of the execution time comprises a relatively small part of the
    code. The only way to find out is by profiling your code; optimization should
    never be done without preliminary profiling.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 正如 Donald Knuth 的名言所示，过早地优化代码通常被认为是一种不良实践。代码优化应仅在真正需要时进行，也就是说，当代码在正常情况下真的运行得很慢时。此外，我们应当准确知道需要优化代码的地方；通常，执行时间的大部分来自于代码的相对小部分。了解这一点的唯一方法是对代码进行性能分析；优化永远不应在没有初步分析的情况下进行。
- en: Tip
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: I was once dealing with some fairly complicated code that was slower than expected.
    I thought I had a pretty good idea of what was causing the problem and how I could
    resolve it. The solution would involve significant changes in the code. Fortunately,
    I first profiled my code, just to be sure. My diagnostic appeared to be utterly
    wrong; I had written somewhere `max(x)` instead of `np.max(x)` by mistake, where
    `x` was a very large vector. It was Python's built-in function that was called,
    instead of NumPy's heavily optimized routine for arrays. If I hadn't profiled
    my code, I would probably have missed this mistake forever. The program was working
    perfectly fine, only 150 times slower!
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: For more general advice on programming optimization, see [http://en.wikipedia.org/wiki/Program_optimization](http://en.wikipedia.org/wiki/Program_optimization).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Profiling code in IPython is particularly simple (especially in the notebook),
    as we have seen in this recipe. However, it may be undesirable or difficult to
    execute the code that we need to profile from IPython (GUIs, for example). In
    this case, we can use `cProfile` directly. It is slightly less straightforward
    than with IPython.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we call the following command:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The file `profresults` will contain the dump of the profiling results of `myscript.py`.
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Then, we execute the following code from Python or IPython to display the profiling
    results in a human-readable form:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Explore the documentation of the `cProfile` and `pstats` modules to discover
    all of the analyses that you can perform on the profiling reports.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The repository at [https://github.com/rossant/easy_profiler](https://github.com/rossant/easy_profiler)
    contains a simple command-line tool that facilitates the profiling of Python scripts.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: There are a few GUI tools for exploring and visualizing the output of a profiling
    session. For example, **RunSnakeRun** allows you to view profile dumps in a GUI
    program.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few references:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Documentation of `cProfile` and `pstats`, available at [https://docs.python.org/3/library/profile.html](https://docs.python.org/3/library/profile.html)
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RunSnakeRun, at [www.vrplumber.com/programming/runsnakerun/](http://www.vrplumber.com/programming/runsnakerun/)
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python profiling tools, available at [http://blog.ionelmc.ro/2013/06/08/python-profiling-tools/](http://blog.ionelmc.ro/2013/06/08/python-profiling-tools/)
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Profiling your code line-by-line with line_profiler* recipe
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling your code line-by-line with line_profiler
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python's native `cProfile` module and the corresponding `%prun` magic break
    down the execution time of code *function by function*. Sometimes, we may need
    an even more fine-grained analysis of code performance with a *line-by-line* report.
    Such reports can be easier to read than the reports of `cProfile`.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: To profile code line-by-line, we need an external Python module named `line_profiler`
    created by Robert Kern, available at [http://pythonhosted.org/line_profiler/](http://pythonhosted.org/line_profiler/).
    In this recipe, we will demonstrate how to use this module within IPython.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要按行分析代码，我们需要一个名为`line_profiler`的外部Python模块，由Robert Kern创建，模块可从[http://pythonhosted.org/line_profiler/](http://pythonhosted.org/line_profiler/)获得。在本教程中，我们将演示如何在IPython中使用该模块。
- en: Getting ready
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备好
- en: To install `line_profiler`, type `pip install line_profiler` in a terminal,
    or type `!pip install line_profiler` in IPython (you need a C compiler).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装`line_profiler`，在终端中输入`pip install line_profiler`，或在IPython中输入`!pip install
    line_profiler`（你需要一个C编译器）。
- en: On Windows, you can use Chris Gohlke's unofficial package available at [www.lfd.uci.edu/~gohlke/pythonlibs/#line_profiler](http://www.lfd.uci.edu/~gohlke/pythonlibs/#line_profiler).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上，你可以使用Chris Gohlke提供的非官方包，下载地址为[www.lfd.uci.edu/~gohlke/pythonlibs/#line_profiler](http://www.lfd.uci.edu/~gohlke/pythonlibs/#line_profiler)。
- en: How do to it...
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 怎么做...
- en: 'We will profile the same simulation code as in the previous recipe, line-by-line:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将逐行分析与上一教程相同的模拟代码：
- en: 'First, let''s import NumPy and the `line_profiler` IPython extension module
    that comes with the package:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们导入NumPy和随包一起提供的`line_profiler` IPython扩展模块：
- en: '[PRE11]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This IPython extension module provides a `%lprun` magic command to profile
    a Python function line-by-line. It works best when the function is defined in
    a file and not in the interactive namespace or in the notebook. Therefore, here
    we write our code in a Python script using the `%%writefile` cell magic:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个IPython扩展模块提供了一个`%lprun`魔法命令，用于逐行分析Python函数。它在函数定义在文件中而不是在交互式命名空间或笔记本中时效果最好。因此，在这里，我们将代码写入Python脚本，并使用`%%writefile`单元魔法：
- en: '[PRE12]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, let''s import this script into the interactive namespace so that we can
    execute and profile our code:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将这个脚本导入到交互式命名空间中，以便执行和分析我们的代码：
- en: '[PRE13]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We execute the function under the control of the line profiler. The functions
    to be profiled need to be explicitly specified in the `%lprun` magic command.
    We also save the report in a file, `lprof0`:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在行级分析器的控制下执行函数。需要分析的函数必须在`%lprun`魔法命令中明确指定。我们还将报告保存在一个文件中，命名为`lprof0`：
- en: '[PRE14]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let''s display the report (the following output is a stripped-down version
    that fits in the page):'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们展示报告（以下输出是经过精简的版本，以适应页面）：
- en: '[PRE15]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'If we perform the same analysis with 10 times the previous number of iterations
    (`simulation.simulate(500)`), we get the following report:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们用比之前多10倍的迭代次数（`simulation.simulate(500)`）执行相同的分析，我们会得到如下报告：
- en: '[PRE16]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: How it works...
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `%lprun` command accepts a Python statement as its main argument. The functions
    to profile need to be explicitly specified with `-f`. Other optional arguments
    include `-D`, `-T`, and `-r`, and they work in a similar way to their `%prun`
    magic command counterparts.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`%lprun`命令接受一个Python语句作为其主要参数。需要分析的函数必须通过`-f`明确指定。其他可选参数包括`-D`、`-T`和`-r`，它们的工作方式类似于`%prun`魔法命令的对应参数。'
- en: The `line_profiler` module displays the time spent on each line of the profiled
    functions, either in timer units or as a fraction of the total execution time.
    These details are essential when we are looking for hotspots in our code.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`line_profiler`模块显示每一行分析函数所花费的时间，可以以计时单位或总执行时间的分数形式显示。当我们在查找代码热点时，这些详细信息至关重要。'
- en: There's more...
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: As in the previous recipe, there may be a need to run the line-by-line profiler
    on a standalone Python program that cannot be launched easily from IPython. The
    procedure is a bit convoluted.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 与上一教程一样，可能需要对一个独立的Python程序运行逐行分析器，该程序无法从IPython轻松启动。这个过程稍显复杂。
- en: We download the `kernprof` file from [https://github.com/rkern/line_profiler/blob/master/kernprof.py](https://github.com/rkern/line_profiler/blob/master/kernprof.py),
    and save it in your code's directory.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从[https://github.com/rkern/line_profiler/blob/master/kernprof.py](https://github.com/rkern/line_profiler/blob/master/kernprof.py)下载`kernprof`文件，并将其保存在代码的目录中。
- en: 'In the code, we decorate the functions we wish to profile with `@profile`.
    We need to remove these decorators at the end of the profiling session, as they
    will raise `NameError` exceptions if the code is executed normally (that is, not
    under the control of the line profiler):'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在代码中，我们用`@profile`装饰器来装饰我们希望分析的函数。我们需要在分析会话结束后删除这些装饰器，因为如果代码正常执行（即不在行级分析器的控制下），它们会引发`NameError`异常：
- en: '[PRE17]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Tip
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: See also the [http://stackoverflow.com/questions/18229628/python-profiling-using-line-profiler-clever-way-to-remove-profile-statements](http://stackoverflow.com/questions/18229628/python-profiling-using-line-profiler-clever-way-to-remove-profile-statements)
    link for a clever way to remove profile statements.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 参见[http://stackoverflow.com/questions/18229628/python-profiling-using-line-profiler-clever-way-to-remove-profile-statements](http://stackoverflow.com/questions/18229628/python-profiling-using-line-profiler-clever-way-to-remove-profile-statements)链接，了解一种巧妙的方法来移除配置文件语句。
- en: 'We execute the following command in a terminal:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在终端中执行以下命令：
- en: '[PRE18]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The `myscript.py` script will be executed, and the report will be saved in `lprof.txt`.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将执行`myscript.py`脚本，并将报告保存到`lprof.txt`中。
- en: Tip
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: The repository at [https://github.com/rossant/easy_profiler](https://github.com/rossant/easy_profiler)
    offers a slightly simpler way of using the line-by-line profiler.
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://github.com/rossant/easy_profiler](https://github.com/rossant/easy_profiler)上的代码库提供了一个稍微简化的逐行分析工具使用方法。'
- en: Tracing the step-by-step execution of a Python program
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跟踪Python程序逐步执行过程
- en: Let's also talk about **tracing** tools for Python, which can be useful for
    profiling or debugging a program, or for educational purposes.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将讨论**跟踪**工具，它们对于性能分析、调试程序或用于教育目的非常有用。
- en: Python's `trace` module allows us to trace program execution of Python code.
    That's extremely useful during in-depth debugging and profiling sessions. We can
    follow the entire sequence of instructions executed by the Python interpreter.
    More information on the trace module is available at [https://docs.python.org/3/library/trace.html](https://docs.python.org/3/library/trace.html).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Python的`trace`模块允许我们跟踪Python代码的程序执行。这在深入调试和性能分析过程中非常有用。我们可以跟踪Python解释器执行的所有指令序列。有关trace模块的更多信息，请访问[https://docs.python.org/3/library/trace.html](https://docs.python.org/3/library/trace.html)。
- en: In addition, the **Online Python Tutor** is an online interactive educational
    tool that can help us understand what the Python interpreter is doing step-by-step
    as it executes a program's source code. The Online Python Tutor is available at
    [http://pythontutor.com/](http://pythontutor.com/).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，**在线 Python Tutor** 是一个在线交互式教育工具，帮助我们逐步理解 Python 解释器在执行程序源代码时的操作。在线 Python
    Tutor 可通过[http://pythontutor.com/](http://pythontutor.com/)访问。
- en: See also
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: The *Profiling your code easily with cProfile and IPython* recipe
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用cProfile和IPython轻松进行代码性能分析*的技巧'
- en: The *Profiling the memory usage of your code with memory_profiler* recipe
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用memory_profiler分析代码的内存使用情况*的技巧'
- en: Profiling the memory usage of your code with memory_profiler
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用memory_profiler分析代码的内存使用情况
- en: The methods described in the previous recipe were about CPU time profiling.
    That may be the most obvious factor when it comes to code profiling. However,
    memory is also a critical factor. For instance, running `np.zeros(500000000)`
    is likely to instantaneously crash your computer! This command may allocate more
    memory than is available on your system; your computer will then reach a nonresponsive
    state within seconds.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 前一篇配方中描述的方法是关于CPU时间的性能分析。这可能是代码性能分析中最显著的因素。然而，内存也是一个关键因素。例如，运行`np.zeros(500000000)`很可能会立即崩溃你的计算机！这个命令可能会分配超过系统可用内存的内存；你的计算机会在几秒钟内进入无响应状态。
- en: Writing memory-optimized code is not trivial and can really make your program
    faster. This is particularly important when dealing with large NumPy arrays, as
    we will see later in this chapter.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 编写内存优化代码并不简单，但能显著提升程序的运行速度。尤其在处理大型NumPy数组时，这一点尤为重要，正如我们将在本章后面看到的那样。
- en: In this recipe, we will look at a simple memory profiler. This library, unsurprisingly
    called `memory_profiler`, was created by Fabian Pedregosa. Its usage is very similar
    to `line_profiler`, and it can be conveniently used from IPython. You can download
    it from [https://pypi.python.org/pypi/memory_profiler](https://pypi.python.org/pypi/memory_profiler).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将介绍一个简单的内存分析工具。这个库，毫不奇怪地叫做`memory_profiler`，由Fabian Pedregosa创建。它的使用方式与`line_profiler`非常相似，且可以方便地从IPython中使用。你可以从[https://pypi.python.org/pypi/memory_profiler](https://pypi.python.org/pypi/memory_profiler)下载它。
- en: Getting ready
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You can install `memory_profiler` with `pip install memory_profiler`.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过`pip install memory_profiler`来安装`memory_profiler`。
- en: On Windows, you also need `psutil`, which is available at [https://pypi.python.org/pypi/psutil](https://pypi.python.org/pypi/psutil).
    You can install it with `pip install psutil`, or by downloading the package from
    [https://code.google.com/p/psutil/](https://code.google.com/p/psutil/). You can
    also download an installer from Chris Gohlke's webpage at [www.lfd.uci.edu/~gohlke/pythonlibs/](http://www.lfd.uci.edu/~gohlke/pythonlibs/).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows 上，您还需要 `psutil`，它可以在 [https://pypi.python.org/pypi/psutil](https://pypi.python.org/pypi/psutil)
    上找到。您可以使用 `pip install psutil` 安装，或者从 [https://code.google.com/p/psutil/](https://code.google.com/p/psutil/)
    下载该包。您也可以从 Chris Gohlke 的网页 [www.lfd.uci.edu/~gohlke/pythonlibs/](http://www.lfd.uci.edu/~gohlke/pythonlibs/)
    下载安装程序。
- en: The example in this recipe is the continuation of the previous recipe.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 本方法中的示例是前一个方法的延续。
- en: How to do it...
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Assuming that the simulation code has been loaded as shown in the previous
    recipe, we load the memory profiler IPython extension:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设仿真代码已经如前一个方法中所示加载，我们加载内存分析器的 IPython 扩展：
- en: '[PRE19]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, let''s run the code under the control of the memory profiler:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们在内存分析器的控制下运行代码：
- en: '[PRE20]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s show the results:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们展示结果：
- en: '[PRE21]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Finally, here is the report with 500 iterations:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，这是进行 500 次迭代的报告：
- en: '[PRE22]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: How it works...
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `memory_profiler` package checks the memory usage of the interpreter at
    every line. The **increment** column allows us to spot those places in the code
    where large amounts of memory are allocated. This is especially important when
    working with arrays. Unnecessary array creations and copies can considerably slow
    down a program. We will tackle this issue in the next few recipes.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`memory_profiler` 包检查每行代码的内存使用情况。**增量** 列帮助我们发现代码中分配大量内存的地方。当处理数组时，这一点尤其重要。不必要的数组创建和复制会显著减慢程序速度。我们将在接下来的几个方法中解决这个问题。'
- en: There's more...
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: We can use `memory_profiler` without IPython, and we can also use a quick memory
    benchmark in IPython for single commands.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在没有 IPython 的情况下使用 `memory_profiler`，也可以在 IPython 中对单个命令进行快速内存基准测试。
- en: Using memory_profiler for standalone Python programs
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在独立的 Python 程序中使用 memory_profiler
- en: Using the memory profiler with standalone Python programs is similar but slightly
    simpler than with `line_profiler`.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在独立的 Python 程序中使用内存分析器与使用 `line_profiler` 类似，但稍微简单一些。
- en: First, in our Python scripts, we decorate the functions we wish to profile with
    `@profile`.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，在我们的 Python 脚本中，我们通过 `@profile` 装饰器标记我们希望分析的函数。
- en: 'Then, we run:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们运行：
- en: '[PRE23]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The profiling report will be saved in `myprof.txt`.
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分析报告将保存在 `myprof.txt` 中。
- en: Using the %memit magic command in IPython
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 IPython 中使用 %memit 魔法命令
- en: 'The `memory_profiler` IPython extension also comes with a `%memit` magic command
    that lets us benchmark the memory used by a single Python statement. Here is a
    simple example:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '`memory_profiler` 的 IPython 扩展还附带了一个 `%memit` 魔法命令，让我们可以基准测试单个 Python 语句所使用的内存。这里是一个简单的例子：'
- en: '[PRE24]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Other tools
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他工具
- en: There are other tools to monitor the memory usage of a Python program, notably
    Guppy-PE ([http://guppy-pe.sourceforge.net/](http://guppy-pe.sourceforge.net/)),
    PySizer ([http://pysizer.8325.org/](http://pysizer.8325.org/)), and Pympler ([https://code.google.com/p/pympler/](https://code.google.com/p/pympler/)).
    Used in conjunction with IPython and Python's introspection capabilities, these
    tools allow you to analyze the memory usage of a namespace or a particular object.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他工具可以监控 Python 程序的内存使用情况，特别是 Guppy-PE ([http://guppy-pe.sourceforge.net/](http://guppy-pe.sourceforge.net/))、PySizer
    ([http://pysizer.8325.org/](http://pysizer.8325.org/)) 和 Pympler ([https://code.google.com/p/pympler/](https://code.google.com/p/pympler/))。与
    IPython 及 Python 的自省功能结合使用时，这些工具允许您分析命名空间或特定对象的内存使用情况。
- en: See also
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: The *Profiling your code line-by-line with line_profiler* recipe
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*逐行分析代码并使用 line_profiler* 方法'
- en: The *Understanding the internals of NumPy to avoid unnecessary array copying*
    recipe
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*理解 NumPy 的内部机制以避免不必要的数组复制* 方法'
- en: Understanding the internals of NumPy to avoid unnecessary array copying
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 NumPy 的内部机制以避免不必要的数组复制
- en: We can achieve significant performance speedups with NumPy over native Python
    code, particularly when our computations follow the **Single Instruction, Multiple
    Data** (**SIMD**) paradigm. However, it is also possible to unintentionally write
    non-optimized code with NumPy.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 NumPy，我们可以显著提高性能，特别是当我们的计算遵循 **单指令多数据** (**SIMD**) 模式时。然而，也有可能无意中写出非优化的 NumPy
    代码。
- en: In the next few recipes, we will see some tricks that can help us write optimized
    NumPy code. In this recipe, we will see how to avoid unnecessary array copies
    in order to save memory. In that respect, we will need to dig into the internals
    of NumPy.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几个案例中，我们将看到一些可以帮助我们编写优化NumPy代码的技巧。在这个案例中，我们将看到如何避免不必要的数组复制，从而节省内存。在这方面，我们需要深入了解NumPy的内部实现。
- en: Getting ready
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'First, we need a way to check whether two arrays share the same underlying
    data buffer in memory. Let''s define a function `id()` that returns the memory
    location of the underlying data buffer:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一种方法来检查两个数组是否共享相同的底层数据缓冲区。我们可以定义一个返回底层数据缓冲区内存位置的函数`id()`：
- en: '[PRE25]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Two arrays with the same data location (as returned by `id`) share the same
    underlying data buffer. However, the opposite is true only if the arrays have
    the same **offset** (meaning that they have the same first element). Two shared
    arrays with different offsets will have slightly different memory locations, as
    shown in the following example:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 两个具有相同数据位置（由`id`返回的）数组共享相同的底层数据缓冲区。然而，只有在数组具有相同**偏移量**（意味着它们的第一个元素相同）时，才会发生这种情况。具有不同偏移量的共享数组会有稍微不同的内存位置，下面的示例说明了这一点：
- en: '[PRE26]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In the next few recipes, we''ll make sure to use this method with arrays that
    have the same offset. Here is a more general and reliable solution for finding
    out whether two arrays share the same data:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几个案例中，我们将确保使用相同偏移量的数组。以下是一个更通用且可靠的解决方案，用于判断两个数组是否共享相同的数据：
- en: '[PRE27]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Thanks to Michael Droettboom for pointing this out and proposing this alternative
    solution.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢Michael Droettboom指出这一点并提出这种替代解决方案。
- en: How to do it...
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'Computations with NumPy arrays may involve internal copies between blocks of
    memory. These copies are not always necessary, in which case they should be avoided,
    as we will see in the following tips:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 使用NumPy数组进行计算可能涉及内存块之间的内部复制。这些复制并非总是必要的，如果没有必要，应避免它们，正如我们将在以下提示中看到的：
- en: 'We may sometimes need to make a copy of an array; for instance, if we need
    to manipulate an array while keeping an original copy in memory:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们有时需要对数组进行复制；例如，如果我们需要在保留原始副本的情况下操作数组：
- en: '[PRE28]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Array computations can involve in-place operations (the first example in the
    following code: the array is modified) or implicit-copy operations (the second
    example: a new array is created):'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数组计算可以涉及就地操作（以下代码中的第一个示例：数组被修改）或隐式复制操作（第二个示例：创建了一个新数组）：
- en: '[PRE29]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Be sure to choose the type of operation you actually need. Implicit-copy operations
    are significantly slower, as shown here:'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确保选择你实际需要的操作类型。隐式复制操作显著较慢，如下所示：
- en: '[PRE30]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Reshaping an array may or may not involve a copy. The reasons will be explained
    in the *How it works...* section. For instance, reshaping a 2D matrix does not
    involve a copy, unless it is transposed (or more generally, **non-contiguous**):'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重塑数组可能会或可能不会涉及复制。原因将在*它是如何工作的...*部分解释。例如，重塑一个二维矩阵不会涉及复制，除非它被转置（或者更一般地说，**非连续**）：
- en: '[PRE31]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Therefore, the latter instruction will be significantly slower than the former.
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，后者的操作将显著慢于前者。
- en: Both the `flatten` and the `ravel` methods of an array reshape it into a 1D
    vector (a flattened array). However, the `flatten` method always returns a copy,
    and the `ravel` method returns a copy only if necessary (thus it's faster, especially
    with large arrays).
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数组的`flatten`和`ravel`方法都会将其重塑为一维向量（一个扁平化的数组）。然而，`flatten`方法总是返回一个副本，而`ravel`方法仅在必要时返回副本（因此它更快，尤其是在处理大数组时）。
- en: '[PRE32]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '**Broadcasting rules** allow us to make computations on arrays with different
    but compatible shapes. In other words, we don''t always need to reshape or tile
    our arrays to make their shapes match. The following example illustrates two ways
    of doing an **outer product** between two vectors: the first method involves array
    tiling, the second one (faster) involves broadcasting:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**广播规则**允许我们对形状不同但兼容的数组进行计算。换句话说，我们不总是需要重塑或拼接数组来使它们的形状匹配。以下示例演示了在两个向量之间进行**外积**的两种方法：第一种方法涉及数组拼接，第二种方法（更快）涉及广播：'
- en: '[PRE33]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: How it works...
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this section, we will see what happens under the hood when using NumPy, and
    how this knowledge allows us to understand the tricks given in this recipe.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到在使用NumPy时，内部发生了什么，以及这些知识如何帮助我们理解本食谱中的技巧。
- en: Why are NumPy arrays efficient?
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么NumPy数组高效？
- en: A NumPy array is basically described by metadata (notably the number of dimensions,
    the shape, and the data type) and the actual data. The data is stored in a homogeneous
    and contiguous block of memory, at a particular address in system memory (**Random
    Access Memory**, or **RAM**). This block of memory is called the **data buffer**.
    This is the main difference when compared to a pure Python structure, such as
    a list, where the items are scattered across the system memory. This aspect is
    the critical feature that makes NumPy arrays so efficient.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: 'Why is this so important? Here are the main reasons:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: Computations on arrays can be written very efficiently in a low-level language
    such as C (and a large part of NumPy is actually written in C). Knowing the address
    of the memory block and the data type, it is just simple arithmetic to loop over
    all items, for example. There would be a significant overhead to do that in Python
    with a list.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spatial locality** in memory access patterns results in performance gains
    notably due to the CPU cache. Indeed, the cache loads bytes in chunks from RAM
    to the CPU registers. Adjacent items are then loaded very efficiently (**sequential
    locality**, or **locality of reference**).'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the fact that items are stored contiguously in memory allows NumPy
    to take advantage of **vectorized instructions** of modern CPUs, such as Intel's
    **SSE** and **AVX**, AMD's XOP, and so on. For example, multiple consecutive floating
    point numbers can be loaded in 128, 256, or 512 bits registers for vectorized
    arithmetical computations implemented as CPU instructions.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: Additionally, NumPy can be linked to highly optimized linear algebra libraries
    such as **BLAS** and **LAPACK** through **ATLAS** or the **Intel Math Kernel Library**
    (**MKL**). A few specific matrix computations may also be multithreaded, taking
    advantage of the power of modern multicore processors.
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In conclusion, storing data in a contiguous block of memory ensures that the
    architecture of modern CPUs is used optimally, in terms of memory access patterns,
    CPU cache, and vectorized instructions.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: What is the difference between in-place and implicit-copy operations?
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's explain the example in step 2\. An expression such as `a *= 2` corresponds
    to an in-place operation, where all values of the array are multiplied by two.
    By contrast, `a = a*2` means that a new array containing the values of `a*2` is
    created, and the variable `a` now points to this new array. The old array becomes
    unreferenced and will be deleted by the garbage collector. No memory allocation
    happens in the first case, contrary to the second case.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: More generally, expressions such as `a[i:j]` are **views** to parts of an array;
    they point to the memory buffer containing the data. Modifying them with in-place
    operations changes the original array. Hence, `a[:] = a*2` results in an in-place
    operation, unlike `a = a*2`.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Knowing this subtlety of NumPy can help you fix some bugs (where an array is
    implicitly and unintentionally modified because of an operation on a view), and
    optimize the speed and memory consumption of your code by reducing the number
    of unnecessary copies.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Why can't some arrays be reshaped without a copy?
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We explain the example in step 3 here, where a transposed 2D matrix cannot
    be flattened without a copy. A 2D matrix contains items indexed by two numbers
    (row and column), but it is stored internally as a 1D contiguous block of memory,
    accessible with a single number. There is more than one way of storing matrix
    items in a 1D block of memory: we can put the elements of the first row first,
    then the second row, and so on, or the elements of the first column first, then
    the second column, and so on. The first method is called **row-major order**,
    whereas the latter is called **column-major order**. Choosing between the two
    methods is only a matter of internal convention: NumPy uses the row-major order,
    like C, but unlike FORTRAN.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '![Why can''t some arrays be reshaped without a copy?](img/4818OS_04_01.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
- en: 'Internal array layouts: row-major and column-major orders'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: 'More generally, NumPy uses the notion of `strides` to convert between a multidimensional
    index and the memory location of the underlying (1D) sequence of elements. The
    specific mapping between `array[i1, i2]` and the relevant byte address of the
    internal data is given by:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: When reshaping an array, NumPy avoids copies when possible by modifying the
    `strides` attribute. For example, when transposing a matrix, the order of strides
    is reversed, but the underlying data remains identical. However, flattening a
    transposed array cannot be accomplished simply by modifying strides (try it!),
    so a copy is needed (thanks to Chris Beaumont for clarifying an earlier version
    of this paragraph).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Internal array layout can also explain some unexpected performance discrepancies
    between very similar NumPy operations. As a small exercise, can you explain the
    following benchmarks?
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: What are NumPy broadcasting rules?
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Broadcasting rules describe how arrays with different dimensions and/or shapes
    can be used for computations. The general rule is that *two dimensions are compatible
    when they are equal, or when one of them is 1*. NumPy uses this rule to compare
    the shapes of the two arrays element-wise, starting with the trailing dimensions
    and working its way forward. The smallest dimension is internally stretched to
    match the other dimension, but this operation does not involve any memory copy.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are a few references:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: Broadcasting rules and examples, available at [http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Array interface in NumPy, at [http://docs.scipy.org/doc/numpy/reference/arrays.interface.html](http://docs.scipy.org/doc/numpy/reference/arrays.interface.html)
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Locality of reference, at [http://en.wikipedia.org/wiki/Locality_of_reference](http://en.wikipedia.org/wiki/Locality_of_reference)
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Internals of NumPy in the SciPy lectures notes, available at [http://scipy-lectures.github.io/advanced/advanced_numpy/](http://scipy-lectures.github.io/advanced/advanced_numpy/)
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 100 NumPy exercises by Nicolas Rougier, available at [www.loria.fr/~rougier/teaching/numpy.100/index.html](http://www.loria.fr/~rougier/teaching/numpy.100/index.html)
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Using stride tricks with NumPy* recipe
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using stride tricks with NumPy
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will dig deeper into the internals of NumPy arrays, by generalizing
    the notion of row-major and column-major orders to multidimensional arrays. The
    general notion is that of **strides**, which describe how the items of a multidimensional
    array are organized within a one-dimensional data buffer. Strides are mostly an
    implementation detail, but they can also be used in specific situations to optimize
    some algorithms.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We suppose that NumPy has been imported and that the `id` function has been
    defined (see the previous recipe, *Understanding the internals of NumPy to avoid
    unnecessary array copying*).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Strides are integer numbers describing the byte step in the contiguous block
    of memory for each dimension.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: This vector `x` contains double-precision floating point numbers (float64, 8
    bytes); one needs to go *8 bytes forward* to go from one item to the next.
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s look at the strides of a 2D array:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: In the first dimension (vertical), one needs to go *80 bytes* (10 float64 items)
    *forward* to go from one item to the next, because the items are internally stored
    in row-major order. In the second dimension (horizontal), one needs to go *8 bytes*
    *forward* to go from one item to the next.
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s show how we can revisit the broadcasting rules from the previous recipe
    using strides:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We will create a new array, `b`, pointing to the same memory block as `a`,
    but with a different shape and different strides. This new array will look like
    a vertically-tiled version of `a`. We use a special function in NumPy to change
    the strides of an array:'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: NumPy believes that this array contains one million different elements, whereas
    the data buffer actually contains the same 1000 elements as `a`.
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can now perform an efficient outer product using the same principle as with
    broadcasting rules:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: How it works...
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every array has a number of dimensions, a shape, a data type, and strides. Strides
    describe how the items of a multidimensional array are organized in the data buffer.
    There are many different schemes for arranging the items of a multidimensional
    array in a one-dimensional block. NumPy implements a **strided indexing scheme**,
    where the position of any element is a **linear combination** of the dimensions,
    the coefficients being the strides. In other words, strides describe, in any dimension,
    how many bytes we need to jump over in the data buffer to go from one item to
    the next.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'The position of any element in a multidimensional array is given by a linear
    combination of its indices, as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/4818OS_04_02.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
- en: Artificially changing the strides allows us to make some array operations more
    efficient than with standard methods, which may involve array copies. Internally,
    that's how broadcasting works in NumPy.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: The `as_strided` method takes an array, a shape, and strides as arguments. It
    creates a new array, but uses the same data buffer as the original array. The
    only thing that changes is the metadata. This trick lets us manipulate NumPy arrays
    as usual, except that they may take much less memory than what NumPy thinks. Here,
    using 0 in the strides implies that any array item can be addressed by many multidimensional
    indices, resulting in memory savings.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Be careful with strided arrays! The `as_strided` function does not check whether
    you stay inside the memory block bounds. This means that you need to handle edge
    effects manually; otherwise, you may end up with garbage values in your arrays.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: We will see a more useful application of stride tricks in the next recipe.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: See also
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Implementing an efficient rolling average algorithm with stride tricks*
    recipe
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing an efficient rolling average algorithm with stride tricks
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Stride tricks can be useful for local computations on arrays, when the computed
    value at a given position depends on the neighboring values. Examples include
    dynamical systems, digital filters, and cellular automata.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will implement an efficient **rolling average** algorithm
    (a particular type of convolution-based linear filter) with NumPy stride tricks.
    A rolling average of a 1D vector contains, at each position, the average of the
    elements around this position in the original vector. Roughly speaking, this process
    filters out the noisy components of a signal so as to keep only the slower components.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Make sure to reuse the `id()` function from the *Understanding the internals
    of NumPy to avoid unnecessary array copying* recipe. This function returns the
    memory address of the internal data buffer of a NumPy array.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The idea is to start from a 1D vector, and make a *virtual* 2D array where each
    line is a shifted version of the previous line. When using stride tricks, this
    process is very efficient as it does not involve any copy.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s generate a 1D vector:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Let''s change the strides of `a` to add shifted rows:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The last value indicates an out-of-bounds problem: stride tricks can be dangerous
    as memory access is not checked. Here, we should take edge effects into account
    by limiting the shape of the array.'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now, let''s implement the computation of the rolling average. The first version
    (standard method) involves explicit array copies, whereas the second version uses
    stride tricks:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'These two functions return the same result, except that the array returned
    by the second function refers to the original data buffer:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Let''s generate a signal:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We compute the signal rolling average by creating the shifted version of the
    signal, and averaging along the vertical dimension. The result is shown in the
    next figure:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '![How to do it...](img/4818OS_04_03.jpg)'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: A signal and its rolling average
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s evaluate the time taken by the first method:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'And by the second method:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: In the first version, most of the time is spent in the array copy, whereas in
    the stride trick version, most of the time is instead spent in the computation
    of the average.
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: See also
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Using stride tricks with NumPy* recipe
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making efficient array selections in NumPy
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: NumPy offers several ways of selecting slices of arrays. **Array views** refer
    to the original data buffer of an array, but with different offsets, shapes, and
    strides. They only permit strided selections (that is, with linearly spaced indices).
    NumPy also offers specific functions to make arbitrary selections along one axis.
    Finally, fancy indexing is the most general selection method, but it is also the
    slowest as we will see in this recipe. Faster alternatives should be chosen when
    possible.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We suppose that NumPy has been imported and that the `id` function has been
    defined (see the *Understanding the internals of NumPy to avoid unnecessary array
    copying* recipe).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s create an array with a large number of rows. We will select slices of
    this array along the first dimension:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Let''s select one row from every 10 rows, using two different methods (array
    view and fancy indexing):'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The view refers to the original data buffer, whereas fancy indexing yields
    a copy:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Let''s compare the performance of both methods:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Fancy indexing is several orders of magnitude slower as it involves copying
    a large array.
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'When nonstrided selections need to be done along one dimension, array views
    are not an option. However, alternatives to fancy indexing still exist in this
    case. Given a list of indices, NumPy''s `take()` function performs a selection
    along one axis:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The second method is faster:'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Tip
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: Performance of fancy indexing has been improved in recent versions of NumPy;
    this trick is especially useful on older versions of NumPy.
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'When the indices to select along one axis are specified by a vector of Boolean
    masks, the `compress()` function is an alternative to fancy indexing:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The second method is also faster than fancy indexing.
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fancy indexing is the most general way of making completely arbitrary selections
    of an array. However, more specific and faster methods often exist and should
    be preferred when possible.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: Array views should be used whenever strided selections have to be done, but
    we need to be careful about the fact that views refer to the original data buffer.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-307
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are a few references:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: The complete list of NumPy routines is available in the NumPy Reference Guide,
    at [http://docs.scipy.org/doc/numpy/reference/](http://docs.scipy.org/doc/numpy/reference/)
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The list of indexing routines is available at [http://docs.scipy.org/doc/numpy/reference/routines.indexing.html](http://docs.scipy.org/doc/numpy/reference/routines.indexing.html)
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing huge NumPy arrays with memory mapping
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, we need to deal with NumPy arrays that are too big to fit in the
    system memory. A common solution is to use **memory mapping** and implement **out-of-core
    computations**. The array is stored in a file on the hard drive, and we create
    a memory-mapped object to this file that can be used as a regular NumPy array.
    Accessing a portion of the array results in the corresponding data being automatically
    fetched from the hard drive. Therefore, we only consume what we use.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-313
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s create a memory-mapped array:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Let's feed the array with random values, one column at a time because our system's
    memory is limited!
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'We save the last column of the array:'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Now, we flush memory changes to disk by deleting the object:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Reading a memory-mapped array from disk involves the same `memmap` function.
    The data type and the shape need to be specified again, as this information is
    not stored in the file:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Tip
  id: totrans-324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This method is not the most adapted for long-term storage of data and data sharing.
    The following recipes in this chapter will show a better way based on the HDF5
    file format.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Memory mapping lets you work with huge arrays almost as if they were regular
    arrays. Python code that accepts a NumPy array as input will also accept a `memmap`
    array. However, we need to ensure that the array is used efficiently. That is,
    the array is never loaded as a whole (otherwise, it would waste system memory
    and would dismiss any advantage of the technique).
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: Memory mapping is also useful when you have a huge file containing raw data
    in a homogeneous binary format with a known data type and shape. In this case,
    an alternative solution is to use NumPy's `fromfile()` function with a file handle
    created with Python's native `open()` function. Using `f.seek()` lets you position
    the cursor at any location and load a given number of bytes into a NumPy array.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another way of dealing with huge NumPy matrices is to use **sparse matrices**
    through SciPy's **sparse** subpackage. It is adapted when our matrices contain
    mostly zeros, as is often the case with simulations of partial differential equations,
    graph algorithms, or specific machine learning applications. Representing matrices
    as dense structures can be a waste of memory, and sparse matrices offer a more
    efficient compressed representation.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: 'Using sparse matrices in SciPy is not straightforward as multiple implementations
    exist. Each implementation is best for a particular kind of application. Here
    are a few references:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: SciPy lecture notes about sparse matrices, available at [http://scipy-lectures.github.io/advanced/scipy_sparse/index.html](http://scipy-lectures.github.io/advanced/scipy_sparse/index.html)
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reference documentation on sparse matrices, at [http://docs.scipy.org/doc/scipy/reference/sparse.html](http://docs.scipy.org/doc/scipy/reference/sparse.html)
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Documentation of memmap, at [http://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html](http://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html)
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Manipulating large arrays with HDF5 and PyTables* recipe
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Manipulating large heterogeneous tables with HDF5 and PyTables* recipe
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating large arrays with HDF5 and PyTables
  id: totrans-338
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'NumPy arrays can be persistently saved on disk using built-in functions in
    NumPy such as `np.savetxt`, `np.save`, or `np.savez`, and loaded in memory using
    analogous functions. These methods are best when the arrays contain less than
    a few million points. For larger arrays, these methods suffer from two major problems:
    they become too slow, and they require the arrays to be fully loaded in memory.
    Arrays containing billions of points can be too big to fit in system memory, and
    alternative methods are required.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: 'These alternative methods rely on **memory mapping**: the array resides on
    the hard drive, and chunks of the array are selectively loaded in memory as soon
    as the CPU needs them. This technique is memory-efficient, at the expense of a
    slight overhead due to hard drive access. Cache mechanisms and optimizations can
    mitigate this issue.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: The previous recipe showed a basic memory mapping technique using NumPy. In
    this recipe, we will use a package named **PyTables**, which is specifically designed
    to deal with very large datasets. It implements fast memory-mapping techniques
    via a widely-used and open file format specification called **Hierarchical Data
    Format**, or **HDF5**. An HDF5 file contains one or several datasets (arrays or
    heterogeneous tables) organized into a POSIX-like hierarchy. Any part of the datasets
    can be accessed efficiently and easily without unnecessarily wasting the system
    memory.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: As we will see later in this recipe, an alternative for PyTables is **h5py**.
    It is more lightweight and more adapted than PyTables in some situations.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will see how to manipulate large arrays using HDF5 and PyTables.
    The next recipe will be about pandas-like heterogeneous tables.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-344
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need PyTables 3.0+ for this recipe and the next one. With Anaconda, you
    can install PyTables using `conda install tables`. You will also find binary installers
    at [http://pytables.github.io/usersguide/installation.html](http://pytables.github.io/usersguide/installation.html).
    Windows users can find installers on [www.lfd.uci.edu/~gohlke/pythonlibs/#pytables](http://www.lfd.uci.edu/~gohlke/pythonlibs/#pytables).
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-346
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Prior to version 3.0, PyTables used a camel case convention for the names of
    attributes and methods. The latest versions use the more standard Python convention
    using underscores. So, for example, `tb.open_file` is `tb.openFile` in versions
    prior to 3.0.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-348
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we need to import NumPy and PyTables (the package''s name is `tables`):'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Let''s create a new empty HDF5 file:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'We create a new top-level group named `experiment1`:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Let''s also add some metadata to this group:'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'In this group, we create a 1000*1000 array named `array1`:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Finally, we need to close the file to commit the changes on disk:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Now, let's open this file. We could have done this in another Python session
    since the array has been saved in the HDF5 file.
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'We can retrieve an attribute by giving the group path and the attribute name:'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: We can access any item in the file using attributes, replacing slashes with
    dots in the paths, and starting with `root` (corresponding to the path `/`). IPython's
    tab completion is particularly useful in this respect when exploring a file interactively.
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: The array can be used as a NumPy array, but an important distinction is that
    it is stored on disk instead of system memory. Performing a computation on this
    array automatically loads the requested section of the array into memory, thus
    it is more efficient to access only the array's views.
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'It is also possible to get a node from its absolute path, which is useful when
    the path is only known at runtime:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'We''re done for this recipe, so let''s do some clean-up:'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: How it works...
  id: totrans-373
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we stored a single array in the file, but HDF5 is especially
    useful when many arrays need to be saved in a single file. HDF5 is generally used
    in big projects, when large arrays have to be organized within a hierarchical
    structure. For example, it is largely used at NASA, NOAA, and many other scientific
    institutions (see [www.hdfgroup.org/users.html](http://www.hdfgroup.org/users.html)).
    Researchers can store recorded data across multiple devices, multiple trials,
    and multiple experiments.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: In HDF5, the data is organized within a tree. Nodes are either **groups** (analogous
    to folders in a file system) or **datasets** (analogous to files). A group can
    contain subgroups and datasets, whereas datasets only contain data. Both groups
    and datasets can contain attributes (metadata) that have a basic data type (integer
    or floating point number, string, and so on). HDF5 also supports internal and
    external links; a given path can refer to another group or dataset within the
    same file, or within another file. This feature may be useful if you need different
    files for the same experiment or project.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: Being able to access a chunk of a single array without loading the rest of the
    array and the file in memory is quite convenient. Moreover, a loaded array can
    be polymorphically accessed using standard NumPy's slicing syntax. Code that accepts
    a NumPy array as an argument can, in principle, accept a PyTables array object
    as an argument as well.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-377
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we created a PyTables `Array` object to store our NumPy array.
    Other similar types of objects include `CArrays` that store large arrays in chunks
    and support lossless compression. Also, an `EArray` object is extendable in at
    most one dimension, which is useful when the dimensions of the array are not known
    when creating the array in the file. A common use case is recording data during
    an online experiment.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: The other main type of HDF5 object is `Table`, which stores tabular data in
    a two-dimensional table with heterogeneous data types. In PyTables, a `Table`
    is to an `Array` what a pandas `DataFrame` is to a NumPy `ndarray`. We will see
    those in the next recipe.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: An interesting feature of HDF5 files is that they are not tied to PyTables.
    As HDF5 is an open format specification, libraries exist in most languages (C,
    FORTRAN, MATLAB, and many others), so it's easy to open an HDF5 file in these
    languages.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: In HDF5, a dataset may be stored in a **contiguous** block of memory, or in
    chunks. **Chunks** are atomic objects and HDF5/PyTables can only read and write
    entire chunks. Chunks are internally organized within a tree data structure called
    a **B-tree**. When we create a new array or table, we can specify the **chunk
    shape**. It is an internal detail, but it can greatly affect performance when
    writing and reading parts of the dataset.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: The optimal chunk shape depends on how we plan to access the data. There is
    a trade-off between many small chunks (large overhead due to managing lots of
    chunks) and a few large chunks (inefficient disk I/O). In general, the chunk size
    is recommended to be smaller than 1 MB. The chunk cache is also an important parameter
    that may affect performance.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: Relatedly, we should specify as an optional argument the expected number of
    rows when we create an `EArray` or a `Table` object so as to optimize the internal
    structure of the file. You can find more information in the PyTables users guide
    section on optimization (see the link mentioned in the following references),
    which is a must-read if you plan to do anything slightly complex on large HDF5
    files (more than 100 MB).
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we should mention another HDF5 library in Python named **h5py**. This
    lightweight library offers an easy interface to HDF5 files, with emphasis on arrays
    rather than tables. It provides very natural access to HDF5 arrays from NumPy,
    and may be sufficient if you do not need the database-like features of PyTables.
    For more information on h5py, refer to [www.h5py.org](http://www.h5py.org).
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few references:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: HDF5 chunking, at [www.hdfgroup.org/HDF5/doc/Advanced/Chunking/](http://www.hdfgroup.org/HDF5/doc/Advanced/Chunking/)
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PyTables optimization guide, available at [http://pytables.github.io/usersguide/optimization.html](http://pytables.github.io/usersguide/optimization.html)
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Difference between PyTables and h5py, from the perspective of h5py, at [https://github.com/h5py/h5py/wiki/FAQ#whats-the-difference-between-h5py-and-pytables](https://github.com/h5py/h5py/wiki/FAQ#whats-the-difference-between-h5py-and-pytables)
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Difference between PyTables and h5py, from the perspective of PyTables, at [www.pytables.org/moin/FAQ#HowdoesPyTablescomparewiththeh5pyproject.3F](http://www.pytables.org/moin/FAQ#HowdoesPyTablescomparewiththeh5pyproject.3F)
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  id: totrans-390
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Processing huge NumPy arrays with memory mapping* recipe
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Manipulating large heterogeneous tables with HDF5 and PyTables* recipe
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Ten tips for conducting reproducible interactive computing experiments*
    recipe in [Chapter 2](ch02.html "Chapter 2. Best Practices in Interactive Computing"),
    *Best Practices in Interactive Computing*
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating large heterogeneous tables with HDF5 and PyTables
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PyTables can store homogeneous blocks of data as NumPy-like arrays in HDF5 files.
    It can also store heterogeneous tables, as we will see in this recipe.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-396
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need PyTables for this recipe (see the previous recipe for installation
    instructions).
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-398
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s import NumPy and PyTables:'
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Let''s create a new HDF5 file:'
  id: totrans-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'We will create an HDF5 table with two columns: the name of a city (a string
    with 64 characters at most), and its population (a 32-bit integer). We can specify
    the columns by creating a complex data type with NumPy:'
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Now, we create the table in `/table1`:'
  id: totrans-405
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Let''s add a few rows:'
  id: totrans-407
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'After adding rows, we need to flush the table to commit the changes on disk:'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'There are many ways to access the data from a table. The easiest but not particularly
    efficient way is to load the entire table in memory, which returns a NumPy array:'
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'It is also possible to load a particular column (with all rows):'
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'When dealing with a large number of rows, we can make a SQL-like query in the
    table to load all rows that satisfy particular conditions:'
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Finally, if their indices are known, we can access specific rows:'
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: How it works...
  id: totrans-419
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A table can be created from scratch like in this recipe, or from either an existing
    NumPy array or a pandas `DataFrame`. In the first case, the description of the
    columns can be given with a NumPy data type as shown here, with a dictionary,
    or with a class deriving from `IsDescription`. In the second case, the table description
    will be automatically inferred from the given array or table.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: Rows can be added efficiently at the end of the table using `table.append()`.
    To add a single row, first get a new row instance with `row = table.row`, set
    the fields of the row as if it were a dictionary, and then call `row.append()`
    to add the new row at the end of the table. Calling `flush()` after a set of writing
    operations ensures that these changes are synchronized on disk. PyTables uses
    complex cache mechanisms to ensure maximum performance when writing and reading
    data in a table; thus, new rows are not immediately written to the disk.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: PyTables supports highly efficient SQL-like queries called **in-kernel queries**.
    The string containing the query expression is compiled and evaluated on all rows.
    A less-efficient method consists of iterating over all rows with `table.iterrows()`
    and using an `if` statement on the rows' fields.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-423
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are a few references:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: In-kernel queries, at [http://pytables.github.io/usersguide/condition_syntax.html](http://pytables.github.io/usersguide/condition_syntax.html).
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An alternative to PyTables and HDF5 might come from the Blaze project, still
    in early development at the time of writing. For more information on Blaze, refer
    to [http://blaze.pydata.org](http://blaze.pydata.org).
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  id: totrans-427
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Manipulating large arrays with HDF5 and PyTables* recipe
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
