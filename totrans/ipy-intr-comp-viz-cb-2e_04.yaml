- en: Chapter 4. Profiling and Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the time taken by a statement in IPython
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling your code easily with cProfile and IPython
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling your code line-by-line with line_profiler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling the memory usage of your code with memory_profiler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the internals of NumPy to avoid unnecessary array copying
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using stride tricks with NumPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing an efficient rolling average algorithm with stride tricks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making efficient array selections in NumPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing huge NumPy arrays with memory mapping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating large arrays with HDF5 and PyTables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating large heterogeneous tables with HDF5 and PyTables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although Python is generally known (a bit unfairly) as a *slow* language, it
    is possible to achieve very good performance with the right methods. This is the
    objective of this chapter and the next. This chapter describes how to evaluate
    (**profile**) what makes a program slow, and how this information can be used
    to **optimize** the code and make it more efficient. The next chapter will deal
    with more advanced high-performance computing methods that should only be tackled
    when the methods described here are not sufficient.
  prefs: []
  type: TYPE_NORMAL
- en: 'The recipes of this chapter are organized into three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Time and memory profiling**: Evaluating the performance of code'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NumPy optimization**: Using NumPy more efficiently, particularly with large
    arrays'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Memory mapping with arrays**: Implementing memory mapping techniques for
    out-of-core computations on huge arrays, notably with the HDF5 file format'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating the time taken by a statement in IPython
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `%timeit` magic and the `%%timeit` cell magic (that applies to an entire
    code cell) allow you to quickly evaluate the time taken by one or several Python
    statements. For more extensive profiling, you may need to use more advanced methods
    presented in the next recipes.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We are going to estimate the time taken to calculate the sum of the inverse
    squares of all positive integer numbers up to a given `n`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s define `n`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s time this computation in pure Python:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s use the `%%timeit` cell magic to time the same computation written
    on two lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, let''s time the NumPy version of this computation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `%timeit` command accepts several optional parameters. One such parameter
    is the number of statement evaluations. By default, this number is chosen automatically
    so that the `%timeit` command returns within a few seconds. However, this number
    can be specified directly with the `-r` and `-n` parameters. Type `%timeit?` in
    IPython to get more information.
  prefs: []
  type: TYPE_NORMAL
- en: The `%%timeit` cell magic also accepts an optional setup statement in the first
    line (on the same line as `%%timeit`), which is executed but not timed. All variables
    created in this statement are available inside the cell.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you are not in an IPython interactive session, you can use `timeit.timeit()`.
    This function, defined in Python's `timeit` module, benchmarks a Python statement
    stored in a string. IPython's `%timeit` magic command is a convenient wrapper
    around `timeit()`, useful in an interactive session. For more information on the
    `timeit` module, refer to [https://docs.python.org/3/library/timeit.html](https://docs.python.org/3/library/timeit.html).
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Profiling your code easily with cProfile and IPython* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Profiling your code line-by-line with line_profiler* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling your code easily with cProfile and IPython
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `%timeit` magic command is often helpful, yet a bit limited when you need
    detailed information about what takes most of the execution time in your code.
    This magic command is meant for **benchmarking** (comparing the execution times
    of different versions of a function) rather than **profiling** (getting a detailed
    report of the execution time, function by function).
  prefs: []
  type: TYPE_NORMAL
- en: Python includes a profiler named `cProfile` that breaks down the execution time
    into the contributions of all called functions. IPython provides convenient ways
    to leverage this tool in an interactive session.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: IPython offers the `%prun` line magic and the `%%prun` cell magic to easily
    profile one or multiple lines of code. The `%run` magic command also accepts a
    `-p` flag to run a Python script under the control of the profiler. These commands
    accept a lot of options, and you may want to take a look at their documentation
    with `%prun?` and `%run?`.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we will profile a numerical simulation of random walks starting
    at the origin. We will cover these kinds of simulations in more detail in [Chapter
    13](ch13.html "Chapter 13. Stochastic Dynamical Systems"), *Stochastic Dynamical
    Systems*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s import NumPy and matplotlib:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s create a function generating random +1 and -1 values in an array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, let's write the simulation code in a cell starting with `%%prun` in order
    to profile the entire simulation. The various options allow us to save the report
    in a file and to sort the first 10 results by cumulative time. We will explain
    these options in more detail in the *How it works…* section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The profiling report has been saved in a text file named `prun0`. Let''s display
    it (the following output is a stripped down version that fits on this page):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we observe the time taken by the different functions involved, directly
    or indirectly, in our code.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If we run the exact same simulation with 500 iterations instead of 50, we obtain
    the following results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can observe that the number of iterations has a big influence on the relative
    performance cost of the involved functions (notably `cumsum` here).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python's profiler creates a detailed report of the execution time of our code,
    function by function. Here, we can observe the number of calls of the functions
    `histogram`, `cumsum`, `step`, `sort`, and `rand`, and the total time spent in
    those functions during the code's execution. Internal functions are also profiled.
    For each function, we get the total number of calls, the total and cumulative
    times, and their per-call counterparts (division by `ncalls`). The **total time**
    represents how long the interpreter stays in a given function, *excluding* the
    time spent in calls to subfunctions. The **cumulative time** is similar but *includes*
    the time spent in calls to subfunctions. The filename, function name, and line
    number are displayed in the last column.
  prefs: []
  type: TYPE_NORMAL
- en: The `%prun` and `%%prun` magic commands accept multiple optional options (type
    `%prun?` for more details). In the example, `-s` allows us to **sort** the report
    by a particular column, `-q` to suppress (**quell**) the pager output (which is
    useful when we want to integrate the output in a notebook), `-l` to **limit**
    the number of lines displayed or to filter the results by function name (which
    is useful when we are interested in a particular function), and `-T` to save the
    report in a **text** file. In addition, we can choose to save (**dump**) the binary
    report in a file with `-D`, or to **return** it in IPython with `-r`. This database-like
    object contains all information about the profiling and can be analyzed through
    Python's `pstats` module.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Every profiler brings its own overhead that can bias the profiling results (**probe
    effect**). In other words, a profiled program may run significantly slower than
    a non-profiled program. That's a point to keep in mind.
  prefs: []
  type: TYPE_NORMAL
- en: '"Premature optimization is the root of all evil"'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As Donald Knuth's well-known quote suggests, optimizing code prematurely is
    generally considered a bad practice. Code optimization should only be conducted
    when it's really needed, that is, when the code is really too slow in normal situations.
    Additionally, we should know exactly where we need to optimize your code; typically,
    the vast majority of the execution time comprises a relatively small part of the
    code. The only way to find out is by profiling your code; optimization should
    never be done without preliminary profiling.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I was once dealing with some fairly complicated code that was slower than expected.
    I thought I had a pretty good idea of what was causing the problem and how I could
    resolve it. The solution would involve significant changes in the code. Fortunately,
    I first profiled my code, just to be sure. My diagnostic appeared to be utterly
    wrong; I had written somewhere `max(x)` instead of `np.max(x)` by mistake, where
    `x` was a very large vector. It was Python's built-in function that was called,
    instead of NumPy's heavily optimized routine for arrays. If I hadn't profiled
    my code, I would probably have missed this mistake forever. The program was working
    perfectly fine, only 150 times slower!
  prefs: []
  type: TYPE_NORMAL
- en: For more general advice on programming optimization, see [http://en.wikipedia.org/wiki/Program_optimization](http://en.wikipedia.org/wiki/Program_optimization).
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Profiling code in IPython is particularly simple (especially in the notebook),
    as we have seen in this recipe. However, it may be undesirable or difficult to
    execute the code that we need to profile from IPython (GUIs, for example). In
    this case, we can use `cProfile` directly. It is slightly less straightforward
    than with IPython.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we call the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The file `profresults` will contain the dump of the profiling results of `myscript.py`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Then, we execute the following code from Python or IPython to display the profiling
    results in a human-readable form:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Explore the documentation of the `cProfile` and `pstats` modules to discover
    all of the analyses that you can perform on the profiling reports.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The repository at [https://github.com/rossant/easy_profiler](https://github.com/rossant/easy_profiler)
    contains a simple command-line tool that facilitates the profiling of Python scripts.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few GUI tools for exploring and visualizing the output of a profiling
    session. For example, **RunSnakeRun** allows you to view profile dumps in a GUI
    program.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few references:'
  prefs: []
  type: TYPE_NORMAL
- en: Documentation of `cProfile` and `pstats`, available at [https://docs.python.org/3/library/profile.html](https://docs.python.org/3/library/profile.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RunSnakeRun, at [www.vrplumber.com/programming/runsnakerun/](http://www.vrplumber.com/programming/runsnakerun/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python profiling tools, available at [http://blog.ionelmc.ro/2013/06/08/python-profiling-tools/](http://blog.ionelmc.ro/2013/06/08/python-profiling-tools/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Profiling your code line-by-line with line_profiler* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling your code line-by-line with line_profiler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python's native `cProfile` module and the corresponding `%prun` magic break
    down the execution time of code *function by function*. Sometimes, we may need
    an even more fine-grained analysis of code performance with a *line-by-line* report.
    Such reports can be easier to read than the reports of `cProfile`.
  prefs: []
  type: TYPE_NORMAL
- en: To profile code line-by-line, we need an external Python module named `line_profiler`
    created by Robert Kern, available at [http://pythonhosted.org/line_profiler/](http://pythonhosted.org/line_profiler/).
    In this recipe, we will demonstrate how to use this module within IPython.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To install `line_profiler`, type `pip install line_profiler` in a terminal,
    or type `!pip install line_profiler` in IPython (you need a C compiler).
  prefs: []
  type: TYPE_NORMAL
- en: On Windows, you can use Chris Gohlke's unofficial package available at [www.lfd.uci.edu/~gohlke/pythonlibs/#line_profiler](http://www.lfd.uci.edu/~gohlke/pythonlibs/#line_profiler).
  prefs: []
  type: TYPE_NORMAL
- en: How do to it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will profile the same simulation code as in the previous recipe, line-by-line:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s import NumPy and the `line_profiler` IPython extension module
    that comes with the package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This IPython extension module provides a `%lprun` magic command to profile
    a Python function line-by-line. It works best when the function is defined in
    a file and not in the interactive namespace or in the notebook. Therefore, here
    we write our code in a Python script using the `%%writefile` cell magic:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s import this script into the interactive namespace so that we can
    execute and profile our code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We execute the function under the control of the line profiler. The functions
    to be profiled need to be explicitly specified in the `%lprun` magic command.
    We also save the report in a file, `lprof0`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s display the report (the following output is a stripped-down version
    that fits in the page):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If we perform the same analysis with 10 times the previous number of iterations
    (`simulation.simulate(500)`), we get the following report:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `%lprun` command accepts a Python statement as its main argument. The functions
    to profile need to be explicitly specified with `-f`. Other optional arguments
    include `-D`, `-T`, and `-r`, and they work in a similar way to their `%prun`
    magic command counterparts.
  prefs: []
  type: TYPE_NORMAL
- en: The `line_profiler` module displays the time spent on each line of the profiled
    functions, either in timer units or as a fraction of the total execution time.
    These details are essential when we are looking for hotspots in our code.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As in the previous recipe, there may be a need to run the line-by-line profiler
    on a standalone Python program that cannot be launched easily from IPython. The
    procedure is a bit convoluted.
  prefs: []
  type: TYPE_NORMAL
- en: We download the `kernprof` file from [https://github.com/rkern/line_profiler/blob/master/kernprof.py](https://github.com/rkern/line_profiler/blob/master/kernprof.py),
    and save it in your code's directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the code, we decorate the functions we wish to profile with `@profile`.
    We need to remove these decorators at the end of the profiling session, as they
    will raise `NameError` exceptions if the code is executed normally (that is, not
    under the control of the line profiler):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: See also the [http://stackoverflow.com/questions/18229628/python-profiling-using-line-profiler-clever-way-to-remove-profile-statements](http://stackoverflow.com/questions/18229628/python-profiling-using-line-profiler-clever-way-to-remove-profile-statements)
    link for a clever way to remove profile statements.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We execute the following command in a terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `myscript.py` script will be executed, and the report will be saved in `lprof.txt`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: The repository at [https://github.com/rossant/easy_profiler](https://github.com/rossant/easy_profiler)
    offers a slightly simpler way of using the line-by-line profiler.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Tracing the step-by-step execution of a Python program
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's also talk about **tracing** tools for Python, which can be useful for
    profiling or debugging a program, or for educational purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Python's `trace` module allows us to trace program execution of Python code.
    That's extremely useful during in-depth debugging and profiling sessions. We can
    follow the entire sequence of instructions executed by the Python interpreter.
    More information on the trace module is available at [https://docs.python.org/3/library/trace.html](https://docs.python.org/3/library/trace.html).
  prefs: []
  type: TYPE_NORMAL
- en: In addition, the **Online Python Tutor** is an online interactive educational
    tool that can help us understand what the Python interpreter is doing step-by-step
    as it executes a program's source code. The Online Python Tutor is available at
    [http://pythontutor.com/](http://pythontutor.com/).
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Profiling your code easily with cProfile and IPython* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Profiling the memory usage of your code with memory_profiler* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling the memory usage of your code with memory_profiler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The methods described in the previous recipe were about CPU time profiling.
    That may be the most obvious factor when it comes to code profiling. However,
    memory is also a critical factor. For instance, running `np.zeros(500000000)`
    is likely to instantaneously crash your computer! This command may allocate more
    memory than is available on your system; your computer will then reach a nonresponsive
    state within seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Writing memory-optimized code is not trivial and can really make your program
    faster. This is particularly important when dealing with large NumPy arrays, as
    we will see later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will look at a simple memory profiler. This library, unsurprisingly
    called `memory_profiler`, was created by Fabian Pedregosa. Its usage is very similar
    to `line_profiler`, and it can be conveniently used from IPython. You can download
    it from [https://pypi.python.org/pypi/memory_profiler](https://pypi.python.org/pypi/memory_profiler).
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can install `memory_profiler` with `pip install memory_profiler`.
  prefs: []
  type: TYPE_NORMAL
- en: On Windows, you also need `psutil`, which is available at [https://pypi.python.org/pypi/psutil](https://pypi.python.org/pypi/psutil).
    You can install it with `pip install psutil`, or by downloading the package from
    [https://code.google.com/p/psutil/](https://code.google.com/p/psutil/). You can
    also download an installer from Chris Gohlke's webpage at [www.lfd.uci.edu/~gohlke/pythonlibs/](http://www.lfd.uci.edu/~gohlke/pythonlibs/).
  prefs: []
  type: TYPE_NORMAL
- en: The example in this recipe is the continuation of the previous recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Assuming that the simulation code has been loaded as shown in the previous
    recipe, we load the memory profiler IPython extension:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s run the code under the control of the memory profiler:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s show the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, here is the report with 500 iterations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `memory_profiler` package checks the memory usage of the interpreter at
    every line. The **increment** column allows us to spot those places in the code
    where large amounts of memory are allocated. This is especially important when
    working with arrays. Unnecessary array creations and copies can considerably slow
    down a program. We will tackle this issue in the next few recipes.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can use `memory_profiler` without IPython, and we can also use a quick memory
    benchmark in IPython for single commands.
  prefs: []
  type: TYPE_NORMAL
- en: Using memory_profiler for standalone Python programs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using the memory profiler with standalone Python programs is similar but slightly
    simpler than with `line_profiler`.
  prefs: []
  type: TYPE_NORMAL
- en: First, in our Python scripts, we decorate the functions we wish to profile with
    `@profile`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, we run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The profiling report will be saved in `myprof.txt`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Using the %memit magic command in IPython
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `memory_profiler` IPython extension also comes with a `%memit` magic command
    that lets us benchmark the memory used by a single Python statement. Here is a
    simple example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Other tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are other tools to monitor the memory usage of a Python program, notably
    Guppy-PE ([http://guppy-pe.sourceforge.net/](http://guppy-pe.sourceforge.net/)),
    PySizer ([http://pysizer.8325.org/](http://pysizer.8325.org/)), and Pympler ([https://code.google.com/p/pympler/](https://code.google.com/p/pympler/)).
    Used in conjunction with IPython and Python's introspection capabilities, these
    tools allow you to analyze the memory usage of a namespace or a particular object.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Profiling your code line-by-line with line_profiler* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Understanding the internals of NumPy to avoid unnecessary array copying*
    recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the internals of NumPy to avoid unnecessary array copying
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can achieve significant performance speedups with NumPy over native Python
    code, particularly when our computations follow the **Single Instruction, Multiple
    Data** (**SIMD**) paradigm. However, it is also possible to unintentionally write
    non-optimized code with NumPy.
  prefs: []
  type: TYPE_NORMAL
- en: In the next few recipes, we will see some tricks that can help us write optimized
    NumPy code. In this recipe, we will see how to avoid unnecessary array copies
    in order to save memory. In that respect, we will need to dig into the internals
    of NumPy.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we need a way to check whether two arrays share the same underlying
    data buffer in memory. Let''s define a function `id()` that returns the memory
    location of the underlying data buffer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Two arrays with the same data location (as returned by `id`) share the same
    underlying data buffer. However, the opposite is true only if the arrays have
    the same **offset** (meaning that they have the same first element). Two shared
    arrays with different offsets will have slightly different memory locations, as
    shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next few recipes, we''ll make sure to use this method with arrays that
    have the same offset. Here is a more general and reliable solution for finding
    out whether two arrays share the same data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Thanks to Michael Droettboom for pointing this out and proposing this alternative
    solution.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Computations with NumPy arrays may involve internal copies between blocks of
    memory. These copies are not always necessary, in which case they should be avoided,
    as we will see in the following tips:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We may sometimes need to make a copy of an array; for instance, if we need
    to manipulate an array while keeping an original copy in memory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Array computations can involve in-place operations (the first example in the
    following code: the array is modified) or implicit-copy operations (the second
    example: a new array is created):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Be sure to choose the type of operation you actually need. Implicit-copy operations
    are significantly slower, as shown here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reshaping an array may or may not involve a copy. The reasons will be explained
    in the *How it works...* section. For instance, reshaping a 2D matrix does not
    involve a copy, unless it is transposed (or more generally, **non-contiguous**):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Therefore, the latter instruction will be significantly slower than the former.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Both the `flatten` and the `ravel` methods of an array reshape it into a 1D
    vector (a flattened array). However, the `flatten` method always returns a copy,
    and the `ravel` method returns a copy only if necessary (thus it's faster, especially
    with large arrays).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Broadcasting rules** allow us to make computations on arrays with different
    but compatible shapes. In other words, we don''t always need to reshape or tile
    our arrays to make their shapes match. The following example illustrates two ways
    of doing an **outer product** between two vectors: the first method involves array
    tiling, the second one (faster) involves broadcasting:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will see what happens under the hood when using NumPy, and
    how this knowledge allows us to understand the tricks given in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Why are NumPy arrays efficient?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A NumPy array is basically described by metadata (notably the number of dimensions,
    the shape, and the data type) and the actual data. The data is stored in a homogeneous
    and contiguous block of memory, at a particular address in system memory (**Random
    Access Memory**, or **RAM**). This block of memory is called the **data buffer**.
    This is the main difference when compared to a pure Python structure, such as
    a list, where the items are scattered across the system memory. This aspect is
    the critical feature that makes NumPy arrays so efficient.
  prefs: []
  type: TYPE_NORMAL
- en: 'Why is this so important? Here are the main reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Computations on arrays can be written very efficiently in a low-level language
    such as C (and a large part of NumPy is actually written in C). Knowing the address
    of the memory block and the data type, it is just simple arithmetic to loop over
    all items, for example. There would be a significant overhead to do that in Python
    with a list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spatial locality** in memory access patterns results in performance gains
    notably due to the CPU cache. Indeed, the cache loads bytes in chunks from RAM
    to the CPU registers. Adjacent items are then loaded very efficiently (**sequential
    locality**, or **locality of reference**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the fact that items are stored contiguously in memory allows NumPy
    to take advantage of **vectorized instructions** of modern CPUs, such as Intel's
    **SSE** and **AVX**, AMD's XOP, and so on. For example, multiple consecutive floating
    point numbers can be loaded in 128, 256, or 512 bits registers for vectorized
    arithmetical computations implemented as CPU instructions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: Additionally, NumPy can be linked to highly optimized linear algebra libraries
    such as **BLAS** and **LAPACK** through **ATLAS** or the **Intel Math Kernel Library**
    (**MKL**). A few specific matrix computations may also be multithreaded, taking
    advantage of the power of modern multicore processors.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In conclusion, storing data in a contiguous block of memory ensures that the
    architecture of modern CPUs is used optimally, in terms of memory access patterns,
    CPU cache, and vectorized instructions.
  prefs: []
  type: TYPE_NORMAL
- en: What is the difference between in-place and implicit-copy operations?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's explain the example in step 2\. An expression such as `a *= 2` corresponds
    to an in-place operation, where all values of the array are multiplied by two.
    By contrast, `a = a*2` means that a new array containing the values of `a*2` is
    created, and the variable `a` now points to this new array. The old array becomes
    unreferenced and will be deleted by the garbage collector. No memory allocation
    happens in the first case, contrary to the second case.
  prefs: []
  type: TYPE_NORMAL
- en: More generally, expressions such as `a[i:j]` are **views** to parts of an array;
    they point to the memory buffer containing the data. Modifying them with in-place
    operations changes the original array. Hence, `a[:] = a*2` results in an in-place
    operation, unlike `a = a*2`.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing this subtlety of NumPy can help you fix some bugs (where an array is
    implicitly and unintentionally modified because of an operation on a view), and
    optimize the speed and memory consumption of your code by reducing the number
    of unnecessary copies.
  prefs: []
  type: TYPE_NORMAL
- en: Why can't some arrays be reshaped without a copy?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We explain the example in step 3 here, where a transposed 2D matrix cannot
    be flattened without a copy. A 2D matrix contains items indexed by two numbers
    (row and column), but it is stored internally as a 1D contiguous block of memory,
    accessible with a single number. There is more than one way of storing matrix
    items in a 1D block of memory: we can put the elements of the first row first,
    then the second row, and so on, or the elements of the first column first, then
    the second column, and so on. The first method is called **row-major order**,
    whereas the latter is called **column-major order**. Choosing between the two
    methods is only a matter of internal convention: NumPy uses the row-major order,
    like C, but unlike FORTRAN.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Why can''t some arrays be reshaped without a copy?](img/4818OS_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Internal array layouts: row-major and column-major orders'
  prefs: []
  type: TYPE_NORMAL
- en: 'More generally, NumPy uses the notion of `strides` to convert between a multidimensional
    index and the memory location of the underlying (1D) sequence of elements. The
    specific mapping between `array[i1, i2]` and the relevant byte address of the
    internal data is given by:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: When reshaping an array, NumPy avoids copies when possible by modifying the
    `strides` attribute. For example, when transposing a matrix, the order of strides
    is reversed, but the underlying data remains identical. However, flattening a
    transposed array cannot be accomplished simply by modifying strides (try it!),
    so a copy is needed (thanks to Chris Beaumont for clarifying an earlier version
    of this paragraph).
  prefs: []
  type: TYPE_NORMAL
- en: Internal array layout can also explain some unexpected performance discrepancies
    between very similar NumPy operations. As a small exercise, can you explain the
    following benchmarks?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: What are NumPy broadcasting rules?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Broadcasting rules describe how arrays with different dimensions and/or shapes
    can be used for computations. The general rule is that *two dimensions are compatible
    when they are equal, or when one of them is 1*. NumPy uses this rule to compare
    the shapes of the two arrays element-wise, starting with the trailing dimensions
    and working its way forward. The smallest dimension is internally stretched to
    match the other dimension, but this operation does not involve any memory copy.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are a few references:'
  prefs: []
  type: TYPE_NORMAL
- en: Broadcasting rules and examples, available at [http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Array interface in NumPy, at [http://docs.scipy.org/doc/numpy/reference/arrays.interface.html](http://docs.scipy.org/doc/numpy/reference/arrays.interface.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Locality of reference, at [http://en.wikipedia.org/wiki/Locality_of_reference](http://en.wikipedia.org/wiki/Locality_of_reference)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Internals of NumPy in the SciPy lectures notes, available at [http://scipy-lectures.github.io/advanced/advanced_numpy/](http://scipy-lectures.github.io/advanced/advanced_numpy/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 100 NumPy exercises by Nicolas Rougier, available at [www.loria.fr/~rougier/teaching/numpy.100/index.html](http://www.loria.fr/~rougier/teaching/numpy.100/index.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Using stride tricks with NumPy* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using stride tricks with NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will dig deeper into the internals of NumPy arrays, by generalizing
    the notion of row-major and column-major orders to multidimensional arrays. The
    general notion is that of **strides**, which describe how the items of a multidimensional
    array are organized within a one-dimensional data buffer. Strides are mostly an
    implementation detail, but they can also be used in specific situations to optimize
    some algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We suppose that NumPy has been imported and that the `id` function has been
    defined (see the previous recipe, *Understanding the internals of NumPy to avoid
    unnecessary array copying*).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Strides are integer numbers describing the byte step in the contiguous block
    of memory for each dimension.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This vector `x` contains double-precision floating point numbers (float64, 8
    bytes); one needs to go *8 bytes forward* to go from one item to the next.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s look at the strides of a 2D array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the first dimension (vertical), one needs to go *80 bytes* (10 float64 items)
    *forward* to go from one item to the next, because the items are internally stored
    in row-major order. In the second dimension (horizontal), one needs to go *8 bytes*
    *forward* to go from one item to the next.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s show how we can revisit the broadcasting rules from the previous recipe
    using strides:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will create a new array, `b`, pointing to the same memory block as `a`,
    but with a different shape and different strides. This new array will look like
    a vertically-tiled version of `a`. We use a special function in NumPy to change
    the strides of an array:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: NumPy believes that this array contains one million different elements, whereas
    the data buffer actually contains the same 1000 elements as `a`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can now perform an efficient outer product using the same principle as with
    broadcasting rules:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every array has a number of dimensions, a shape, a data type, and strides. Strides
    describe how the items of a multidimensional array are organized in the data buffer.
    There are many different schemes for arranging the items of a multidimensional
    array in a one-dimensional block. NumPy implements a **strided indexing scheme**,
    where the position of any element is a **linear combination** of the dimensions,
    the coefficients being the strides. In other words, strides describe, in any dimension,
    how many bytes we need to jump over in the data buffer to go from one item to
    the next.
  prefs: []
  type: TYPE_NORMAL
- en: 'The position of any element in a multidimensional array is given by a linear
    combination of its indices, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/4818OS_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Artificially changing the strides allows us to make some array operations more
    efficient than with standard methods, which may involve array copies. Internally,
    that's how broadcasting works in NumPy.
  prefs: []
  type: TYPE_NORMAL
- en: The `as_strided` method takes an array, a shape, and strides as arguments. It
    creates a new array, but uses the same data buffer as the original array. The
    only thing that changes is the metadata. This trick lets us manipulate NumPy arrays
    as usual, except that they may take much less memory than what NumPy thinks. Here,
    using 0 in the strides implies that any array item can be addressed by many multidimensional
    indices, resulting in memory savings.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Be careful with strided arrays! The `as_strided` function does not check whether
    you stay inside the memory block bounds. This means that you need to handle edge
    effects manually; otherwise, you may end up with garbage values in your arrays.
  prefs: []
  type: TYPE_NORMAL
- en: We will see a more useful application of stride tricks in the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Implementing an efficient rolling average algorithm with stride tricks*
    recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing an efficient rolling average algorithm with stride tricks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Stride tricks can be useful for local computations on arrays, when the computed
    value at a given position depends on the neighboring values. Examples include
    dynamical systems, digital filters, and cellular automata.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will implement an efficient **rolling average** algorithm
    (a particular type of convolution-based linear filter) with NumPy stride tricks.
    A rolling average of a 1D vector contains, at each position, the average of the
    elements around this position in the original vector. Roughly speaking, this process
    filters out the noisy components of a signal so as to keep only the slower components.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Make sure to reuse the `id()` function from the *Understanding the internals
    of NumPy to avoid unnecessary array copying* recipe. This function returns the
    memory address of the internal data buffer of a NumPy array.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The idea is to start from a 1D vector, and make a *virtual* 2D array where each
    line is a shifted version of the previous line. When using stride tricks, this
    process is very efficient as it does not involve any copy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s generate a 1D vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s change the strides of `a` to add shifted rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The last value indicates an out-of-bounds problem: stride tricks can be dangerous
    as memory access is not checked. Here, we should take edge effects into account
    by limiting the shape of the array.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let''s implement the computation of the rolling average. The first version
    (standard method) involves explicit array copies, whereas the second version uses
    stride tricks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'These two functions return the same result, except that the array returned
    by the second function refers to the original data buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s generate a signal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We compute the signal rolling average by creating the shifted version of the
    signal, and averaging along the vertical dimension. The result is shown in the
    next figure:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/4818OS_04_03.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: A signal and its rolling average
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s evaluate the time taken by the first method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And by the second method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the first version, most of the time is spent in the array copy, whereas in
    the stride trick version, most of the time is instead spent in the computation
    of the average.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Using stride tricks with NumPy* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making efficient array selections in NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: NumPy offers several ways of selecting slices of arrays. **Array views** refer
    to the original data buffer of an array, but with different offsets, shapes, and
    strides. They only permit strided selections (that is, with linearly spaced indices).
    NumPy also offers specific functions to make arbitrary selections along one axis.
    Finally, fancy indexing is the most general selection method, but it is also the
    slowest as we will see in this recipe. Faster alternatives should be chosen when
    possible.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We suppose that NumPy has been imported and that the `id` function has been
    defined (see the *Understanding the internals of NumPy to avoid unnecessary array
    copying* recipe).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s create an array with a large number of rows. We will select slices of
    this array along the first dimension:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s select one row from every 10 rows, using two different methods (array
    view and fancy indexing):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The view refers to the original data buffer, whereas fancy indexing yields
    a copy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s compare the performance of both methods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Fancy indexing is several orders of magnitude slower as it involves copying
    a large array.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'When nonstrided selections need to be done along one dimension, array views
    are not an option. However, alternatives to fancy indexing still exist in this
    case. Given a list of indices, NumPy''s `take()` function performs a selection
    along one axis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The second method is faster:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: Performance of fancy indexing has been improved in recent versions of NumPy;
    this trick is especially useful on older versions of NumPy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'When the indices to select along one axis are specified by a vector of Boolean
    masks, the `compress()` function is an alternative to fancy indexing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The second method is also faster than fancy indexing.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fancy indexing is the most general way of making completely arbitrary selections
    of an array. However, more specific and faster methods often exist and should
    be preferred when possible.
  prefs: []
  type: TYPE_NORMAL
- en: Array views should be used whenever strided selections have to be done, but
    we need to be careful about the fact that views refer to the original data buffer.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are a few references:'
  prefs: []
  type: TYPE_NORMAL
- en: The complete list of NumPy routines is available in the NumPy Reference Guide,
    at [http://docs.scipy.org/doc/numpy/reference/](http://docs.scipy.org/doc/numpy/reference/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The list of indexing routines is available at [http://docs.scipy.org/doc/numpy/reference/routines.indexing.html](http://docs.scipy.org/doc/numpy/reference/routines.indexing.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing huge NumPy arrays with memory mapping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, we need to deal with NumPy arrays that are too big to fit in the
    system memory. A common solution is to use **memory mapping** and implement **out-of-core
    computations**. The array is stored in a file on the hard drive, and we create
    a memory-mapped object to this file that can be used as a regular NumPy array.
    Accessing a portion of the array results in the corresponding data being automatically
    fetched from the hard drive. Therefore, we only consume what we use.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s create a memory-mapped array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Let's feed the array with random values, one column at a time because our system's
    memory is limited!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We save the last column of the array:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we flush memory changes to disk by deleting the object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reading a memory-mapped array from disk involves the same `memmap` function.
    The data type and the shape need to be specified again, as this information is
    not stored in the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This method is not the most adapted for long-term storage of data and data sharing.
    The following recipes in this chapter will show a better way based on the HDF5
    file format.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Memory mapping lets you work with huge arrays almost as if they were regular
    arrays. Python code that accepts a NumPy array as input will also accept a `memmap`
    array. However, we need to ensure that the array is used efficiently. That is,
    the array is never loaded as a whole (otherwise, it would waste system memory
    and would dismiss any advantage of the technique).
  prefs: []
  type: TYPE_NORMAL
- en: Memory mapping is also useful when you have a huge file containing raw data
    in a homogeneous binary format with a known data type and shape. In this case,
    an alternative solution is to use NumPy's `fromfile()` function with a file handle
    created with Python's native `open()` function. Using `f.seek()` lets you position
    the cursor at any location and load a given number of bytes into a NumPy array.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another way of dealing with huge NumPy matrices is to use **sparse matrices**
    through SciPy's **sparse** subpackage. It is adapted when our matrices contain
    mostly zeros, as is often the case with simulations of partial differential equations,
    graph algorithms, or specific machine learning applications. Representing matrices
    as dense structures can be a waste of memory, and sparse matrices offer a more
    efficient compressed representation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using sparse matrices in SciPy is not straightforward as multiple implementations
    exist. Each implementation is best for a particular kind of application. Here
    are a few references:'
  prefs: []
  type: TYPE_NORMAL
- en: SciPy lecture notes about sparse matrices, available at [http://scipy-lectures.github.io/advanced/scipy_sparse/index.html](http://scipy-lectures.github.io/advanced/scipy_sparse/index.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reference documentation on sparse matrices, at [http://docs.scipy.org/doc/scipy/reference/sparse.html](http://docs.scipy.org/doc/scipy/reference/sparse.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Documentation of memmap, at [http://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html](http://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Manipulating large arrays with HDF5 and PyTables* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Manipulating large heterogeneous tables with HDF5 and PyTables* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating large arrays with HDF5 and PyTables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'NumPy arrays can be persistently saved on disk using built-in functions in
    NumPy such as `np.savetxt`, `np.save`, or `np.savez`, and loaded in memory using
    analogous functions. These methods are best when the arrays contain less than
    a few million points. For larger arrays, these methods suffer from two major problems:
    they become too slow, and they require the arrays to be fully loaded in memory.
    Arrays containing billions of points can be too big to fit in system memory, and
    alternative methods are required.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These alternative methods rely on **memory mapping**: the array resides on
    the hard drive, and chunks of the array are selectively loaded in memory as soon
    as the CPU needs them. This technique is memory-efficient, at the expense of a
    slight overhead due to hard drive access. Cache mechanisms and optimizations can
    mitigate this issue.'
  prefs: []
  type: TYPE_NORMAL
- en: The previous recipe showed a basic memory mapping technique using NumPy. In
    this recipe, we will use a package named **PyTables**, which is specifically designed
    to deal with very large datasets. It implements fast memory-mapping techniques
    via a widely-used and open file format specification called **Hierarchical Data
    Format**, or **HDF5**. An HDF5 file contains one or several datasets (arrays or
    heterogeneous tables) organized into a POSIX-like hierarchy. Any part of the datasets
    can be accessed efficiently and easily without unnecessarily wasting the system
    memory.
  prefs: []
  type: TYPE_NORMAL
- en: As we will see later in this recipe, an alternative for PyTables is **h5py**.
    It is more lightweight and more adapted than PyTables in some situations.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will see how to manipulate large arrays using HDF5 and PyTables.
    The next recipe will be about pandas-like heterogeneous tables.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need PyTables 3.0+ for this recipe and the next one. With Anaconda, you
    can install PyTables using `conda install tables`. You will also find binary installers
    at [http://pytables.github.io/usersguide/installation.html](http://pytables.github.io/usersguide/installation.html).
    Windows users can find installers on [www.lfd.uci.edu/~gohlke/pythonlibs/#pytables](http://www.lfd.uci.edu/~gohlke/pythonlibs/#pytables).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Prior to version 3.0, PyTables used a camel case convention for the names of
    attributes and methods. The latest versions use the more standard Python convention
    using underscores. So, for example, `tb.open_file` is `tb.openFile` in versions
    prior to 3.0.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we need to import NumPy and PyTables (the package''s name is `tables`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s create a new empty HDF5 file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We create a new top-level group named `experiment1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s also add some metadata to this group:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In this group, we create a 1000*1000 array named `array1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we need to close the file to commit the changes on disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, let's open this file. We could have done this in another Python session
    since the array has been saved in the HDF5 file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can retrieve an attribute by giving the group path and the attribute name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can access any item in the file using attributes, replacing slashes with
    dots in the paths, and starting with `root` (corresponding to the path `/`). IPython's
    tab completion is particularly useful in this respect when exploring a file interactively.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The array can be used as a NumPy array, but an important distinction is that
    it is stored on disk instead of system memory. Performing a computation on this
    array automatically loads the requested section of the array into memory, thus
    it is more efficient to access only the array's views.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'It is also possible to get a node from its absolute path, which is useful when
    the path is only known at runtime:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We''re done for this recipe, so let''s do some clean-up:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we stored a single array in the file, but HDF5 is especially
    useful when many arrays need to be saved in a single file. HDF5 is generally used
    in big projects, when large arrays have to be organized within a hierarchical
    structure. For example, it is largely used at NASA, NOAA, and many other scientific
    institutions (see [www.hdfgroup.org/users.html](http://www.hdfgroup.org/users.html)).
    Researchers can store recorded data across multiple devices, multiple trials,
    and multiple experiments.
  prefs: []
  type: TYPE_NORMAL
- en: In HDF5, the data is organized within a tree. Nodes are either **groups** (analogous
    to folders in a file system) or **datasets** (analogous to files). A group can
    contain subgroups and datasets, whereas datasets only contain data. Both groups
    and datasets can contain attributes (metadata) that have a basic data type (integer
    or floating point number, string, and so on). HDF5 also supports internal and
    external links; a given path can refer to another group or dataset within the
    same file, or within another file. This feature may be useful if you need different
    files for the same experiment or project.
  prefs: []
  type: TYPE_NORMAL
- en: Being able to access a chunk of a single array without loading the rest of the
    array and the file in memory is quite convenient. Moreover, a loaded array can
    be polymorphically accessed using standard NumPy's slicing syntax. Code that accepts
    a NumPy array as an argument can, in principle, accept a PyTables array object
    as an argument as well.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we created a PyTables `Array` object to store our NumPy array.
    Other similar types of objects include `CArrays` that store large arrays in chunks
    and support lossless compression. Also, an `EArray` object is extendable in at
    most one dimension, which is useful when the dimensions of the array are not known
    when creating the array in the file. A common use case is recording data during
    an online experiment.
  prefs: []
  type: TYPE_NORMAL
- en: The other main type of HDF5 object is `Table`, which stores tabular data in
    a two-dimensional table with heterogeneous data types. In PyTables, a `Table`
    is to an `Array` what a pandas `DataFrame` is to a NumPy `ndarray`. We will see
    those in the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: An interesting feature of HDF5 files is that they are not tied to PyTables.
    As HDF5 is an open format specification, libraries exist in most languages (C,
    FORTRAN, MATLAB, and many others), so it's easy to open an HDF5 file in these
    languages.
  prefs: []
  type: TYPE_NORMAL
- en: In HDF5, a dataset may be stored in a **contiguous** block of memory, or in
    chunks. **Chunks** are atomic objects and HDF5/PyTables can only read and write
    entire chunks. Chunks are internally organized within a tree data structure called
    a **B-tree**. When we create a new array or table, we can specify the **chunk
    shape**. It is an internal detail, but it can greatly affect performance when
    writing and reading parts of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The optimal chunk shape depends on how we plan to access the data. There is
    a trade-off between many small chunks (large overhead due to managing lots of
    chunks) and a few large chunks (inefficient disk I/O). In general, the chunk size
    is recommended to be smaller than 1 MB. The chunk cache is also an important parameter
    that may affect performance.
  prefs: []
  type: TYPE_NORMAL
- en: Relatedly, we should specify as an optional argument the expected number of
    rows when we create an `EArray` or a `Table` object so as to optimize the internal
    structure of the file. You can find more information in the PyTables users guide
    section on optimization (see the link mentioned in the following references),
    which is a must-read if you plan to do anything slightly complex on large HDF5
    files (more than 100 MB).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we should mention another HDF5 library in Python named **h5py**. This
    lightweight library offers an easy interface to HDF5 files, with emphasis on arrays
    rather than tables. It provides very natural access to HDF5 arrays from NumPy,
    and may be sufficient if you do not need the database-like features of PyTables.
    For more information on h5py, refer to [www.h5py.org](http://www.h5py.org).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few references:'
  prefs: []
  type: TYPE_NORMAL
- en: HDF5 chunking, at [www.hdfgroup.org/HDF5/doc/Advanced/Chunking/](http://www.hdfgroup.org/HDF5/doc/Advanced/Chunking/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PyTables optimization guide, available at [http://pytables.github.io/usersguide/optimization.html](http://pytables.github.io/usersguide/optimization.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Difference between PyTables and h5py, from the perspective of h5py, at [https://github.com/h5py/h5py/wiki/FAQ#whats-the-difference-between-h5py-and-pytables](https://github.com/h5py/h5py/wiki/FAQ#whats-the-difference-between-h5py-and-pytables)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Difference between PyTables and h5py, from the perspective of PyTables, at [www.pytables.org/moin/FAQ#HowdoesPyTablescomparewiththeh5pyproject.3F](http://www.pytables.org/moin/FAQ#HowdoesPyTablescomparewiththeh5pyproject.3F)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Processing huge NumPy arrays with memory mapping* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Manipulating large heterogeneous tables with HDF5 and PyTables* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Ten tips for conducting reproducible interactive computing experiments*
    recipe in [Chapter 2](ch02.html "Chapter 2. Best Practices in Interactive Computing"),
    *Best Practices in Interactive Computing*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating large heterogeneous tables with HDF5 and PyTables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PyTables can store homogeneous blocks of data as NumPy-like arrays in HDF5 files.
    It can also store heterogeneous tables, as we will see in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need PyTables for this recipe (see the previous recipe for installation
    instructions).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s import NumPy and PyTables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s create a new HDF5 file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will create an HDF5 table with two columns: the name of a city (a string
    with 64 characters at most), and its population (a 32-bit integer). We can specify
    the columns by creating a complex data type with NumPy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we create the table in `/table1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s add a few rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After adding rows, we need to flush the table to commit the changes on disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'There are many ways to access the data from a table. The easiest but not particularly
    efficient way is to load the entire table in memory, which returns a NumPy array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'It is also possible to load a particular column (with all rows):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When dealing with a large number of rows, we can make a SQL-like query in the
    table to load all rows that satisfy particular conditions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, if their indices are known, we can access specific rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A table can be created from scratch like in this recipe, or from either an existing
    NumPy array or a pandas `DataFrame`. In the first case, the description of the
    columns can be given with a NumPy data type as shown here, with a dictionary,
    or with a class deriving from `IsDescription`. In the second case, the table description
    will be automatically inferred from the given array or table.
  prefs: []
  type: TYPE_NORMAL
- en: Rows can be added efficiently at the end of the table using `table.append()`.
    To add a single row, first get a new row instance with `row = table.row`, set
    the fields of the row as if it were a dictionary, and then call `row.append()`
    to add the new row at the end of the table. Calling `flush()` after a set of writing
    operations ensures that these changes are synchronized on disk. PyTables uses
    complex cache mechanisms to ensure maximum performance when writing and reading
    data in a table; thus, new rows are not immediately written to the disk.
  prefs: []
  type: TYPE_NORMAL
- en: PyTables supports highly efficient SQL-like queries called **in-kernel queries**.
    The string containing the query expression is compiled and evaluated on all rows.
    A less-efficient method consists of iterating over all rows with `table.iterrows()`
    and using an `if` statement on the rows' fields.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are a few references:'
  prefs: []
  type: TYPE_NORMAL
- en: In-kernel queries, at [http://pytables.github.io/usersguide/condition_syntax.html](http://pytables.github.io/usersguide/condition_syntax.html).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An alternative to PyTables and HDF5 might come from the Blaze project, still
    in early development at the time of writing. For more information on Blaze, refer
    to [http://blaze.pydata.org](http://blaze.pydata.org).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Manipulating large arrays with HDF5 and PyTables* recipe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
