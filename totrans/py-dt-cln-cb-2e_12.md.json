["```py\nimport pandas as pd\ndef getfirstlook(df, nrows=5, uniqueids=None):\n...   out = {}\n...   out['head'] = df.head(nrows)\n...   out['dtypes'] = df.dtypes\n...   out['nrows'] = df.shape[0]\n...   out['ncols'] = df.shape[1]\n...   out['index'] = df.index\n...   if (uniqueids is not None):\n...     out['uniqueids'] = df[uniqueids].nunique()\n...   return out\ndef displaydict(dicttodisplay):\n...   print(*(': '.join(map(str, x)) \\\n...     for x in dicttodisplay.items()), sep='\\n\\n') \n```", "```py\nimport pandas as pd\nimport os\nimport sys\nnls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\nnls97.set_index('personid', inplace=True) \n```", "```py\nsys.path.append(os.getcwd() + \"/helperfunctions\")\nimport basicdescriptives as bd\n# import importlib\n# importlib.reload(bd) \n```", "```py\ndfinfo = bd.getfirstlook(nls97)\nbd.displaydict(dfinfo) \n```", "```py\nhead:       gender    birthmonth    birthyear    ...    parentincome  \\\npersonid                                         ...               \n135335     Female             9       1981       ...              -3  \n999406       Male             7       1982       ...              -4  \n151672     Female             9       1983       ...           63000  \n750699     Female             2       1981       ...           11700  \n781297       Male            10       1982       ...              -3  \n          fatherhighgrade   motherhighgrade \npersonid                                  \n135335                16                  8 \n999406                17                 15 \n151672                -3                 12 \n750699                12                 12 \n781297                12                 12 \n[5 rows x 110 columns]\ndtypes: gender      object\nbirthmonth          int64\nbirthyear           int64\nsampletype         object\nethnicity          object\noriginalid          int64\nmotherage           int64\nparentincome        int64\nfatherhighgrade     int64\nmotherhighgrade     int64\nLength: 110, dtype: object\nnrows: 8984\nncols: 110\nindex: Index([135335, 999406, 151672, 750699, 781297, 613800, 403743,\n       474817, 530234, 351406,\n       ...\n       290800, 209909, 756325, 543646, 411195, 505861, 368078,\n       215605, 643085, 713757],\n      dtype='int64', name='personid', length=8984) \n```", "```py\ndfinfo = bd.getfirstlook(nls97,2,'originalid')\nbd.displaydict(dfinfo) \n```", "```py\nhead:       gender    birthmonth    birthyear    ...    parentincome  \\\npersonid                                         ...               \n135335      Female             9         1981    ...              -3  \n999406        Male             7         1982    ...              -4  \n         fatherhighgrade  motherhighgrade \npersonid                                  \n135335                16                8 \n999406                17               15 \n[2 rows x 110 columns]\ndtypes: gender      object\nbirthmonth          int64\nbirthyear           int64\nsampletype         object\nethnicity          object\noriginalid          int64\nmotherage           int64\nparentincome        int64\nfatherhighgrade     int64\nmotherhighgrade     int64\nLength: 110, dtype: object\nnrows: 8984\nncols: 110\nindex: Index([135335, 999406, 151672, 750699, 781297, 613800, 403743,\n       474817, 530234, 351406,\n       ...\n       290800, 209909, 756325, 543646, 411195, 505861, 368078,\n       215605, 643085, 713757],\n      dtype='int64', name='personid', length=8984)\nuniqueids: 8984 \n```", "```py\ndfinfo['nrows'] \n```", "```py\n8984 \n```", "```py\ndfinfo['dtypes'] \n```", "```py\ngender             object\nbirthmonth          int64\nbirthyear           int64\nsampletype         object\nethnicity          object\noriginalid          int64\nmotherage           int64\nparentincome        int64\nfatherhighgrade     int64\nmotherhighgrade     int64\nLength: 110, dtype: object \n```", "```py\ndfinfo['nrows'] == dfinfo['uniqueids'] \n```", "```py\nTrue \n```", "```py\ndef gettots(df):\n...   out = {}\n...   out['min'] = df.min()\n...   out['per15'] = df.quantile(0.15)\n...   out['qr1'] = df.quantile(0.25)\n...   out['med'] = df.median()\n...   out['qr3'] = df.quantile(0.75)\n...   out['per85'] = df.quantile(0.85)\n...   out['max'] = df.max()\n...   out['count'] = df.count()\n...   out['mean'] = df.mean()\n...   out['iqr'] = out['qr3']-out['qr1']\n...   return pd.DataFrame(out) \n```", "```py\nimport pandas as pd\nimport os\nimport sys\nnls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\nnls97.set_index('personid', inplace=True) \n```", "```py\n    sys.path.append(os.getcwd() + \"/helperfunctions\")\n    import basicdescriptives as bd \n    ```", "```py\nbd.gettots(nls97[['satverbal','satmath']]).T \n```", "```py\n satverbal  satmath\nmin           14        7\nper15        390      390\nqr1          430      430\nmed          500      500\nqr3          570      580\nper85        620      621\nmax          800      800\ncount      1,406    1,407\nmean         500      501\niqr          140      150 \n```", "```py\nbd.gettots(nls97.filter(like=\"weeksworked\")) \n```", "```py\n min  per15  qr1  ...  count  mean  iqr\nweeksworked00    0      0    5  ...   8626    26   45\nweeksworked01    0      0   10  ...   8591    30   41\nweeksworked02    0      0   13  ...   8591    32   39\nweeksworked03    0      0   14  ...   8535    34   38\nweeksworked04    0      1   17  ...   8513    35   35\nweeksworked05    0      5   22  ...   8468    37   31\nweeksworked06    0      9   27  ...   8419    38   25\nweeksworked07    0     10   30  ...   8360    39   22\nweeksworked08    0      9   30  ...   8292    39   22\nweeksworked09    0      0   22  ...   8267    38   30\nweeksworked10    0      0   21  ...   8198    37   31\nweeksworked11    0      0   22  ...   8123    38   31\nweeksworked12    0      0   23  ...   7988    38   29\nweeksworked13    0      0   28  ...   7942    39   24\nweeksworked14    0      0   26  ...   7896    39   26\nweeksworked15    0      0   33  ...   7767    40   19\nweeksworked16    0      0   31  ...   7654    40   22\nweeksworked17    0      0   38  ...   7496    40   14\nweeksworked18    0      0   35  ...   7435    40   17\nweeksworked19    0      4   42  ...   7237    41   10\nweeksworked20    0      0   21  ...   6971    38   31\nweeksworked21    0      0   35  ...   6627    36   15\nweeksworked22    0      0    2  ...   2202    11   17\n[23 rows x 10 columns] \n```", "```py\ndef getmissings(df, byrowperc=False):\n  return df.isnull().sum(),\\\n    df.isnull().sum(axis=1).\\\n    value_counts(normalize=byrowperc).\\\n    sort_index() \n```", "```py\nmissingsbycols, missingsbyrows = \\\n  bd.getmissings(nls97[['weeksworked20',\n  'weeksworked21']], True)\nmissingsbycols \n```", "```py\nweeksworked20    2013\nweeksworked21    2357\ndtype: int64 \n```", "```py\nmissingsbyrows \n```", "```py\n0   0.73\n1   0.05\n2   0.22\nName: proportion, dtype: float64 \n```", "```py\nmissingsbycols, missingsbyrows = \\\n  bd.getmissings(nls97[['weeksworked20',\n  'weeksworked21']])\nmissingsbyrows \n```", "```py\n0    6594\n1     410\n2    1980\nName: count, dtype: int64 \n```", "```py\ndef makefreqs(df, outfile):\n...   freqout = open(outfile, 'w')\n...   for col in df.\\\n...     select_dtypes(include=[\"category\"]):\n...       print(col, \"----------------------\",\n...         \"frequencies\",\n...         df[col].value_counts().sort_index(),\n...         \"percentages\",\n...         df[col].value_counts(normalize=True).\\\n...         sort_index(),\n...         sep=\"\\n\\n\", end=\"\\n\\n\\n\",\n...         file=freqout)\n...   freqout.close() \n```", "```py\nnls97.loc[:, nls97.dtypes == 'object'] = \\\n...   nls97.select_dtypes(['object']). \\\n...   apply(lambda x: x.astype('category'))\nbd.makefreqs(nls97, \"views/nlsfreqs.txt\") \n```", "```py\ndef getcnts(df, cats, rowsel=None):\n...   tots = cats[:-1]\n...   catcnt = df.groupby(cats, dropna=False).size().\\\n...     reset_index(name='catcnt')\n...   totcnt = df.groupby(tots, dropna=False).size().\\\n...     reset_index(name='totcnt')\n...   percs = pd.merge(catcnt, totcnt, left_on=tots,\n...     right_on=tots, how=\"left\")\n...   percs['percent'] = percs.catcnt / percs.totcnt\n...   if (rowsel is not None):\n...     percs = percs.loc[eval(\"percs.\" + rowsel)]\n...   return percs \n```", "```py\nbd.getcnts(nls97,\n  ['maritalstatus','colenroct00']) \n```", "```py\n maritalstatus           colenroct00   catcnt   totcnt   percent\n0        Divorced       1\\. Not enrolled      560      669      0.84\n1        Divorced     2\\. 2-year college       50      669      0.07\n2        Divorced     3\\. 4-year college       59      669      0.09\n3         Married       1\\. Not enrolled     2264     3068      0.74\n4         Married     2\\. 2-year college      236     3068      0.08\n5         Married     3\\. 4-year college      568     3068      0.19\n6   Never-married       1\\. Not enrolled     2363     2767      0.85\n7   Never-married     2\\. 2-year college      131     2767      0.05\n8   Never-married     3\\. 4-year college      273     2767      0.10\n9       Separated       1\\. Not enrolled      127      148      0.86\n10      Separated     2\\. 2-year college       13      148      0.09\n11      Separated     3\\. 4-year college        8      148      0.05\n12        Widowed       1\\. Not enrolled       19       23      0.83\n13        Widowed     2\\. 2-year college        1       23      0.04\n14        Widowed     3\\. 4-year college        3       23      0.13\n15            NaN       1\\. Not enrolled     1745     2309      0.76\n16            NaN     2\\. 2-year college      153     2309      0.07\n17            NaN     3\\. 4-year college      261     2309      0.11\n18            NaN                   NaN     150      2309      0.06 \n```", "```py\n    bd.getcnts(nls97,\n      ['maritalstatus','colenroct20'],\n      \"colenroct20.str[0:1]=='1'\") \n    ```", "```py\n     maritalstatus       colenroct00   catcnt    totcnt    percent\n    0         Divorced   1\\. Not enrolled      560       669       0.84\n    3          Married   1\\. Not enrolled     2264      3068       0.74\n    6    Never-married   1\\. Not enrolled     2363      2767       0.85\n    9        Separated   1\\. Not enrolled      127       148       0.86\n    12         Widowed   1\\. Not enrolled       19        23       0.83\n    15             NaN   1\\. Not enrolled     1745      2309       0.76 \n    ```", "```py\nimport pandas as pd\nimport os\nimport sys\nimport pprint\nnls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\nnls97.set_index('personid', inplace=True)\ncovidtotals = pd.read_csv(\"data/covidtotals.csv\") \n```", "```py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy.stats as scistat\nimport math\ndef getdistprops(seriestotest):\n...   out = {}\n...   normstat, normpvalue = scistat.shapiro(seriestotest)\n...   if (not math.isnan(normstat)):\n...     out['normstat'] = normstat\n...     if (normpvalue>=0.05):\n...       out['normpvalue'] = str(round(normpvalue, 2)) + \": Accept Normal\"\n...     elif (normpvalue<0.05):\n...       out['normpvalue'] = str(round(normpvalue, 2)) + \": Reject Normal\"\n...   out['mean'] = seriestotest.mean()\n...   out['median'] = seriestotest.median()\n...   out['std'] = seriestotest.std()\n...   out['kurtosis'] = seriestotest.kurtosis()\n...   out['skew'] = seriestotest.skew()\n...   out['count'] = seriestotest.count()\n...   return out \n```", "```py\ndist = ol.getdistprops(covidtotals.total_cases_pm)\npprint.pprint(dist) \n```", "```py\n{'count': 231,\n 'kurtosis': -0.4280595203351645,\n 'mean': 206177.79462337663,\n 'median': 133946.251,\n 'normpvalue': '0.0: Reject Normal',\n 'normstat': 0.8750641345977783,\n 'skew': 0.8349032460009967,\n 'std': 203858.09625231632} \n```", "```py\ndef getoutliers(dfin, sumvars, othervars):\n...   dfin = dfin[sumvars + othervars]\n...   dfout = pd.DataFrame(columns=dfin.columns, data=None)\n...   dfsums = dfin[sumvars]\n...   for col in dfsums.columns:\n...     thirdq, firstq = dfsums[col].quantile(0.75),\\\n...       dfsums[col].quantile(0.25)\n...     interquartilerange = 1.5*(thirdq-firstq)\n...     outlierhigh, outlierlow = interquartilerange+thirdq,\\\n...       firstq-interquartilerange\n...     df = dfin.loc[(dfin[col]>outlierhigh) | \\\n...       (dfin[col]<outlierlow)]\n...     df = df.assign(varname = col, threshlow = outlierlow,\\\n...       threshhigh = outlierhigh)\n...     dfout = pd.concat([dfout, df])\n...   return dfout \n```", "```py\nsumvars = ['satmath','wageincome20']\nothervars = ['originalid','highestdegree','gender','maritalstatus']\noutliers = ol.getoutliers(nls97, sumvars, othervars)\noutliers.varname.value_counts(sort=False) \n```", "```py\nvarname\nsatmath          10\nwageincome20    234\nName: count, dtype: int64 \n```", "```py\noutliers.loc[outliers.varname=='satmath', othervars + sumvars] \n```", "```py\n originalid      highestdegree   ...    satmath    wageincome20\n337438         159     2\\. High School   ...     200.00       32,000.00\n448463         326       4\\. Bachelors   ...      47.00             NaN\n799095         535         5\\. Masters   ...      59.00             NaN\n267254        1622     2\\. High School   ...      48.00             NaN\n955430        2547     2\\. High School   ...     200.00             NaN\n748274        3394       4\\. Bachelors   ...      42.00             NaN\n399109        3883     2\\. High School   ...      36.00       37,000.00\n223058        6696            0\\. None   ...      46.00             NaN\n291029        7088     2\\. High School   ...      51.00             NaN\n738290        7705     2\\. High School   ...       7.00       50,000.00\n[10 rows x 6 columns] \n```", "```py\noutliers.to_excel(\"views/nlsoutliers.xlsx\") \n```", "```py\ndef makeplot(seriestoplot, title, xlabel, plottype=\"hist\"):\n...   if (plottype==\"hist\"):\n...     plt.hist(seriestoplot)\n...     plt.axvline(seriestoplot.mean(), color='red',\\\n...       linestyle='dashed', linewidth=1)\n...     plt.xlabel(xlabel)\n...     plt.ylabel(\"Frequency\")\n...   elif (plottype==\"box\"):\n...     plt.boxplot(seriestoplot.dropna(), labels=[xlabel])\n...   plt.title(title)\n...   plt.show() \n```", "```py\n    ol.makeplot(nls97.satmath, \"Histogram of SAT Math\", \"SAT Math\") \n    ```", "```py\n    ol.makeplot(nls97.satmath, \"Boxplot of SAT Math\", \"SAT Math\", \"box\") \n    ```", "```py\n    import pandas as pd\n    import os\n    import sys \n    ```", "```py\ndef adjmeans(df, byvar, var, period, changeexclude=None, excludetype=None):\n...   df = df.sort_values([byvar, period])\n...   df = df.dropna(subset=[var])\n...   # iterate using numpy arrays\n...   prevbyvar = 'ZZZ'\n...   prevvarvalue = 0\n...   rowlist = []\n...   varvalues = df[[byvar, var]].values\n...   # convert exclusion ratio to absolute number\n...   if (excludetype==\"ratio\" and changeexclude is not None):\n...     changeexclude = df[var].mean()*changeexclude\n...   # loop through variable values\n...   for j in range(len(varvalues)):\n...     byvar = varvalues[j][0]\n...     varvalue = varvalues[j][1]\n...     if (prevbyvar!=byvar):\n...       if (prevbyvar!='ZZZ'):\n...         rowlist.append({'byvar':prevbyvar, 'avgvar':varsum/byvarcnt,\\\n...           'sumvar':varsum, 'byvarcnt':byvarcnt})\n...       varsum = 0\n...       byvarcnt = 0\n...       prevbyvar = byvar\n...     # exclude extreme changes in variable value\n...     if ((changeexclude is None) or (0 <= abs(varvalue-prevvarvalue) \\\n...       <= changeexclude) or (byvarcnt==0)):\n...       varsum += varvalue\n...       byvarcnt += 1\n...     prevvarvalue = varvalue\n...   rowlist.append({'byvar':prevbyvar, 'avgvar':varsum/byvarcnt, \\\n...     'sumvar':varsum, 'byvarcnt':byvarcnt})\n...   return pd.DataFrame(rowlist) \n```", "```py\n    sys.path.append(os.getcwd() + \"/helperfunctions\")\n    import combineagg as ca \n    ```", "```py\n    coviddaily = pd.read_csv(\"data/coviddaily.csv\")\n    ltbrazil = pd.read_csv(\"data/ltbrazil.csv\")\n    countries = pd.read_csv(\"data/ltcountries.csv\")\n    locations = pd.read_csv(\"data/ltlocations.csv\") \n    ```", "```py\nca.adjmeans(coviddaily, 'location','new_cases','casedate') \n```", "```py\n byvar     avgvar        sumvar     byvarcnt\n0             Afghanistan      1,129       231,539          205\n1                 Albania      1,914       334,863          175\n2                 Algeria      1,439       272,010          189\n3          American Samoa        144         8,359           58\n4                 Andorra        304        48,015          158\n..                    ...        ...           ...          ...\n226               Vietnam     60,542    11,624,000          192\n227     Wallis and Futuna        154         3,550           23\n228                 Yemen         98        11,945          122\n229                Zambia      2,019       349,304          173\n230              Zimbabwe      1,358       266,266          196\n[231 rows x 4 columns] \n```", "```py\n    ca.adjmeans(coviddaily, 'location','new_cases','casedate', 5000) \n    ```", "```py\n     byvar     avgvar     sumvar     byvarcnt\n    0             Afghanistan      1,129    231,539          205\n    1                 Albania      1,855    322,772          174\n    2                 Algeria      1,290    239,896          186\n    3          American Samoa        144      8,359           58\n    4                 Andorra        304     48,015          158\n    ..                    ...        ...        ...          ...\n    226               Vietnam      6,410    967,910          151\n    227     Wallis and Futuna        154      3,550           23\n    228                 Yemen         98     11,945          122\n    229                Zambia      1,555    259,768          167\n    230              Zimbabwe      1,112    214,526          193\n    [231 rows x 4 columns] \n    ```", "```py\ndef checkmerge(dfleft, dfright, mergebyleft, mergebyright):\n...   dfleft['inleft'] = \"Y\"\n...   dfright['inright'] = \"Y\"\n...   dfboth = pd.merge(dfleft[[mergebyleft,'inleft']],\\\n...     dfright[[mergebyright,'inright']], left_on=[mergebyleft],\\\n...     right_on=[mergebyright], how=\"outer\")\n...   dfboth.fillna('N', inplace=True)\n...   print(pd.crosstab(dfboth.inleft, dfboth.inright))\n...   print(dfboth.loc[(dfboth.inleft=='N') | (dfboth.inright=='N')].head(20)) \n```", "```py\nca.checkmerge(countries.copy(), locations.copy(),\\\n...   \"countryid\", \"countryid\") \n```", "```py\ninright    N        Y\ninleft          \nN          0        1\nY          2    27472\n        countryid    inleft    inright\n7363           FO         N          Y\n9716           LQ         Y          N\n13104          ST         Y          N \n```", "```py\ndef addfiles(directory):\n...   dfout = pd.DataFrame()\n...   columnsmatched = True\n...   # loop through the files\n...   for filename in os.listdir(directory):\n...     if filename.endswith(\".csv\"):\n...       fileloc = os.path.join(directory, filename)\n...       # open the next file\n...       with open(fileloc) as f:\n...         dfnew = pd.read_csv(fileloc)\n...         print(filename + \" has \" + str(dfnew.shape[0]) + \" rows.\")\n...         dfout = pd.concat([dfout, dfnew])\n...         # check if current file has any different columns\n...         columndiff = dfout.columns.symmetric_difference(dfnew.columns)\n...         if (not columndiff.empty):\n...           print(\"\", \"Different column names for:\", filename,\\\n...             columndiff, \"\", sep=\"\\n\")\n...           columnsmatched = False\n...   print(\"Columns Matched:\", columnsmatched)\n...   return dfout \n```", "```py\nlandtemps = ca.addfiles(\"data/ltcountry\") \n```", "```py\nltpoland.csv has 120 rows.\nltcameroon.csv has 48 rows.\nltmexico.csv has 852 rows.\nltjapan.csv has 1800 rows.\nltindia.csv has 1116 rows.\nltoman.csv has 288 rows.\nDifferent column names for:\nltoman.csv\nIndex(['latabs'], dtype='object')\nltbrazil.csv has 1008 rows.\nColumns Matched: False \n```", "```py\nlandtemps.country.value_counts() \n```", "```py\ncountry\nJapan       1800\nIndia       1116\nBrazil      1008\nMexico       852\nOman         288\nPoland       120\nCameroon      48\nName: count, dtype: int64 \n```", "```py\nimport pandas as pd\nimport os\nimport sys\nimport pprint \n```", "```py\nimport math\nimport datetime as dt\nclass Respondent:\n...   respondentcnt = 0\n...   def __init__(self, respdict):\n...     self.respdict = respdict\n...     Respondent.respondentcnt+=1 \n```", "```py\ndef childnum(self):\n...   return self.respdict['childathome'] + self.respdict['childnotathome'] \n```", "```py\ndef avgweeksworked(self):\n...   workdict = {k: v for k, v in self.respdict.items() \\\n...     if k.startswith('weeksworked') and not math.isnan(v)}\n...   nweeks = len(workdict)\n...   if (nweeks>0):\n...     avgww = sum(workdict.values())/nweeks\n...   else:\n...     avgww = 0\n...   return avgww \n```", "```py\ndef ageby(self, bydatestring):\n...   bydate = dt.datetime.strptime(bydatestring, '%Y%m%d')\n...   birthyear = self.respdict['birthyear']\n...   birthmonth = self.respdict['birthmonth']\n...   age = bydate.year - birthyear\n...   if (bydate.month<birthmonth or (bydate.month==birthmonth \\\n...       and bydate.day<15)):\n...     age = age -1\n...   return age \n```", "```py\ndef baenrollment(self):\n...   colenrdict = {k: v for k, v in self.respdict.items() \\\n...     if k.startswith('colenr') and v==\"3\\. 4-year college\"}\n...   if (len(colenrdict)>0):\n...     return \"Y\"\n...   else:\n...     return \"N\" \n```", "```py\nsys.path.append(os.getcwd() + \"/helperfunctions\")\nimport respondent as rp \n```", "```py\nnls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\nnls97list = nls97.to_dict('records')\nnls97.shape \n```", "```py\n(8984, 111) \n```", "```py\nlen(nls97list) \n```", "```py\n8984 \n```", "```py\npprint.pprint(nls97list[0:1]) \n```", "```py\n[{'birthmonth': 9,\n  'birthyear': 1981,\n  'childathome': nan,\n  'childnotathome': nan,\n  'colenrfeb00': '3\\. 4-year college',\n  'colenrfeb01': '3\\. 4-year college',\n  ...\n  'weeksworked21': nan,\n  'weeksworked22': nan}] \n```", "```py\nanalysislist = []\nfor respdict in nls97list:\n...   resp = rp.Respondent(respdict)\n...   newdict = dict(originalid=respdict['originalid'],\n...     childnum=resp.childnum(),\n...     avgweeksworked=resp.avgweeksworked(),\n...     age=resp.ageby('20201015'),\n...     baenrollment=resp.baenrollment())\n...   analysislist.append(newdict) \n```", "```py\nlen(analysislist) \n```", "```py\n8984 \n```", "```py\nresp.respondentcnt \n```", "```py\n8984 \n```", "```py\npprint.pprint(analysislist[0:2]) \n```", "```py\n[{'age': 39,\n  'avgweeksworked': 48.4375,\n  'baenrollment': 'Y',\n  'childnum': nan,\n  'originalid': 1},\n {'age': 38,\n  'avgweeksworked': 49.90909090909091,\n  'baenrollment': 'Y',\n  'childnum': nan,\n  'originalid': 2}] \n```", "```py\nanalysis = pd.DataFrame(analysislist)\nanalysis.head(2) \n```", "```py\n originalid    childnum   avgweeksworked    age    baenrollment\n0            1         NaN               48     39               Y\n1            2         NaN               50     38               Y \n```", "```py\n{\n\"id\": 165157,\n\"title\": \"Fulton and Nostrand\",\n\"creation_date\": \"1958\",\n\"citations\": [\n  {\n   \"citation\": \"Annual Exhibition: Sculpture, Paintings, Watercolors, Drawings, \n   \"page_number\": \"Unpaginated, [8],[12]\",\n   \"url\": null\n   },\n  {\n   \"citation\": \"\\\"Moscow to See Modern U.S. Art,\\\"<em> New York Times</em> (May 31, 1959).\",  \n   \"page_number\": \"P. 60\",\n   \"url\": null\n  }]\n\"creators\": [\n      {\n     \"description\": \"Jacob Lawrence (American, 1917-2000)\",\n     \"role\": \"artist\",\n     \"birth_year\": \"1917\",\n     \"death_year\": \"2000\"\n     }\n  ]\n } \n```", "```py\nimport pandas as pd\nimport json\nimport pprint\nimport requests \n```", "```py\nclass Collectionitem:\n...   collectionitemcnt = 0\n...   def __init__(self, colldict):\n...     self.colldict = colldict\n...     Collectionitem.collectionitemcnt+=1 \n```", "```py\ndef birthyearcreator1(self):\n...   if (\"birth_year\" in self.colldict['creators'][0]):\n...     byear = self.colldict['creators'][0]['birth_year']\n...   else:\n...     byear = \"Unknown\"\n...   return byear \n```", "```py\ndef birthyearsall(self):\n...   byearlist = [item.get('birth_year') for item in \\\n...     self.colldict['creators']]\n...   return byearlist \n```", "```py\n    def ncreators(self):\n    ...   return len(self.colldict['creators']) \n    ```", "```py\n    def ncitations(self):\n    ...   return len(self.colldict['citations']) \n    ```", "```py\nsys.path.append(os.getcwd() + \"/helperfunctions\")\nimport collectionitem as ci \n```", "```py\nresponse = requests.get(\"https://openaccess-api.clevelandart.org/api/artworks/?african_american_artists\")\ncamcollections = json.loads(response.text)\ncamcollections = camcollections['data'] \n```", "```py\nanalysislist = []\nfor colldict in camcollections:\n...   coll = ci.Collectionitem(colldict)\n...   newdict = dict(id=colldict['id'],\n...     title=colldict['title'],\n...     type=colldict['type'],\n...     creationdate=colldict['creation_date'],\n...     ncreators=coll.ncreators(),\n...     ncitations=coll.ncitations(),\n...     birthyearsall=coll.birthyearsall(),\n...     birthyear=coll.birthyearcreator1())\n...   analysislist.append(newdict) \n```", "```py\nlen(camcollections) \n```", "```py\n1000 \n```", "```py\nlen(analysislist) \n```", "```py\n1000 \n```", "```py\npprint.pprint(analysislist[0:1]) \n```", "```py\n[{'birthyear': '1917',\n  'birthyearsall': ['1917'],\n  'creationdate': '1958',\n  'id': 165157,\n  'ncitations': 30,\n  'ncreators': 1,\n  'title': 'Fulton and Nostrand',\n  'type': 'Painting'}] \n```", "```py\nanalysis = pd.DataFrame(analysislist)\nanalysis.birthyearsall.value_counts().head() \n```", "```py\nbirthyearsall\n[1951]          283\n[1953]          119\n[1961, None]    105\n[1937]           55\n[1922]           41\nName: count, dtype: int64 \n```", "```py\nanalysis.head(2).T \n```", "```py\n 0              1\nid                          165157         163769\ntitle          Fulton and Nostrand  Go Down Death\ntype                      Painting       Painting\ncreationdate                  1958           1934\nncreators                        1              1\nncitations                      30             18\nbirthyearsall               [1917]         [1899]\nbirthyear                     1917           1899 \n```", "```py\n    def checkcats(cat1,cat2):\n      missingcats = \\\n       set(cat1).symmetric_difference(set(cat2))\n      return missingcats\n    def checkoutliers(values):\n      thirdq, firstq = values.\\\n        quantile(0.75),values.\\\n        quantile(0.25)\n      interquartilerange = 1.5*(thirdq-firstq)\n      outlierhigh, outlierlow = \\\n        interquartilerange+thirdq, \\\n        firstq-interquartilerange\n      return outlierhigh, outlierlow \n    ```", "```py\n    def runchecks(df,dc,numvars,catvars,idvars): \n    ```", "```py\n     for col in df[catvars]:\n        dcvals = dc.loc[col]\n        print(\"\\n\\nChecks for categorical variable\", col)\n        compcat = list(dcvals.categories.split('|'))\n        valuediff = checkcats(compcat,df[col].dropna().\\\n          str.strip().unique())\n        if len(valuediff) > 0:\n          print(\"at least one non-matching category:\",\n            valuediff)\n\n        missingper = df[col].isnull().sum()/df.shape[0]\n        if missingper > dcvals.missingthreshold:\n          print(\"missing percent beyond threshold of\",\n          dcvals.missingthreshold, \"is\", missingper) \n    ```", "```py\n for col in df[numvars]:\n    dcvals = dc.loc[col]\n    print(\"\\n\\nChecks for numeric variable\", col)\n\n    range = np.fromstring(dcvals.range, sep='|')\n    min = df[col].min()\n    max = df[col].max()\n    if min < range[0]:\n      print(\"at least one record below range starting at \",\n       range[0], \"min value is\", min)\n    if max > range[1]:\n      print(\"at least one record above range ending at \",\n       range[1], \"max value is\", max)\n    missingper = df[col].isnull().sum()/df.shape[0]\n    if missingper > dcvals.missingthreshold:\n      print(\"missing percent beyond threshold of\",\n       dcvals.missingthreshold, \"is\", missingper)\n\n    if dcvals.showoutliers == \"Y\":\n      outlierhigh, outlierlow = checkoutliers(df[col])\n      print(\"\\nvalues less than\", outlierlow, \"\\n\",\n        df.loc[df[col]<outlierlow,col].\\\n        agg([\"min\",'max','count']), end=\"\\n\")\n      print(\"\\nvalues greater than\", outlierhigh,\n        \"\\n\", df.loc[df[col]>outlierhigh,col].\\\n        agg([\"min\",'max','count']), end=\"\\n\")\n    skewcol = df[col].skew()\n    if abs(skewcol-dcvals.skewtarget)>1.2:\n      print(\"skew substantially different from target of\",\n        dcvals.skewtarget, \"is\", skewcol)\n\n    kurtosiscol = df[col].kurtosis()\n    if abs(kurtosiscol-dcvals.kurtosistarget)>1.2:\n      print(\"kurtosis substantially different from target of\",\n        dcvals.kurtosistarget, \"is\", kurtosiscol) \n```", "```py\n     for col in df[idvars]:\n        print(\"\\n\\nChecks for id variable\", col)\n\n        uniquevals = df[col].nunique()\n        nrows = df.shape[0]\n        if uniquevals != nrows:\n          print(\"not unique identifier\", uniquevals,\n            \"unique values not equal to\", nrows, \"rows.\")\n\n        missingvals = df[col].isnull().sum()\n        if missingvals > 0:\n          print(\"unique value has\", missingvals,\n            \"missing values\") \n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    import os\n    import sys\n    nls97 = pd.read_csv(\"data/nls97g.csv\", low_memory=False)\n    dc = pd.read_csv(\"data/datacheckingtargets.csv\")\n    dc.set_index('varname', inplace=True) \n    ```", "```py\n    sys.path.append(os.getcwd() + \"/helperfunctions\")\n    import runchecks as rc \n    ```", "```py\n    nls97.originalid.head(7) \n    ```", "```py\n    0    1\n    1    2\n    2    3\n    3    4\n    4    5\n    5    6\n    6    7\n    Name: originalid, dtype: int64 \n    ```", "```py\n    nls97.loc[nls97.originalid==2,\"originalid\"] = 1\n    nls97.loc[nls97.originalid.between(3,7), \"originalid\"] = np.nan\n    nls97.originalid.head(7) \n    ```", "```py\n    0    1.0\n    1    1.0\n    2    NaN\n    3    NaN\n    4    NaN\n    5    NaN\n    6    NaN\n    Name: originalid, dtype: float64 \n    ```", "```py\n    nls97[\"highestgradecompleted\"] = nls97.highestgradecompleted.replace(95, np.nan) \n    ```", "```py\n    dc = dc.loc[dc.include==\"Y\"]\n    numvars = dc.loc[dc.type==\"numeric\"].index.to_list()\n    catvars = dc.loc[dc.type==\"categorical\"].index.to_list()\n    idvars = dc.loc[dc.type==\"unique\"].index.to_list() \n    ```", "```py\n    rc.runchecks(nls97,dc,numvars,catvars,idvars) \n    ```", "```py\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.linear_model import LinearRegression\n    from sklearn.impute import SimpleImputer\n    from sklearn.pipeline import make_pipeline\n    from sklearn.model_selection import cross_validate\n    from sklearn.model_selection import KFold \n    ```", "```py\n    landtemps = pd.read_csv(\"data/landtemps2023avgs.csv\")\n    feature_cols = ['latabs','elevation']\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(landtemps[feature_cols],\\\n      landtemps[['avgtemp']], test_size=0.1, random_state=0) \n    ```", "```py\n    kf = KFold(n_splits=5, shuffle=True, random_state=0) \n    ```", "```py\n    pipeline = \\\n      make_pipeline(StandardScaler(),\n      SimpleImputer(strategy=\"mean\"),LinearRegression()) \n    ```", "```py\n    scores = \\\n      cross_validate(pipeline, X=X_train, y=y_train.values,\n      cv=kf, scoring=['r2','neg_mean_absolute_error'],\n      n_jobs=1)\n    print(\"Mean Absolute Error: %.2f, R-squared: %.2f\" %\n      (scores['test_neg_mean_absolute_error'].mean(),\n      scores['test_r2'].mean())) \n    ```", "```py\n    Mean Absolute Error: -2.53, R-squared: 0.82 \n    ```", "```py\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.linear_model import LinearRegression\n    from sklearn.impute import SimpleImputer\n    from sklearn.pipeline import make_pipeline\n    from feature_engine.encoding import OneHotEncoder\n    from sklearn.impute import KNNImputer\n    from sklearn.model_selection import cross_validate, KFold\n    from sklearn.compose import ColumnTransformer\n    from sklearn.compose import TransformedTargetRegressor \n    ```", "```py\n    import os\n    import sys\n    sys.path.append(os.getcwd() + \"/helperfunctions\")\n    from preprocfunc import OutlierTrans \n    ```", "```py\nclass OutlierTrans(BaseEstimator,TransformerMixin):\n  def __init__(self,threshold=1.5):\n    self.threshold = threshold\n\n  def fit(self,X,y=None):\n    return self\n\n  def transform(self,X,y=None):\n    Xnew = X.copy()\n    for col in Xnew.columns:\n      thirdq, firstq = Xnew[col].quantile(0.75),\\\n        Xnew[col].quantile(0.25)\n      inlierrange = self.threshold*(thirdq-firstq)\n      outlierhigh, outlierlow = inlierrange+thirdq,\\\n        firstq-inlierrange\n      Xnew.loc[(Xnew[col]>outlierhigh) | \\\n        (Xnew[col]<outlierlow),col] = np.nan\n    return Xnew.values \n```", "```py\nnls97wages = pd.read_csv(\"data/nls97wages.csv\" , low_memory=False)\nnls97wages.set_index(\"personid\", inplace=True)\nnum_cols = ['gpascience','gpaenglish','gpamath',\n  'gpaoverall','motherhighgrade','fatherhighgrade',\n  'parentincome','weeksworked20']\ncat_cols = ['gender']\nbin_cols = ['completedba']\ntarget = nls97wages[['wageincome20']]\nfeatures = nls97wages[num_cols + cat_cols + bin_cols]\nX_train, X_test, y_train, y_test =  \\\n  train_test_split(features,\\\n  target, test_size=0.2, random_state=0) \n```", "```py\nstandtrans = make_pipeline(OutlierTrans(2),\n  StandardScaler())\ncattrans = \\\n  make_pipeline(SimpleImputer(strategy=\\\n  \"most_frequent\"),OneHotEncoder(drop_last=True))\nbintrans = \\\n  make_pipeline(SimpleImputer(strategy=\\\n  \"most_frequent\"))\ncoltrans = ColumnTransformer(\n  transformers=[\n    (\"stand\", standtrans, num_cols),\n    (\"cat\", cattrans, ['gender']),\n    (\"bin\", bintrans, ['completedba'])\n  ]\n) \n```", "```py\nlr = LinearRegression()\npipe1 = make_pipeline(coltrans,\n  KNNImputer(n_neighbors=5), lr)\nttr=TransformedTargetRegressor(regressor=pipe1,\n  transformer=StandardScaler()) \n```", "```py\n    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n    scores = cross_validate(ttr, X=X_train, y=y_train,\n      cv=kf, scoring=('r2', 'neg_mean_absolute_error'),\n      n_jobs=1)\n    print(\"Mean Absolute Error: %.2f, R-squared: %.2f\" %\n      (scores['test_neg_mean_absolute_error'].mean(),\n      scores['test_r2'].mean())) \n    ```", "```py\n    Mean Absolute Error: -32899.64, R-squared: 0.16 \n    ```"]