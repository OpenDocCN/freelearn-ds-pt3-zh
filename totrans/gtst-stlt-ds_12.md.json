["```py\n    pip install streamlit-lottie\n    ```", "```py\n    git clone https://github.com/tylerjrichards/Getting-Started-with-Streamlit-for-Data-Science\n    ```", "```py\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nimport pickle\npenguin_df = pd.read_csv('penguins.csv')\npenguin_df.dropna(inplace=True)\noutput = penguin_df['species']\nfeatures = penguin_df[['island', 'bill_length_mm', 'bill_depth_mm',\n                       'flipper_length_mm', 'body_mass_g', 'sex']]\nfeatures = pd.get_dummies(features)\noutput, uniques = pd.factorize(output)\nx_train, x_test, y_train, y_test = train_test_split(\n    features, output, test_size=.8)\nrfc = RandomForestClassifier(random_state=15)\nrfc.fit(x_train, y_train)\ny_pred = rfc.predict(x_test)\nscore = accuracy_score(y_pred, y_test)\nprint('Our accuracy score for this model is {}'.format(score))\n```", "```py\nrf_pickle = open('random_forest_penguin.pickle', 'wb')\npickle.dump(rfc, rf_pickle)\nrf_pickle.close()\noutput_pickle = open('output_penguin.pickle', 'wb')\npickle.dump(uniques, output_pickle)\noutput_pickle.close()\n```", "```py\n#define multiple columns, add two graphs\ncol1, col2 = st.beta_columns(2)\nwith col1:\n     st.write('Trees by Width')\n     fig_1, ax_1 = plt.subplots()\n     ax_1 = sns.histplot(trees_df['dbh'], \n          color=graph_color)\n     plt.xlabel('Tree Width')\n     st.pyplot(fig_1)\nwith col2:\n     st.write('Trees by Age')\n     fig_2, ax_2 = plt.subplots()\n     ax_2 = sns.histplot(trees_df['age'],\n          color=graph_color)\n     plt.xlabel('Age (Days)')\n     st.pyplot(fig_2)\nst.write('Trees by Location')\ntrees_df = trees_df.dropna(subset=['longitude', 'latitude'])\ntrees_df = trees_df.sample(n = 1000, replace=True)\nst.map(trees_df)\n```", "```py\ntouch job_streamlit.py\n```", "```py\nimport streamlit as st\nfrom streamlit_lottie import st_lottie\nimport pandas as pd\nimport requests\ndef load_lottieurl(url: str):\n    r = requests.get(url)\n    if r.status_code != 200:\n        return None\n    return r.json()\nlottie_airplane = load_lottieurl('https://assets4.lottiefiles.com/packages/lf20_jhu1lqdz.json')\nst_lottie(lottie_airplane, speed=1, height=200, key=\"initial\")\nst.title('Major US Airline Job Application')\nst.write('by Tyler Richards')\nst.subheader('Question 1: Airport Distance')\n```", "```py\n'''\nThe first exercise asks us 'Given the table of airports and \nlocations (in latitude and longitude) below, \nwrite a function that takes an airport code as input and \nreturns the airports listed from nearest to furthest from \nthe input airport.' There are three steps here:\n1\\. Load Data\n2\\. Implement Distance Algorithm\n3\\. Apply distance formula across all airports other than the input\n4\\. Return sorted list of airports Distance\n'''\n```", "```py\nairport_distance_df = pd.read_csv('airport_location.csv')\nwith st.echo():\n     #load necessary data\n     airport_distance_df = pd.read_csv('airport_location.csv')\n```", "```py\n'''\nFrom some quick googling, I found that the haversine distance is \na good approximation for distance. At least good enough to get the \ndistance between airports! Haversine distances can be off by up to .5%, \nbecause the earth is not actually a sphere. It looks like the latitudes \nand longitudes are in degrees, so I'll make sure to have a way to account \nfor that as well. The haversine distance formula is labeled below, \nfollowed by an implementation in python\n'''\nst.image('haversine.png')\n```", "```py\nwith st.echo():\n     from math import radians, sin, cos, atan2, sqrt\n     def haversine_distance(long1, lat1, long2, lat2, degrees=False):\n         #degrees vs radians\n         if degrees == True:\n             long1 = radians(long1)\n             lat1 = radians(lat1)\n             long2 = radians(long2)\n             lat2 = radians(lat2)\n\n         #implementing haversine\n         a = sin((lat2-lat1) / 2)**2 + cos(lat1) * cos(lat2) * sin((long2-long1) / 2)**2\n         c = 2*atan2(sqrt(a), sqrt(1-a))\n         distance = 6371 * c #radius of earth in kilometers\n         return(distance)\n```", "```py\n#execute haversine function definition\nfrom math import radians, sin, cos, atan2, sqrt\ndef haversine_distance(long1, lat1, long2, lat2, degrees=False):\n    #degrees vs radians\n    if degrees == True:\n        long1 = radians(long1)\n        lat1 = radians(lat1)\n        long2 = radians(long2)\n        lat2 = radians(lat2)\n\n    #implementing haversine\n    a = sin((lat2-lat1) / 2)**2 + cos(lat1) * cos(lat2) * sin((long2-long1) / 2)**2\n    c = 2*atan2(sqrt(a), sqrt(1-a))\n    distance = 6371 * c #radius of earth in kilometers\n    return(distance)\n```", "```py\n'''\nNow, we need to test out our function! The \ndistance between the default points is \n18,986 kilometers, but feel free to try out\nyour own points of interest. \n'''\nlong1 = st.number_input('Longitude 1', value = 2.55)\nlong2 = st.number_input('Longitude 2', value = 172.00)\nlat1 = st.number_input('Latitude 1', value = 49.01)\nlat2 = st.number_input('Latitude 2', value = -43.48)\ntest_distance = haversine_distance(long1 = long1, long2 = long2,\n          lat1 = lat1, lat2 = lat2, degrees=True)\nst.write('Your distance is: {} kilometers'.format(int(test_distance)))\n```", "```py\n'''\nWe have the Haversine distance implemented, and we also have\nproven to ourselves that it works reasonably well.\nOur next step is to implement this in a function!\n'''\ndef get_distance_list(airport_dataframe, airport_code):\n    df = airport_dataframe.copy() \n    row = df[df.loc[:,'Airport Code'] == airport_code] \n    lat = row['Lat'] \n    long = row['Long'] \n    df = df[df['Airport Code'] != airport_code] \n    df['Distance'] = df.apply(lambda x: haversine_distance(lat1=lat, long1=long, \n         lat2 = x.Lat, long2 = x.Long, degrees=True), axis=1)\n    return(df.sort_values(by='Distance').reset_index()['Airport Code']) \nwith st.echo():\n     def get_distance_list(airport_dataframe, airport_code):\n          *copy of function above with comments*\n```", "```py\n'''\nTo use this function, select an airport from the airports provided in the dataframe\nand this application will find the distance between each one, and \nreturn a list of the airports closest to furthest.\n'''\nselected_airport = st.selectbox('Airport Code', airport_distance_df['Airport Code'])\ndistance_airports = get_distance_list(\n     airport_dataframe=airport_distance_df, airport_code=selected_airport)\nst.write('Your closest airports in order are {}'.format(list(distance_airports)))\n```", "```py\n'''\nThis all seems to work just fine! There are a few ways I would improve this if I was working on \nthis for a longer period of time.  \n1\\. I would implement the [Vincenty Distance](https://en.wikipedia.org/wiki/Vincenty%27s_formulae) \ninstead of the Haversine distance, which is much more accurate but cumbersome to implement.  \n2\\. I would vectorize this function and make it more efficient overall. \nBecause this dataset is only 7 rows long, it wasn't particularly important, \nbut if this was a crucial function that was run in production we would want to vectorize it for speed. \n'''\n```", "```py\n'''\nFor this transformation, there are a few things \nthat I would start with. First, I would have to define \nwhat a unique trip actually was. In order to do this, I would \ngroup by the origin, the destination, and the departure date \n(for the departure date, often customers will change around \nthis departure date, so we should group by the date plus or \nminus at least 1 buffer day to capture all the correct dates).   \nAdditionally, we can see that often users search from an entire city, \nand then shrink that down into a specific airport. So we should also \nconsider a group of individual queries from cities and airpots in the \nsame city, as the same search, and do the same for destination.    \nFrom that point, we should add these important columns to each unique search.\n'''\n```", "```py\nexample_df = pd.DataFrame(columns=['userid', 'number_of_queries', 'round_trip', 'distance', 'number_unique_destinations',\n                     'number_unique_origins', 'datetime_first_searched','average_length_of_stay',\n                     'length_of_search'])\nexample_row = {'userid':98593, 'number_of_queries':5, 'round_trip':1,\n                   'distance':893, 'number_unique_destinations':5,\n                     'number_unique_origins':1, 'datetime_first_searched':'2015-01-09',\n                   'average_length_of_stay':5, 'length_of_search':4}\nst.write(example_df.append(example_row, ignore_index=True))\n```", "```py\n'''\nFor answering the second part of the question, we should take the euclidian distance \non two normalized vectors. There are two solid options for comparing two \nentirely numeric rows, the euclidian distance (which is just the straight line \ndifference between two values), and the manhattan distance (think of this as the \ndistance traveled if you had to use city blocks to travel diagonally across manhattan). \nBecause we have normalized data, and the data is not high dimensional or sparse, I \nwould recommend using the euclidian distance to start off. This distance would tell \nus how similar two trips were.\n'''\n```", "```py\npassword_attempt = st.text_input('Please Enter The Password')\nif password_attempt != 'example_password':\n     st.write('Incorrect Password!')\n     st.stop()\n```"]