<html><head></head><body>
  <div id="_idContainer129" class="Basic-Text-Frame">
    <h1 class="chapterNumber">11</h1>
    <h1 id="_idParaDest-395" class="chapterTitle">Tidying and Reshaping Data</h1>
    <p class="normal">Echoing Leo Tolstoy’s wisdom (“Happy families are all alike; every unhappy family is unhappy in its own way.”), Hadley Wickham tells us, all tidy data is fundamentally alike, but all untidy data is messy in its own special way. How many times have we all stared at some rows of data and thought, <em class="italic">“What… how... why did they do that?”</em> This overstates the case somewhat. Although there are many ways that data can be poorly structured, there are limits to human creativity in this regard. It is possible to categorize the most frequent ways in which datasets deviate from normalized or tidy forms.</p>
    <p class="normal">This was Hadley Wickham’s observation in his seminal work on tidy data. We can lean on that work, and our own experiences with oddly structured data, to prepare for the reshaping we have to do. Untidy data often has one or more of the following characteristics: a lack of clarity about merge-by column relationships; data redundancy on the <em class="italic">one</em> side of one-to-many relationships; data redundancy due to many-to-many relationships; values stored in column names; multiple values stored in one variable value; and data not being structured at the unit of analysis. (Although the last category is not necessarily a case of untidy data, some of the techniques we will review in the next few recipes are applicable to common unit-of-analysis problems.)</p>
    <p class="normal">We use powerful tools in this chapter to deal with the challenges of data cleaning like the preceding. Specifically, we’ll go over the following:</p>
    <ul>
      <li class="bulletList">Removing duplicated rows</li>
      <li class="bulletList">Fixing many-to-many relationships</li>
      <li class="bulletList">Using <code class="inlineCode">stack</code> and <code class="inlineCode">melt</code> to reshape data from wide to long format</li>
      <li class="bulletList">Melting multiple groups of columns</li>
      <li class="bulletList">Using <code class="inlineCode">unstack</code> and <code class="inlineCode">pivot</code> to reshape data from long to wide format</li>
    </ul>
    <h1 id="_idParaDest-396" class="heading-1">Technical requirements</h1>
    <p class="normal">You will need pandas, NumPy, and Matplotlib to complete the recipes in this chapter. I used pandas 2.1.4, but the code will run on pandas 1.5.3 or later.</p>
    <p class="normal">The code in this chapter can be downloaded from the book’s GitHub repository, <a href="https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition"><span class="url">https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition</span></a>.</p>
    <h1 id="_idParaDest-397" class="heading-1">Removing duplicated rows</h1>
    <p class="normal">There are several reasons<a id="_idIndexMarker852"/> why we might have data duplicated <a id="_idIndexMarker853"/>at the unit of analysis:</p>
    <ul>
      <li class="bulletList">The existing DataFrame may be the result of a one-to-many merge, and the one side is the unit of analysis.</li>
      <li class="bulletList">The DataFrame is repeated measures or panel data collapsed into a flat file, which is just a special case of the first situation.</li>
      <li class="bulletList">We may be working with an analysis file where multiple one-to-many relationships have been flattened, creating many-to-many relationships.</li>
    </ul>
    <p class="normal">When the <em class="italic">one</em> side is the unit of analysis, data on the <em class="italic">many</em> side may need to be collapsed in some way. For example, if we are analyzing outcomes for a cohort of students at a college, students are the unit of analysis; but we may also have course enrollment data for each student. To prepare the data for analysis, we might need to first count the number of courses, sum the total credits, or calculate the GPA for each student, before ending up with one row per student. To generalize from this example, we often need to aggregate the information on the <em class="italic">many</em> side before removing duplicated data.</p>
    <p class="normal">In this recipe, we look at the pandas techniques for removing duplicate rows, and consider when we do and don’t need to do aggregation during that process. We address duplication in many-to-many relationships in the next recipe.</p>
    <h2 id="_idParaDest-398" class="heading-2">Getting ready</h2>
    <p class="normal">We will work with the COVID-19 daily case data in this recipe. It has one row per day per country, each row having the number of new cases and new deaths for that day. There are also demographic data for each country, and running totals for cases and deaths, so the last row for each country provides total cases and total deaths.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Data note</strong></p>
      <p class="normal">Our World in Data provides COVID-19 public use data at <a href="https://ourworldindata.org/covid-cases"><span class="url">https://ourworldindata.org/covid-cases</span></a>. The dataset includes total cases and deaths, tests administered, hospital beds, and demographic data such as median age, gross domestic product, and diabetes prevalence. The dataset used in this recipe was downloaded on March 3, 2024.</p>
    </div>
    <h2 id="_idParaDest-399" class="heading-2">How to do it…</h2>
    <p class="normal">We use <code class="inlineCode">drop_duplicates</code> to remove<a id="_idIndexMarker854"/> duplicated demographic data for each country in the COVID-19 daily data. We explore <code class="inlineCode">groupby</code> as an alternative to <code class="inlineCode">drop_duplicates</code> when we need to do some aggregation before removing duplicated data:</p>
    <ol>
      <li class="numberedList" value="1">Import <code class="inlineCode">pandas</code> and the COVID-19 daily cases data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
covidcases = pd.read_csv(<span class="hljs-string">"</span><span class="hljs-string">data/covidcases.csv"</span>)
</code></pre>
      </li>
      <li class="numberedList">Create lists for the daily cases and deaths columns, case total columns, and demographic columns (the <code class="inlineCode">total_cases</code> and <code class="inlineCode">total_deaths</code> columns are the running totals for cases and deaths respectively for that country):
        <pre class="programlisting code-one"><code class="hljs-code">dailyvars = [<span class="hljs-string">'casedate'</span>,<span class="hljs-string">'new_cases'</span>,<span class="hljs-string">'new_deaths'</span>]
totvars = [<span class="hljs-string">'location'</span>,<span class="hljs-string">'total_cases'</span>,<span class="hljs-string">'total_deaths'</span>]
demovars = [<span class="hljs-string">'</span><span class="hljs-string">population'</span>,<span class="hljs-string">'population_density'</span>,
<span class="hljs-meta">... </span>  <span class="hljs-string">'median_age'</span>,<span class="hljs-string">'gdp_per_capita'</span>,
<span class="hljs-meta">... </span>  <span class="hljs-string">'hospital_beds_per_thousand'</span>,<span class="hljs-string">'region'</span>]
covidcases[dailyvars + totvars + demovars].head(<span class="hljs-number">2</span>).T
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                                         0               1
casedate                        2020-03-01      2020-03-15
new_cases                                1               6
new_deaths                               0               0
location                       Afghanistan     Afghanistan
total_cases                              1               7
total_deaths                             0               0
population                        41128772        41128772
population_density                      54              54
median_age                              19              19
gdp_per_capita                       1,804           1,804
hospital_beds_per_thousand               0               0
region                          South Asia      South Asia
</code></pre>
      </li>
      <li class="numberedList">Create a DataFrame with just the daily data:
        <pre class="programlisting code-one"><code class="hljs-code">coviddaily = covidcases[[<span class="hljs-string">'location'</span>] + dailyvars]
coviddaily.shape
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">(36501, 4)
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">coviddaily.head()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">      location       casedate     new_cases     new_deaths
0  Afghanistan     2020-03-01             1              0
1  Afghanistan     2020-03-15             6              0
2  Afghanistan     2020-03-22            17              0
3  Afghanistan     2020-03-29            67              2
4  Afghanistan     2020-04-05           183              3
</code></pre>
      </li>
      <li class="numberedList">Select one row per country.</li>
    </ol>
    <p class="normal-one">Check to see how many<a id="_idIndexMarker855"/> countries (location) to expect by getting the number of unique locations. Sort by location and casedate. Then use <code class="inlineCode">drop_duplicates</code> to select one row per location, and use the keep parameter to indicate that we want the last row for each country:</p>
    <pre class="programlisting code-one"><code class="hljs-code">covidcases.location.nunique()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">231
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">coviddemo = \
  covidcases[[<span class="hljs-string">'casedate'</span>] + totvars + demovars].\
  sort_values([<span class="hljs-string">'location'</span>,<span class="hljs-string">'casedate'</span>]).\
  drop_duplicates([<span class="hljs-string">'location'</span>], keep=<span class="hljs-string">'last'</span>).\
  rename(columns={<span class="hljs-string">'casedate'</span>:<span class="hljs-string">'lastdate'</span>})
coviddemo.shape
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">(231, 10)
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">coviddemo.head(<span class="hljs-number">2</span>).T
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                                     204                379
lastdate                      2024-02-04         2024-01-28
location                     Afghanistan            Albania
total_cases                      231,539            334,863
total_deaths                       7,982              3,605
population                      41128772            2842318
population_density                    54                105
median_age                            19                 38
gdp_per_capita                     1,804             11,803
hospital_beds_per_thousand             0                  3
region                        South Asia     Eastern Europe
</code></pre>
    <ol>
      <li class="numberedList" value="5">Sum the values for each group.</li>
    </ol>
    <p class="normal-one">Use the pandas DataFrame groupby method<a id="_idIndexMarker856"/> to sum total cases and deaths for each country. (We calculate sums for cases and deaths here rather than using the running total of cases and deaths already in the DataFrame.) Also, get the last value for some of the columns that are duplicated across all rows for each country: <code class="inlineCode">median_age</code>, <code class="inlineCode">gdp_per_capita</code>, <code class="inlineCode">region</code>, and <code class="inlineCode">casedate</code>. (We select only a few columns from the DataFrame.) Notice that the numbers match those from <em class="italic">step 4</em>:</p>
    <pre class="programlisting code-one"><code class="hljs-code">covidtotals = covidcases.groupby([<span class="hljs-string">'location'</span>],
<span class="hljs-meta">... </span>  as_index=<span class="hljs-literal">False</span>).\
<span class="hljs-meta">... </span>  agg({<span class="hljs-string">'new_cases'</span>:<span class="hljs-string">'sum'</span>,<span class="hljs-string">'new_deaths'</span>:<span class="hljs-string">'sum'</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">'median_age'</span>:<span class="hljs-string">'last'</span>,<span class="hljs-string">'gdp_per_capita'</span>:<span class="hljs-string">'last'</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">'region'</span>:<span class="hljs-string">'last'</span>,<span class="hljs-string">'casedate'</span>:<span class="hljs-string">'last'</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">'population'</span>:<span class="hljs-string">'last'</span>}).\
<span class="hljs-meta">... </span>  rename(columns={<span class="hljs-string">'new_cases'</span>:<span class="hljs-string">'total_cases'</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">'new_deaths'</span>:<span class="hljs-string">'total_deaths'</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">'casedate'</span>:<span class="hljs-string">'lastdate'</span>})
covidtotals.head(<span class="hljs-number">2</span>).T
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                                0                     1
location              Afghanistan               Albania
total_cases               231,539               334,863
total_deaths                7,982                 3,605
median_age                     19                    38
gdp_per_capita              1,804                11,803
region                 South Asia        Eastern Europe
lastdate               2024-02-04            2024-01-28
population               41128772               2842318
</code></pre>
    <p class="normal">The choice of <code class="inlineCode">drop_duplicates</code> or <code class="inlineCode">groupby</code> to eliminate data redundancy comes down to whether we need to do any aggregation before collapsing the <em class="italic">many</em> side.</p>
    <h2 id="_idParaDest-400" class="heading-2">How it works...</h2>
    <p class="normal">The COVID-19 data has one row per country per day, but very little of the data is actually daily data. Only <code class="inlineCode">casedate</code>, <code class="inlineCode">new_cases</code>, and <code class="inlineCode">new_deaths</code> can be considered daily data. The other columns show cumulative cases and deaths, or demographic data. The cumulative data is redundant since we have the actual values for <code class="inlineCode">new_cases</code> and <code class="inlineCode">new_deaths</code>. The demographic data has the same values for each country across all days.</p>
    <p class="normal">There is an implied one-to-many relationship between the country (and its associated demographic data) on the <em class="italic">one</em> side and the daily data on the <em class="italic">many</em> side. We can recover that structure by creating a DataFrame with the daily data, and another DataFrame with the demographic data. We do that in <em class="italic">steps 3</em> and <em class="italic">4</em>. When we need totals across countries we can generate those ourselves, rather than storing redundant data.</p>
    <p class="normal">The running totals variables are not completely useless, however. We can use them to check our calculations of total cases and total deaths. <em class="italic">Step 5</em> shows how we can use <code class="inlineCode">groupby</code> to restructure data<a id="_idIndexMarker857"/> when we need to do more than drop duplicates. In this case, we want to summarize <code class="inlineCode">new_cases</code> and <code class="inlineCode">new_deaths</code> for each country.</p>
    <h2 id="_idParaDest-401" class="heading-2">There’s more...</h2>
    <p class="normal">I can sometimes forget a small detail. When changing the structure of data, the meaning of certain columns can change. In this example, <code class="inlineCode">casedate</code> becomes the date for the last row for each country. We rename that column <code class="inlineCode">lastdate</code>.</p>
    <h2 id="_idParaDest-402" class="heading-2">See also</h2>
    <p class="normal">We explore <code class="inlineCode">groupby</code> in more detail in <em class="chapterRef">Chapter 9</em>, <em class="italic">Fixing Messy Data When Aggregating</em>.</p>
    <p class="normal">Hadley Wickham’s <em class="italic">Tidy Data</em> paper is available at <a href="https://vita.had.co.nz/papers/tidy-data.pdf"><span class="url">https://vita.had.co.nz/papers/tidy-data.pdf</span></a>.</p>
    <h1 id="_idParaDest-403" class="heading-1">Fixing many-to-many relationships</h1>
    <p class="normal">We sometimes have to work<a id="_idIndexMarker858"/> with a data table that was created from a many-to-many merge. This is a merge where merge-by column values are duplicated on both the left and right sides. As we discussed in the previous chapter, many-to-many relationships in a data file often represent multiple one-to-many relationships where the <em class="italic">one</em> side has been removed. There is a one-to-many relationship between dataset A and dataset B, and also a one-to-many relationship between dataset A and dataset C. The problem we sometimes have is that we receive a data file with B and C merged but with A excluded.</p>
    <p class="normal">The best way to work with data structured in this way is to recreate the implied one-to-many relationships, if possible. We do this by first creating a dataset structured like A; that is, how A is likely structured given the many-to-many relationship we see between B and C. The key to being able to do this is to identify a good merge-by column for the data on both sides of the many-to-many relationship. This column, or these columns, will be duplicated in both the B and C datasets, but will be unduplicated in the theoretical A dataset.</p>
    <p class="normal">The data we use in this recipe is a good example. We have data from the Cleveland Museum of Art on its collections. We have multiple rows for every item in the museum’s collection. Those rows have data on the collection item (including title and creation date); the creator (including years of birth and death); and citations of the work in the press. When there are multiple creators and multiple citations, which is often, rows are duplicated. More precisely, the number of rows for each collection item is the Cartesian product of the number of citations and creations. So, if there are 5 citations and 2 creators, we see 10 rows for that item.</p>
    <p class="normal">What we want instead is a collections file with one row (and a unique identifier) for each item in the collection, a creators file with one row per creator for each item, and a citations file with one row per citation of each item. We will create those files in this recipe.</p>
    <p class="normal">Some of you will have noticed that there is still more tidying up to do here. We ultimately want a separate creator file with one row for every creator, and another file with just a creator id and a collection item id. We need this structure because a creator may be the creator for multiple items. We ignore that added complication in this recipe.</p>
    <p class="normal">I should add that this situation is not the fault of the Cleveland Museum of Art, which generously provides an API that returns collections data as a JSON file. It is the responsibility of individuals who use the API to create data files that are most appropriate for their research purposes. It is also possible, and often a good choice, to work directly from the more flexible structure of a JSON file. We demonstrate how to do that in <em class="chapterRef">Chapter 12</em>, <em class="italic">Automate Data Cleaning with User-Defined Functions, Classes, and Pipelines</em>.</p>
    <h2 id="_idParaDest-404" class="heading-2">Getting ready</h2>
    <p class="normal">We will work with data<a id="_idIndexMarker859"/> on the Cleveland Museum of Art’s collections. The CSV file has data on both creators and citations, merged by an <code class="inlineCode">itemid</code> column that identifies the collection item. There are one or many rows for citations and creators for each item.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Data note</strong></p>
      <p class="normal">The Cleveland Museum of Art provides an API for public access to this data: <a href="https://openaccess-api.clevelandart.org/"><span class="url">https://openaccess-api.clevelandart.org/</span></a>. Much more than the citations and creators data is available in the API. The data in this recipe were downloaded in April 2024.</p>
    </div>
    <h2 id="_idParaDest-405" class="heading-2">How to do it…</h2>
    <p class="normal">We handle many-to-many relationships between DataFrames by recovering the multiple implied one-to-many relationships in the data:</p>
    <ol>
      <li class="numberedList" value="1">Import <code class="inlineCode">pandas</code> and the museum’s <code class="inlineCode">collections</code> data. Let’s also limit the length of values in the <code class="inlineCode">collection</code> and <code class="inlineCode">title</code> columns for easier display:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
cma = pd.read_csv(<span class="hljs-string">"data/cmacollections.csv"</span>)
cma[<span class="hljs-string">'category'</span>] = cma.category.<span class="hljs-built_in">str</span>.strip().<span class="hljs-built_in">str</span>[<span class="hljs-number">0</span>:<span class="hljs-number">15</span>]
cma[<span class="hljs-string">'title'</span>] = cma.title.<span class="hljs-built_in">str</span>.strip().<span class="hljs-built_in">str</span>[<span class="hljs-number">0</span>:<span class="hljs-number">30</span>]
</code></pre>
      </li>
      <li class="numberedList">Show some of the museum’s <code class="inlineCode">collections</code> data. Notice that almost all of the data values are redundant, except for <code class="inlineCode">citation</code>.</li>
    </ol>
    <p class="normal-one">Also, show the number of unique <code class="inlineCode">itemid</code>, <code class="inlineCode">citation</code>, and <code class="inlineCode">creator</code> values. There are 986 unique collection items, 12,941 citations, and 1,062 item/creator combinations:</p>
    <pre class="programlisting code-one"><code class="hljs-code">cma.shape
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">(17001, 9)
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">cma.head(<span class="hljs-number">4</span>).T
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                                   0                      1  \
itemid                         75551                  75551  
citation             Purrmann, Hans.        &lt;em&gt;Henri Matis  
creatorid                      2,130                  2,130  
creator              Henri Matisse (        Henri Matisse (  
title                         Tulips                 Tulips  
birth_year                      1869                   1869  
death_year                      1954                   1954  
category             Mod Euro - Pain        Mod Euro - Pain  
creation_date                   1914                   1914  
                                   2                      3 
itemid                         75551                  75551 
citation             Flam, Jack D. &lt;        &lt;em&gt;Masters of  
creatorid                      2,130                  2,130 
creator              Henri Matisse (        Henri Matisse ( 
title                         Tulips                 Tulips 
birth_year                      1869                   1869 
death_year                      1954                   1954 
category             Mod Euro - Pain        Mod Euro - Pain 
creation_date                   1914                   1914
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">cma.itemid.nunique()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">986
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">cma.drop_duplicates([<span class="hljs-string">'itemid'</span>,<span class="hljs-string">'citation'</span>]).\
  itemid.count()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">12941
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">cma.drop_duplicates([<span class="hljs-string">'itemid'</span>,<span class="hljs-string">'creatorid'</span>]).\
  itemid.count()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">1062
</code></pre>
    <ol>
      <li class="numberedList" value="3">Show a collection item with duplicated<a id="_idIndexMarker860"/> citations and creators.</li>
    </ol>
    <p class="normal-one">Only show the first 6 rows (there are actually 28 in total). Notice that the citation data is duplicated for every creator:</p>
    <pre class="programlisting code-one"><code class="hljs-code">cma.set_index([<span class="hljs-string">'itemid'</span>], inplace=<span class="hljs-literal">True</span>)
cma.loc[<span class="hljs-number">124733</span>, [<span class="hljs-string">'title'</span>,<span class="hljs-string">'citation'</span>,
  <span class="hljs-string">'creation_date'</span>,<span class="hljs-string">'creator'</span>,<span class="hljs-string">'birth_year'</span>]].head(<span class="hljs-number">6</span>)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                        title              citation  \
itemid                                     
124733       Dead Blue Roller       Weigel, J. A. G  
124733       Dead Blue Roller       Weigel, J. A. G  
124733       Dead Blue Roller       Winkler, Friedr  
124733       Dead Blue Roller       Winkler, Friedr  
124733       Dead Blue Roller       Francis, Henry   
124733       Dead Blue Roller       Francis, Henry   
            creation_date               creator birth_year 
itemid                                                
124733               1583       Hans Hoffmann (       1545 
124733               1583       Albrecht Dürer        1471 
124733               1583       Hans Hoffmann (       1545 
124733               1583       Albrecht Dürer        1471 
124733               1583       Hans Hoffmann (       1545 
124733               1583       Albrecht Dürer        1471
</code></pre>
    <ol>
      <li class="numberedList" value="4">Create a collections DataFrame. <code class="inlineCode">title</code>, <code class="inlineCode">category</code>, and <code class="inlineCode">creation_date</code> should be unique<a id="_idIndexMarker861"/> to a collection item, so we create a DataFrame with just those columns, along with the <code class="inlineCode">itemid</code> index. We get the expected number of rows, <code class="inlineCode">986</code>:
        <pre class="programlisting code-one"><code class="hljs-code">collectionsvars = \
  [<span class="hljs-string">'title'</span>,<span class="hljs-string">'category'</span>,<span class="hljs-string">'creation_date'</span>]
cmacollections = cma[collectionsvars].\
  reset_index().\
  drop_duplicates([<span class="hljs-string">'</span><span class="hljs-string">itemid'</span>]).\
  set_index([<span class="hljs-string">'itemid'</span>])
cmacollections.shape
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">(986, 3)
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">cmacollections.head()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                                 title  \
itemid                                  
75551                           Tulips  
75763   Procession or Pardon at Perros  
78982       The Resurrection of Christ  
84662                The Orange Christ  
86110   Sunset Glow over a Fishing Vil  
             category   creation_date 
itemid                                
75551   Mod Euro - Pain          1914 
75763   Mod Euro - Pain          1891 
78982   P - German befo          1622 
84662   Mod Euro - Pain          1889 
86110   ASIAN - Hanging   1460s–1550s
</code></pre>
      </li>
      <li class="numberedList">Let’s look at the row in the new<a id="_idIndexMarker862"/> DataFrame, <code class="inlineCode">cmacollections</code>, for the same item we displayed in <em class="italic">step 3</em>:
        <pre class="programlisting code-one"><code class="hljs-code">cmacollections.loc[<span class="hljs-number">124733</span>]
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">title            Dead Blue Roller
category              DR - German
creation_date                1583
Name: 124733, dtype: object
</code></pre>
      </li>
      <li class="numberedList">Create a citations DataFrame.</li>
    </ol>
    <p class="normal-one">This will just have <code class="inlineCode">itemid</code> and <code class="inlineCode">citation</code>:</p>
    <pre class="programlisting code-one"><code class="hljs-code">cmacitations = cma[[<span class="hljs-string">'citation'</span>]].\
  reset_index().\
  drop_duplicates([<span class="hljs-string">'itemid'</span>,<span class="hljs-string">'citation'</span>]).\
  set_index([<span class="hljs-string">'itemid'</span>])
cmacitations.loc[<span class="hljs-number">124733</span>]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                    citation
itemid                     
124733       Weigel, J. A. G
124733       Winkler, Friedr
124733       Francis, Henry
124733       Kurz, Otto. &lt;em
124733       Minneapolis Ins
124733       Pilz, Kurt. "Ha
124733       Koschatzky, Wal
124733       Johnson, Mark M
124733       Kaufmann, Thoma
124733        Koreny, Fritz.
124733       Achilles-Syndra
124733       Schoch, Rainer,
124733       DeGrazia, Diane
124733       Dunbar, Burton
</code></pre>
    <ol>
      <li class="numberedList" value="7">Create a creators<a id="_idIndexMarker863"/> DataFrame:
        <pre class="programlisting code-one"><code class="hljs-code">creatorsvars = \
  [<span class="hljs-string">'creator'</span>,<span class="hljs-string">'birth_year'</span>,<span class="hljs-string">'death_year'</span>]
cmacreators = cma[creatorsvars].\
  reset_index().\
  drop_duplicates([<span class="hljs-string">'itemid'</span>,<span class="hljs-string">'</span><span class="hljs-string">creator'</span>]).\
  set_index([<span class="hljs-string">'itemid'</span>])
cmacreators.loc[<span class="hljs-number">124733</span>]
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                  creator        birth_year      death_year
itemid                                                     
124733     Hans Hoffmann (             1545            1592
124733     Albrecht Dürer              1471            1528
</code></pre>
      </li>
      <li class="numberedList">Count the number of collection items with a creator born after 1950.</li>
    </ol>
    <p class="normal-one">First, convert the <code class="inlineCode">birth_year</code> values from string to numeric. Then, create a DataFrame with just young artists:</p>
    <pre class="programlisting code-one"><code class="hljs-code">cmacreators[<span class="hljs-string">'birth_year'</span>] = \
  cmacreators.birth_year.<span class="hljs-built_in">str</span>.\
  findall(<span class="hljs-string">"\d+"</span>).<span class="hljs-built_in">str</span>[<span class="hljs-number">0</span>].astype(<span class="hljs-built_in">float</span>)
youngartists = \
  cmacreators.loc[cmacreators.birth_year&gt;<span class="hljs-number">1950</span>,
  [<span class="hljs-string">'creator'</span>]].assign(creatorbornafter1950=<span class="hljs-string">'Y'</span>)
youngartists.shape[<span class="hljs-number">0</span>]==youngartists.index.nunique()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">True
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">youngartists
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                creator creatorbornafter1950
itemid                                     
168529  Richard Barnes                     Y
369885  Simone Leigh (A                    Y
371392  Belkis Ayón (Cu                    Y
378931  Teresa Margolle                    Y
</code></pre>
    <ol>
      <li class="numberedList" value="9">Now, we can merge the <code class="inlineCode">youngartists</code> DataFrame with the collections DataFrame to create a flag for collection items that have at least one creator born after 1950:
        <pre class="programlisting code-one"><code class="hljs-code">cmacollections = \
  pd.merge(cmacollections, youngartists,
  left_on=[<span class="hljs-string">'itemid'</span>], right_on=[<span class="hljs-string">'itemid'</span>], how=<span class="hljs-string">'left'</span>)
cmacollections.fillna({<span class="hljs-string">'creatorbornafter1950'</span>:<span class="hljs-string">'N'</span>}, inplace=<span class="hljs-literal">True</span>)
cmacollections.shape
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">(986, 9)
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">cmacollections.creatorbornafter1950.value_counts()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">creatorbornafter1950
N    982
Y      4
Name: count, dtype: int64
</code></pre>
      </li>
    </ol>
    <p class="normal">Now we have three<a id="_idIndexMarker864"/> DataFrames—collection items (<code class="inlineCode">cmacollections</code>), citations (<code class="inlineCode">cmacitations</code>), and creators (<code class="inlineCode">cmacreators</code>)—instead of one. <code class="inlineCode">cmacollections</code> has a one-to-many relationship with both <code class="inlineCode">cmacitations</code> and <code class="inlineCode">cmacreators</code>.</p>
    <h2 id="_idParaDest-406" class="heading-2">How it works...</h2>
    <p class="normal">If you mainly work directly with enterprise data, you probably rarely see a file with this kind of structure, but many of us are not so lucky. If we requested data from the museum on both the media citations and creators of their collections, it would not be completely surprising to get a data file similar to this one, with duplicated data for citations and creators. But the presence of what looks like a unique identifier of collection items gives us some hope of recovering the one-to-many relationships between a collection item and its citations, and a collection item and its creators.</p>
    <p class="normal"><em class="italic">Step 2</em> shows that there are 986 unique <code class="inlineCode">itemid</code> values. This suggests that there are probably only 986 collection items represented in the 17,001 rows of the DataFrame. There are 12,941 unique <code class="inlineCode">itemid</code> and <code class="inlineCode">citation</code> pairs, or about 13 citations per collection item on average. There are 1,062 <code class="inlineCode">itemid</code> and <code class="inlineCode">creator</code> pairs.</p>
    <p class="normal"><em class="italic">Step 3</em> shows the duplication of collection item values such as <code class="inlineCode">title</code>. The number of rows returned is equal to the Cartesian product of the merge-by values on the left and right sides of a merge. For the <em class="italic">Dead Blue Roller</em> item, there are 28 rows (we only show six of them in <em class="italic">step 3</em>), since there were 14 citations and 2 creators. The row for each creator is duplicated 14 times; once for each citation. Each citation is there twice; once for each creator. There are very few use cases for which it makes sense to leave the data in this state.</p>
    <p class="normal">Our North Star to guide us in getting this data into better shape is the <code class="inlineCode">itemid</code> column. We use it to create a collections DataFrame in <em class="italic">step 4</em>. We keep only one row for each value of <code class="inlineCode">itemid</code>, and get other columns associated with a collection item, rather than a citation or creator—<code class="inlineCode">title</code>, <code class="inlineCode">category</code>, and <code class="inlineCode">creation_date</code> (since <code class="inlineCode">itemid</code> is the index, we need to first reset the index before dropping duplicates).</p>
    <p class="normal">We follow the same procedure to create <code class="inlineCode">citations</code> and <code class="inlineCode">creators</code> DataFrames in <em class="italic">steps 6</em> and <em class="italic">7</em>. We use <code class="inlineCode">drop_duplicates</code> to keep unique combinations of <code class="inlineCode">itemid</code> and <code class="inlineCode">citation</code>, and unique combinations of <code class="inlineCode">itemid</code> and <code class="inlineCode">creator</code>, respectively. This gives us the expected number of rows in the example case: 14 <code class="inlineCode">citations</code> rows and 2 <code class="inlineCode">creators</code> rows.</p>
    <p class="normal"><em class="italic">Step 8</em> demonstrates how we can now work with these DataFrames to construct new columns and do analysis. We want the number of collection items that have at least one creator born after 1950. The unit of analysis is the collection items, but we need information from the creators DataFrame for the calculation. Since the relationship between <code class="inlineCode">cmacollections</code> and <code class="inlineCode">cmacreators</code> is one-to-many, we make<a id="_idIndexMarker865"/> sure that we are only retrieving one row per <code class="inlineCode">itemid</code> in the creators DataFrame, even if more than one creator for an item was born after 1950:</p>
    <pre class="programlisting code"><code class="hljs-code">youngartists.shape[<span class="hljs-number">0</span>]==youngartists.index.nunique()
</code></pre>
    <h2 id="_idParaDest-407" class="heading-2">There’s more...</h2>
    <p class="normal">The duplication that occurs with many-to-many merges is most problematic when we are working with quantitative data. If the original file had the assessed value of each item in the collection, it would be duplicated in much the same way as <code class="inlineCode">title</code> is duplicated. Any descriptive statistics we generated on the assessed value would be off by a fair bit. For example, if the <em class="italic">Dead Blue Roller</em> item had an assessed value of $1,000,000, we would get $28,000,000 when summarizing the assessed value, since there are 28 duplicated values.</p>
    <p class="normal">This shows the importance of normalized and tidy data. If there were an assessed value column, we would have included it in the <code class="inlineCode">cmacollections</code> DataFrame we created in <em class="italic">step 4</em>. This value would be unduplicated and we would be able to generate summary statistics for collections.</p>
    <p class="normal">I find it helpful to always return to the unit of analysis, which overlaps with the tidy data concept but is different in some ways. The approach in <em class="italic">step 8</em> would have been very different if we were just interested in the number of creators born after 1950, instead of the number of collection items with a creator born after 1950. In that case, the unit of analysis would be the creator and we would just use the creators DataFrame.</p>
    <h2 id="_idParaDest-408" class="heading-2">See also</h2>
    <p class="normal">We examine many-to-many merges in the <em class="italic">Doing many-to-many merges</em> recipe in <em class="chapterRef">Chapter 10</em>, <em class="italic">Addressing Data Issues When Combining DataFrames</em>.</p>
    <p class="normal">We demonstrate a very different way to work with data structured in this way in <em class="chapterRef">Chapter 12</em>, <em class="italic">Automate Data Cleaning with User-Defined Functions, Classes and Pipelines</em>, in the <em class="italic">Classes that handle non-tabular data structures</em> recipe.</p>
    <h1 id="_idParaDest-409" class="heading-1">Using stack and melt to reshape data from wide to long format</h1>
    <p class="normal">One type of untidiness that Wickham identified<a id="_idIndexMarker866"/> is variable values<a id="_idIndexMarker867"/> embedded in column<a id="_idIndexMarker868"/> names. Although this rarely<a id="_idIndexMarker869"/> happens with enterprise or relational data, it is fairly common with analytical or survey data. Variable names might have suffixes that indicate a time period, such as a month or year. Or similar variables on a survey might have similar names, such as <code class="inlineCode">familymember1age</code> and <code class="inlineCode">familymember2age</code>, because that is convenient and consistent with the survey designers’ understanding of the variable.</p>
    <p class="normal">One reason why this messiness happens relatively frequently with survey data is that there can be multiple units of analysis on one survey instrument. An example is the United States decennial census, which asks both household and personal questions. Survey data is also sometimes made up of repeated measures or panel data, but nonetheless often has only one row per respondent. When this is the case, new measurements or responses are stored in new columns rather than new rows, and the column names will be similar to column names for responses from earlier periods, except for a change in suffix.</p>
    <p class="normal">The United States <strong class="keyWord">National Longitudinal Survey of Youth</strong> (<strong class="keyWord">NLS</strong>) is a good example of this. It is panel<a id="_idIndexMarker870"/> data, where each individual<a id="_idIndexMarker871"/> is surveyed each year. However, there<a id="_idIndexMarker872"/> is just one row<a id="_idIndexMarker873"/> of data per respondent<a id="_idIndexMarker874"/> in the analysis file provided. Responses to questions such as the number of weeks worked in a given year are placed in new columns. Tidying the NLS data means converting columns such as <code class="inlineCode">weeksworked17</code> through <code class="inlineCode">weeksworked21</code> (for weeks worked in 2017 through 2021) to just one column for weeks worked, another column for year, and five rows for each person (one for each year) rather than one. This is sometimes<a id="_idIndexMarker875"/> referred to as converting data from <em class="italic">wide to long</em> format.</p>
    <p class="normal">Amazingly, pandas has several functions that make transformations like this relatively easy: <code class="inlineCode">stack</code>, <code class="inlineCode">melt</code>, and <code class="inlineCode">wide_to_long</code>. We use <code class="inlineCode">stack</code> and <code class="inlineCode">melt</code> in this recipe, and explore <code class="inlineCode">wide_to_long</code> in the next.</p>
    <h2 id="_idParaDest-410" class="heading-2">Getting ready</h2>
    <p class="normal">We will work with the NLS data on the number of weeks worked and college enrollment status for each year. The DataFrame has one row per survey respondent.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Data note</strong></p>
      <p class="normal">The <strong class="keyWord">National Longitudinal Surveys</strong> (<strong class="keyWord">NLS</strong>), administered by the United States Bureau of Labor Statistics, are longitudinal surveys of individuals who were in high school in 1997 when the surveys started. Participants were surveyed each year through 2023. The surveys are available for public use at <a href="https://nlsinfo.org"><span class="url">nlsinfo.org</span></a>.</p>
    </div>
    <h2 id="_idParaDest-411" class="heading-2">How to do it…</h2>
    <p class="normal">We will use <code class="inlineCode">stack</code> and <code class="inlineCode">melt</code> to transform the NLS weeks worked data from wide to long, pulling out year values from the column names as we do so:</p>
    <ol>
      <li class="numberedList" value="1">Import <code class="inlineCode">pandas</code> and the NLS data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
nls97 = pd.read_csv(<span class="hljs-string">"data/nls97g.csv"</span>, low_memory=<span class="hljs-literal">False</span>)
</code></pre>
      </li>
      <li class="numberedList">View some of the values for the number of weeks worked.</li>
    </ol>
    <p class="normal-one">First, set the index:</p>
    <pre class="programlisting code-one"><code class="hljs-code">nls97.set_index([<span class="hljs-string">'originalid'</span>], inplace=<span class="hljs-literal">True</span>)
weeksworkedcols = [<span class="hljs-string">'weeksworked17'</span>,<span class="hljs-string">'weeksworked18'</span>,
  <span class="hljs-string">'weeksworked19'</span>,<span class="hljs-string">'weeksworked20'</span>,<span class="hljs-string">'weeksworked21'</span>]
nls97.loc[[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],weeksworkedcols].T
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">originalid          2       3
weeksworked17      52      52
weeksworked18      52      52
weeksworked19      52       9
weeksworked20      52       0
weeksworked21      46       0
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">nls97.shape
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">(8984, 110)
</code></pre>
    <ol>
      <li class="numberedList" value="3">Use <code class="inlineCode">stack</code> to transform <a id="_idIndexMarker876"/>the data from<a id="_idIndexMarker877"/> wide to long.</li>
    </ol>
    <p class="normal-one">First, select only <a id="_idIndexMarker878"/>the <code class="inlineCode">weeksworked##</code> columns. Use stack<a id="_idIndexMarker879"/> to move each column name in the original DataFrame into the index and move the <code class="inlineCode">weeksworked##</code> values into the associated row. Reset the <code class="inlineCode">index</code> so that the <code class="inlineCode">weeksworked##</code> column names become the values for the <code class="inlineCode">level_1</code> column (which we rename <code class="inlineCode">year</code>), and the <code class="inlineCode">weeksworked##</code> values become the values for the 0 column (which we rename <code class="inlineCode">weeksworked</code>):</p>
    <div class="note-one">
      <p class="normal"> <strong class="keyWord">Data note</strong></p>
      <p class="normal">For future upgrades to <code class="inlineCode">pandas 3.0</code>, we would have to mention keyword argument as <code class="inlineCode">(future_stack=True)</code> in the <code class="inlineCode">stack</code> function.</p>
    </div>
    <pre class="programlisting code-one"><code class="hljs-code">weeksworked = nls97[weeksworkedcols].\
  stack().\
  reset_index().\
  rename(columns={<span class="hljs-string">'level_1'</span>:<span class="hljs-string">'year'</span>,<span class="hljs-number">0</span>:<span class="hljs-string">'weeksworked'</span>})
weeksworked.loc[weeksworked.originalid.isin([<span class="hljs-number">2</span>,<span class="hljs-number">3</span>])]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">    originalid                year       weeksworked
5            2       weeksworked17                52
6            2       weeksworked18                52
7            2       weeksworked19                52
8            2       weeksworked20                52
9            2       weeksworked21                46
10           3       weeksworked17                52
11           3       weeksworked18                52
12           3       weeksworked19                 9
13           3       weeksworked20                 0
14           3       weeksworked21                 0
</code></pre>
    <ol>
      <li class="numberedList" value="4">Fix the <code class="inlineCode">year</code> values.</li>
    </ol>
    <p class="normal-one">Get the last digits<a id="_idIndexMarker880"/> of the year <a id="_idIndexMarker881"/>values, convert<a id="_idIndexMarker882"/> them to<a id="_idIndexMarker883"/> integers, and add 2,000:</p>
    <pre class="programlisting code-one"><code class="hljs-code">weeksworked[<span class="hljs-string">'</span><span class="hljs-string">year'</span>] = \
  weeksworked.year.<span class="hljs-built_in">str</span>[-<span class="hljs-number">2</span>:].astype(<span class="hljs-built_in">int</span>)+<span class="hljs-number">2000</span>
weeksworked.loc[weeksworked.originalid.isin([<span class="hljs-number">2</span>,<span class="hljs-number">3</span>])]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">         originalid       year       weeksworked
5                 2       2017                52
6                 2       2018                52
7                 2       2019                52
8                 2       2020                52
9                 2       2021                46
10                3       2017                52
11                3       2018                52
12                3       2019                 9
13                3       2020                 0
14                3       2021                 0
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">weeksworked.shape
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">(44920, 3)
</code></pre>
    <ol>
      <li class="numberedList" value="5">Alternatively, use <code class="inlineCode">melt</code> to transform the data from wide to long.</li>
    </ol>
    <p class="normal-one">First, reset the <code class="inlineCode">index</code> and select the <code class="inlineCode">originalid</code> and <code class="inlineCode">weeksworked##</code> columns. Use the <code class="inlineCode">id_vars</code> and <code class="inlineCode">value_vars</code> parameters of <code class="inlineCode">melt</code> to specify <code class="inlineCode">originalid</code> as the <code class="inlineCode">ID</code> variable and the <code class="inlineCode">weeksworked##</code> columns as the columns to be rotated, or melted. Use the <code class="inlineCode">var_name</code> and <code class="inlineCode">value_name</code> parameters to rename the columns as <code class="inlineCode">year</code> and <code class="inlineCode">weeksworked</code> respectively. The column names in <code class="inlineCode">value_vars</code> become the values for the new year column (which we convert to an integer using the original suffix). The values for the <code class="inlineCode">value_vars</code> columns<a id="_idIndexMarker884"/> are assigned<a id="_idIndexMarker885"/> to the new <code class="inlineCode">weeksworked</code> column<a id="_idIndexMarker886"/> for the associated<a id="_idIndexMarker887"/> row:</p>
    <pre class="programlisting code-one"><code class="hljs-code">weeksworked = nls97.reset_index().\
  loc[:,[<span class="hljs-string">'originalid'</span>] + weeksworkedcols].\
  melt(id_vars=[<span class="hljs-string">'originalid'</span>],
  value_vars=weeksworkedcols,
  var_name=<span class="hljs-string">'year'</span>, value_name=<span class="hljs-string">'</span><span class="hljs-string">weeksworked'</span>)
weeksworked[<span class="hljs-string">'year'</span>] = \
  weeksworked.year.<span class="hljs-built_in">str</span>[-<span class="hljs-number">2</span>:].astype(<span class="hljs-built_in">int</span>)+<span class="hljs-number">2000</span>
weeksworked.set_index([<span class="hljs-string">'originalid'</span>], inplace=<span class="hljs-literal">True</span>)
weeksworked.loc[[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                 year       weeksworked
originalid                       
2                2017                52
2                2018                52
2                2019                52
2                2020                52
2                2021                46
3                2017                52
3                2018                52
3                2019                 9
3                2020                 0
3                2021                 0
</code></pre>
    <ol>
      <li class="numberedList" value="6">Reshape the college enrollment columns with <code class="inlineCode">melt</code>.</li>
    </ol>
    <p class="normal-one">This works the same way as the <code class="inlineCode">melt</code> function for the weeks worked columns:</p>
    <pre class="programlisting code-one"><code class="hljs-code">colenrcols = \
  [<span class="hljs-string">'colenroct17'</span>,<span class="hljs-string">'colenroct18'</span>,<span class="hljs-string">'colenroct19'</span>,
  <span class="hljs-string">'colenroct20'</span>,<span class="hljs-string">'colenroct21'</span>]
colenr = nls97.reset_index().\
  loc[:,[<span class="hljs-string">'originalid'</span>] + colenrcols].\
  melt(id_vars=[<span class="hljs-string">'originalid'</span>], value_vars=colenrcols,
var_name=<span class="hljs-string">'</span><span class="hljs-string">year'</span>, value_name=<span class="hljs-string">'colenr'</span>)
colenr[<span class="hljs-string">'year'</span>] = colenr.year.<span class="hljs-built_in">str</span>[-<span class="hljs-number">2</span>:].astype(<span class="hljs-built_in">int</span>)+<span class="hljs-number">2000</span>
colenr.set_index([<span class="hljs-string">'originalid'</span>], inplace=<span class="hljs-literal">True</span>)
colenr.loc[[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                 year                     colenr
originalid                                
2                2017            1. Not enrolled
2                2018            1. Not enrolled
2                2019            1. Not enrolled
2                2020            1. Not enrolled
2                2021            1. Not enrolled
3                2017            1. Not enrolled
3                2018            1. Not enrolled
3                2019            1. Not enrolled
3                2020            1. Not enrolled
3                2021            1. Not enrolled
</code></pre>
    <ol>
      <li class="numberedList" value="7">Merge the weeks<a id="_idIndexMarker888"/> worked<a id="_idIndexMarker889"/> and college<a id="_idIndexMarker890"/> enrollment<a id="_idIndexMarker891"/> data:
        <pre class="programlisting code-one"><code class="hljs-code">workschool = \
  pd.merge(weeksworked, colenr, on=[<span class="hljs-string">'originalid'</span>,<span class="hljs-string">'year'</span>], how=<span class="hljs-string">"inner"</span>)
workschool.shape
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">(44920, 3)
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">workschool.loc[[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]]
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">            year       weeksworked                colenr
originalid                                        
2           2017                52       1. Not enrolled
2           2018                52       1. Not enrolled
2           2019                52       1. Not enrolled
2           2020                52       1. Not enrolled
2           2021                46       1. Not enrolled
3           2017                52       1. Not enrolled
3           2018                52       1. Not enrolled
3           2019                 9       1. Not enrolled
3           2020                 0       1. Not enrolled
3           2021                 0       1. Not enrolled
</code></pre>
      </li>
    </ol>
    <p class="normal">This gives us one DataFrame from the melting of both the weeks worked and the college enrollment columns.</p>
    <h2 id="_idParaDest-412" class="heading-2">How it works...</h2>
    <p class="normal">We can use <code class="inlineCode">stack</code> or <code class="inlineCode">melt</code> to reshape data from wide to long format, but <code class="inlineCode">melt</code> provides more flexibility. <code class="inlineCode">stack</code> will move all of the column names into the index. We see in <em class="italic">step 4</em> that we get the expected number of rows after stacking, <code class="inlineCode">44920</code>, which is 5*8984, the number of rows in the initial data.</p>
    <p class="normal">With <code class="inlineCode">melt</code>, we can rotate the column names and values based on an <code class="inlineCode">ID</code> variable other than the index. We do this with the <code class="inlineCode">id_vars</code> parameter. We specify which variables to melt by using the <code class="inlineCode">value_vars</code> parameter.</p>
    <p class="normal">In <em class="italic">step 6</em>, we also reshape the college<a id="_idIndexMarker892"/> enrollment columns. To create<a id="_idIndexMarker893"/> one DataFrame with the reshaped weeks worked and college enrollment data, we merge the two DataFrames we created in <em class="italic">steps 5</em> and <em class="italic">6</em>. We will see<a id="_idIndexMarker894"/> in the next recipe how to accomplish what<a id="_idIndexMarker895"/> we did in <em class="italic">steps 5</em> through <em class="italic">7</em> in one step.</p>
    <h1 id="_idParaDest-413" class="heading-1">Melting multiple groups of columns</h1>
    <p class="normal">When we needed to melt<a id="_idIndexMarker896"/> multiple groups of columns in the previous recipe, we used <code class="inlineCode">melt</code> twice and then merged the resulting DataFrames. That worked fine, but we can accomplish the same tasks in one step with the <code class="inlineCode">wide_to_long</code> function. <code class="inlineCode">wide_to_long</code> has more functionality than <code class="inlineCode">melt</code>, but is a bit more complicated to use.</p>
    <h2 id="_idParaDest-414" class="heading-2">Getting ready</h2>
    <p class="normal">We will work with the weeks worked and college enrollment data from the NLS in this recipe.</p>
    <h2 id="_idParaDest-415" class="heading-2">How to do it…</h2>
    <p class="normal">We will transform multiple groups<a id="_idIndexMarker897"/> of columns at once using <code class="inlineCode">wide_to_long</code>:</p>
    <ol>
      <li class="numberedList" value="1">Import <code class="inlineCode">pandas</code> and load the NLS data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
nls97 = pd.read_csv(<span class="hljs-string">"data/nls97g.csv"</span>, low_memory=<span class="hljs-literal">False</span>)
nls97.set_index(<span class="hljs-string">'personid'</span>, inplace=<span class="hljs-literal">True</span>)
</code></pre>
      </li>
      <li class="numberedList">View some of the weeks worked and college enrollment data:
        <pre class="programlisting code-one"><code class="hljs-code">weeksworkedcols = [<span class="hljs-string">'weeksworked17'</span>,<span class="hljs-string">'weeksworked18'</span>,
  <span class="hljs-string">'weeksworked19'</span>,<span class="hljs-string">'weeksworked20'</span>,<span class="hljs-string">'weeksworked21'</span>]
colenrcols = [<span class="hljs-string">'colenroct17'</span>,<span class="hljs-string">'colenroct18'</span>,
   <span class="hljs-string">'colenroct19'</span>,<span class="hljs-string">'</span><span class="hljs-string">colenroct20'</span>,<span class="hljs-string">'colenroct21'</span>]
nls97.loc[nls97.originalid.isin([<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]),
  [<span class="hljs-string">'originalid'</span>] + weeksworkedcols + colenrcols].T
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">personid                     999406                151672
originalid                        2                     3
weeksworked17                    52                    52
weeksworked18                    52                    52
weeksworked19                    52                     9
weeksworked20                    52                     0
weeksworked21                    46                     0
colenroct17         1. Not enrolled       1. Not enrolled
colenroct18         1. Not enrolled       1. Not enrolled
colenroct19         1. Not enrolled       1. Not enrolled
colenroct20         1. Not enrolled       1. Not enrolled
colenroct21         1. Not enrolled       1. Not enrolled
</code></pre>
      </li>
      <li class="numberedList">Run the <code class="inlineCode">wide_to_long</code> function.</li>
    </ol>
    <p class="normal-one">Pass a list to stubnames to indicate the column groups that are wanted. (All columns starting with the same characters as each item in the list will be selected for melting.) Use the <code class="inlineCode">i</code> parameter to indicate the ID variable (<code class="inlineCode">originalid</code>), and use the <code class="inlineCode">j</code> parameter to name the column (<code class="inlineCode">year</code>) that is based on the column<a id="_idIndexMarker898"/> suffixes—<code class="inlineCode">17</code>, <code class="inlineCode">18</code>, and so on:</p>
    <pre class="programlisting code-one"><code class="hljs-code">workschool = pd.wide_to_long(nls97[[<span class="hljs-string">'originalid'</span>]
<span class="hljs-meta">... </span>  + weeksworkedcols + colenrcols],
<span class="hljs-meta">... </span>  stubnames=[<span class="hljs-string">'weeksworked'</span>,<span class="hljs-string">'colenroct'</span>],
<span class="hljs-meta">... </span>  i=[<span class="hljs-string">'</span><span class="hljs-string">originalid'</span>], j=<span class="hljs-string">'year'</span>).reset_index()
workschool[<span class="hljs-string">'year'</span>] = workschool.year+<span class="hljs-number">2000</span>
workschool = workschool.\
<span class="hljs-meta">... </span>  sort_values([<span class="hljs-string">'originalid'</span>,<span class="hljs-string">'year'</span>])
workschool.set_index([<span class="hljs-string">'originalid'</span>], inplace=<span class="hljs-literal">True</span>)
workschool.loc[[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                 year       weeksworked             colenroct
originalid                                        
2                2017                52       1. Not enrolled
2                2018                52       1. Not enrolled
2                2019                52       1. Not enrolled
2                2020                52       1. Not enrolled
2                2021                46       1. Not enrolled
3                2017                52       1. Not enrolled
3                2018                52       1. Not enrolled
3                2019                 9       1. Not enrolled
3                2020                 0       1. Not enrolled
3                2021                 0       1. Not enrolled
</code></pre>
    <p class="normal"><code class="inlineCode">wide_to_long</code> accomplishes in one step what it took us several steps to accomplish in the previous recipe using <code class="inlineCode">melt</code>.</p>
    <h2 id="_idParaDest-416" class="heading-2">How it works...</h2>
    <p class="normal">The <code class="inlineCode">wide_to_long</code> function does almost all of the work for us, though it takes more effort to set it up than for <code class="inlineCode">stack</code> or <code class="inlineCode">melt</code>. We need to provide the function with the characters (<code class="inlineCode">weeksworked</code> and <code class="inlineCode">colenroct</code> in this case) of the column groups. Since our variables are named with suffixes indicating the year, <code class="inlineCode">wide_to_long</code> translates the suffixes into values that make sense and melts them into the column<a id="_idIndexMarker899"/> that is named with the <code class="inlineCode">j</code> parameter. It’s almost magic!</p>
    <h2 id="_idParaDest-417" class="heading-2">There’s more...</h2>
    <p class="normal">The suffixes of the <code class="inlineCode">stubnames</code> columns in this recipe are the same: 17 through 21. But that does not have to be the case. When suffixes are present for one column group, but not for another, the values for the latter column group for that suffix will be missing. We can see that by excluding <code class="inlineCode">weeksworked17</code> from the DataFrame and adding <code class="inlineCode">weeksworked16</code>:</p>
    <pre class="programlisting code-one"><code class="hljs-code">weeksworkedcols = [<span class="hljs-string">'weeksworked16'</span>,<span class="hljs-string">'weeksworked18'</span>,
  <span class="hljs-string">'weeksworked19'</span>,<span class="hljs-string">'</span><span class="hljs-string">weeksworked20'</span>,<span class="hljs-string">'weeksworked21'</span>]
workschool = pd.wide_to_long(nls97[[<span class="hljs-string">'originalid'</span>]
<span class="hljs-meta">... </span>  + weeksworkedcols + colenrcols],
<span class="hljs-meta">... </span>  stubnames=[<span class="hljs-string">'weeksworked'</span>,<span class="hljs-string">'colenroct'</span>],
<span class="hljs-meta">... </span>  i=[<span class="hljs-string">'originalid'</span>], j=<span class="hljs-string">'year'</span>).reset_index()
workschool[<span class="hljs-string">'year'</span>] = workschool.year+<span class="hljs-number">2000</span>
workschool = workschool.sort_values([<span class="hljs-string">'originalid'</span>,<span class="hljs-string">'year'</span>])
workschool.set_index([<span class="hljs-string">'originalid'</span>], inplace=<span class="hljs-literal">True</span>)
workschool.loc[[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                 year       weeksworked             colenroct
originalid                                                  
2                2016                53                   NaN
2                2017               NaN       1. Not enrolled
2                2018                52       1. Not enrolled
2                2019                52       1. Not enrolled
2                2020                52       1. Not enrolled
2                2021                46       1. Not enrolled
3                2016                53                   NaN
3                2017               NaN       1. Not enrolled
3                2018                52       1. Not enrolled
3                2019                 9       1. Not enrolled
3                2020                 0       1. Not enrolled
3                2021                 0       1. Not enrolled
</code></pre>
    <p class="normal">The <code class="inlineCode">weeksworked</code> values for 2017 are now missing, as are the <code class="inlineCode">colenroct</code> values for 2016.</p>
    <h1 id="_idParaDest-418" class="heading-1">Using unstack and pivot to reshape data from long to wide format</h1>
    <p class="normal">Sometimes, we actually have<a id="_idIndexMarker900"/> to move data from a tidy<a id="_idIndexMarker901"/> to an untidy <a id="_idIndexMarker902"/>structure. This is often because<a id="_idIndexMarker903"/> we need to prepare the data for analysis with software packages that do not handle relational data well, or because we are submitting data to some external authority that has requested it in an untidy format. <code class="inlineCode">unstack</code> and <code class="inlineCode">pivot</code> can be helpful when we need to reshape data from long to wide format. <code class="inlineCode">unstack</code> does the opposite of what we did with <code class="inlineCode">stack</code>, and <code class="inlineCode">pivot</code> does the opposite of <code class="inlineCode">melt</code>.</p>
    <h2 id="_idParaDest-419" class="heading-2">Getting ready</h2>
    <p class="normal">We continue to work with the NLS data on weeks worked and college enrollment in this recipe.</p>
    <h2 id="_idParaDest-420" class="heading-2">How to do it…</h2>
    <p class="normal">We use <code class="inlineCode">unstack</code> and <code class="inlineCode">pivot</code> to return the melted NLS DataFrame to its original state:</p>
    <ol>
      <li class="numberedList" value="1">Import <code class="inlineCode">pandas</code> and load the stacked and melted NLS data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
nls97 = pd.read_csv(<span class="hljs-string">"data/nls97g.csv"</span>, low_memory=<span class="hljs-literal">False</span>)
nls97.set_index([<span class="hljs-string">'originalid'</span>], inplace=<span class="hljs-literal">True</span>)
</code></pre>
      </li>
      <li class="numberedList">Stack the data again.</li>
    </ol>
    <p class="normal-one">This repeats the stack from an earlier recipe in this chapter:</p>
    <pre class="programlisting code-one"><code class="hljs-code">weeksworkedcols = [<span class="hljs-string">'weeksworked17'</span>,<span class="hljs-string">'weeksworked18'</span>,
  <span class="hljs-string">'weeksworked19'</span>,<span class="hljs-string">'weeksworked20'</span>,<span class="hljs-string">'weeksworked21'</span>]
weeksworkedstacked = nls97[weeksworkedcols].\
  stack()
weeksworkedstacked.loc[[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">originalid              
2           weeksworked17        52
            weeksworked18        52
            weeksworked19        52
            weeksworked20        52
            weeksworked21        46
3           weeksworked17        52
            weeksworked18        52
            weeksworked19         9
            weeksworked20         0
            weeksworked21         0
dtype: float64
</code></pre>
    <ol>
      <li class="numberedList" value="3">Melt the data again.</li>
    </ol>
    <p class="normal-one">This repeats<a id="_idIndexMarker904"/> the <code class="inlineCode">melt</code> from<a id="_idIndexMarker905"/> an earlier recipe<a id="_idIndexMarker906"/> in this<a id="_idIndexMarker907"/> chapter:</p>
    <pre class="programlisting code-one"><code class="hljs-code">weeksworkedmelted = nls97.reset_index().\
<span class="hljs-meta">... </span>  loc[:,[<span class="hljs-string">'originalid'</span>] + weeksworkedcols].\
<span class="hljs-meta">... </span>  melt(id_vars=[<span class="hljs-string">'originalid'</span>],
<span class="hljs-meta">... </span>  value_vars=weeksworkedcols,
<span class="hljs-meta">... </span>  var_name=<span class="hljs-string">'year'</span>, value_name=<span class="hljs-string">'weeksworked'</span>)
weeksworkedmelted.loc[weeksworkedmelted.\
  originalid.isin([<span class="hljs-number">2</span>,<span class="hljs-number">3</span>])].\
  sort_values([<span class="hljs-string">'originalid'</span>,<span class="hljs-string">'year'</span>])
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">            originalid                year       weeksworked
1                    2       weeksworked17                52
8985                 2       weeksworked18                52
17969                2       weeksworked19                52
26953                2       weeksworked20                52
35937                2       weeksworked21                46
2                    3       weeksworked17                52
8986                 3       weeksworked18                52
17970                3       weeksworked19                 9
26954                3       weeksworked20                 0
35938                3       weeksworked21                 0
</code></pre>
    <ol>
      <li class="numberedList" value="4">Use <code class="inlineCode">unstack</code> to convert the stacked data from long to wide:
        <pre class="programlisting code-one"><code class="hljs-code">weeksworked = weeksworkedstacked.unstack()
weeksworked.loc[[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]].T
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">originalid          2       3
weeksworked17      52      52
weeksworked18      52      52
weeksworked19      52       9
weeksworked20      52       0
weeksworked21      46       0
</code></pre>
      </li>
      <li class="numberedList">Use <code class="inlineCode">pivot</code> to convert the melted data from long to wide.</li>
    </ol>
    <p class="normal-one">pivot is slightly more complicated<a id="_idIndexMarker908"/> than unstack. We need<a id="_idIndexMarker909"/> to pass arguments<a id="_idIndexMarker910"/> to do the reverse<a id="_idIndexMarker911"/> of melt, telling pivot the column to use for the column name suffixes (<code class="inlineCode">year</code>) and where to grab the values to be unmelted (from the <code class="inlineCode">weeksworked</code> columns, in this case):</p>
    <pre class="programlisting code-one"><code class="hljs-code">weeksworked = weeksworkedmelted.\
<span class="hljs-meta">... </span>  pivot(index=<span class="hljs-string">'originalid'</span>,
<span class="hljs-meta">... </span>  columns=<span class="hljs-string">'year'</span>, values=[<span class="hljs-string">'weeksworked'</span>]).\
<span class="hljs-meta">... </span>  reset_index()
weeksworked.columns = [<span class="hljs-string">'</span><span class="hljs-string">originalid'</span>] + \
<span class="hljs-meta">... </span>  [col[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> weeksworked.columns[<span class="hljs-number">1</span>:]]
weeksworked.loc[weeksworked.originalid.isin([<span class="hljs-number">2</span>,<span class="hljs-number">3</span>])].T
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                    1       2
originalid          2       3
weeksworked17      52      52
weeksworked18      52      52
weeksworked19      52       9
weeksworked20      52       0
weeksworked21      46       0
</code></pre>
    <p class="normal">This returns the NLS data back to its original untidy form.</p>
    <h2 id="_idParaDest-421" class="heading-2">How it works...</h2>
    <p class="normal">We first do a <code class="inlineCode">stack</code> and a <code class="inlineCode">melt</code> in <em class="italic">steps 2 </em>and<em class="italic"> 3</em> respectively. This rotates the DataFrames from wide to long format. We then <code class="inlineCode">unstack</code> (<em class="italic">step 4</em>) and <code class="inlineCode">pivot</code> (<em class="italic">step 5</em>) those DataFrames to rotate them back from long to wide.</p>
    <p class="normal"><code class="inlineCode">unstack</code> uses the multi-index that is created by the <code class="inlineCode">stack</code> to figure out how to rotate the data.</p>
    <p class="normal">The <code class="inlineCode">pivot</code> function needs us to indicate<a id="_idIndexMarker912"/> the index column (<code class="inlineCode">originalid</code>), the column whose values will be appended to the<a id="_idIndexMarker913"/> column names (<code class="inlineCode">year</code>), and the name of the columns with the values to be unmelted (<code class="inlineCode">weeksworked</code>). <code class="inlineCode">Pivot</code> will return multilevel column names. We fix that by pulling<a id="_idIndexMarker914"/> from the second level<a id="_idIndexMarker915"/> with <code class="inlineCode">[col[1] for col in weeksworked.columns[1:]]</code>.</p>
    <h1 id="_idParaDest-422" class="heading-1">Summary</h1>
    <p class="normal">We explored key tidy data topics in this chapter. These topics included handling duplicated data, either by dropping rows where the data are redundant, or aggregating by group. We also restructured data stored in a many-to-many format into a tidy format. Finally, we stepped through several ways of converting data from wide to long format, and back to wide when necessary. Up next is the final chapter of the book, where we will learn to automate data cleaning with user-defined functions, classes and pipelines.</p>
    <h1 class="heading-1">Join our community on Discord</h1>
    <p class="normal">Join our community’s Discord space for discussions with the author and other readers:</p>
    <p class="normal"><a href="https://discord.gg/p8uSgEAETX "><span class="url">https://discord.gg/p8uSgEAETX</span></a></p>
    <p class="normal"><img src="../Images/QR_Code10336218961138498953.png" alt="" role="presentation"/></p>
  </div>
</body></html>