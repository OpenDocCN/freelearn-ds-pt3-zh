<html><head></head><body>
  <div id="_idContainer140" class="Basic-Text-Frame">
    <h1 class="chapterNumber">12</h1>
    <h1 id="_idParaDest-423" class="chapterTitle">Automate Data Cleaning with User-Defined Functions, Classes, and Pipelines</h1>
    <p class="normal">There are a number of great reasons to write code that is reusable. When we step back from the particular data-cleaning problem at hand and consider its relationship to very similar problems, we can actually improve our understanding of the key issues involved. We are also more likely to address a task systematically when we set our sights more on solving it for the long term than on the before-lunch solution. This has the additional benefit of helping us to disentangle the substantive issues from the mechanics of data manipulation.</p>
    <p class="normal">We will create several modules to accomplish routine data-cleaning tasks in this chapter. The functions and classes in these modules are examples of code that can be reused across DataFrames, or for one DataFrame over an extended period of time. These functions handle many of the tasks we discussed in the first eleven chapters, but in a manner that allows us to reuse our code.</p>
    <p class="normal">Specifically, the recipes in this chapter cover the following:</p>
    <ul>
      <li class="bulletList">Functions for getting a first look at our data</li>
      <li class="bulletList">Functions for displaying summary statistics and frequencies</li>
      <li class="bulletList">Functions for identifying outliers and unexpected values</li>
      <li class="bulletList">Functions for aggregating or combining data</li>
      <li class="bulletList">Classes that contain the logic for updating Series values</li>
      <li class="bulletList">Classes that handle non-tabular data structures</li>
      <li class="bulletList">Functions for checking overall data quality</li>
      <li class="bulletList">Pre-processing data with pipelines: a simple example</li>
      <li class="bulletList">Pre-processing data with pipelines: a more complicated example</li>
    </ul>
    <h1 id="_idParaDest-424" class="heading-1">Technical requirements</h1>
    <p class="normal">You will need pandas, NumPy, and Matplotlib to complete the recipes in this chapter. I used pandas 2.1.4, but the code will run on pandas 1.5.3 or later.</p>
    <p class="normal">The code in this chapter can be downloaded from the book’s GitHub repository, <a href="https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition"><span class="url">https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition</span></a>.</p>
    <h1 id="_idParaDest-425" class="heading-1">Functions for getting a first look at our data</h1>
    <p class="normal">The first few<a id="_idIndexMarker916"/> steps we take after we import our data into a pandas DataFrame are pretty much the same regardless of the characteristics of the data. We almost always want to know the number of columns and rows and the column data types, and to see the first few rows. We also might want to view the index and check whether there is a unique identifier for DataFrame rows. These discrete, easily repeatable tasks are good candidates for a collection of functions we can organize into a module.</p>
    <p class="normal">In this recipe, we will create a module with functions that give us a good first look at any pandas DataFrame. A module is simply a collection of Python code that we can import into another Python program. Modules are easy to reuse because they can be referenced by any program with access to the folder where the module is saved.</p>
    <h2 id="_idParaDest-426" class="heading-2">Getting ready</h2>
    <p class="normal">We create two files in this recipe: one with a function we will use to look at our data and another to call that function. Let’s call the file with the function we will use <code class="inlineCode">basicdesciptives.py</code> and place it in a subfolder called <code class="inlineCode">helperfunctions</code>.</p>
    <p class="normal">We work with the <strong class="keyWord">National Longitudinal Surveys</strong> (<strong class="keyWord">NLS</strong>) data<a id="_idIndexMarker917"/> in this recipe.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Data note</strong></p>
      <p class="normal">The NLS, administered by the United States Bureau of Labor Statistics, is a collection of longitudinal surveys of individuals who were in high school in 1997 when the surveys started. Participants were surveyed each year through 2023. The surveys are available for public use at <a href="https://nlsinfo.org"><span class="url">nlsinfo.org</span></a>.</p>
    </div>
    <h2 id="_idParaDest-427" class="heading-2">How to do it...</h2>
    <p class="normal">We will create a <a id="_idIndexMarker918"/>function to take an initial look at a DataFrame.</p>
    <ol>
      <li class="numberedList" value="1">Create the <code class="inlineCode">basicdescriptives.py</code> file with the function we want.</li>
    </ol>
    <p class="normal-one">The <code class="inlineCode">getfirstlook</code> function will return a dictionary with summary information on a DataFrame. Save the file in the <code class="inlineCode">helperfunctions</code> subfolder as <code class="inlineCode">basicdescriptives.py</code>. (You can also just download the code from the GitHub repository.) Also, create a function (<code class="inlineCode">displaydict</code>) to pretty up the display of a dictionary:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">def</span> <span class="hljs-title">getfirstlook</span>(<span class="hljs-params">df, nrows=</span><span class="hljs-number">5</span><span class="hljs-params">, uniqueids=</span><span class="hljs-literal">None</span>):
<span class="hljs-meta">... </span>  out = {}
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'head'</span>] = df.head(nrows)
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'dtypes'</span>] = df.dtypes
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'nrows'</span>] = df.shape[<span class="hljs-number">0</span>]
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'</span><span class="hljs-string">ncols'</span>] = df.shape[<span class="hljs-number">1</span>]
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'index'</span>] = df.index
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> (uniqueids <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>):
<span class="hljs-meta">... </span>    out[<span class="hljs-string">'</span><span class="hljs-string">uniqueids'</span>] = df[uniqueids].nunique()
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> out
<span class="hljs-keyword">def</span> <span class="hljs-title">displaydict</span>(<span class="hljs-params">dicttodisplay</span>):
<span class="hljs-meta">... </span>  <span class="hljs-built_in">print</span>(*(<span class="hljs-string">': '</span>.join(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">str</span>, x)) \
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> dicttodisplay.items()), sep=<span class="hljs-string">'\n\n'</span>)
</code></pre>
    <ol>
      <li class="numberedList" value="2">Create a separate file, <code class="inlineCode">firstlook.py</code>, to call the <code class="inlineCode">getfirstlook</code> function.</li>
    </ol>
    <p class="normal-one">Import the <code class="inlineCode">pandas</code>, <code class="inlineCode">os</code>, and <code class="inlineCode">sys</code> libraries, and load the NLS data:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> sys
nls97 = pd.read_csv(<span class="hljs-string">"data/nls97g.csv"</span>, low_memory=<span class="hljs-literal">False</span>)
nls97.set_index(<span class="hljs-string">'personid'</span>, inplace=<span class="hljs-literal">True</span>)
</code></pre>
    <ol>
      <li class="numberedList" value="3">Import <a id="_idIndexMarker919"/>the <code class="inlineCode">basicdescriptives</code> module.</li>
    </ol>
    <p class="normal-one">First, append the <code class="inlineCode">helperfunctions</code> subfolder to the Python path. We can then import <code class="inlineCode">basicdescriptives</code>. We use the same name as the name of the file to import the module. We create an alias, <code class="inlineCode">bd</code>, to make it easier to access the functions in the module later. (We can use <code class="inlineCode">importlib</code>, commented out here, if we need to reload <code class="inlineCode">basicdescriptives</code> because we have made some changes in the code in that module.)</p>
    <pre class="programlisting code-one"><code class="hljs-code">sys.path.append(os.getcwd() + <span class="hljs-string">"/helperfunctions"</span>)
<span class="hljs-keyword">import</span> basicdescriptives <span class="hljs-keyword">as</span> bd
<span class="hljs-comment"># import importlib</span>
<span class="hljs-comment"># importlib.reload(bd)</span>
</code></pre>
    <ol>
      <li class="numberedList" value="4">Take a first look at the NLS data.</li>
    </ol>
    <p class="normal-one">We can just pass the DataFrame to the <code class="inlineCode">getfirstlook</code> function in the <code class="inlineCode">basicdescriptives</code> module to get a quick summary of the NLS data. The <code class="inlineCode">displaydict</code> function gives us prettier printing of the dictionary:</p>
    <pre class="programlisting code-one"><code class="hljs-code">dfinfo = bd.getfirstlook(nls97)
bd.displaydict(dfinfo)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">head:       gender    birthmonth    birthyear    ...    parentincome  \
personid                                         ...               
135335     Female             9       1981       ...              -3  
999406       Male             7       1982       ...              -4  
151672     Female             9       1983       ...           63000  
750699     Female             2       1981       ...           11700  
781297       Male            10       1982       ...              -3  
          fatherhighgrade   motherhighgrade 
personid                                  
135335                16                  8 
999406                17                 15 
151672                -3                 12 
750699                12                 12 
781297                12                 12 
[5 rows x 110 columns]
dtypes: gender      object
birthmonth          int64
birthyear           int64
sampletype         object
ethnicity          object
originalid          int64
motherage           int64
parentincome        int64
fatherhighgrade     int64
motherhighgrade     int64
Length: 110, dtype: object
nrows: 8984
ncols: 110
index: Index([135335, 999406, 151672, 750699, 781297, 613800, 403743,
       474817, 530234, 351406,
       ...
       290800, 209909, 756325, 543646, 411195, 505861, 368078,
       215605, 643085, 713757],
      dtype='int64', name='personid', length=8984)
</code></pre>
    <ol>
      <li class="numberedList" value="5">Pass values <a id="_idIndexMarker920"/>to the <code class="inlineCode">nrows</code> and <code class="inlineCode">uniqueids</code> parameters of <code class="inlineCode">getfirstlook</code>.</li>
    </ol>
    <p class="normal-one">The two parameters default to values of 5 and <code class="inlineCode">None</code> respectively, unless we provide values:</p>
    <pre class="programlisting code-one"><code class="hljs-code">dfinfo = bd.getfirstlook(nls97,<span class="hljs-number">2</span>,<span class="hljs-string">'originalid'</span>)
bd.displaydict(dfinfo)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">head:       gender    birthmonth    birthyear    ...    parentincome  \
personid                                         ...               
135335      Female             9         1981    ...              -3  
999406        Male             7         1982    ...              -4  
         fatherhighgrade  motherhighgrade 
personid                                  
135335                16                8 
999406                17               15 
[2 rows x 110 columns]
dtypes: gender      object
birthmonth          int64
birthyear           int64
sampletype         object
ethnicity          object
originalid          int64
motherage           int64
parentincome        int64
fatherhighgrade     int64
motherhighgrade     int64
Length: 110, dtype: object
nrows: 8984
ncols: 110
index: Index([135335, 999406, 151672, 750699, 781297, 613800, 403743,
       474817, 530234, 351406,
       ...
       290800, 209909, 756325, 543646, 411195, 505861, 368078,
       215605, 643085, 713757],
      dtype='int64', name='personid', length=8984)
uniqueids: 8984
</code></pre>
    <ol>
      <li class="numberedList" value="6">Work with <a id="_idIndexMarker921"/>some of the returned dictionary keys and values.</li>
    </ol>
    <p class="normal-one">We can also display selected key values from the dictionary returned from <code class="inlineCode">getfirstlook</code>. Show the number of rows and data types, and check to see whether each row has a <code class="inlineCode">uniqueid</code> instance (<code class="inlineCode">dfinfo['nrows'] == dfinfo['uniqueids']</code>):</p>
    <pre class="programlisting code-one"><code class="hljs-code">dfinfo[<span class="hljs-string">'nrows'</span>]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">8984
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">dfinfo[<span class="hljs-string">'dtypes'</span>]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">gender             object
birthmonth          int64
birthyear           int64
sampletype         object
ethnicity          object
originalid          int64
motherage           int64
parentincome        int64
fatherhighgrade     int64
motherhighgrade     int64
Length: 110, dtype: object
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">dfinfo[<span class="hljs-string">'nrows'</span>] == dfinfo[<span class="hljs-string">'uniqueids'</span>]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">True
</code></pre>
    <p class="normal">Let’s take a closer look at how the function works and how we call it.</p>
    <h2 id="_idParaDest-428" class="heading-2">How it works...</h2>
    <p class="normal">Almost all of the <a id="_idIndexMarker922"/>action in this recipe is in the <code class="inlineCode">getfirstlook</code> function, which we look at in <em class="italic">step 1</em>. We place the <code class="inlineCode">getfirstlook</code> function in a separate file that we name <code class="inlineCode">basicdescriptives.py</code>, which we can import as a module with that name (minus the extension).</p>
    <p class="normal">We could have typed the function into the file we were using and called it from there. By putting it in a module instead, we can call it from any file that has access to the folder where the module is saved. When we import the <code class="inlineCode">basicdescriptives</code> module in <em class="italic">step 3</em>, we load all of the code in <code class="inlineCode">basicdescriptives</code>, allowing us to call all functions in that module.</p>
    <p class="normal">The <code class="inlineCode">getfirstlook</code> function returns a dictionary with useful information about the DataFrame that is passed to it. We see the first five rows, the number of columns and rows, the data types, and the index. By passing a value to the <code class="inlineCode">uniqueid</code> parameter, we also get the number of unique values for the column.</p>
    <p class="normal">By adding keyword parameters (<code class="inlineCode">nrows</code> and <code class="inlineCode">uniqueid</code>) with default values, we improve the flexibility of <code class="inlineCode">getfirstlook</code>, without increasing the amount of effort it takes to call the function when we do not need the extra functionality. </p>
    <p class="normal">In the first call, in <em class="italic">step 4</em>, we do not pass values for <code class="inlineCode">nrows</code> or <code class="inlineCode">uniqueid</code>, sticking with the default values. In <em class="italic">step 5</em>, we indicate that<a id="_idIndexMarker923"/> we only want two rows displayed and that we want to examine unique values for <code class="inlineCode">originalid</code>.</p>
    <h2 id="_idParaDest-429" class="heading-2">There’s more...</h2>
    <p class="normal">The point of this recipe, and the ones that follow it, is not to provide code that you can download and run on your own data, though you are certainly welcome to do that. I am mainly trying to demonstrate how you can collect your favorite approaches to data cleaning in handy modules, and how this allows for easy code reuse. The specific code here is just a serving suggestion, if you will.</p>
    <p class="normal">Whenever we use a combination of positional and keyword parameters, the positional parameters must go first.</p>
    <h1 id="_idParaDest-430" class="heading-1">Functions for displaying summary statistics and frequencies</h1>
    <p class="normal">During<a id="_idIndexMarker924"/> the first few days of working with a DataFrame, we try to get a good sense of the distribution of continuous variables and counts for categorical variables. We also often do counts by selected groups. Although pandas and NumPy have many built-in methods for these purposes—<code class="inlineCode">describe</code>, <code class="inlineCode">mean</code>, <code class="inlineCode">valuecounts</code>, <code class="inlineCode">crosstab</code>, and so on—data analysts often have preferences for how they work with these tools. If, for example, an analyst finds that they usually need to see more percentiles than those generated by <code class="inlineCode">describe</code>, they can use their own function instead. We will create user-defined functions for displaying summary statistics and frequencies in this recipe.</p>
    <h2 id="_idParaDest-431" class="heading-2">Getting ready</h2>
    <p class="normal">We will be working with the <code class="inlineCode">basicdescriptives</code> module again in this recipe. All of the functions we will define are saved in that module. We will continue to work with the NLS data.</p>
    <h2 id="_idParaDest-432" class="heading-2">How to do it...</h2>
    <p class="normal">We will use functions we create to generate summary statistics and counts:</p>
    <ol>
      <li class="numberedList" value="1">Create the <code class="inlineCode">gettots</code> function in the <code class="inlineCode">basicdescriptives</code> module.</li>
    </ol>
    <p class="normal-one">The function takes a pandas DataFrame and creates a dictionary with selected summary statistics. It returns a pandas DataFrame:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">gettots</span>(<span class="hljs-params">df</span>):
<span class="hljs-meta">... </span>  out = {}
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'</span><span class="hljs-string">min'</span>] = df.<span class="hljs-built_in">min</span>()
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'per15'</span>] = df.quantile(<span class="hljs-number">0.15</span>)
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'qr1'</span>] = df.quantile(<span class="hljs-number">0.25</span>)
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'med'</span>] = df.median()
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'qr3'</span>] = df.quantile(<span class="hljs-number">0.75</span>)
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'per85'</span>] = df.quantile(<span class="hljs-number">0.85</span>)
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'max'</span>] = df.<span class="hljs-built_in">max</span>()
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'</span><span class="hljs-string">count'</span>] = df.count()
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'mean'</span>] = df.mean()
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'iqr'</span>] = out[<span class="hljs-string">'qr3'</span>]-out[<span class="hljs-string">'qr1'</span>]
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> pd.DataFrame(out)
</code></pre>
    <ol>
      <li class="numberedList" value="2">Import the <code class="inlineCode">pandas</code>, <code class="inlineCode">os</code>, and <code class="inlineCode">sys</code> libraries.</li>
    </ol>
    <p class="normal-one">Do this <a id="_idIndexMarker925"/>from a different file, which you can call <code class="inlineCode">taking_measure.py</code>:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> sys
nls97 = pd.read_csv(<span class="hljs-string">"data/nls97g.csv"</span>, low_memory=<span class="hljs-literal">False</span>)
nls97.set_index(<span class="hljs-string">'personid'</span>, inplace=<span class="hljs-literal">True</span>)
</code></pre>
    <ol>
      <li class="numberedList" value="3">Import the <code class="inlineCode">basicdescriptives</code> module:
        <pre class="programlisting code-one"><code class="hljs-code">sys.path.append(os.getcwd() + <span class="hljs-string">"/helperfunctions"</span>)
<span class="hljs-keyword">import</span> basicdescriptives <span class="hljs-keyword">as</span> bd
</code></pre>
      </li>
      <li class="numberedList">Show summary statistics for continuous variables.</li>
    </ol>
    <p class="normal-one">Use the <code class="inlineCode">gettots</code> function from the <code class="inlineCode">basicdescriptives</code> module that we created in <em class="italic">step 1</em>:</p>
    <pre class="programlisting code-one"><code class="hljs-code">bd.gettots(nls97[[<span class="hljs-string">'satverbal'</span>,<span class="hljs-string">'satmath'</span>]]).T
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">       satverbal  satmath
min           14        7
per15        390      390
qr1          430      430
med          500      500
qr3          570      580
per85        620      621
max          800      800
count      1,406    1,407
mean         500      501
iqr          140      150
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">bd.gettots(nls97.<span class="hljs-built_in">filter</span>(like=<span class="hljs-string">"weeksworked"</span>))
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">               min  per15  qr1  ...  count  mean  iqr
weeksworked00    0      0    5  ...   8626    26   45
weeksworked01    0      0   10  ...   8591    30   41
weeksworked02    0      0   13  ...   8591    32   39
weeksworked03    0      0   14  ...   8535    34   38
weeksworked04    0      1   17  ...   8513    35   35
weeksworked05    0      5   22  ...   8468    37   31
weeksworked06    0      9   27  ...   8419    38   25
weeksworked07    0     10   30  ...   8360    39   22
weeksworked08    0      9   30  ...   8292    39   22
weeksworked09    0      0   22  ...   8267    38   30
weeksworked10    0      0   21  ...   8198    37   31
weeksworked11    0      0   22  ...   8123    38   31
weeksworked12    0      0   23  ...   7988    38   29
weeksworked13    0      0   28  ...   7942    39   24
weeksworked14    0      0   26  ...   7896    39   26
weeksworked15    0      0   33  ...   7767    40   19
weeksworked16    0      0   31  ...   7654    40   22
weeksworked17    0      0   38  ...   7496    40   14
weeksworked18    0      0   35  ...   7435    40   17
weeksworked19    0      4   42  ...   7237    41   10
weeksworked20    0      0   21  ...   6971    38   31
weeksworked21    0      0   35  ...   6627    36   15
weeksworked22    0      0    2  ...   2202    11   17
[23 rows x 10 columns]
</code></pre>
    <ol>
      <li class="numberedList" value="5">Create a<a id="_idIndexMarker926"/> function to count missing values by columns and rows.</li>
    </ol>
    <p class="normal-one">The <code class="inlineCode">getmissings</code> function will take a DataFrame and a parameter for showing percentages or counts. It returns two Series, one with the missing values for each column and the other with missing values by row. Save the function in the <code class="inlineCode">basicdescriptives</code> module:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">getmissings</span>(<span class="hljs-params">df, byrowperc=</span><span class="hljs-literal">False</span>):
  <span class="hljs-keyword">return</span> df.isnull().<span class="hljs-built_in">sum</span>(),\
    df.isnull().<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>).\
    value_counts(normalize=byrowperc).\
    sort_index()
</code></pre>
    <ol>
      <li class="numberedList" value="6">Call the <code class="inlineCode">getmissings</code> function.</li>
    </ol>
    <p class="normal-one">Call it first <a id="_idIndexMarker927"/>with <code class="inlineCode">byrowperc</code> (the second parameter) set to <code class="inlineCode">True</code>. This will show the percentage of rows with the associated number of missing values. For example, the <code class="inlineCode">missingbyrows</code> value shows that 73% of rows have 0 missing values for <code class="inlineCode">weeksworked20</code> and <code class="inlineCode">weeksworked21</code>. Call it again, leaving <code class="inlineCode">byrowperc</code> at its default value of <code class="inlineCode">False</code>, to get counts instead:</p>
    <pre class="programlisting code-one"><code class="hljs-code">missingsbycols, missingsbyrows = \
  bd.getmissings(nls97[[<span class="hljs-string">'weeksworked20'</span>,
  <span class="hljs-string">'weeksworked21'</span>]], <span class="hljs-literal">True</span>)
missingsbycols
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">weeksworked20    2013
weeksworked21    2357
dtype: int64
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">missingsbyrows
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">0   0.73
1   0.05
2   0.22
Name: proportion, dtype: float64
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">missingsbycols, missingsbyrows = \
  bd.getmissings(nls97[[<span class="hljs-string">'weeksworked20'</span>,
  <span class="hljs-string">'weeksworked21'</span>]])
missingsbyrows
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">0    6594
1     410
2    1980
Name: count, dtype: int64
</code></pre>
    <ol>
      <li class="numberedList" value="7">Create a function to calculate frequencies for all categorical variables.</li>
    </ol>
    <p class="normal-one">The <code class="inlineCode">makefreqs</code> function loops through all columns with the category data type in the passed DataFrame, running <code class="inlineCode">value_counts</code> on each one. The frequencies are saved to the file indicated by <code class="inlineCode">outfile</code>:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">makefreqs</span>(<span class="hljs-params">df, outfile</span>):
<span class="hljs-meta">... </span>  freqout = <span class="hljs-built_in">open</span>(outfile, <span class="hljs-string">'w'</span>)
<span class="hljs-meta">... </span>  <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> df.\
<span class="hljs-meta">... </span>    select_dtypes(include=[<span class="hljs-string">"category"</span>]):
<span class="hljs-meta">... </span>      <span class="hljs-built_in">print</span>(col, <span class="hljs-string">"----------------------"</span>,
<span class="hljs-meta">... </span>        <span class="hljs-string">"frequencies"</span>,
<span class="hljs-meta">... </span>        df[col].value_counts().sort_index(),
<span class="hljs-meta">... </span>        <span class="hljs-string">"percentages"</span>,
<span class="hljs-meta">... </span>        df[col].value_counts(normalize=<span class="hljs-literal">True</span>).\
<span class="hljs-meta">... </span>        sort_index(),
<span class="hljs-meta">... </span>        sep=<span class="hljs-string">"\n\n"</span>, end=<span class="hljs-string">"\n\n\n"</span>,
<span class="hljs-meta">... </span>        file=freqout)
<span class="hljs-meta">... </span>  freqout.close()
</code></pre>
    <ol>
      <li class="numberedList" value="8">Call the <code class="inlineCode">makefreqs</code> function.</li>
    </ol>
    <p class="normal-one">First change<a id="_idIndexMarker928"/> the data type of each object column to <code class="inlineCode">category</code>. This call runs <code class="inlineCode">value_counts</code> on category data columns in the NLS DataFrame and saves the frequencies to <code class="inlineCode">nlsfreqs.txt</code> in the <code class="inlineCode">views</code> subfolder of the current folder.</p>
    <pre class="programlisting code-one"><code class="hljs-code">nls97.loc[:, nls97.dtypes == <span class="hljs-string">'</span><span class="hljs-string">object'</span>] = \
<span class="hljs-meta">... </span>  nls97.select_dtypes([<span class="hljs-string">'object'</span>]). \
<span class="hljs-meta">... </span>  apply(<span class="hljs-keyword">lambda</span> x: x.astype(<span class="hljs-string">'category'</span>))
bd.makefreqs(nls97, <span class="hljs-string">"views/nlsfreqs.txt"</span>)
</code></pre>
    <ol>
      <li class="numberedList" value="9">Create a function to get counts by groups.</li>
    </ol>
    <p class="normal-one">The <code class="inlineCode">getcnts</code> function counts the number of rows for each combination of column values in <code class="inlineCode">cats</code>, a list of column names. It also counts the number of rows for each combination of column values excluding the final column in <code class="inlineCode">cats</code>. This provides a total across all values of the final column. (The next step shows what this looks like.)</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">getcnts</span>(<span class="hljs-params">df, cats, rowsel=</span><span class="hljs-literal">None</span>):
<span class="hljs-meta">... </span>  tots = cats[:-<span class="hljs-number">1</span>]
<span class="hljs-meta">... </span>  catcnt = df.groupby(cats, dropna=<span class="hljs-literal">False</span>).size().\
<span class="hljs-meta">... </span>    reset_index(name=<span class="hljs-string">'catcnt'</span>)
<span class="hljs-meta">... </span>  totcnt = df.groupby(tots, dropna=<span class="hljs-literal">False</span>).size().\
<span class="hljs-meta">... </span>    reset_index(name=<span class="hljs-string">'totcnt'</span>)
<span class="hljs-meta">... </span>  percs = pd.merge(catcnt, totcnt, left_on=tots,
<span class="hljs-meta">... </span>    right_on=tots, how=<span class="hljs-string">"left"</span>)
<span class="hljs-meta">... </span>  percs[<span class="hljs-string">'percent'</span>] = percs.catcnt / percs.totcnt
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> (rowsel <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>):
<span class="hljs-meta">... </span>    percs = percs.loc[<span class="hljs-built_in">eval</span>(<span class="hljs-string">"percs."</span> + rowsel)]
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> percs
</code></pre>
    <ol>
      <li class="numberedList" value="10">Pass the <code class="inlineCode">maritalstatus</code> and <code class="inlineCode">colenroct00</code> columns to the <code class="inlineCode">getcnts</code> function.</li>
    </ol>
    <p class="normal-one">This <a id="_idIndexMarker929"/>returns a DataFrame with counts for each column value combination, as well as counts for all combinations excluding the last column. This is used to calculate percentages within groups. For example, 669 respondents were divorced and 560 of those (or 84%) were not enrolled in college in October 2000:</p>
    <pre class="programlisting code-one"><code class="hljs-code">bd.getcnts(nls97,
  [<span class="hljs-string">'maritalstatus'</span>,<span class="hljs-string">'colenroct00'</span>])
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">    maritalstatus           colenroct00   catcnt   totcnt   percent
0        Divorced       1. Not enrolled      560      669      0.84
1        Divorced     2. 2-year college       50      669      0.07
2        Divorced     3. 4-year college       59      669      0.09
3         Married       1. Not enrolled     2264     3068      0.74
4         Married     2. 2-year college      236     3068      0.08
5         Married     3. 4-year college      568     3068      0.19
6   Never-married       1. Not enrolled     2363     2767      0.85
7   Never-married     2. 2-year college      131     2767      0.05
8   Never-married     3. 4-year college      273     2767      0.10
9       Separated       1. Not enrolled      127      148      0.86
10      Separated     2. 2-year college       13      148      0.09
11      Separated     3. 4-year college        8      148      0.05
12        Widowed       1. Not enrolled       19       23      0.83
13        Widowed     2. 2-year college        1       23      0.04
14        Widowed     3. 4-year college        3       23      0.13
15            NaN       1. Not enrolled     1745     2309      0.76
16            NaN     2. 2-year college      153     2309      0.07
17            NaN     3. 4-year college      261     2309      0.11
18            NaN                   NaN     150      2309      0.06
</code></pre>
    <ol>
      <li class="numberedList" value="11">Use the <code class="inlineCode">rowsel</code> parameter of <code class="inlineCode">getcnts</code> to limit the output to specific rows. This will show only the not-enrolled-in-college rows:
        <pre class="programlisting code-one"><code class="hljs-code">bd.getcnts(nls97,
  [<span class="hljs-string">'maritalstatus'</span>,<span class="hljs-string">'colenroct20'</span>],
  <span class="hljs-string">"colenroct20.str[0:1]=='1'"</span>)
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">     maritalstatus       colenroct00   catcnt    totcnt    percent
0         Divorced   1. Not enrolled      560       669       0.84
3          Married   1. Not enrolled     2264      3068       0.74
6    Never-married   1. Not enrolled     2363      2767       0.85
9        Separated   1. Not enrolled      127       148       0.86
12         Widowed   1. Not enrolled       19        23       0.83
15             NaN   1. Not enrolled     1745      2309       0.76
</code></pre>
      </li>
    </ol>
    <p class="normal">These steps demonstrate how to create functions and use them to generate summary statistics and frequencies.</p>
    <h2 id="_idParaDest-433" class="heading-2">How it works...</h2>
    <p class="normal">In <em class="italic">step 1</em>, we<a id="_idIndexMarker930"/> created a function, <code class="inlineCode">gettots</code>, that calculated descriptive statistics for all columns in a DataFrame, returning those results in a summary DataFrame. Most of the statistics can be generated with the <code class="inlineCode">describe</code> method, but we add a few statistics—the 15<sup class="superscript">th</sup> percentile, the 85<sup class="superscript">th</sup> percentile, and the interquartile range. We call that function twice in <em class="italic">step 4</em>, the first time for the SAT verbal and math scores and the second time for all weeks worked columns.</p>
    <p class="normal"><em class="italic">Steps 5 </em>and<em class="italic"> 6</em> create and call a function that shows the number of missing values for each column in the passed DataFrame. The function also counts missing values for each row, displaying the frequency of missing values. The frequency of missing values by row can also be displayed as a percentage of all rows by passing a value of <code class="inlineCode">True</code> to the <code class="inlineCode">byrowperc</code> parameter.</p>
    <p class="normal"><em class="italic">Steps 7 </em>and<em class="italic"> 8</em> produce a text file with frequencies for all categorical variables in the passed DataFrame. We just loop through all columns with the category data type and run <code class="inlineCode">value_counts</code>. Since often the output is long, we save it to a file. It is also good to have frequencies saved somewhere for later reference.</p>
    <p class="normal">The <code class="inlineCode">getcnts</code> function we create in <em class="italic">step 9</em> and call in <em class="italic">steps 10</em> and <em class="italic">11</em> is a tad idiosyncratic. pandas has a very useful <code class="inlineCode">crosstab</code> function, which I use frequently. But I often need a no-fuss way to look at group counts and percentages for subgroups within groups. The <code class="inlineCode">getcnts</code> function does that.</p>
    <h2 id="_idParaDest-434" class="heading-2">There’s more...</h2>
    <p class="normal">A function can be very helpful even when it does not do very much. There is not much code in the <code class="inlineCode">getmissings</code> function, but I check for missing values so frequently that the small time savings are significant cumulatively. It also reminds me to check for missing values by column and by row.</p>
    <h2 id="_idParaDest-435" class="heading-2">See also</h2>
    <p class="normal">We explore pandas’ tools for generating summary statistics and frequencies in <em class="chapterRef">Chapter 3</em>, <em class="italic">Taking the Measure of Your Data</em>.</p>
    <h1 id="_idParaDest-436" class="heading-1">Functions for identifying outliers and unexpected values</h1>
    <p class="normal">If I had to <a id="_idIndexMarker931"/>pick one data-cleaning area where I find reusable code most beneficial, it would be in the identification of outliers and unexpected values. This is because our prior assumptions often lead us to the central tendency of a distribution, rather than to the extremes. Quickly—think of a cat. Unless you were thinking about a particular cat in your life, an image of a generic feline between 8 and 10 pounds probably came to mind; not one that is 6 pounds or 22 pounds.</p>
    <p class="normal">We often need to be more deliberate to elevate extreme values to consciousness. This is where having a standard set of diagnostic functions to run on our data is very helpful. We can run these functions even if nothing in particular triggers us to run them. This recipe provides examples of functions that we can use regularly to identify outliers and unexpected values.</p>
    <h2 id="_idParaDest-437" class="heading-2">Getting ready</h2>
    <p class="normal">We will create two files in this recipe, one with the functions we will use to check for outliers and another with the code we will use to call those functions. Let’s call the file with the functions we will use <code class="inlineCode">outliers.py</code>, and place it in a subfolder called <code class="inlineCode">helperfunctions</code>.</p>
    <p class="normal">You will need the <code class="inlineCode">matplotlib</code> and <code class="inlineCode">scipy</code> libraries, in addition to pandas, to run the code in this recipe. You can install <code class="inlineCode">matplotlib</code> and <code class="inlineCode">scipy</code> by entering <code class="inlineCode">pip install matplotlib</code> and <code class="inlineCode">pip install scipy</code> in a Terminal client or in Windows PowerShell. You will also need the <code class="inlineCode">pprint</code> utility, which you can install with <code class="inlineCode">pip install pprint</code>.</p>
    <p class="normal">We will work with the NLS and COVID-19 data in this recipe. The COVID-19 data has one row per country, with cumulative cases and deaths for that country.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Data note</strong></p>
      <p class="normal">Our World in Data provides COVID-19 public use data at <a href="https://ourworldindata.org/covid-cases"><span class="url">https://ourworldindata.org/covid-cases</span></a>. The dataset includes total cases and deaths, tests administered, hospital beds, and demographic data such as median age, gross domestic product, and diabetes prevalence. The dataset used in this recipe was downloaded on March 3, 2024.</p>
    </div>
    <h2 id="_idParaDest-438" class="heading-2">How to do it...</h2>
    <p class="normal">We create<a id="_idIndexMarker932"/> and call functions to check the distribution of variables, list extreme values, and visualize a distribution:</p>
    <ol>
      <li class="numberedList" value="1">Import the <code class="inlineCode">pandas</code>, <code class="inlineCode">os</code>, <code class="inlineCode">sys</code>, and <code class="inlineCode">pprint</code> libraries.</li>
    </ol>
    <p class="normal-one">Also, load the NLS and COVID-19 data:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> pprint
nls97 = pd.read_csv(<span class="hljs-string">"data/nls97g.csv"</span>, low_memory=<span class="hljs-literal">False</span>)
nls97.set_index(<span class="hljs-string">'personid'</span>, inplace=<span class="hljs-literal">True</span>)
covidtotals = pd.read_csv(<span class="hljs-string">"data/covidtotals.csv"</span>)
</code></pre>
    <ol>
      <li class="numberedList" value="2">Create a function to show some important properties of a distribution.</li>
    </ol>
    <p class="normal-one">The <code class="inlineCode">getdistprops</code> function takes a Series and generates measures of central tendency, shape, and spread. The function returns a dictionary with these measures. It also handles situations where the Shapiro test for normality does not return a value. It will not add keys for <code class="inlineCode">normstat</code> and <code class="inlineCode">normpvalue</code> when that happens. Save the function in a file named <code class="inlineCode">outliers.py</code> in the <code class="inlineCode">helperfunctions</code> subfolder of the current directory. (Also load the <code class="inlineCode">pandas</code>, <code class="inlineCode">matplotlib</code>, <code class="inlineCode">scipy</code>, and <code class="inlineCode">math</code> libraries we will need for this and other functions in this module.)</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> scipy.stats <span class="hljs-keyword">as</span> scistat
<span class="hljs-keyword">import</span> math
<span class="hljs-keyword">def</span> <span class="hljs-title">getdistprops</span>(<span class="hljs-params">seriestotest</span>):
<span class="hljs-meta">... </span>  out = {}
<span class="hljs-meta">... </span>  normstat, normpvalue = scistat.shapiro(seriestotest)
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> (<span class="hljs-keyword">not</span> math.isnan(normstat)):
<span class="hljs-meta">... </span>    out[<span class="hljs-string">'normstat'</span>] = normstat
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> (normpvalue&gt;=<span class="hljs-number">0.05</span>):
<span class="hljs-meta">... </span>      out[<span class="hljs-string">'normpvalue'</span>] = <span class="hljs-built_in">str</span>(<span class="hljs-built_in">round</span>(normpvalue, <span class="hljs-number">2</span>)) + <span class="hljs-string">": Accept Normal"</span>
<span class="hljs-meta">... </span>    <span class="hljs-keyword">elif</span> (normpvalue&lt;<span class="hljs-number">0.05</span>):
<span class="hljs-meta">... </span>      out[<span class="hljs-string">'</span><span class="hljs-string">normpvalue'</span>] = <span class="hljs-built_in">str</span>(<span class="hljs-built_in">round</span>(normpvalue, <span class="hljs-number">2</span>)) + <span class="hljs-string">": Reject Normal"</span>
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'mean'</span>] = seriestotest.mean()
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'median'</span>] = seriestotest.median()
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'</span><span class="hljs-string">std'</span>] = seriestotest.std()
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'kurtosis'</span>] = seriestotest.kurtosis()
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'skew'</span>] = seriestotest.skew()
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'count'</span>] = seriestotest.count()
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> out
</code></pre>
    <ol>
      <li class="numberedList" value="3">Pass the<a id="_idIndexMarker933"/> total cases per million in population series to the <code class="inlineCode">getdistprops</code> function.</li>
    </ol>
    <p class="normal-one">The <code class="inlineCode">skew</code> and <code class="inlineCode">kurtosis</code> values suggest that the distribution of <code class="inlineCode">total_cases_pm</code> has a positive skew and shorter tails than a normally distributed variable. The Shapiro test of normality (<code class="inlineCode">normpvalue</code>) confirms this. (Use <code class="inlineCode">pprint</code> to improve the display of the dictionary returned by <code class="inlineCode">getdistprops</code>.) </p>
    <pre class="programlisting code-one"><code class="hljs-code">dist = ol.getdistprops(covidtotals.total_cases_pm)
pprint.pprint(dist)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">{'count': 231,
 'kurtosis': -0.4280595203351645,
 'mean': 206177.79462337663,
 'median': 133946.251,
 'normpvalue': '0.0: Reject Normal',
 'normstat': 0.8750641345977783,
 'skew': 0.8349032460009967,
 'std': 203858.09625231632}
</code></pre>
    <ol>
      <li class="numberedList" value="4">Create a function to list the outliers in a DataFrame.</li>
    </ol>
    <p class="normal-one">The <code class="inlineCode">getoutliers</code> function iterates over all columns in <code class="inlineCode">sumvars</code>. It determines outlier thresholds for those columns, setting them at 1.5 times the interquartile range (the distance between the first and third quartiles) below the first quartile or above the third quartile. It then selects all rows with values above the high threshold or below the low threshold. It adds columns that indicate the variable examined (<code class="inlineCode">varname</code>) for outliers and the threshold levels. It also includes columns in the <code class="inlineCode">othervars</code> list in the DataFrame it returns:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">getoutliers</span>(<span class="hljs-params">dfin, sumvars, othervars</span>):
<span class="hljs-meta">... </span>  dfin = dfin[sumvars + othervars]
<span class="hljs-meta">... </span>  dfout = pd.DataFrame(columns=dfin.columns, data=<span class="hljs-literal">None</span>)
<span class="hljs-meta">... </span>  dfsums = dfin[sumvars]
<span class="hljs-meta">... </span>  <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> dfsums.columns:
<span class="hljs-meta">... </span>    thirdq, firstq = dfsums[col].quantile(<span class="hljs-number">0.75</span>),\
<span class="hljs-meta">... </span>      dfsums[col].quantile(<span class="hljs-number">0.25</span>)
<span class="hljs-meta">... </span>    interquartilerange = <span class="hljs-number">1.5</span>*(thirdq-firstq)
<span class="hljs-meta">... </span>    outlierhigh, outlierlow = interquartilerange+thirdq,\
<span class="hljs-meta">... </span>      firstq-interquartilerange
<span class="hljs-meta">... </span>    df = dfin.loc[(dfin[col]&gt;outlierhigh) | \
<span class="hljs-meta">... </span>      (dfin[col]&lt;outlierlow)]
<span class="hljs-meta">... </span>    df = df.assign(varname = col, threshlow = outlierlow,\
<span class="hljs-meta">... </span>      threshhigh = outlierhigh)
<span class="hljs-meta">... </span>    dfout = pd.concat([dfout, df])
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> dfout
</code></pre>
    <ol>
      <li class="numberedList" value="5">Call the <code class="inlineCode">getoutlier</code> function.</li>
    </ol>
    <p class="normal-one">Pass a list of<a id="_idIndexMarker934"/> columns to check for outliers (<code class="inlineCode">sumvars</code>) and another list of columns to include in the returned DataFrame (<code class="inlineCode">othervars</code>). Show the count of outliers for each variable and view the outliers for SAT math:</p>
    <pre class="programlisting code-one"><code class="hljs-code">sumvars = [<span class="hljs-string">'satmath'</span>,<span class="hljs-string">'wageincome20'</span>]
othervars = [<span class="hljs-string">'originalid'</span>,<span class="hljs-string">'highestdegree'</span>,<span class="hljs-string">'gender'</span>,<span class="hljs-string">'maritalstatus'</span>]
outliers = ol.getoutliers(nls97, sumvars, othervars)
outliers.varname.value_counts(sort=<span class="hljs-literal">False</span>)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">varname
satmath          10
wageincome20    234
Name: count, dtype: int64
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">outliers.loc[outliers.varname==<span class="hljs-string">'satmath'</span>, othervars + sumvars]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">        originalid      highestdegree   ...    satmath    wageincome20
337438         159     2. High School   ...     200.00       32,000.00
448463         326       4. Bachelors   ...      47.00             NaN
799095         535         5. Masters   ...      59.00             NaN
267254        1622     2. High School   ...      48.00             NaN
955430        2547     2. High School   ...     200.00             NaN
748274        3394       4. Bachelors   ...      42.00             NaN
399109        3883     2. High School   ...      36.00       37,000.00
223058        6696            0. None   ...      46.00             NaN
291029        7088     2. High School   ...      51.00             NaN
738290        7705     2. High School   ...       7.00       50,000.00
[10 rows x 6 columns]
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">outliers.to_excel(<span class="hljs-string">"views/nlsoutliers.xlsx"</span>)
</code></pre>
    <ol>
      <li class="numberedList" value="6">Create a<a id="_idIndexMarker935"/> function to generate histograms and boxplots.</li>
    </ol>
    <p class="normal-one">The <code class="inlineCode">makeplot</code> function takes a Series, title, and label for the <em class="italic">x</em>-axis. The default plot is set as a histogram:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">makeplot</span>(<span class="hljs-params">seriestoplot, title, xlabel, plottype=</span><span class="hljs-string">"hist"</span>):
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> (plottype==<span class="hljs-string">"hist"</span>):
<span class="hljs-meta">... </span>    plt.hist(seriestoplot)
<span class="hljs-meta">... </span>    plt.axvline(seriestoplot.mean(), color=<span class="hljs-string">'red'</span>,\
<span class="hljs-meta">... </span>      linestyle=<span class="hljs-string">'dashed'</span>, linewidth=<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    plt.xlabel(xlabel)
<span class="hljs-meta">... </span>    plt.ylabel(<span class="hljs-string">"</span><span class="hljs-string">Frequency"</span>)
<span class="hljs-meta">... </span>  <span class="hljs-keyword">elif</span> (plottype==<span class="hljs-string">"box"</span>):
<span class="hljs-meta">... </span>    plt.boxplot(seriestoplot.dropna(), labels=[xlabel])
<span class="hljs-meta">... </span>  plt.title(title)
<span class="hljs-meta">... </span>  plt.show()
</code></pre>
    <ol>
      <li class="numberedList" value="7">Call the <code class="inlineCode">makeplot</code> function to create a histogram:
        <pre class="programlisting code-one"><code class="hljs-code">ol.makeplot(nls97.satmath, <span class="hljs-string">"Histogram of SAT Math"</span>, <span class="hljs-string">"</span><span class="hljs-string">SAT Math"</span>)
</code></pre>
      </li>
    </ol>
    <p class="normal-one">This generates the following histogram:</p>
    <figure class="mediaobject"><img src="../Images/B18596_12_01.png" alt="" role="presentation"/></figure>
    <p class="packt_figref">Figure 12.1: Frequencies of SAT math values</p>
    <ol>
      <li class="numberedList" value="8">Use the <code class="inlineCode">makeplot</code> function<a id="_idIndexMarker936"/> to create a boxplot:
        <pre class="programlisting code-one"><code class="hljs-code">ol.makeplot(nls97.satmath, <span class="hljs-string">"Boxplot of SAT Math"</span>, <span class="hljs-string">"SAT Math"</span>, <span class="hljs-string">"box"</span>)
</code></pre>
      </li>
    </ol>
    <p class="normal-one">This generates the following boxplot:</p>
    <figure class="mediaobject"><img src="../Images/B18596_12_02.png" alt="" role="presentation"/></figure>
    <p class="packt_figref">Figure 12.2: Show the median, interquartile range, and outlier thresholds with a boxplot</p>
    <p class="normal">The preceding steps show how we can develop reusable code to check for outliers and unexpected values.</p>
    <h2 id="_idParaDest-439" class="heading-2">How it works...</h2>
    <p class="normal">We start by<a id="_idIndexMarker937"/> getting the key attributes of a distribution, including the mean, median, standard deviation, skew, and kurtosis. We do this by passing a Series to the <code class="inlineCode">getdistprop</code> function in <em class="italic">step 3</em>, getting back a dictionary with these measures.</p>
    <p class="normal">The function in <em class="italic">step 4</em> selects rows where one of the columns in <code class="inlineCode">sumvars</code> has a value that is an outlier. It also includes the values for the columns in <code class="inlineCode">othervars</code> and the threshold amounts in the DataFrame it returns.</p>
    <p class="normal">We create a<a id="_idIndexMarker938"/> function in <em class="italic">step 6</em> that makes it easier to create a simple histogram or boxplot. The functionality of <code class="inlineCode">matplotlib</code> is great, but it can take a minute to remind ourselves of the syntax when we just want to create a simple histogram or boxplot. We can avoid that by defining a function with a few routine parameters: Series, title, and <em class="italic">x</em>-label. We call that function in <em class="italic">steps 7</em> and <em class="italic">8</em>.</p>
    <h2 id="_idParaDest-440" class="heading-2">There’s more...</h2>
    <p class="normal">We do not want to do too much work with a continuous variable before getting a good sense of how its values are distributed; what is the central tendency and shape of the distribution? If we run something like the functions in this recipe for key continuous variables, we would be off to a good start.</p>
    <p class="normal">The relatively painless portability of Python modules makes this pretty easy to do. If we wanted to use the <code class="inlineCode">outliers</code> module that we used in this example, we would just need to save the <code class="inlineCode">outliers.py</code> file to a folder that our program can access, add that folder to the Python path, and import it.</p>
    <p class="normal">Usually, when we are inspecting an extreme value, we want to have a better idea of the context of other variables that might explain why the value is extreme. For example, a height of 178 centimeters is not an outlier for an adult male, but it definitely is for a 9-year-old. The DataFrame produced in <em class="italic">steps 4</em> and <em class="italic">5</em> provides us with both the outlier values and other data that might be relevant. Saving the data to an Excel file makes it easy to inspect outlier rows later or share that data with others.</p>
    <h2 id="_idParaDest-441" class="heading-2">See also</h2>
    <p class="normal">We go into a fair bit of detail on detecting outliers and unexpected values in <em class="chapterRef">Chapter 4</em>, <em class="italic">Identifying Outliers in Subsets of Data</em>. We examine histograms, boxplots, and many other visualizations in <em class="chapterRef">Chapter 5</em>, <em class="italic">Using Visualizations for the Identification of Unexpected Values</em>.</p>
    <h1 id="_idParaDest-442" class="heading-1">Functions for aggregating or combining data</h1>
    <p class="normal">Most data <a id="_idIndexMarker939"/>analysis projects require some reshaping of data. We may need to aggregate by group or combine data vertically or horizontally. We have to do similar tasks each time we prepare our data for this reshaping. We can routinize some of these tasks with functions, improving both the reliability of our code and our efficiency in getting the work done. We sometimes need to check for mismatches in merge-by columns before doing a merge, check for unexpected changes in values in panel data from one period to the next before aggregating, or concatenate a number of files at once and verify that data has been combined accurately.</p>
    <p class="normal">These are just a few examples of the kind of data aggregation and combining tasks that might lend themselves to a more generalized coding solution. In this recipe, we define functions that can help with these tasks.</p>
    <h2 id="_idParaDest-443" class="heading-2">Getting ready</h2>
    <p class="normal">We will <a id="_idIndexMarker940"/>work with the COVID-19 daily data in this recipe. This data comprises new cases and new deaths for each country by day. We will also work with land temperature data for several countries in 2023. The data for each country is in a separate file and has one row per weather station in that country for each month.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Data note</strong></p>
      <p class="normal">The land temperature DataFrame has the average temperature readings (in °C) in 2023 from over 12,000 stations across the world, though a majority of the stations are in the United States. The raw data was retrieved from the Global Historical Climatology Network integrated database. It is made available for public use by the United States National Oceanic and Atmospheric Administration at <a href="https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-monthly"><span class="url">https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-monthly</span></a>.</p>
    </div>
    <h2 id="_idParaDest-444" class="heading-2">How to do it...</h2>
    <p class="normal">We will use functions to aggregate data, combine data vertically, and check merge-by values:</p>
    <ol>
      <li class="numberedList" value="1">Import the <code class="inlineCode">pandas</code>, <code class="inlineCode">os</code>, and <code class="inlineCode">sys</code> libraries:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> sys
</code></pre>
      </li>
      <li class="numberedList">Create a function (<code class="inlineCode">adjmeans</code>) to aggregate values by period for a group.</li>
    </ol>
    <p class="normal-one">Sort the values in the passed DataFrame by group (<code class="inlineCode">byvar</code>) and then <code class="inlineCode">period</code>. Convert the DataFrame values to a NumPy array. Loop through the values, do a running tally of the <code class="inlineCode">var</code> column, and set the running tally back to 0 when you reach a new value for <code class="inlineCode">byvar</code>. Before aggregating, check for extreme changes in values from one period to the next. The <code class="inlineCode">changeexclude</code> parameter indicates the size of a change from one period to the next that should be considered extreme. The <code class="inlineCode">excludetype</code> parameter indicates whether the <code class="inlineCode">changeexclude</code> value is an absolute amount or a percentage of the <code class="inlineCode">var</code> column’s mean. Save<a id="_idIndexMarker941"/> the function in a file called <code class="inlineCode">combineagg.py</code> in the <code class="inlineCode">helperfunctions</code> subfolder:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">adjmeans</span>(<span class="hljs-params">df, byvar, var, period, changeexclude=</span><span class="hljs-literal">None</span><span class="hljs-params">, excludetype=</span><span class="hljs-literal">None</span>):
<span class="hljs-meta">... </span>  df = df.sort_values([byvar, period])
<span class="hljs-meta">... </span>  df = df.dropna(subset=[var])
<span class="hljs-meta">... </span>  <span class="hljs-comment"># iterate using numpy arrays</span>
<span class="hljs-meta">... </span>  prevbyvar = <span class="hljs-string">'ZZZ'</span>
<span class="hljs-meta">... </span>  prevvarvalue = <span class="hljs-number">0</span>
<span class="hljs-meta">... </span>  rowlist = []
<span class="hljs-meta">... </span>  varvalues = df[[byvar, var]].values
<span class="hljs-meta">... </span>  <span class="hljs-comment"># convert exclusion ratio to absolute number</span>
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> (excludetype==<span class="hljs-string">"ratio"</span> <span class="hljs-keyword">and</span> changeexclude <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>):
<span class="hljs-meta">... </span>    changeexclude = df[var].mean()*changeexclude
<span class="hljs-meta">... </span>  <span class="hljs-comment"># loop through variable values</span>
<span class="hljs-meta">... </span>  <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(varvalues)):
<span class="hljs-meta">... </span>    byvar = varvalues[j][<span class="hljs-number">0</span>]
<span class="hljs-meta">... </span>    varvalue = varvalues[j][<span class="hljs-number">1</span>]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> (prevbyvar!=byvar):
<span class="hljs-meta">... </span>      <span class="hljs-keyword">if</span> (prevbyvar!=<span class="hljs-string">'ZZZ'</span>):
<span class="hljs-meta">... </span>        rowlist.append({<span class="hljs-string">'byvar'</span>:prevbyvar, <span class="hljs-string">'avgvar'</span>:varsum/byvarcnt,\
<span class="hljs-meta">... </span>          <span class="hljs-string">'sumvar'</span>:varsum, <span class="hljs-string">'byvarcnt'</span>:byvarcnt})
<span class="hljs-meta">... </span>      varsum = <span class="hljs-number">0</span>
<span class="hljs-meta">... </span>      byvarcnt = <span class="hljs-number">0</span>
<span class="hljs-meta">... </span>      prevbyvar = byvar
<span class="hljs-meta">... </span>    <span class="hljs-comment"># exclude extreme changes in variable value</span>
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> ((changeexclude <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>) <span class="hljs-keyword">or</span> (<span class="hljs-number">0</span> &lt;= <span class="hljs-built_in">abs</span>(varvalue-prevvarvalue) \
<span class="hljs-meta">... </span>      &lt;= changeexclude) <span class="hljs-keyword">or</span> (byvarcnt==<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>      varsum += varvalue
<span class="hljs-meta">... </span>      byvarcnt += <span class="hljs-number">1</span>
<span class="hljs-meta">... </span>    prevvarvalue = varvalue
<span class="hljs-meta">... </span>  rowlist.append({<span class="hljs-string">'byvar'</span>:prevbyvar, <span class="hljs-string">'avgvar'</span>:varsum/byvarcnt, \
<span class="hljs-meta">... </span>    <span class="hljs-string">'sumvar'</span>:varsum, <span class="hljs-string">'byvarcnt'</span>:byvarcnt})
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> pd.DataFrame(rowlist)
</code></pre>
    <ol>
      <li class="numberedList" value="3">Import the <code class="inlineCode">combineagg</code> module:
        <pre class="programlisting code-one"><code class="hljs-code">sys.path.append(os.getcwd() + <span class="hljs-string">"/helperfunctions"</span>)
<span class="hljs-keyword">import</span> combineagg <span class="hljs-keyword">as</span> ca
</code></pre>
      </li>
      <li class="numberedList">Load the DataFrames:
        <pre class="programlisting code-one"><code class="hljs-code">coviddaily = pd.read_csv(<span class="hljs-string">"data/coviddaily.csv"</span>)
ltbrazil = pd.read_csv(<span class="hljs-string">"data/ltbrazil.csv"</span>)
countries = pd.read_csv(<span class="hljs-string">"data/ltcountries.csv"</span>)
locations = pd.read_csv(<span class="hljs-string">"data/ltlocations.csv"</span>)
</code></pre>
      </li>
      <li class="numberedList">Call the <code class="inlineCode">adjmeans</code> function to summarize panel data by group and time period.</li>
    </ol>
    <p class="normal-one">Indicate <a id="_idIndexMarker942"/>that we want a summary of <code class="inlineCode">new_cases</code> by <code class="inlineCode">location</code>:</p>
    <pre class="programlisting code-one"><code class="hljs-code">ca.adjmeans(coviddaily, <span class="hljs-string">'location'</span>,<span class="hljs-string">'new_cases'</span>,<span class="hljs-string">'casedate'</span>)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                    byvar     avgvar        sumvar     byvarcnt
0             Afghanistan      1,129       231,539          205
1                 Albania      1,914       334,863          175
2                 Algeria      1,439       272,010          189
3          American Samoa        144         8,359           58
4                 Andorra        304        48,015          158
..                    ...        ...           ...          ...
226               Vietnam     60,542    11,624,000          192
227     Wallis and Futuna        154         3,550           23
228                 Yemen         98        11,945          122
229                Zambia      2,019       349,304          173
230              Zimbabwe      1,358       266,266          196
[231 rows x 4 columns]
</code></pre>
    <ol>
      <li class="numberedList" value="6">Call the <code class="inlineCode">adjmeans</code> function again, this time excluding values where <code class="inlineCode">new_cases</code> goes up or down by more than 5,000 from one day to the next. Notice some reduction in the counts for some countries:
        <pre class="programlisting code-one"><code class="hljs-code">ca.adjmeans(coviddaily, <span class="hljs-string">'location'</span>,<span class="hljs-string">'new_cases'</span>,<span class="hljs-string">'casedate'</span>, <span class="hljs-number">5000</span>)
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                    byvar     avgvar     sumvar     byvarcnt
0             Afghanistan      1,129    231,539          205
1                 Albania      1,855    322,772          174
2                 Algeria      1,290    239,896          186
3          American Samoa        144      8,359           58
4                 Andorra        304     48,015          158
..                    ...        ...        ...          ...
226               Vietnam      6,410    967,910          151
227     Wallis and Futuna        154      3,550           23
228                 Yemen         98     11,945          122
229                Zambia      1,555    259,768          167
230              Zimbabwe      1,112    214,526          193
[231 rows x 4 columns]
</code></pre>
      </li>
      <li class="numberedList">Create a<a id="_idIndexMarker943"/> function to check values for merge-by columns on one file but not another.</li>
    </ol>
    <p class="normal-one">The <code class="inlineCode">checkmerge</code> function does an outer join of two DataFrames passed to it, using the third and fourth parameters for the merge-by columns for the first and second DataFrames respectively. It then does a crosstab that shows the number of rows with merge-by values in both DataFrames and those in one DataFrame but not the other. It also shows up to 20 rows of data for merge-by values found in just one file:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">checkmerge</span>(<span class="hljs-params">dfleft, dfright, mergebyleft, mergebyright</span>):
<span class="hljs-meta">... </span>  dfleft[<span class="hljs-string">'inleft'</span>] = <span class="hljs-string">"Y"</span>
<span class="hljs-meta">... </span>  dfright[<span class="hljs-string">'inright'</span>] = <span class="hljs-string">"Y"</span>
<span class="hljs-meta">... </span>  dfboth = pd.merge(dfleft[[mergebyleft,<span class="hljs-string">'inleft'</span>]],\
<span class="hljs-meta">... </span>    dfright[[mergebyright,<span class="hljs-string">'inright'</span>]], left_on=[mergebyleft],\
<span class="hljs-meta">... </span>    right_on=[mergebyright], how=<span class="hljs-string">"outer"</span>)
<span class="hljs-meta">... </span>  dfboth.fillna(<span class="hljs-string">'N'</span>, inplace=<span class="hljs-literal">True</span>)
<span class="hljs-meta">... </span>  <span class="hljs-built_in">print</span>(pd.crosstab(dfboth.inleft, dfboth.inright))
<span class="hljs-meta">... </span>  <span class="hljs-built_in">print</span>(dfboth.loc[(dfboth.inleft==<span class="hljs-string">'N'</span>) | (dfboth.inright==<span class="hljs-string">'N'</span>)].head(<span class="hljs-number">20</span>))
</code></pre>
    <ol>
      <li class="numberedList" value="8">Call the <code class="inlineCode">checkmerge</code> function.</li>
    </ol>
    <p class="normal-one">Check a merge between the <code class="inlineCode">countries</code> land temperatures DataFrame (which has one row per country) and the <code class="inlineCode">locations</code> DataFrame (which has one row for each weather station in each country). The crosstab shows that 27,472 merge-by column values are in both DataFrames, two are in the <code class="inlineCode">countries</code> file and not in the <code class="inlineCode">locations</code> file, and one is in the <code class="inlineCode">locations</code> file but not the <code class="inlineCode">countries</code> file:</p>
    <pre class="programlisting code-one"><code class="hljs-code">ca.checkmerge(countries.copy(), locations.copy(),\
<span class="hljs-meta">... </span>  <span class="hljs-string">"countryid"</span>, <span class="hljs-string">"countryid"</span>)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">inright    N        Y
inleft          
N          0        1
Y          2    27472
        countryid    inleft    inright
7363           FO         N          Y
9716           LQ         Y          N
13104          ST         Y          N
</code></pre>
    <ol>
      <li class="numberedList" value="9">Create a function that concatenates all CSV files in a folder.</li>
    </ol>
    <p class="normal-one">This<a id="_idIndexMarker944"/> function loops through all of the filenames in the specified folder. It uses the <code class="inlineCode">endswith</code> method to check that the filename has a CSV file extension. It then loads the DataFrame and prints out the number of rows. Finally, it uses <code class="inlineCode">concat</code> to append the rows of the new DataFrame to the rows already appended. If column names on a file are different, it prints those column names:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">addfiles</span>(<span class="hljs-params">directory</span>):
<span class="hljs-meta">... </span>  dfout = pd.DataFrame()
<span class="hljs-meta">... </span>  columnsmatched = <span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>  <span class="hljs-comment"># loop through the files</span>
<span class="hljs-meta">... </span>  <span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> os.listdir(directory):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> filename.endswith(<span class="hljs-string">".csv"</span>):
<span class="hljs-meta">... </span>      fileloc = os.path.join(directory, filename)
<span class="hljs-meta">... </span>      <span class="hljs-comment"># open the next file</span>
<span class="hljs-meta">... </span>      <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(fileloc) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>        dfnew = pd.read_csv(fileloc)
<span class="hljs-meta">... </span>        <span class="hljs-built_in">print</span>(filename + <span class="hljs-string">" has "</span> + <span class="hljs-built_in">str</span>(dfnew.shape[<span class="hljs-number">0</span>]) + <span class="hljs-string">" rows."</span>)
<span class="hljs-meta">... </span>        dfout = pd.concat([dfout, dfnew])
<span class="hljs-meta">... </span>        <span class="hljs-comment"># check if current file has any different columns</span>
<span class="hljs-meta">... </span>        columndiff = dfout.columns.symmetric_difference(dfnew.columns)
<span class="hljs-meta">... </span>        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">not</span> columndiff.empty):
<span class="hljs-meta">... </span>          <span class="hljs-built_in">print</span>(<span class="hljs-string">""</span>, <span class="hljs-string">"Different column names for:"</span>, filename,\
<span class="hljs-meta">... </span>            columndiff, <span class="hljs-string">""</span>, sep=<span class="hljs-string">"\n"</span>)
<span class="hljs-meta">... </span>          columnsmatched = <span class="hljs-literal">False</span>
<span class="hljs-meta">... </span>  <span class="hljs-built_in">print</span>(<span class="hljs-string">"Columns Matched:"</span>, columnsmatched)
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> dfout
</code></pre>
    <ol>
      <li class="numberedList" value="10">Use <a id="_idIndexMarker945"/>the <code class="inlineCode">addfiles</code> function to concatenate all of the <code class="inlineCode">countries</code> land temperature files.</li>
    </ol>
    <p class="normal-one">It looks like the file for Oman (<code class="inlineCode">ltoman</code>) is slightly different. It does not have the <code class="inlineCode">latabs</code> column. Notice that the counts for each country in the combined DataFrame match the number of rows for each country file:</p>
    <pre class="programlisting code-one"><code class="hljs-code">landtemps = ca.addfiles(<span class="hljs-string">"data/ltcountry"</span>)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">ltpoland.csv has 120 rows.
ltcameroon.csv has 48 rows.
ltmexico.csv has 852 rows.
ltjapan.csv has 1800 rows.
ltindia.csv has 1116 rows.
ltoman.csv has 288 rows.
Different column names for:
ltoman.csv
Index(['latabs'], dtype='object')
ltbrazil.csv has 1008 rows.
Columns Matched: False
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">landtemps.country.value_counts()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">country
Japan       1800
India       1116
Brazil      1008
Mexico       852
Oman         288
Poland       120
Cameroon      48
Name: count, dtype: int64
</code></pre>
    <p class="normal">The preceding steps demonstrate how we can systematize some of our messy data reshaping work. I am sure you can think of a number of other functions that might be helpful.</p>
    <h2 id="_idParaDest-445" class="heading-2">How it works...</h2>
    <p class="normal">You may <a id="_idIndexMarker946"/>have noticed that in the <code class="inlineCode">adjmeans</code> function we define in <em class="italic">step 2</em>, we actually do not append our summary of the <code class="inlineCode">var</code> column values until we get to the next <code class="inlineCode">byvar</code> column value. This is because there is no way to tell that we are on the last row for any <code class="inlineCode">byvar</code> value until we get to the next <code class="inlineCode">byvar</code> value. That is not a problem because we append the summary to <code class="inlineCode">rowlist</code> right before we reset the value to <code class="inlineCode">0</code>. This also means that we need to do something special to output the totals for the last <code class="inlineCode">byvar</code> value since no next <code class="inlineCode">byvar</code> value is reached. We do this with a final append after the loop is complete.</p>
    <p class="normal">In <em class="italic">step 5</em>, we call the <code class="inlineCode">adjmeans</code> function we defined in <em class="italic">step 2</em>. Since we do not set a value for the <code class="inlineCode">changeexclude</code> parameter, the function will include all values in the aggregation. This will give us the same results as we would get using <code class="inlineCode">groupby</code> with an aggregation function. When we pass an argument to <code class="inlineCode">changeexclude</code>, however, we determine which rows to exclude from the aggregation. In <em class="italic">step 6</em>, the fifth argument in the call to <code class="inlineCode">adjmeans</code> indicates that we should exclude new case values that are more than 5,000 cases higher or lower than the value for the previous day.</p>
    <p class="normal">The function in <em class="italic">step 9</em> works well when the data files to be concatenated have the same, or nearly the same, structure. We print an alert when the column names are different, as <em class="italic">step 10</em> shows. The <code class="inlineCode">latabs</code> column is not in the Oman file. This means that in the concatenated file, <code class="inlineCode">latabs</code> will be missing for all of the rows for Oman.</p>
    <h2 id="_idParaDest-446" class="heading-2">There’s more...</h2>
    <p class="normal">The <code class="inlineCode">adjmeans</code> function does a fairly straightforward check of each new value to be aggregated before including it in the total. But we could imagine much more complicated checks. We could even have made a call to another function within the <code class="inlineCode">adjmeans</code> function where we are deciding whether to include the row.</p>
    <h2 id="_idParaDest-447" class="heading-2">See also</h2>
    <p class="normal">We examine combining DataFrames vertically and horizontally in <em class="chapterRef">Chapter 10</em>, <em class="italic">Addressing Data Issues When Combining DataFrames</em>.</p>
    <h1 id="_idParaDest-448" class="heading-1">Classes that contain the logic for updating Series values</h1>
    <p class="normal">We <a id="_idIndexMarker947"/>sometimes work with a particular dataset for an extended period of time, occasionally years. The data might be updated regularly, for a new month or year, or with additional individuals, but the data structure might be fairly stable. If that dataset also has a large number of columns, we might be able to improve the reliability and readability of our code by implementing classes.</p>
    <p class="normal">When we create classes, we define the attributes and methods of objects. When I use classes for my data-cleaning work, I tend to conceptualize a class as representing my unit of analysis. So, if my unit of analysis is a student, then I have a student class. Each instance of a student created by that class might have birth date and gender attributes and a course registration method. I might also create a subclass for alumni that inherits methods and attributes from the student class.</p>
    <p class="normal">Data cleaning for the NLS DataFrame could be implemented nicely with classes. The dataset has been relatively stable for 25 years, both in terms of the variables and the allowable values for each variable. We explore how to create a respondent class for NLS survey responses in this recipe.</p>
    <h2 id="_idParaDest-449" class="heading-2">Getting ready</h2>
    <p class="normal">You will need to create a <code class="inlineCode">helperfunctions</code> subfolder in your current directory to run the code in this recipe. We will save the file (<code class="inlineCode">respondent.py</code>) for our new class in that subfolder.</p>
    <h2 id="_idParaDest-450" class="heading-2">How to do it...</h2>
    <p class="normal">We will define a respondent class to create several new Series based on the NLS data:</p>
    <ol>
      <li class="numberedList" value="1">Import the <code class="inlineCode">pandas</code>, <code class="inlineCode">os</code>, <code class="inlineCode">sys</code>, and <code class="inlineCode">pprint</code> libraries.</li>
    </ol>
    <p class="normal-one">We store this code in a different file than we will save the respondent class. Let’s call this file <code class="inlineCode">class_cleaning.py</code>. We will instantiate respondent objects from this file:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> pprint
</code></pre>
    <ol>
      <li class="numberedList" value="2">Create<a id="_idIndexMarker948"/> a <code class="inlineCode">Respondent</code> class and save it to <code class="inlineCode">respondent.py</code> in the <code class="inlineCode">helperfunctions</code> subfolder.</li>
    </ol>
    <p class="normal-one">When we call our class (instantiate a class object), the <code class="inlineCode">__init__</code> method runs automatically. (There is a double underscore before and after <code class="inlineCode">init</code>.) The <code class="inlineCode">__init__</code> method has <code class="inlineCode">self</code> as the first parameter, as any instance method does. The <code class="inlineCode">__init__</code> method of this class also has a <code class="inlineCode">respdict</code> parameter, which expects a dictionary of values from the NLS data. In later steps, we will instantiate a respondent object once for each row of data in the NLS DataFrame.</p>
    <p class="normal-one">The <code class="inlineCode">__init__</code> method assigns the passed <code class="inlineCode">respdict</code> value to <code class="inlineCode">self.respdict</code> to create an instance variable that we can reference in other methods. Finally, we increment a counter, <code class="inlineCode">respondentcnt</code>. We will be able to use this later to confirm the number of instances of <code class="inlineCode">respondent</code> that we created. We also import the <code class="inlineCode">math</code> and <code class="inlineCode">datetime</code> modules because we will need them later. (Notice that class names are capitalized by convention.)</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> math
<span class="hljs-keyword">import</span> datetime <span class="hljs-keyword">as</span> dt
<span class="hljs-keyword">class</span> <span class="hljs-title">Respondent</span>:
<span class="hljs-meta">... </span>  respondentcnt = <span class="hljs-number">0</span>
<span class="hljs-meta">... </span>  <span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, respdict</span>):
<span class="hljs-meta">... </span>    self.respdict = respdict
<span class="hljs-meta">... </span>    Respondent.respondentcnt+=<span class="hljs-number">1</span>
</code></pre>
    <ol>
      <li class="numberedList" value="3">Add a method for counting the number of children.</li>
    </ol>
    <p class="normal-one">This is a very simple method that just adds the number of children living with the respondent to the number of children not living with the respondent, to get the total number of children. It uses the <code class="inlineCode">childathome</code> and <code class="inlineCode">childnotathome</code> key values in the <code class="inlineCode">self.respdict</code> dictionary:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">childnum</span>(<span class="hljs-params">self</span>):
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> self.respdict[<span class="hljs-string">'childathome'</span>] + self.respdict[<span class="hljs-string">'childnotathome'</span>]
</code></pre>
    <ol>
      <li class="numberedList" value="4">Add a method for calculating average weeks worked across the 25 years of the survey.</li>
    </ol>
    <p class="normal-one">Use dictionary comprehension to create a dictionary (<code class="inlineCode">workdict</code>) of the weeks-worked keys that do not have missing values. Sum the values in <code class="inlineCode">workdict</code> and divide that by the length of <code class="inlineCode">workdict</code>:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">avgweeksworked</span>(<span class="hljs-params">self</span>):
<span class="hljs-meta">... </span>  workdict = {k: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> self.respdict.items() \
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> k.startswith(<span class="hljs-string">'weeksworked'</span>) <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> math.isnan(v)}
<span class="hljs-meta">... </span>  nweeks = <span class="hljs-built_in">len</span>(workdict)
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> (nweeks&gt;<span class="hljs-number">0</span>):
<span class="hljs-meta">... </span>    avgww = <span class="hljs-built_in">sum</span>(workdict.values())/nweeks
<span class="hljs-meta">... </span>  <span class="hljs-keyword">else</span>:
<span class="hljs-meta">... </span>    avgww = <span class="hljs-number">0</span>
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> avgww
</code></pre>
    <ol>
      <li class="numberedList" value="5">Add <a id="_idIndexMarker949"/>a method for calculating age as of a given date.</li>
    </ol>
    <p class="normal-one">This method takes a date string (<code class="inlineCode">bydatestring</code>) to use for the end date of the age calculation. We use the <code class="inlineCode">datetime</code> module to convert the <code class="inlineCode">date</code> string to a <code class="inlineCode">datetime</code> object, <code class="inlineCode">bydate</code>. We subtract the birth year value in <code class="inlineCode">self.respdict</code> from the year of <code class="inlineCode">bydate</code>, subtracting 1 from that calculation if the birth date has not happened yet that year. (We only have birth month and birth year in the NLS data, so we choose 15 as a midpoint.)</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">ageby</span>(<span class="hljs-params">self, bydatestring</span>):
<span class="hljs-meta">... </span>  bydate = dt.datetime.strptime(bydatestring, <span class="hljs-string">'%Y%m%d'</span>)
<span class="hljs-meta">... </span>  birthyear = self.respdict[<span class="hljs-string">'birthyear'</span>]
<span class="hljs-meta">... </span>  birthmonth = self.respdict[<span class="hljs-string">'birthmonth'</span>]
<span class="hljs-meta">... </span>  age = bydate.year - birthyear
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> (bydate.month&lt;birthmonth <span class="hljs-keyword">or</span> (bydate.month==birthmonth \
<span class="hljs-meta">... </span>      <span class="hljs-keyword">and</span> bydate.day&lt;<span class="hljs-number">15</span>)):
<span class="hljs-meta">... </span>    age = age -<span class="hljs-number">1</span>
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> age
</code></pre>
    <ol>
      <li class="numberedList" value="6">Add a method to create a flag if the respondent ever enrolled at a 4-year college.</li>
    </ol>
    <p class="normal-one">Use dictionary comprehension to check whether any college enrollment values are at a 4-year college:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">baenrollment</span>(<span class="hljs-params">self</span>):
<span class="hljs-meta">... </span>  colenrdict = {k: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> self.respdict.items() \
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> k.startswith(<span class="hljs-string">'colenr'</span>) <span class="hljs-keyword">and</span> v==<span class="hljs-string">"3. 4-year college"</span>}
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">len</span>(colenrdict)&gt;<span class="hljs-number">0</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> <span class="hljs-string">"Y"</span>
<span class="hljs-meta">... </span>  <span class="hljs-keyword">else</span>:
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> <span class="hljs-string">"N"</span>
</code></pre>
    <ol>
      <li class="numberedList" value="7"> Import the respondent class.</li>
    </ol>
    <p class="normal-one">Now we are ready to instantiate some <code class="inlineCode">Respondent</code> objects! Let’s do that from the <code class="inlineCode">class_cleaning.py</code> file we started in <em class="italic">step 1</em>. We start by importing the respondent class. (This step assumes that <code class="inlineCode">respondent.py</code> is in the <code class="inlineCode">helperfunctions</code> subfolder.)</p>
    <pre class="programlisting code-one"><code class="hljs-code">sys.path.append(os.getcwd() + <span class="hljs-string">"/helperfunctions"</span>)
<span class="hljs-keyword">import</span> respondent <span class="hljs-keyword">as</span> rp
</code></pre>
    <ol>
      <li class="numberedList" value="8">Load <a id="_idIndexMarker950"/>the NLS data and create a list of dictionaries.</li>
    </ol>
    <p class="normal-one">Use the <code class="inlineCode">to_dict</code> method to create the list of dictionaries (<code class="inlineCode">nls97list</code>). Each row from the DataFrame will be a dictionary with column names as keys. Show part of the first dictionary (the first row):</p>
    <pre class="programlisting code-one"><code class="hljs-code">nls97 = pd.read_csv(<span class="hljs-string">"data/nls97g.csv"</span>, low_memory=<span class="hljs-literal">False</span>)
nls97list = nls97.to_dict(<span class="hljs-string">'records'</span>)
nls97.shape
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">(8984, 111)
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-built_in">len</span>(nls97list)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">8984
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">pprint.pprint(nls97list[<span class="hljs-number">0</span>:<span class="hljs-number">1</span>])
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">[{'birthmonth': 9,
  'birthyear': 1981,
  'childathome': nan,
  'childnotathome': nan,
  'colenrfeb00': '3. 4-year college',
  'colenrfeb01': '3. 4-year college',
  ...
  'weeksworked21': nan,
  'weeksworked22': nan}]
</code></pre>
    <ol>
      <li class="numberedList" value="9">Loop<a id="_idIndexMarker951"/> through the list, creating a <code class="inlineCode">respondent</code> instance each time.</li>
    </ol>
    <p class="normal-one">We pass each dictionary to the respondent class, <code class="inlineCode">rp.Respondent(respdict)</code>. Once we have created a respondent object (<code class="inlineCode">resp</code>), we can then use all of the instance methods to get the values we need. We create a new dictionary with those values returned by instance methods. We then append that dictionary to <code class="inlineCode">analysisdict</code>:</p>
    <pre class="programlisting code-one"><code class="hljs-code">analysislist = []
<span class="hljs-keyword">for</span> respdict <span class="hljs-keyword">in</span> nls97list:
<span class="hljs-meta">... </span>  resp = rp.Respondent(respdict)
<span class="hljs-meta">... </span>  newdict = <span class="hljs-built_in">dict</span>(originalid=respdict[<span class="hljs-string">'originalid'</span>],
<span class="hljs-meta">... </span>    childnum=resp.childnum(),
<span class="hljs-meta">... </span>    avgweeksworked=resp.avgweeksworked(),
<span class="hljs-meta">... </span>    age=resp.ageby(<span class="hljs-string">'20201015'</span>),
<span class="hljs-meta">... </span>    baenrollment=resp.baenrollment())
<span class="hljs-meta">... </span>  analysislist.append(newdict)
</code></pre>
    <ol>
      <li class="numberedList" value="10">Pass the dictionary to the pandas <code class="inlineCode">DataFrame</code> method.</li>
    </ol>
    <p class="normal-one">First, check the number of items in <code class="inlineCode">analysislist</code> and the number of instances created:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-built_in">len</span>(analysislist)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">8984
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">resp.respondentcnt
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">8984
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">pprint.pprint(analysislist[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>])
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">[{'age': 39,
  'avgweeksworked': 48.4375,
  'baenrollment': 'Y',
  'childnum': nan,
  'originalid': 1},
 {'age': 38,
  'avgweeksworked': 49.90909090909091,
  'baenrollment': 'Y',
  'childnum': nan,
  'originalid': 2}]
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">analysis = pd.DataFrame(analysislist)
analysis.head(<span class="hljs-number">2</span>)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">    originalid    childnum   avgweeksworked    age    baenrollment
0            1         NaN               48     39               Y
1            2         NaN               50     38               Y
</code></pre>
    <p class="normal">These steps<a id="_idIndexMarker952"/> demonstrated how to create a class in Python, how to pass data to a class, how to create an instance of a class, and how to call the methods of the class to update variable values.</p>
    <h2 id="_idParaDest-451" class="heading-2">How it works...</h2>
    <p class="normal">The key work in this recipe is done in <em class="italic">step 2</em>. It creates the respondent class and sets us up well for the remaining steps. We pass a dictionary with the values for each row to the class’s <code class="inlineCode">__init__</code> method. The <code class="inlineCode">__init__</code> method assigns that dictionary to an instance variable that will be available to all of the class’s methods (<code class="inlineCode">self.respdict = respdict</code>).</p>
    <p class="normal"><em class="italic">Steps 3 </em>through<em class="italic"> 6</em> use that dictionary to calculate the number of children, average weeks worked per year, age, and college enrollment. <em class="italic">Steps 4</em> and <em class="italic">6</em> show how helpful dictionary comprehensions are when we need to test for the same value over many keys. The dictionary comprehensions select the relevant keys, <code class="inlineCode">weeksworked##</code>, <code class="inlineCode">colenroct##</code>, and <code class="inlineCode">colenrfeb##</code>, and allow us to inspect the values of those keys. This is incredibly useful when we have data that is untidy in this way, as survey data often is.</p>
    <p class="normal">In <em class="italic">step 8</em>, we create a list of dictionaries with the <code class="inlineCode">to_dict</code> method. It has the expected number of list items, 8,984, the same as the number of rows in the DataFrame. We use <code class="inlineCode">pprint</code> to show what the dictionary looks like for the first list item. The dictionary has keys for the column names and values for the column values.</p>
    <p class="normal">We iterate over the list in <em class="italic">step 9</em>, creating a new respondent object and passing the list item. We call the methods to get the values we want, except for <code class="inlineCode">originalid</code>, which we can pull directly from the dictionary. We create a dictionary (<code class="inlineCode">newdict</code>) with those values, which we append to a list (<code class="inlineCode">analysislist</code>).</p>
    <p class="normal">In <em class="italic">step 10</em>, we<a id="_idIndexMarker953"/> create a pandas DataFrame from the list (<code class="inlineCode">analysislist</code>) we created in <em class="italic">step 9</em>. We do this by passing the list to the pandas DataFrame method.</p>
    <h2 id="_idParaDest-452" class="heading-2">There’s more...</h2>
    <p class="normal">We pass dictionaries to the class rather than data rows, which is also a possibility. We do this because navigating a NumPy array is more efficient than looping over a DataFrame with <code class="inlineCode">itertuples</code> or <code class="inlineCode">iterrows</code>. We do not lose much of the functionality needed for our class when we work with dictionaries rather than DataFrame rows. We are still able to use functions such as <code class="inlineCode">sum</code> and <code class="inlineCode">mean</code> and count the number of values meeting certain criteria.</p>
    <p class="normal">It is hard to avoid having to iterate over data with this conceptualization of a respondent class. This respondent class is consistent with our understanding of the unit of analysis, the survey respondent. That is also, unsurprisingly, how the data comes to us. But iterating over data one row at a time is resource-intensive, even with more efficient NumPy arrays.</p>
    <p class="normal">I would argue, however, that you gain more than you lose by constructing a class like this one when working with data with many columns and with a structure that does not change much over time. The most important advantage is that it matches our intuition about the data and focuses our work on understanding the data for each respondent. I also think we find that when we construct the class well, we do far fewer passes through the data than we otherwise might.</p>
    <h2 id="_idParaDest-453" class="heading-2">See also</h2>
    <p class="normal">We examine navigating over DataFrame rows and NumPy arrays in <em class="chapterRef">Chapter 9</em>, <em class="italic">Fixing Messy Data When Aggregating</em>.</p>
    <p class="normal">This was a very quick introduction to working with classes in Python. If you would like to learn more about object-oriented programming in Python, I would recommend <em class="italic">Python 3 Object-Oriented Programming</em>, <em class="italic">Third Edition</em> by Dusty Phillips.</p>
    <h1 id="_idParaDest-454" class="heading-1">Classes that handle non-tabular data structures</h1>
    <p class="normal">Data scientists<a id="_idIndexMarker954"/> increasingly receive non-tabular data, often in the form of JSON or XML files. The flexibility of JSON and XML allows organizations to capture complicated relationships between data items in one file. A one-to-many relationship stored in two tables in an enterprise data system can be represented well in JSON by a parent node for the one side and child nodes for data on the many side.</p>
    <p class="normal">When we receive JSON data we often start by trying to normalize it. Indeed, we do that in a couple of recipes in this book. We try to recover the one-to-one and one-to-many relationships in the data obfuscated by the flexibility of JSON. But there is another way to work with such data, one that has many advantages.</p>
    <p class="normal">Instead of normalizing the data, we can create a class that instantiates objects at the appropriate unit of analysis, and use the methods of the class to navigate the many side of one-to-many relationships. For example, if we get a JSON file that has student nodes and then multiple child nodes for each course taken by a student, we would usually normalize that data by creating a student file and a course file, with student ID as the merge-by column on both files. An alternative, which we explore in this recipe, would be to leave the data as it is, create a student class, and create methods that do calculations on the child nodes, such as calculating total credits taken.</p>
    <p class="normal">Let’s try that with this recipe using data from the Cleveland Museum of Art that has collection items, one or more nodes for media citations for each item, and one or more nodes for each creator of the item.</p>
    <h2 id="_idParaDest-455" class="heading-2">Getting ready</h2>
    <p class="normal">This recipe assumes you have the <code class="inlineCode">requests</code> and <code class="inlineCode">pprint</code> libraries. If they are not installed, you can install them with <code class="inlineCode">pip</code>. From Terminal, or PowerShell (in Windows), enter <code class="inlineCode">pip install requests</code> and <code class="inlineCode">pip install pprint</code>.</p>
    <p class="normal">I show here the structure of the JSON file that is created when using the <code class="inlineCode">collections</code> API of the Cleveland <a id="_idIndexMarker955"/>Museum of Art (I have abbreviated the JSON file to save space).</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-punctuation">{</span>
<span class="hljs-attr">"id"</span><span class="hljs-punctuation">:</span> <span class="hljs-number">165157</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"title"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Fulton and Nostrand"</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"creation_date"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"1958"</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"citations"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
  <span class="hljs-punctuation">{</span>
   <span class="hljs-attr">"citation"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Annual Exhibition: Sculpture, Paintings, Watercolors, Drawings, </span>
<span class="hljs-string">   "</span>page_number<span class="hljs-string">": "</span>Unpaginated<span class="hljs-punctuation">,</span> <span class="hljs-punctuation">[</span><span class="hljs-number">8</span><span class="hljs-punctuation">],[</span><span class="hljs-number">12</span><span class="hljs-punctuation">]</span><span class="hljs-string">",</span>
<span class="hljs-string">   "</span>url<span class="hljs-string">": null</span>
<span class="hljs-string">   },</span>
<span class="hljs-string">  {</span>
<span class="hljs-string">   "</span>citation<span class="hljs-string">": "</span>\<span class="hljs-string">"Moscow to See Modern U.S. Art,\"&lt;em&gt; New York Times&lt;/em&gt; (May 31, 1959)."</span><span class="hljs-punctuation">,</span>  
   <span class="hljs-attr">"page_number"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"P. 60"</span><span class="hljs-punctuation">,</span>
   <span class="hljs-attr">"url"</span><span class="hljs-punctuation">:</span> <span class="hljs-keyword">null</span>
  <span class="hljs-punctuation">}]</span>
<span class="hljs-attr">"creators"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
      <span class="hljs-punctuation">{</span>
     <span class="hljs-attr">"description"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"Jacob Lawrence (American, 1917-2000)"</span><span class="hljs-punctuation">,</span>
     <span class="hljs-attr">"role"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"artist"</span><span class="hljs-punctuation">,</span>
     <span class="hljs-attr">"birth_year"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"1917"</span><span class="hljs-punctuation">,</span>
     <span class="hljs-attr">"death_year"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"2000"</span>
     <span class="hljs-punctuation">}</span>
  <span class="hljs-punctuation">]</span>
 <span class="hljs-punctuation">}</span>
</code></pre>
    <div class="note">
      <p class="normal"><strong class="keyWord">Data note</strong></p>
      <p class="normal">The Cleveland Museum of Art provides an API for public access to this data: <a href="https://openaccess-api.clevelandart.org/"><span class="url">https://openaccess-api.clevelandart.org/</span></a>. Much more than the citations and creators data used in this recipe is available with the API.</p>
    </div>
    <h2 id="_idParaDest-456" class="heading-2">How to do it...</h2>
    <p class="normal">We create <a id="_idIndexMarker956"/>a collection item class that summarizes the data we need on creators and media citations:</p>
    <ol>
      <li class="numberedList" value="1">Import the <code class="inlineCode">pandas</code>, <code class="inlineCode">json</code>, <code class="inlineCode">pprint</code>, and <code class="inlineCode">requests</code> libraries.</li>
    </ol>
    <p class="normal-one">Let’s first create a file that we will use to instantiate collection item objects and call it <code class="inlineCode">class_cleaning_json.py</code>:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> json
<span class="hljs-keyword">import</span> pprint
<span class="hljs-keyword">import</span> requests
</code></pre>
    <ol>
      <li class="numberedList" value="2">Create a <code class="inlineCode">Collectionitem</code> class.</li>
    </ol>
    <p class="normal-one">We pass a dictionary for each collection item to the <code class="inlineCode">__init__</code> method of the class, which runs automatically when an instance of the class is created. We assign the collection item dictionary to an instance variable. Save the class as <code class="inlineCode">collectionitem.py</code> in the <code class="inlineCode">helperfunctions</code> folder:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">class</span> <span class="hljs-title">Collectionitem</span>:
<span class="hljs-meta">... </span>  collectionitemcnt = <span class="hljs-number">0</span>
<span class="hljs-meta">... </span>  <span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, colldict</span>):
<span class="hljs-meta">... </span>    self.colldict = colldict
<span class="hljs-meta">... </span>    Collectionitem.collectionitemcnt+=<span class="hljs-number">1</span>
</code></pre>
    <ol>
      <li class="numberedList" value="3">Create a method to get the birth year of the first creator for each collection item.</li>
    </ol>
    <p class="normal-one">Remember <a id="_idIndexMarker957"/>that collection items can have multiple creators. This means that the <code class="inlineCode">creators</code> key has one or more list items as values, and these items are themselves dictionaries. To get the birth year of the first creator, then, we need <code class="inlineCode">['creators'][0]['birth_year']</code>. We also need to allow for the birth year key to be missing, so we test for that first:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">birthyearcreator1</span>(<span class="hljs-params">self</span>):
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> (<span class="hljs-string">"birth_year"</span> <span class="hljs-keyword">in</span> self.colldict[<span class="hljs-string">'creators'</span>][<span class="hljs-number">0</span>]):
<span class="hljs-meta">... </span>    byear = self.colldict[<span class="hljs-string">'creators'</span>][<span class="hljs-number">0</span>][<span class="hljs-string">'birth_year'</span>]
<span class="hljs-meta">... </span>  <span class="hljs-keyword">else</span>:
<span class="hljs-meta">... </span>    byear = <span class="hljs-string">"Unknown"</span>
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> byear
</code></pre>
    <ol>
      <li class="numberedList" value="4">Create a method to get the birth years for all creators.</li>
    </ol>
    <p class="normal-one">Use list comprehension to loop through all the <code class="inlineCode">creators</code> items. This will return the birth years as a list:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">birthyearsall</span>(<span class="hljs-params">self</span>):
<span class="hljs-meta">... </span>  byearlist = [item.get(<span class="hljs-string">'</span><span class="hljs-string">birth_year'</span>) <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> \
<span class="hljs-meta">... </span>    self.colldict[<span class="hljs-string">'creators'</span>]]
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> byearlist
</code></pre>
    <ol>
      <li class="numberedList" value="5">Create a method to count the number of creators:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">ncreators</span>(<span class="hljs-params">self</span>):
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.colldict[<span class="hljs-string">'creators'</span>])
</code></pre>
      </li>
      <li class="numberedList">Create a method to count the number of media citations:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">ncitations</span>(<span class="hljs-params">self</span>):
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.colldict[<span class="hljs-string">'citations'</span>])
</code></pre>
      </li>
      <li class="numberedList">Import the <code class="inlineCode">collectionitem</code> module.</li>
    </ol>
    <p class="normal-one">We do<a id="_idIndexMarker958"/> this from the <code class="inlineCode">class_cleaning_json.py</code> file we created in <em class="italic">step 1</em>:</p>
    <pre class="programlisting code-one"><code class="hljs-code">sys.path.append(os.getcwd() + <span class="hljs-string">"/helperfunctions"</span>)
<span class="hljs-keyword">import</span> collectionitem <span class="hljs-keyword">as</span> ci
</code></pre>
    <ol>
      <li class="numberedList" value="8">Load the art museum’s collections data.</li>
    </ol>
    <p class="normal-one">This returns a list of dictionaries. We just pull a subset of the museum collections data with African American artists:</p>
    <pre class="programlisting code-one"><code class="hljs-code">response = requests.get(<span class="hljs-string">"https://openaccess-api.clevelandart.org/api/artworks/?african_american_artists"</span>)
camcollections = json.loads(response.text)
camcollections = camcollections[<span class="hljs-string">'data'</span>]
</code></pre>
    <ol>
      <li class="numberedList" value="9">Loop through the <code class="inlineCode">camcollections</code> list.</li>
    </ol>
    <p class="normal-one">Create a collection item instance for each item in <code class="inlineCode">camcollections</code>. Pass each item, which is a dictionary of collections, creators, and citation keys, to the class. Call the methods we have just created and assign the values they return to a new dictionary (<code class="inlineCode">newdict</code>). Append that dictionary to a list (<code class="inlineCode">analysislist</code>). (Some of the values can be pulled directly from the dictionary, such as with <code class="inlineCode">title=colldict['title']</code>, since we do not need to change the value in any way.)</p>
    <pre class="programlisting code-one"><code class="hljs-code">analysislist = []
<span class="hljs-keyword">for</span> colldict <span class="hljs-keyword">in</span> camcollections:
<span class="hljs-meta">... </span>  coll = ci.Collectionitem(colldict)
<span class="hljs-meta">... </span>  newdict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">id</span>=colldict[<span class="hljs-string">'id'</span>],
<span class="hljs-meta">... </span>    title=colldict[<span class="hljs-string">'title'</span>],
<span class="hljs-meta">... </span>    <span class="hljs-built_in">type</span>=colldict[<span class="hljs-string">'type'</span>],
<span class="hljs-meta">... </span>    creationdate=colldict[<span class="hljs-string">'creation_date'</span>],
<span class="hljs-meta">... </span>    ncreators=coll.ncreators(),
<span class="hljs-meta">... </span>    ncitations=coll.ncitations(),
<span class="hljs-meta">... </span>    birthyearsall=coll.birthyearsall(),
<span class="hljs-meta">... </span>    birthyear=coll.birthyearcreator1())
<span class="hljs-meta">... </span>  analysislist.append(newdict)
</code></pre>
    <ol>
      <li class="numberedList" value="10">Create an analysis DataFrame with the new list of dictionaries.</li>
    </ol>
    <p class="normal-one">Confirm<a id="_idIndexMarker959"/> that we are getting the correct counts, and print the dictionary for the first item:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-built_in">len</span>(camcollections)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">1000
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-built_in">len</span>(analysislist)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">1000
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">pprint.pprint(analysislist[<span class="hljs-number">0</span>:<span class="hljs-number">1</span>])
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">[{'birthyear': '1917',
  'birthyearsall': ['1917'],
  'creationdate': '1958',
  'id': 165157,
  'ncitations': 30,
  'ncreators': 1,
  'title': 'Fulton and Nostrand',
  'type': 'Painting'}]
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">analysis = pd.DataFrame(analysislist)
analysis.birthyearsall.value_counts().head()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">birthyearsall
[1951]          283
[1953]          119
[1961, None]    105
[1937]           55
[1922]           41
Name: count, dtype: int64
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">analysis.head(<span class="hljs-number">2</span>).T
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                                 0              1
id                          165157         163769
title          Fulton and Nostrand  Go Down Death
type                      Painting       Painting
creationdate                  1958           1934
ncreators                        1              1
ncitations                      30             18
birthyearsall               [1917]         [1899]
birthyear                     1917           1899
</code></pre>
    <p class="normal">These steps give a sense of how we can use classes to handle non-tabular data.</p>
    <h2 id="_idParaDest-457" class="heading-2">How it works...</h2>
    <p class="normal">This recipe <a id="_idIndexMarker960"/>demonstrated how to work directly with a JSON file, or any file with implied one-to-many or many-to-many relationships. We created a class at the unit of analysis (a collection item, in this case) and then created methods to summarize multiple nodes of data for each collection item.</p>
    <p class="normal">The methods we created in <em class="italic">steps 3</em> to <em class="italic">6</em> are satisfyingly straightforward. When we first look at the structure of the data, displayed in the <em class="italic">Getting ready</em> section of this recipe, it is hard not to feel that it will be really difficult to clean. It looks like anything goes. But it turns out to have a fairly reliable structure. We can count on one or more child nodes for <code class="inlineCode">creators</code> and <code class="inlineCode">citations</code>. Each <code class="inlineCode">creators</code> and <code class="inlineCode">citations</code> node also has child nodes, which are key and value pairs. These keys are not always present, so we need to first check to see whether <a id="_idIndexMarker961"/>they are present before trying to grab their values. We did this in <em class="italic">step 3</em>.</p>
    <h2 id="_idParaDest-458" class="heading-2">There’s more...</h2>
    <p class="normal">I go into some detail about the advantages of working directly with JSON files in <em class="chapterRef">Chapter 2</em>, <em class="italic">Anticipating Data Cleaning Issues When Working with HTML, JSON, and Spark Data</em>. I think the museum’s collections data is a good example of why we might want to stick with the JSON if we can. The structure of the data actually makes sense, even if it is in a very different form. There is always a danger when we try to normalize it that we will miss some aspects of its structure.</p>
    <h1 id="_idParaDest-459" class="heading-1">Functions for checking overall data quality</h1>
    <p class="normal">We <a id="_idIndexMarker962"/>can tighten up our data quality checks by being more explicit and upfront about what we are evaluating. We likely have some expectations about the distribution of variable values, about the range of allowable values, and about the number of missing values very early in a data analysis project. This may come from documentation, our knowledge of the underlying real-world processes represented by the data, or our understanding of statistics. It is a good idea to have a routine for delineating those initial assumptions, testing them, and then revising assumptions throughout a project. This recipe will demonstrate what that process might look like.</p>
    <p class="normal">We set up data quality targets for each variable of interest. This includes allowable values and thresholds for missing values for categorical variables. It also includes ranges of values; missing value, skewness, and kurtosis thresholds; and checking for outliers for numeric values. We will check unique identifier variables for duplication and for missing values. We start with the assumptions in this CSV file about variables on the NLS file:</p>
    <figure class="mediaobject"><img src="../Images/B18596_12_03.png" alt="dct"/></figure>
    <p class="packt_figref">Figure 12.3: Data checks for selected NLS columns</p>
    <p class="normal"><em class="italic">Figure 12.3</em> shows <a id="_idIndexMarker963"/>our initial assumptions. For example, for <code class="inlineCode">maritalstatus</code>, we assume the category values <em class="italic">Divorced|Married|Never-married|Separated|Widowed</em>, and that no more than 20% of values will be missing. For <code class="inlineCode">nightlyhrssleep</code>, a numeric variable, we assume that values will be between 3 and 9, that no more than 30% of values will be missing, and that it will have a skew and kurtosis close to that of a normal distribution. </p>
    <p class="normal">We also indicate that we want to check for outliers. The final column is a flag we can use if we only want to do data checks for a few variables. Here we indicate that we want to do checks for <code class="inlineCode">maritalstatus</code>, <code class="inlineCode">originalid</code>, <code class="inlineCode">highestgradecompleted</code>, <code class="inlineCode">gpaenglish</code>, and <code class="inlineCode">nightlyhrssleep</code>.</p>
    <h2 id="_idParaDest-460" class="heading-2">Getting ready</h2>
    <p class="normal">We will work again with the NLS data in this recipe.</p>
    <h2 id="_idParaDest-461" class="heading-2">How to do it...</h2>
    <p class="normal">We use our predefined data-checking targets to analyze selected variables in the NLS data.</p>
    <ol>
      <li class="numberedList" value="1">Create the functions we will need for data checking and save them in the <code class="inlineCode">helperfunctions</code> subfolder with the name <code class="inlineCode">runchecks.py</code>. The following two functions, <code class="inlineCode">checkcats</code> and <code class="inlineCode">checkoutliers</code>, will be used to test values in a list and outliers respectively. We will see how that works in subsequent steps:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">checkcats</span>(<span class="hljs-params">cat1,cat2</span>):
  missingcats = \
   <span class="hljs-built_in">set</span>(cat1).symmetric_difference(<span class="hljs-built_in">set</span>(cat2))
  <span class="hljs-keyword">return</span> missingcats
<span class="hljs-keyword">def</span> <span class="hljs-title">checkoutliers</span>(<span class="hljs-params">values</span>):
  thirdq, firstq = values.\
    quantile(<span class="hljs-number">0.75</span>),values.\
    quantile(<span class="hljs-number">0.25</span>)
  interquartilerange = <span class="hljs-number">1.5</span>*(thirdq-firstq)
  outlierhigh, outlierlow = \
    interquartilerange+thirdq, \
    firstq-interquartilerange
  <span class="hljs-keyword">return</span> outlierhigh, outlierlow
</code></pre>
      </li>
      <li class="numberedList">We then<a id="_idIndexMarker964"/> define a function to run all of our checks, <code class="inlineCode">runchecks</code>, which will take a DataFrame (<code class="inlineCode">df</code>), our data targets (<code class="inlineCode">dc</code>), a list of numerical columns (<code class="inlineCode">numvars</code>), a list of categorical columns (<code class="inlineCode">catvars</code>), and a list of identifier columns (<code class="inlineCode">idvars</code>):
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">runchecks</span>(<span class="hljs-params">df,dc,numvars,catvars,idvars</span>):
</code></pre>
      </li>
      <li class="numberedList">Within the <code class="inlineCode">runchecks</code> function, we loop over the categorical variable columns in our data checks. We get the values of all targets for the variable with <code class="inlineCode">dcvals = dc.loc[col]</code>. We create a NumPy array, <code class="inlineCode">compcat</code>, from the category values. We then compare that array to all of the values for that column in the passed DataFrame (<code class="inlineCode">df[col].dropna().str.strip().unique()</code>). If there is a category in one array but not the other (<code class="inlineCode">valuediff</code>) we print that to the console. We also calculate the missing-value percentage. If it is beyond the threshold we specified, we print a message:
        <pre class="programlisting code-one"><code class="hljs-code">  <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> df[catvars]:
    dcvals = dc.loc[col]
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"</span><span class="hljs-string">\n\nChecks for categorical variable"</span>, col)
    compcat = <span class="hljs-built_in">list</span>(dcvals.categories.split(<span class="hljs-string">'|'</span>))
    valuediff = checkcats(compcat,df[col].dropna().\
      <span class="hljs-built_in">str</span>.strip().unique())
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(valuediff) &gt; <span class="hljs-number">0</span>:
      <span class="hljs-built_in">print</span>(<span class="hljs-string">"at least one non-matching category:"</span>,
        valuediff)
   
    missingper = df[col].isnull().<span class="hljs-built_in">sum</span>()/df.shape[<span class="hljs-number">0</span>]
    <span class="hljs-keyword">if</span> missingper &gt; dcvals.missingthreshold:
      <span class="hljs-built_in">print</span>(<span class="hljs-string">"missing percent beyond threshold of"</span>,
      dcvals.missingthreshold, <span class="hljs-string">"is"</span>, missingper)
</code></pre>
      </li>
      <li class="numberedList">Let’s <a id="_idIndexMarker965"/>now look at the loop for checking the numeric variables. We create a NumPy array from the range value in our data-checking targets, <code class="inlineCode">range = np.fromstring(dcvals.range, sep='|')</code>. The first element of <code class="inlineCode">range</code> is the lower end of the range. The second element is the upper end. We then get the min and max values for the variable from the DataFrame and compare those with the range indicated in the target file.</li>
    </ol>
    <p class="normal-one">We calculate the missing-values percentage and print if it exceeds the threshold we set in the data-checking target file.</p>
    <p class="normal-one">We show outliers if the <code class="inlineCode">showoutliers</code> flag is set to <code class="inlineCode">Y</code>. We use the <code class="inlineCode">checkoutliers</code> function we set up earlier, which uses a simple interquartile range calculation to determine outliers. Finally, we check the skew and kurtosis to get an indication of how far from normally distributed the variable might be:</p>
    <pre class="programlisting code-one"><code class="hljs-code">  <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> df[numvars]:
    dcvals = dc.loc[col]
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"\n\nChecks for numeric variable"</span>, col)
 
    <span class="hljs-built_in">range</span> = np.fromstring(dcvals.<span class="hljs-built_in">range</span>, sep=<span class="hljs-string">'|'</span>)
    <span class="hljs-built_in">min</span> = df[col].<span class="hljs-built_in">min</span>()
    <span class="hljs-built_in">max</span> = df[col].<span class="hljs-built_in">max</span>()
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">min</span> &lt; <span class="hljs-built_in">range</span>[<span class="hljs-number">0</span>]:
      <span class="hljs-built_in">print</span>(<span class="hljs-string">"at least one record below range starting at "</span>,
       <span class="hljs-built_in">range</span>[<span class="hljs-number">0</span>], <span class="hljs-string">"min value is"</span>, <span class="hljs-built_in">min</span>)
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">max</span> &gt; <span class="hljs-built_in">range</span>[<span class="hljs-number">1</span>]:
      <span class="hljs-built_in">print</span>(<span class="hljs-string">"at least one record above range ending at "</span>,
       <span class="hljs-built_in">range</span>[<span class="hljs-number">1</span>], <span class="hljs-string">"max value is"</span>, <span class="hljs-built_in">max</span>)
    missingper = df[col].isnull().<span class="hljs-built_in">sum</span>()/df.shape[<span class="hljs-number">0</span>]
    <span class="hljs-keyword">if</span> missingper &gt; dcvals.missingthreshold:
      <span class="hljs-built_in">print</span>(<span class="hljs-string">"missing percent beyond threshold of"</span>,
       dcvals.missingthreshold, <span class="hljs-string">"is"</span>, missingper)
 
    <span class="hljs-keyword">if</span> dcvals.showoutliers == <span class="hljs-string">"Y"</span>:
      outlierhigh, outlierlow = checkoutliers(df[col])
      <span class="hljs-built_in">print</span>(<span class="hljs-string">"\nvalues less than"</span>, outlierlow, <span class="hljs-string">"\n"</span>,
        df.loc[df[col]&lt;outlierlow,col].\
        agg([<span class="hljs-string">"min"</span>,<span class="hljs-string">'max'</span>,<span class="hljs-string">'count'</span>]), end=<span class="hljs-string">"\n"</span>)
      <span class="hljs-built_in">print</span>(<span class="hljs-string">"\nvalues greater than"</span>, outlierhigh,
        <span class="hljs-string">"\n"</span>, df.loc[df[col]&gt;outlierhigh,col].\
        agg([<span class="hljs-string">"min"</span>,<span class="hljs-string">'max'</span>,<span class="hljs-string">'count'</span>]), end=<span class="hljs-string">"\n"</span>)
    skewcol = df[col].skew()
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(skewcol-dcvals.skewtarget)&gt;<span class="hljs-number">1.2</span>:
      <span class="hljs-built_in">print</span>(<span class="hljs-string">"skew substantially different from target of"</span>,
        dcvals.skewtarget, <span class="hljs-string">"is"</span>, skewcol)
   
    kurtosiscol = df[col].kurtosis()
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(kurtosiscol-dcvals.kurtosistarget)&gt;<span class="hljs-number">1.2</span>:
      <span class="hljs-built_in">print</span>(<span class="hljs-string">"kurtosis substantially different from target of"</span>,
        dcvals.kurtosistarget, <span class="hljs-string">"is"</span>, kurtosiscol)
   
</code></pre>
    <ol>
      <li class="numberedList" value="5">We do a <a id="_idIndexMarker966"/>couple of straightforward checks for variables identified as id variables in the targets file. We look to see if the variable is duplicated and check for missing values:
        <pre class="programlisting code-one"><code class="hljs-code">  <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> df[idvars]:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"\n\nChecks for id variable"</span>, col)
 
    uniquevals = df[col].nunique()
    nrows = df.shape[<span class="hljs-number">0</span>]
    <span class="hljs-keyword">if</span> uniquevals != nrows:
      <span class="hljs-built_in">print</span>(<span class="hljs-string">"not unique identifier"</span>, uniquevals,
        <span class="hljs-string">"unique values not equal to"</span>, nrows, <span class="hljs-string">"rows."</span>)
 
    missingvals = df[col].isnull().<span class="hljs-built_in">sum</span>()
    <span class="hljs-keyword">if</span> missingvals &gt; <span class="hljs-number">0</span>:
      <span class="hljs-built_in">print</span>(<span class="hljs-string">"unique value has"</span>, missingvals,
        <span class="hljs-string">"missing values"</span>)
</code></pre>
      </li>
      <li class="numberedList">Now we<a id="_idIndexMarker967"/> are ready to run the data checks. We start by loading the NLS DataFrame and the data-checking targets.
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> sys
nls97 = pd.read_csv(<span class="hljs-string">"</span><span class="hljs-string">data/nls97g.csv"</span>, low_memory=<span class="hljs-literal">False</span>)
dc = pd.read_csv(<span class="hljs-string">"data/datacheckingtargets.csv"</span>)
dc.set_index(<span class="hljs-string">'varname'</span>, inplace=<span class="hljs-literal">True</span>)
</code></pre>
      </li>
      <li class="numberedList">We import the <code class="inlineCode">runchecks</code> module we just created.
        <pre class="programlisting code-one"><code class="hljs-code">sys.path.append(os.getcwd() + <span class="hljs-string">"/helperfunctions"</span>)
<span class="hljs-keyword">import</span> runchecks <span class="hljs-keyword">as</span> rc
</code></pre>
      </li>
      <li class="numberedList">Let’s mess up some of the id variable values for testing the code. We also fix logical missing values for <code class="inlineCode">highestgradecompleted</code>, setting them to actual missing values.
        <pre class="programlisting code-one"><code class="hljs-code">nls97.originalid.head(<span class="hljs-number">7</span>)
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">0    1
1    2
2    3
3    4
4    5
5    6
6    7
Name: originalid, dtype: int64
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">nls97.loc[nls97.originalid==<span class="hljs-number">2</span>,<span class="hljs-string">"originalid"</span>] = <span class="hljs-number">1</span>
nls97.loc[nls97.originalid.between(<span class="hljs-number">3</span>,<span class="hljs-number">7</span>), <span class="hljs-string">"originalid"</span>] = np.nan
nls97.originalid.head(<span class="hljs-number">7</span>)
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">0    1.0
1    1.0
2    NaN
3    NaN
4    NaN
5    NaN
6    NaN
Name: originalid, dtype: float64
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">nls97[<span class="hljs-string">"highestgradecompleted"</span>] = nls97.highestgradecompleted.replace(<span class="hljs-number">95</span>, np.nan)
</code></pre>
      </li>
      <li class="numberedList">We <a id="_idIndexMarker968"/>select just those targets flagged to be included. We then create categorical variable, numeric variable, and id variable lists based on the data-checking targets file:
        <pre class="programlisting code-one"><code class="hljs-code">dc = dc.loc[dc.include==<span class="hljs-string">"Y"</span>]
numvars = dc.loc[dc.<span class="hljs-built_in">type</span>==<span class="hljs-string">"numeric"</span>].index.to_list()
catvars = dc.loc[dc.<span class="hljs-built_in">type</span>==<span class="hljs-string">"categorical"</span>].index.to_list()
idvars = dc.loc[dc.<span class="hljs-built_in">type</span>==<span class="hljs-string">"unique"</span>].index.to_list()
</code></pre>
      </li>
      <li class="numberedList">Now, we are ready to run the checks.
        <pre class="programlisting code-one"><code class="hljs-code">rc.runchecks(nls97,dc,numvars,catvars,idvars)
</code></pre>
      </li>
    </ol>
    <p class="normal-one">This produces the following output:</p>
    <figure class="mediaobject"><img src="../Images/B18596_12_04.png" alt="datachecksoutput"/></figure>
    <p class="packt_figref">Figure 12.4: Running the checks</p>
    <p class="normal">We see<a id="_idIndexMarker969"/> that <code class="inlineCode">maritalstatus</code> has more missings (26%) than the 20% threshold we set. <code class="inlineCode">highestgradecompleted</code> and <code class="inlineCode">gpaoverall</code> have values that exceed the anticipated range. The kurtosis for both variables is low. <code class="inlineCode">nightlyhrssleep</code> has outliers substantially below and above the interquartile range. 31 respondents have <code class="inlineCode">nightlyhrssleep</code> of 2 or less. 27 respondents have very high <code class="inlineCode">nightlyhrssleep</code>, of 12 or more.</p>
    <p class="normal">These steps show how we can use our prior domain knowledge and understanding of statistics to better target our investigation of data quality.</p>
    <h2 id="_idParaDest-462" class="heading-2">How it works...</h2>
    <p class="normal">We created a CSV file with our data-checking targets. We used that file in our checks of the NLS data. We did that by passing both the NLS DataFrame and the data-checking targets to <code class="inlineCode">runchecks</code>. Code in <code class="inlineCode">runchecks</code> loops through the column names from the data-checking file and does checks based on the type of variable.</p>
    <p class="normal">The targets for each variable are defined by <code class="inlineCode">dcvals = dc.loc[col]</code>, which grabs all of the target values for that row in the target file. We can then refer to <code class="inlineCode">dcvals.missingthreshold</code> to get the missing-values threshold, for example. We then compare the percentage of missing values (<code class="inlineCode">df[col].isnull().sum()/df.shape[0]</code>) to the missing threshold, and print a message if the missing-value percentage is greater than the threshold. We do the same type of checking for range of values, skew, outliers, and so on, depending on the type of variable.</p>
    <p class="normal">We can add new variables<a id="_idIndexMarker970"/> to the data-checking targets file without changing any of the code in <code class="inlineCode">runchecks</code>. We can also change target values. </p>
    <h2 id="_idParaDest-463" class="heading-2">There’s more...</h2>
    <p class="normal">It is sometimes important to be proactive with our data checks. There is a difference between displaying some sample statistics and frequency distributions to get a general sense of the data, and marshaling our domain knowledge and understanding of statistics for careful examination of data quality. A more intentional approach might require us to occasionally step away from our Python development environment for a moment to reflect on our expectations for data values and their distribution. Setting up initial data quality targets, and revisiting them regularly, can help us do that.</p>
    <h1 id="_idParaDest-464" class="heading-1">Pre-processing data with pipelines: a simple example</h1>
    <p class="normal">When<a id="_idIndexMarker971"/> doing predictive analysis, we often need to fold all of our pre-processing and feature engineering into a pipeline, including scaling, encoding, and handling outliers and missing values. We discussed the reasons why we might need to incorporate all of our data preparation into a data pipeline in <em class="chapterRef">Chapter 8</em>, <em class="italic">Encoding, Transforming, and Scaling Features</em>. The main takeaway from that chapter is that pipelines are critical when we are building explanatory models and need to avoid data leakage. This can be trickier still when we are using <em class="italic">k</em>-fold cross-validation for model validation, since testing and training DataFrames change during evaluation. Cross-validation has become the norm when constructing predictive models.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Note</strong></p>
      <p class="normal"><em class="italic">k</em>-fold cross-validation trains our model on all but one of the <em class="italic">k</em> folds, or parts, leaving one out for testing. This is repeated <em class="italic">k</em> times, each time excluding a different fold for testing. Performance metrics are then based on the average scores across the <em class="italic">k</em> folds.</p>
    </div>
    <p class="normal">Another<a id="_idIndexMarker972"/> benefit of pipelines is that they help us ensure reproducible results, as they are often intended to take our analysis from raw data to model evaluation.</p>
    <p class="normal">Although this recipe demonstrates how to use a pipeline all the way through model evaluation, we will not go into detail there. A good resource for both model evaluation and pipelines with scikit-learn tools is the book <em class="italic">Data Cleaning and Exploration with Machine Learning</em>, also written by me.</p>
    <p class="normal">We start with a relatively simple example here, a model with two numeric features and one numeric target. We work on a much more complicated example in the next recipe.</p>
    <h2 id="_idParaDest-465" class="heading-2">Getting ready</h2>
    <p class="normal">We will work with scikit-learn’s pipeline tool in this recipe, and a few other modules for encoding and scaling the data, and imputing values for missing data. We will work with land temperature data again in this recipe.</p>
    <h2 id="_idParaDest-466" class="heading-2">How to do it...</h2>
    <ol>
      <li class="numberedList" value="1">We start by loading the <code class="inlineCode">scikit-learn</code> modules we will be using in this recipe for transforming our data. We will use <code class="inlineCode">StandardScaler</code> to standardize our features, <code class="inlineCode">SimpleImputer</code> to impute values for missing data, and <code class="inlineCode">make_pipeline</code> to pull all of our pre-processing together. We also use <code class="inlineCode">train_test_split</code> to create training and testing DataFrames. I’ll discuss the other modules as we use them:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression
<span class="hljs-keyword">from</span> sklearn.impute <span class="hljs-keyword">import</span> SimpleImputer
<span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> make_pipeline
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> cross_validate
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> KFold
</code></pre>
      </li>
      <li class="numberedList">We <a id="_idIndexMarker973"/>load the land temperature data and create training and testing DataFrames. We will try to model temperature as a function of latitude and elevation. Given the very different ranges of the <code class="inlineCode">latabs</code> and <code class="inlineCode">elevation</code> variables, scaling will be important:
        <pre class="programlisting code-one"><code class="hljs-code">landtemps = pd.read_csv(<span class="hljs-string">"data/landtemps2023avgs.csv"</span>)
feature_cols = [<span class="hljs-string">'latabs'</span>,<span class="hljs-string">'elevation'</span>]
X_train, X_test, y_train, y_test =  \
  train_test_split(landtemps[feature_cols],\
  landtemps[[<span class="hljs-string">'avgtemp'</span>]], test_size=<span class="hljs-number">0.1</span>, random_state=<span class="hljs-number">0</span>)
</code></pre>
      </li>
    </ol>
    <p class="normal-one">For an introduction to <code class="inlineCode">train_test_split</code>, see <em class="chapterRef">Chapter 8</em>, <em class="italic">Encoding, Transforming, and Scaling Features</em>.</p>
    <ol>
      <li class="numberedList" value="3">We set up <em class="italic">k</em>-fold cross-validation. We indicate that we want five folds and for the data to be shuffled:
        <pre class="programlisting code-one"><code class="hljs-code">kf = KFold(n_splits=<span class="hljs-number">5</span>, shuffle=<span class="hljs-literal">True</span>, random_state=<span class="hljs-number">0</span>)
</code></pre>
      </li>
      <li class="numberedList">Now, we are ready to set up our pipeline. The pipeline will do standard scaling, impute the mean when values are missing, and then run a linear regression model. Both features will be handled in the same way.
        <pre class="programlisting code-one"><code class="hljs-code">pipeline = \
  make_pipeline(StandardScaler(),
  SimpleImputer(strategy=<span class="hljs-string">"mean"</span>),LinearRegression())
</code></pre>
      </li>
      <li class="numberedList">After constructing the pipeline, and instantiating a <em class="italic">k</em>-fold cross-validation object, we are ready to run the pre-processing, estimate the model, and generate evaluation metrics. We pass the pipeline to the <code class="inlineCode">cross_validate</code> function, as well as our training data. We also pass the <code class="inlineCode">Kfold</code> object we created in <em class="italic">step 3</em>. We get a pretty decent <em class="italic">R</em>-squared value.
        <pre class="programlisting code-one"><code class="hljs-code">scores = \
  cross_validate(pipeline, X=X_train, y=y_train.values,
  cv=kf, scoring=[<span class="hljs-string">'r2'</span>,<span class="hljs-string">'neg_mean_absolute_error'</span>],
  n_jobs=<span class="hljs-number">1</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Mean Absolute Error: %.2f, R-squared: %.2f"</span> %
  (scores[<span class="hljs-string">'test_neg_mean_absolute_error'</span>].mean(),
  scores[<span class="hljs-string">'test_r2'</span>].mean()))
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">Mean Absolute Error: -2.53, R-squared: 0.82
</code></pre>
      </li>
    </ol>
    <h2 id="_idParaDest-467" class="heading-2">How it works...</h2>
    <p class="normal">We used scikit-learn’s <code class="inlineCode">make_pipeline</code> to create a pipeline with just three steps: apply standard scaling, impute values for missing data based on the mean for that variable, and fit a linear regression model. What is so helpful about pipelines is that they automatically feed a transformation from one step into the next step. This is easy to do, once we get the hang of it, despite the complication of <em class="italic">k</em>-fold cross-validation.</p>
    <p class="normal">We can imagine for a moment how messy it would be to write our own code to do this when the training and testing DataFrames are changing, as with <em class="italic">k</em>-fold cross-validation. Even something as simple as using the mean for imputation is tricky. We would need to take a new mean for the training data each time the training data changed. Our pipeline handles all of this for us.</p>
    <p class="normal">That was a<a id="_idIndexMarker974"/> relatively straightforward example, with just a couple of features that we could handle in the same way. We also did not bother to check for outliers or scale the target variable. We use a pipeline to handle a much trickier modeling project in the next recipe.</p>
    <h1 id="_idParaDest-468" class="heading-1">Pre-processing data with pipelines: a more complicated example</h1>
    <p class="normal">If <a id="_idIndexMarker975"/>you have ever built a data pipeline, you know that it can be a little messy when you are working with several different data types. For example, we might need to impute the median for missing values with continuous features and the most frequent value for categorical features. We might also need to transform our target variable. We explore how to apply different pre-processing to different variables in this recipe.</p>
    <h2 id="_idParaDest-469" class="heading-2">Getting ready</h2>
    <p class="normal">We <a id="_idIndexMarker976"/>will work with a fair number of scikit-learn modules in this recipe. Although this can be confusing at first, you quickly become grateful that scikit-learn has a tool to do pretty much anything you need. Scikit-learn also allows us to add our own transformations to a pipeline if we need to do so. I demonstrate how to construct our own transformer in this recipe.</p>
    <p class="normal">We will work with wage and employment data from the NLS.</p>
    <h2 id="_idParaDest-470" class="heading-2">How to do it...</h2>
    <ol>
      <li class="numberedList" value="1">We start by loading the libraries we used in the previous recipe. Then we add the <code class="inlineCode">ColumnTransformer</code> and <code class="inlineCode">TransformedTargetRegressor</code> classes. We will use those classes to transform our features and target respectively.
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression
<span class="hljs-keyword">from</span> sklearn.impute <span class="hljs-keyword">import</span> SimpleImputer
<span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> make_pipeline
<span class="hljs-keyword">from</span> feature_engine.encoding <span class="hljs-keyword">import</span> OneHotEncoder
<span class="hljs-keyword">from</span> sklearn.impute <span class="hljs-keyword">import</span> KNNImputer
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> cross_validate, KFold
<span class="hljs-keyword">from</span> sklearn.compose <span class="hljs-keyword">import</span> ColumnTransformer
<span class="hljs-keyword">from</span> sklearn.compose <span class="hljs-keyword">import</span> TransformedTargetRegressor
</code></pre>
      </li>
      <li class="numberedList">The column transformer is quite flexible. We can even use it with pre-processing functions we have defined ourselves. The code block below imports the <code class="inlineCode">OutlierTrans</code> class from the <code class="inlineCode">preprocfunc</code> module in the <code class="inlineCode">helperfunctions</code> subfolder.
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> sys
sys.path.append(os.getcwd() + <span class="hljs-string">"</span><span class="hljs-string">/helperfunctions"</span>)
<span class="hljs-keyword">from</span> preprocfunc <span class="hljs-keyword">import</span> OutlierTrans
</code></pre>
      </li>
      <li class="numberedList">The <code class="inlineCode">OutlierTrans</code> class identifies missing values by distance from the interquartile range. This is a technique we demonstrated in <em class="chapterRef">Chapter 4</em>, <em class="italic">Identifying Outliers in Subsets of Data</em>, and have used multiple times in this chapter.</li>
    </ol>
    <p class="normal-one">To <a id="_idIndexMarker977"/>work in a scikit-learn pipeline our class has to have <code class="inlineCode">fit</code> and <code class="inlineCode">transform</code> methods. We also need to inherit the <code class="inlineCode">BaseEstimator</code> and <code class="inlineCode">TransformerMixin</code> classes.</p>
    <p class="normal-one">In this class, almost all of the action happens in the <code class="inlineCode">transform</code> method. Any value that is more than 1.5 times the interquartile range above the third quartile or below the first quartile is assigned missing, though that threshold can be changed:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">class</span> <span class="hljs-title">OutlierTrans</span>(BaseEstimator,TransformerMixin):
  <span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,threshold=</span><span class="hljs-number">1.5</span>):
    self.threshold = threshold
 
  <span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>(<span class="hljs-params">self,X,y=</span><span class="hljs-literal">None</span>):
    <span class="hljs-keyword">return</span> self
 
  <span class="hljs-keyword">def</span> <span class="hljs-title">transform</span>(<span class="hljs-params">self,X,y=</span><span class="hljs-literal">None</span>):
    Xnew = X.copy()
    <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> Xnew.columns:
      thirdq, firstq = Xnew[col].quantile(<span class="hljs-number">0.75</span>),\
        Xnew[col].quantile(<span class="hljs-number">0.25</span>)
      inlierrange = self.threshold*(thirdq-firstq)
      outlierhigh, outlierlow = inlierrange+thirdq,\
        firstq-inlierrange
      Xnew.loc[(Xnew[col]&gt;outlierhigh) | \
        (Xnew[col]&lt;outlierlow),col] = np.nan
    <span class="hljs-keyword">return</span> Xnew.values
</code></pre>
    <p class="normal-one">Our <code class="inlineCode">OutlierTrans</code> class can be used later in our pipeline in the same way we use the <code class="inlineCode">StandardScaler</code> and other transformers. We will do that later.</p>
    <ol>
      <li class="numberedList" value="4">Now we are ready to load the data that needs to be processed. We will work with the NLS wage data. Wage income will be our target, and we will use high school GPA, mother’s and father’s highest grade completed, parent income, gender, weeks worked, and whether the individual completed a bachelor’s degree as features.</li>
    </ol>
    <p class="normal-one">We create lists of features to handle in different ways here. That will be helpful later when we instruct our pipeline to carry out different operations on numerical, categorical, and binary features.</p>
    <pre class="programlisting code-one"><code class="hljs-code">nls97wages = pd.read_csv(<span class="hljs-string">"data/nls97wages.csv"</span> , low_memory=<span class="hljs-literal">False</span>)
nls97wages.set_index(<span class="hljs-string">"personid"</span>, inplace=<span class="hljs-literal">True</span>)
num_cols = [<span class="hljs-string">'gpascience'</span>,<span class="hljs-string">'gpaenglish'</span>,<span class="hljs-string">'gpamath'</span>,
  <span class="hljs-string">'gpaoverall'</span>,<span class="hljs-string">'motherhighgrade'</span>,<span class="hljs-string">'fatherhighgrade'</span>,
  <span class="hljs-string">'parentincome'</span>,<span class="hljs-string">'weeksworked20'</span>]
cat_cols = [<span class="hljs-string">'gender'</span>]
bin_cols = [<span class="hljs-string">'completedba'</span>]
target = nls97wages[[<span class="hljs-string">'wageincome20'</span>]]
features = nls97wages[num_cols + cat_cols + bin_cols]
X_train, X_test, y_train, y_test =  \
  train_test_split(features,\
  target, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">0</span>)
</code></pre>
    <ol>
      <li class="numberedList" value="5">Now <a id="_idIndexMarker978"/>we can set up a column transformer. We first create pipelines for handling numerical data (<code class="inlineCode">standtrans</code>), categorical data, and binary data.</li>
    </ol>
    <p class="normal-one">For the numerical data (continuous), we want to assign outlier values to missing. Here we pass a value of 2 to the <code class="inlineCode">threshold</code> parameter of <code class="inlineCode">OutlierTrans</code>, indicating that we want values 2 times the interquartile range above or below that range to be set to missing. Recall that it is common to use 1.5, so we are being somewhat conservative.</p>
    <p class="normal-one">We do one-hot encoding of the <code class="inlineCode">gender</code> column, essentially creating a dummy variable. We drop the last category to avoid the <strong class="keyWord">dummy variable trap</strong>, as discussed in <em class="chapterRef">Chapter 8</em>, <em class="italic">Encoding, Transforming, and Scaling Features</em>.</p>
    <p class="normal-one">We then create a <code class="inlineCode">ColumnTransformer</code> object, passing to it the three pipelines we just created, and indicating which features to use with which pipeline.</p>
    <p class="normal-one">We do not worry about missing values yet for the numeric variables. We will handle them later:</p>
    <pre class="programlisting code-one"><code class="hljs-code">standtrans = make_pipeline(OutlierTrans(<span class="hljs-number">2</span>),
  StandardScaler())
cattrans = \
  make_pipeline(SimpleImputer(strategy=\
  <span class="hljs-string">"most_frequent"</span>),OneHotEncoder(drop_last=<span class="hljs-literal">True</span>))
bintrans = \
  make_pipeline(SimpleImputer(strategy=\
  <span class="hljs-string">"most_frequent"</span>))
coltrans = ColumnTransformer(
  transformers=[
    (<span class="hljs-string">"stand"</span>, standtrans, num_cols),
    (<span class="hljs-string">"cat"</span>, cattrans, [<span class="hljs-string">'gender'</span>]),
    (<span class="hljs-string">"bin"</span>, bintrans, [<span class="hljs-string">'completedba'</span>])
  ]
)
</code></pre>
    <ol>
      <li class="numberedList" value="6">We <a id="_idIndexMarker979"/>can now add the column transformer to a pipeline that also includes the linear model that we would like to run. We add KNN imputation to the pipeline to handle missing values for the numeric values. We have already handled missing values for the categorical variables.</li>
    </ol>
    <p class="normal-one">We also need to scale the target, which cannot be done in our pipeline. We use scikit-learn’s <code class="inlineCode">TransformedTargetRegressor</code> for that. We pass the pipeline we just created to the target regressor’s <code class="inlineCode">regressor</code> parameter.</p>
    <pre class="programlisting code-one"><code class="hljs-code">lr = LinearRegression()
pipe1 = make_pipeline(coltrans,
  KNNImputer(n_neighbors=<span class="hljs-number">5</span>), lr)
ttr=TransformedTargetRegressor(regressor=pipe1,
  transformer=StandardScaler())
</code></pre>
    <ol>
      <li class="numberedList" value="7">Let’s do <em class="italic">k</em>-fold cross-validation using this pipeline. We can pass our pipeline, via the target regressor <code class="inlineCode">ttr</code>, to the <code class="inlineCode">cross_validate</code> function.
        <pre class="programlisting code-one"><code class="hljs-code">kf = KFold(n_splits=<span class="hljs-number">10</span>, shuffle=<span class="hljs-literal">True</span>, random_state=<span class="hljs-number">0</span>)
scores = cross_validate(ttr, X=X_train, y=y_train,
  cv=kf, scoring=(<span class="hljs-string">'r2'</span>, <span class="hljs-string">'neg_mean_absolute_error'</span>),
  n_jobs=<span class="hljs-number">1</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Mean Absolute Error: %.2f, R-squared: %.2f"</span> %
  (scores[<span class="hljs-string">'test_neg_mean_absolute_error'</span>].mean(),
  scores[<span class="hljs-string">'test_r2'</span>].mean()))
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">Mean Absolute Error: -32899.64, R-squared: 0.16
</code></pre>
      </li>
    </ol>
    <p class="normal">These scores are not very good, though that was not quite the point of this exercise. The key takeaway here is that we typically want to fold most of the pre-processing we will do into a pipeline. This is the best way to avoid data leakage. The column transformer is an extremely flexible tool, allowing us to apply different transformations to different features.</p>
    <h2 id="_idParaDest-471" class="heading-2">How it works...</h2>
    <p class="normal">We created several different pipelines to pre-process our data before fitting our model, one for numeric data, one for categorical data, and one for binary data. The column transformer helps us by allowing us to apply different pipelines to different columns. We set up the column transformer in <em class="italic">step 5</em>.</p>
    <p class="normal">We created another pipeline in <em class="italic">step 6</em>. That pipeline actually begins with the column transformer. Then, the dataset that results from the column transformer’s pre-processing is passed to the KNN imputer to handle missing values from the numeric columns, and then to the linear regression model.</p>
    <p class="normal">It is good to <a id="_idIndexMarker980"/>note that we are able to add transformations to a scikit-learn pipeline, even ones we have designed ourselves, because they inherit the <code class="inlineCode">BaseEstimator</code> and <code class="inlineCode">TransformerMixin</code> classes, as we saw in <em class="italic">step 3</em>.</p>
    <h2 id="_idParaDest-472" class="heading-2">There’s more...</h2>
    <p class="normal">There is one additional thing that is very cool, and useful, about pipelines that was not demonstrated in this example. If you have ever had to generate predictions based on variables that have been scaled or transformed in some way, you likely remember how much of a nuisance that can be. Well, pipelines handle that for us, generating predictions in the appropriate units.</p>
    <h2 id="_idParaDest-473" class="heading-2">See also</h2>
    <p class="normal">This really just scratches the surface of what can be done with pipelines. For a fuller discussion, see the book <em class="italic">Data Cleaning and Exploration with Machine Learning</em>, also written by me.</p>
    <h1 id="_idParaDest-474" class="heading-1">Summary</h1>
    <p class="normal">There was a fair bit packed into this chapter, covering several approaches to automating our data-cleaning work. We created functions for showing the structure of our data and generating descriptive statistics. We created functions for restructuring and aggregating our data. We also developed Python classes for handling data cleaning when we have a large number of variables, each requiring very different treatment. We also saw how Python classes can make it easier to work directly with a JSON file. We examined being more intentional with our data cleaning by checking our data against predefined targets. Finally, we explored how to automate our data cleaning with pipelines.</p>
    <h1 class="heading-1">Leave a review!</h1>
    <p class="normal">Enjoyed this book? Help readers like you by leaving an Amazon review. Scan the QR code below to get a free eBook of your choice.</p>
    <p class="normal"><img src="../Images/Review_copy.png" style="width:10em" alt="" role="presentation"/></p>
  </div>


  <div id="_idContainer144">
    <p class="BM-packtLogo"><img src="../Images/New_Packt_Logo1.png" alt="" role="presentation"/></p>
    <p class="normal"><a href="https://www.packt.com"><span class="url">packt.com</span></a></p>
    <p class="normal">Subscribe to our online digital library for full access to over 7,000 books and videos, as well as industry leading tools to help you plan your personal development and advance your career. For more information, please visit our website.</p>
    <h1 id="_idParaDest-475" class="heading-1">Why subscribe?</h1>
    <ul>
      <li class="bulletList">Spend less time learning and more time coding with practical eBooks and Videos from over 4,000 industry professionals</li>
      <li class="bulletList">Improve your learning with Skill Plans built especially for you</li>
      <li class="bulletList">Get a free eBook or video every month</li>
      <li class="bulletList">Fully searchable for easy access to vital information</li>
      <li class="bulletList">Copy and paste, print, and bookmark content</li>
    </ul>
    <p class="normal">At <a href="https://www.packt.com"><span class="url">www.packt.com</span></a>, you can also read a collection of free technical articles, sign up for a range of free newsletters, and receive exclusive discounts and offers on Packt books and eBooks.</p>
    <p class="eop"/>
    <h1 id="_idParaDest-476" class="mainHeading">Other Books You May Enjoy</h1>
    <p class="normal">If you enjoyed this book, you may be interested in these other books by Packt:</p>
    <p class="BM-bookCover"><a href="https://www.packtpub.com/product/azure-data-factory-cookbook-second-edition/9781803246598"><img src="../Images/978-1-80324-659-8.png" alt="" role="presentation"/></a></p>
    <p class="normal"><strong class="keyWord">Azure Data Factory Cookbook – Second Edition</strong></p>
    <p class="normal">Dmitry Foshin</p>
    <p class="normal">Dimtry Anoshin</p>
    <p class="normal">Tonya Chernyshova</p>
    <p class="normal">Xenia Ireton</p>
    <p class="normal">ISBN: 978-1-80324-659-8</p>
    <ul>
      <li class="bulletList">Create an orchestration and transformation job in ADF</li>
      <li class="bulletList">Develop, execute, and monitor data flows using Azure Synapse</li>
      <li class="bulletList">Create big data pipelines using Databricks and Delta tables</li>
      <li class="bulletList">Work with big data in Azure Data Lake using Spark Pool</li>
      <li class="bulletList">Migrate on-premises SSIS jobs to ADF</li>
      <li class="bulletList">Integrate ADF with commonly used Azure services such as Azure ML, Azure Logic Apps, and Azure Functions</li>
      <li class="bulletList">Run big data compute jobs within HDInsight and Azure Databricks</li>
      <li class="bulletList">Copy data from AWS S3 and Google Cloud Storage to Azure Storage using ADF’s built-in connectors</li>
    </ul>
    <p class="eop"/>
    <p class="BM-bookCover"><a href="https://www.packtpub.com/product/data-engineering-with-aws-second-edition/9781804614426"><img src="../Images/978-1-80461-442-6.png" alt="" role="presentation"/></a></p>
    <p class="normal"><strong class="keyWord">Data Engineering with AWS – Second Edition</strong></p>
    <p class="normal">Gareth Eagar</p>
    <p class="normal">ISBN: 978-1-80461-442-6</p>
    <ul>
      <li class="bulletList">Seamlessly ingest streaming data with Amazon Kinesis Data Firehose</li>
      <li class="bulletList">Optimize, denormalize, and join datasets with AWS Glue Studio</li>
      <li class="bulletList">Use Amazon S3 events to trigger a Lambda process to transform a file</li>
      <li class="bulletList">Load data into a Redshift data warehouse and run queries with ease</li>
      <li class="bulletList">Visualize and explore data using Amazon QuickSight</li>
      <li class="bulletList">Extract sentiment data from a dataset using Amazon Comprehend</li>
      <li class="bulletList">Build transactional data lakes using Apache Iceberg with Amazon Athena</li>
      <li class="bulletList">Learn how a data mesh approach can be implemented on AWS</li>
    </ul>
    <p class="eop"/>
    <h1 id="_idParaDest-477" class="heading-1">Packt is searching for authors like you</h1>
    <p class="normal">If you’re interested in becoming an author for Packt, please visit <a href="https://authors.packtpub.com"><span class="url">authors.packtpub.com</span></a> and apply today. We have worked with thousands of developers and tech professionals, just like you, to help them share their insight with the global tech community. You can make a general application, apply for a specific hot topic that we are recruiting an author for, or submit your own idea.</p>
  </div>
  <div id="_idContainer145" class="Basic-Text-Frame">
    <p class="eop"/>
    <h1 id="_idParaDest-478" class="heading-1">Share your thoughts</h1>
    <p class="normal">Now you’ve finished <em class="italic">Python Data Cleaning Cookbook, Second Edition</em>, we’d love to hear your thoughts! If you purchased the book from Amazon, please<span class="url"> </span><a href="https://packt.link/r/1803239875"><span class="url">click here to go straight to the Amazon review page</span></a> for this book and share your feedback or leave a review on the site that you purchased it from.</p>
    <p class="normal">Your review is important to us and the tech community and will help us make sure we’re delivering excellent quality content.</p>
  </div>
</body></html>