<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Data Case Studies Using pandas</h1>
                </header>
            
            <article>
                
<p>So far, we have covered the extensive functionalities of pandas. We'll try to implement these functionalities in some case studies. These case studies will give us an overview of the use of each functionality and help us determine the pivotal points in handling a DataFrame. Moreover, the step-by-step approach of the case studies helps us to deepen our understanding of the pandas functions. This <span><span>chapter</span></span> is equipped with practical examples along with code snippets to ensure that, by the end, you understand the pandas approach to solving the DataFrame problems.</p>
<p>We will cover the following case studies: </p>
<ul>
<li><span>End-to-end exploratory data analysis</span></li>
<li><span>Web scraping with Python </span></li>
<li><span>Data validation</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">End-to-end exploratory data analysis</h1>
                </header>
            
            <article>
                
<p>Exploratory data analysis refers to the critical process of understanding the quirks of data—the outliers, the columns containing the most relevant information, and determining the relationship between the variables using statistics and graphical representations.</p>
<p>Let's consider the following DataFrame to perform exploratory data analysis:</p>
<pre>df = pd.read_csv("data.csv")
df</pre>
<p>The following screenshot shows the DataFrame loaded in Jupyter Notebook:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/1432bfa2-441d-4f22-90e2-78bd09b48ece.png"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">DataFrame loaded in Jupyter Notebook</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data overview</h1>
                </header>
            
            <article>
                
<p>The preceding <span>DataFrame </span>is the customer data of an automobile servicing firm. They basically provide services to their clients on a periodic basis. Each row in the DataFrame corresponds to a unique customer. Hence, it is customer-level data. Here is an observation from the data: </p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1673 image-border" src="assets/547abf7c-ab9b-4b1c-9a65-48b8df8ff4c9.png" style="width:7.08em;height:4.33em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The shape of the DataFrame</div>
<p>We can observe that the data contains 27,002 records and 26 characteristics.</p>
<p>Before we start exploratory data analysis on any data, it is advised to know as much about the data as possible—the column names and their corresponding data types, whether they contain null values or not (and if so, how many), and so on. The following screenshot shows some of the basic information about the DataFrame obtained using the <kbd>info</kbd> function in pandas:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1674 image-border" src="assets/d9f4f4d1-c447-449f-9f7a-c6d9865e95fe.png" style="width:25.33em;height:34.08em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Basic information about the DataFrame</div>
<p>Using the <kbd>info()</kbd> <span>function, </span>we can see that the data <span>only </span>has float and integer values. Also, none of the columns has null/missing values.</p>
<p>The <kbd>describe()</kbd> function in pandas is used to obtain various summary statistics of all the numeric columns. This function returns the count, mean, standard deviation, minimum and maximum values, and the quantiles of all the numeric columns. The following table shows the description of the data obtained using the <kbd>describe</kbd> function:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1675 image-border" src="assets/a9f15dcf-e64c-4c09-a5c2-535d7daa7c6c.png" style="width:104.17em;height:31.75em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Describing the Data</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Feature selection</h1>
                </header>
            
            <article>
                
<p>If you a have dataset with many variables, a good way to check correlations among columns is by visualizing the correlation matrix as a heatmap. We can identify and remove those that are highly correlated, thereby simplifying our analysis. The visualization can be achieved using the <kbd>seaborn</kbd> library in Python:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1676 image-border" src="assets/9c159842-b5f9-4c9e-aa06-4184d9218eed.png" style="width:29.42em;height:17.42em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The following will be the output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1677 image-border" src="assets/fa3c9dde-f91f-42dd-b039-69e9b4a08718.png" style="width:43.42em;height:38.17em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Correlation heatmap of the DataFrame</div>
<p>We can observe the following in the preceding heatmap:</p>
<ul>
<li><kbd>soldBy</kbd> and <kbd>days_old</kbd> are highly negatively correlated</li>
<li><kbd>age_median</kbd> and <kbd>income_median</kbd> are positively correlated</li>
</ul>
<p>Similarly, we can derive the correlation between different sets of variables. Hence, based on the correlation results, we can minimize the number of independent features by selecting only the important features.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Feature extraction</h1>
                </header>
            
            <article>
                
<p>Apart from selecting the useful features, we also need to extract significant variables from the existing ones. This method is called <strong>feature extraction</strong>. In the current example, a new feature called <kbd>new_tenure</kbd> has been extracted from the existing variables. This variable gives us the amount of time that a customer has stayed with the firm:</p>
<pre>data['new_tenure']=data['active_status']*data['days_old']+(1-data['active_status'])*data['days_active_tenure'] </pre>
<p>The following DataFrame shows the newly extracted variables:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/b70a40ca-73ab-42af-9ac9-8c6d120f2d31.png"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">The DataFrame with the newly extracted variables</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data aggregation</h1>
                </header>
            
            <article>
                
<p>As mentioned earlier, the data presented is customer-level data. It would be more feasible and easy to perform analysis on aggregated data, which in this case is a region. To start with, we need to understand how the customers are spread across each region. Hence, we are going to use the <kbd>groupby</kbd> function to find the number of customers in each zip code. The snippet and its output are shown in the following code:</p>
<pre>data.groupby('zip')['zip'].count().nlargest(10)<strong><br/></strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The following is the output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1680 image-border" src="assets/21e6a21a-c125-4c22-9b88-0f16a5a4ea47.png" style="width:27.25em;height:18.08em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref"> Aggregating the data based on zip codes</div>
<p>This gives the first 10 zip codes that have the maximum number of customers.</p>
<p>Therefore, we can convert our client-level data into zip-level data using aggregation. After grouping the values, we also have to make sure that we remove the NAs. The following code can be used to perform aggregation on the entire DataFrame: </p>
<pre>data_mod=data.groupby('zip') 
data_clean=pd.DataFrame() 
for name,data_group in data_mod: 
    data_group1=data_group.fillna(method='ffill') 
    data_clean=pd.concat([data_clean,data_group1],axis=0) 
 
data_clean.dropna(axis=0, how='any') </pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The following screenshot is the aggregated DataFrame after removing the NAs:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/dddd3a12-a571-4769-b85e-e945a13804d2.png"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Aggregated DataFrame after removing the NAs</div>
<p><kbd>data_clean</kbd> will become the cleaned version of our sample DataFrame, which will be passed to a model for further analysis.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Web scraping with Python</h1>
                </header>
            
            <article>
                
<p>Web scraping deals with extracting large amounts of data from websites in either structured or unstructured forms. For example, a website might have some data already present in an HTML table element or as a CSV file. This is an example of structured data on website. But, in most cases, the required information would be scattered across the content of the web page. Web scraping helps collect these data and store it in a structured form. There are different ways to scrape websites such as online services, APIs, or writing your own code.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Here are some important notes about web scraping:</p>
<ul>
<li>Read through the website's terms and conditions to understand how you can legally use the data. Most sites prohibit you from using the data for commercial purposes.</li>
<li>Make sure you are not downloading data at a rapid rate because this may break the website. You may potentially be blocked from the site as well.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Web scraping using pandas</h1>
                </header>
            
            <article>
                
<p>Python provides different libraries for scraping:</p>
<ul>
<li>pandas</li>
<li>BeautifulSoup</li>
<li>Scrapy</li>
</ul>
<p>In this section, we'll see how to scrape data by leveraging the power of pandas and BeautifulSoup. To start with, pandas is sufficient to extract structured data from a website without the help of BeautifulSoup. In the earlier sections, we learned about loading data from different formats (<kbd>.csv</kbd>, .<kbd>xlsx</kbd>, and <kbd>.xls</kbd>) in Python. Similar to these, pandas has a separate function for loading tabular data from an HTML file. To read an HTML file, a pandas DataFrame looks for a tag. That tag is called a <kbd>&lt;td&gt; &lt;/td&gt;</kbd> tag. This tag is used to define a table in HTML.</p>
<p>pandas uses <kbd>read_html()</kbd> to read the HTML document. This function loads all the structured data from the URL into the Python environment. So, whenever you pass an HTML to pandas and expect it to output a nice-looking <span>DataFrame</span>, make sure the HTML page has a table in it.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>We can try this function on a sample URL (<span class="MsoHyperlink"><a href="https://www.bseindia.com/static/members/TFEquity.aspx">https://www.bseindia.com/static/members/TFEquity.aspx</a></span>):</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1681 image-border" src="assets/48da0222-119d-4f5d-8fc8-b24649577cab.png" style="width:114.83em;height:71.50em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign"> Sample web page</div>
<p>The preceding web page contains multiple tables. Using pandas, we can extract all the tables, which will be stored inside a list:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1682 image-border" src="assets/cd6d4277-e11c-432b-a1dc-91e58c062567.png" style="width:40.17em;height:24.17em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">List containing multiple DataFrames</div>
<p>In the following screenshot, the second table from the web page is being extracted:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1683 image-border" src="assets/3e61565b-b000-45ad-a4e3-7e34cc00fe32.png" style="width:29.50em;height:23.50em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Comparison of the web page and the pandas DataFrame</div>
<p class="mce-root"/>
<p class="mce-root"/>
<p>After cleaning, the extracted DataFrame is an exact replica of what is available on the website: </p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1684 image-border" src="assets/54c4560d-d7c0-42f2-b174-f2a9d83c5e35.png" style="width:39.08em;height:18.17em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">DataFrame after cleaning</div>
<p>With proper indexing, all the tables from a web page can be extracted using the <kbd>read_html</kbd> function.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Web scraping using BeautifulSoup</h1>
                </header>
            
            <article>
                
<p>BeautifulSoup is a Python library (<a href="https://www.crummy.com/software/BeautifulSoup/">https://www.crummy.com/software/BeautifulSoup/</a>) for pulling data out of HTML and XML files. It provides ways of navigating, accessing, searching, and modifying the HTML content of a web page. It is important to understand the basics of HTML in order to successfully scrape a web page. To parse the content, the first thing that we need to do is to figure out where we can locate the links to the files we want to download inside the multiple levels of HTML tags. Simply put, there is a lot of code on a web page, and we want to find the relevant pieces of code that contains our data.</p>
<p>On the website, right-click and click on <span class="packt_screen">Inspect</span>. This allows you to see the raw code behind the site. Once you've clicked on <span class="packt_screen">Inspect</span>, you should see the following console pop up: </p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/73f85c88-ed30-433d-80e5-8a12cd1bb2fb.png"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Inspect menu of a browser</div>
<p>Notice that the table that we are referring to is wrapped in a tag called <strong>table</strong>. Each row will be present between <kbd>&lt;tr&gt;</kbd> tags. Similarly, each cell will be present between <kbd>&lt;td&gt;</kbd> tags. Understanding these basic differences makes it easier to extract the data.</p>
<p>We start by importing the following libraries:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1685 image-border" src="assets/68b0881a-d34a-45e9-a21d-97f13641eb39.png" style="width:17.25em;height:5.25em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Importing libraries</div>
<p>Next, we request the URL with the <kbd>requests</kbd> library. If the access was successful, you should see the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/e9fc1dc8-0f62-4f70-82c6-7a12fc6be37b.png"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Successful response from a website</div>
<p>We then parse <kbd>html</kbd> with <kbd>BeautifulSoup</kbd> so that we can work with a nicer, nested <kbd>BeautifulSoup</kbd> data structure. With a little knowledge of HTML tags, the parsed content can be easily converted into a DataFrame using a <kbd>for</kbd> loop and a pandas <span>DataFrame</span>. The biggest advantage of using BeautifulSoup is that it can even extract data from unstructured sources that can be molded into a table by the supported libraries, whereas the <kbd>read_html</kbd> function of pandas will only work with structured sources. Hence, based on the requirement, we have used <kbd>BeautifulSoup</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1688 image-border" src="assets/35619365-12c4-4da0-9066-c80ceb661ea1.png" style="width:27.42em;height:18.92em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Extracted <span>DataFrame </span>using BeautifulSoup</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data validation</h1>
                </header>
            
            <article>
                
<p>Data validation is the process of examining the quality of data to ensure it is both correct and useful for performing analysis. It uses routines, often called <strong>validation rules</strong>, that check for the genuineness of the data that is input to the models. In the age of big data, where vast caches of information are generated by computers and other forms of technology that contribute to the quantity of data being produced, it would be incompetent to use such data if it lacks quality, highlighting the importance of data validation.</p>
<p>In this case study, we are going to consider two <span>DataFrames</span>:</p>
<ul>
<li>Test <span>DataFrame </span>(from a flat file)</li>
<li>Validation <span>DataFrame </span>(from MongoDB)</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Validation routines are performed on the test <span>DataFrame, </span>keeping its counterpart as the reference.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data overview</h1>
                </header>
            
            <article>
                
<p>The datasets considered here are part of the <strong>Learning Management System</strong> (<strong>LMS</strong>) data. They project information pertaining to student enrolment, tracking, reporting, and delivery of educational courses. Let's load the test <span>DataFrame </span>from the flat file:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/b1ea73e9-25bd-41f9-a6b4-7cbee992b41f.png"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Loading test <span>DataFrame </span>from flat file</div>
<p>The <kbd>pymongo</kbd> <span>library</span><span> i</span><span>s used to connect MongoDB to Python.</span> Generally, MongoDB listens on port <kbd>27017</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1689 image-border" src="assets/ac1e34df-1652-4b6d-804e-80f1f5cadc37.png" style="width:44.25em;height:13.58em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">MongoDB connection from Python</div>
<p>We can see the connection parameters in the following screenshot. Since the database is installed locally, we are connecting to it via localhost. The name of the loaded database is <kbd>lms_db</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/683b1c50-4e42-4bf8-a2c1-7dfa8b8ac53b.png"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Reading data from MongoDB</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Structured databases versus unstructured databases</h1>
                </header>
            
            <article>
                
<p>Since MongoDB falls under the category of unstructured databases, the terminology used widely differs from its structured counterparts, such as MySQL and PostgreSQL. The following table presents various SQL terminology and concepts and the corresponding MongoDB terminology and concepts: </p>
<table style="border-collapse: collapse" class="table" border="1">
<tbody>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>SQL terms/concepts</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>MongoDB terms/concepts</strong></p>
</td>
</tr>
<tr>
<td>
<p>database</p>
</td>
<td>
<p>Database (<a href="https://docs.mongodb.com/manual/reference/glossary/#term-database">h</a><a href="https://docs.mongodb.com/manual/reference/glossary/#term-database">ttps://docs.mongodb.com/manual/reference/glossary/#term-database</a><a href="https://docs.mongodb.com/manual/reference/glossary/#term-database">)</a></p>
</td>
</tr>
<tr>
<td>
<p>table</p>
</td>
<td>
<p>Collection (<a href="https://docs.mongodb.com/manual/reference/glossary/#term-collection">https://docs.mongodb.com/manual/reference/glossary/#term-collection</a>)</p>
</td>
</tr>
<tr>
<td>
<p>row</p>
</td>
<td>
<p>Document or BSON document</p>
</td>
</tr>
<tr>
<td>
<p>column</p>
</td>
<td>
<p>Field (<a href="https://docs.mongodb.com/manual/reference/glossary/#term-field">https://docs.mongodb.com/manual/reference/glossary/#term-field</a>)</p>
</td>
</tr>
<tr>
<td>
<p>index</p>
</td>
<td>
<p>Index (<a href="https://docs.mongodb.com/manual/reference/glossary/#term-index">https://docs.mongodb.com/manual/reference/glossary/#term-index</a>)</p>
</td>
</tr>
<tr>
<td>
<p>table joins</p>
</td>
<td>
<p><kbd>$lookup</kbd>, embedded documents (<a href="https://docs.mongodb.com/manual/reference/operator/aggregation/lookup/#pipe._S_lookup">https://docs.mongodb.com/manual/reference/operator/aggregation/lookup/#pipe._S_lookup</a>)</p>
</td>
</tr>
<tr>
<td>
<p>primary key</p>
</td>
<td>
<p>Primary key (<a href="https://docs.mongodb.com/manual/reference/glossary/#term-primary-key">https://docs.mongodb.com/manual/reference/glossary/#term-primary-key</a>)</p>
</td>
</tr>
<tr>
<td>
<p>Specify any unique column or column combination as primary key.</p>
</td>
<td>
<p>In MongoDB, the primary key is automatically set to the <kbd>_id</kbd> field. (<a href="https://docs.mongodb.com/manual/reference/glossary/#term-id">https://docs.mongodb.com/manual/reference/glossary/#term-id</a>)</p>
</td>
</tr>
<tr>
<td>
<p>aggregation (example group by)</p>
</td>
<td>
<p>Aggregation pipeline</p>
</td>
</tr>
<tr>
<td>
<p>transactions</p>
</td>
<td>
<p>Transactions (<a href="https://docs.mongodb.com/manual/core/transactions/">https://docs.mongodb.com/manual/core/transactions/</a>)</p>
</td>
</tr>
</tbody>
</table>
<div class="CDPAlignCenter CDPAlign packt_figref">Comparative view of SQL MongoDB terminologies</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Validating data types</h1>
                </header>
            
            <article>
                
<p>A data type is a property of a variable that Python uses to understand how to store and manipulate data. For instance, a program needs to understand that variables storing 5 and 10 are numeric to be able to add them and get 15, or that the variables storing <kbd>cat</kbd> and <kbd>hat</kbd> are strings so that they could be concatenated (added) together to get <kbd>cathat</kbd>. Hence it becomes a preliminary and cardinal property of any pandas <span>D</span>ataFrame.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>A user-defined comparison function can be used to validate the data types of the test DataFrame:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1690 image-border" src="assets/e612fdcc-3078-43d5-affc-f33a871cc54c.png" style="width:52.75em;height:24.00em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Validating data types of test DataFrame</div>
<p><kbd>File1</kbd> and <kbd>File2</kbd> correspond to the test and validation datasets respectively. It is evident from the output that all the data types of the test DataFrame match those of the validation DataFrame. If there is a mismatch, the output will display the number of columns that are inconsistent.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Validating dimensions</h1>
                </header>
            
            <article>
                
<p>A DataFrame is a two-dimensional data structure where data is presented in a tabular manner, much like a relational database table, in rows and columns. One of the basic methods to check whether the test and validation datasets are matching is to equate the number of rows and columns. If the shapes of the DataFrames do not match, it becomes clearly evident that the test DataFrame is different from the validation one. The following is a screenshot that shows how to validate dimensions:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1691 image-border" src="assets/10056043-7eb1-4884-9719-17df84ac20dd.png" style="width:39.92em;height:34.25em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Validating dimensions</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Validating individual entries</h1>
                </header>
            
            <article>
                
<p>Once the first two test cases are satisfied, it becomes highly important to scan individual entries to find spurious data. <span><span>The validation process in the preceding figure </span></span>describes the difference between a value obtained from a data collection process and the true value. As the amount of data increases, validating entries becomes difficult. This effect can be diminished by efficiently utilizing pandas. In the following example, individual entries have been scanned using both looping (the brute force method) and pandas indexing.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using pandas indexing</h1>
                </header>
            
            <article>
                
<p>The following screenshot shows how to validate cells using pandas:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/229fbaa0-4d36-4ead-92c6-a1bb93f15028.png"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Validating cells using pandas indexing</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using loops</h1>
                </header>
            
            <article>
                
<p>The following screenshot shows how to validate cells by using loops:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1692 image-border" src="assets/d3e02c99-beba-4d35-8f5b-f062d92522d0.png" style="width:26.92em;height:17.08em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Validating cells using loops</div>
<p>The results were highly encouraging when we used pandas indexing. It took only 0.53 seconds to validate a DataFrame with 200,000 rows and 15 columns, whereas the same validation routine took more than 7 minutes to complete using loops. Therefore it is always recommended to leverage the power of pandas and avoid iterative programming.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>pandas is useful for a lot of ancillary data activities, such as exploratory data analysis, validating the sanctity (such as the data type or count) of data between two data sources, and structuring and shaping data obtained from another source, such as scraping a website or a database. In this chapter, we dealt with some case studies on these topics. A data scientist performs these activities on a day-to-day basis, and this chapter should give a flavor of what it is like to perform them on a real dataset.</p>
<p>In the next chapter, we will discuss the architecture and code structure of the pandas library. This will help us develop an exhaustive understanding of the functionalities of the library and enable us to do better troubleshooting.</p>


            </article>

            
        </section>
    </body></html>