- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Addressing Data Issues When Combining DataFrames
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At some point during most data cleaning projects, the analyst will have to combine
    data from different data tables. This involves either appending data with the
    same structure to existing data rows or doing a merge to retrieve columns from
    a different data table. The former is sometimes referred to as combining data
    vertically, or concatenating, while the latter is referred to as combining data
    horizontally, or merging.
  prefs: []
  type: TYPE_NORMAL
- en: Merges can be categorized by the amount of duplication of merge-by column values.
    With one-to-one merges, merge-by column values appear once on each data table.
    One-to-many merges have unduplicated merge-by column values on one side of the
    merge and duplicated merge-by column values on the other side. Many-to-many merges
    have duplicated merge-by column values on both sides. Merging is further complicated
    by the fact that there is often no perfect correspondence between merge-by values
    on the data tables; each data table may have values in the merge-by column that
    are not present in the other data table.
  prefs: []
  type: TYPE_NORMAL
- en: New data issues can be introduced when data is combined. When data is appended,
    it may have different logical values than the original data, even when the columns
    have the same names and data types. For merges, whenever merge-by values are missing
    on one side of a merge, the other columns from that side will also have missing
    values. For one-to-one or one-to-many merges, there may be unexpected duplicates
    in merge-by values, resulting in values for other columns being duplicated unintentionally.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will combine DataFrames vertically and horizontally and
    consider strategies for dealing with the data problems that often arise. Specifically,
    in this chapter, the recipes will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Combining DataFrames vertically
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doing one-to-one merges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doing one-to-one merges by multiple columns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doing one-to-many merges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doing many-to-many merges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing a merge routine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need pandas, NumPy, and Matplotlib to complete the recipes in this
    chapter. I used pandas 2.1.4, but the code will run on pandas 1.5.3 or later.
  prefs: []
  type: TYPE_NORMAL
- en: The code in this chapter can be downloaded from the book’s GitHub repository,
    [https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition](https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition).
  prefs: []
  type: TYPE_NORMAL
- en: Combining DataFrames vertically
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are times when we need to append rows from one data table to another.
    This will almost always be rows from data tables that have nearly the same columns
    and data types. For example, we might get a new CSV file containing hospital patient
    outcomes each month and need to add that to our existing data. Alternatively,
    we might end up working at a school district central office and receive data from
    many different schools. We might want to combine this data before conducting analyses.
  prefs: []
  type: TYPE_NORMAL
- en: Even when the data structure across months and across schools (in these examples)
    is theoretically the same, it may not be in practice. Business practices can change
    from one period to another. This can be intentional or happen inadvertently due
    to staff turnover or some external factor. One institution or department might
    implement practices somewhat differently than another, and some data values might
    be different for some institutions or missing altogether.
  prefs: []
  type: TYPE_NORMAL
- en: We are likely to come across a change in what seems like similar data when we
    let our guards down, typically when we start to assume that the new data will
    look like the old data. I try to remember this whenever I combine data vertically.
    I will be referring to combining data vertically as concatenating or appending
    for the rest of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we’ll use the pandas `concat` function to append rows from a
    pandas DataFrame to another DataFrame. We will also do a few common checks on
    the `concat` operation to confirm that the resulting DataFrame is what we expected.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will work with land temperature data from several countries in this recipe.
    This data includes the monthly average temperature, latitude, longitude, and elevation
    at many weather stations in each country during 2023\. The data for each country
    is contained in a CSV file.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data note**'
  prefs: []
  type: TYPE_NORMAL
- en: The land temperature DataFrame has the average temperature reading (in °C) in
    2023 from over 12,000 stations across the world, though a majority of the stations
    are in the United States. The raw data was retrieved from the Global Historical
    Climatology Network integrated database. It is made available for public use by
    the United States National Oceanic and Atmospheric Administration at [https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-monthly](https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-monthly).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we will combine similarly structured DataFrames vertically,
    check the values in the concatenated data, and fix missing values. Let’s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and `numpy`, as well as the `os` module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the data from Cameroon and Oman and check the number of rows and columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compare the columns in the Cameroon and Oman DataFrames. Glancing at the columns,
    we can see that the Cameroon DataFrame has the `latabs` column and the Oman DataFrame
    does not. We can confirm this, and that there are no other columns in one DataFrame
    but not the other, using `symetric_difference`. It shows that `latabs` is the
    only column in just one DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can still concatenate the two DataFrames. The only problem is that we now
    have one column, `latabs`, that has non-missing values for all rows for Cameroon
    and all missing values for Oman. We address this problem in the last step of this
    recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Create a function to do the concatenation that incorporates some of the data
    checks we have done. The function takes a list of filenames, loops through the
    list, reads the CSV file associated with each filename into a DataFrame, and then
    concatenates the DataFrame. We get the expected counts. We did not check the column
    names. We will do that in the next step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If we have many files to concatenate, it might be burdensome to create a list
    of the filenames. We can get Python’s `os` module to help us with that by loading
    all files with a CSV file extension in a folder. Let’s do that next, and also
    add some code to check columns. We will build on the code from the previous step.
  prefs: []
  type: TYPE_NORMAL
- en: Concatenate all the country data files in a folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Loop through all the filenames in the folder that contains the CSV files for
    each country. Use the `endswith` method to check that the filenames have a CSV
    file extension. Use `read_csv` to create a new DataFrame and print out the number
    of rows. Use `concat` to append the rows of the new DataFrame to the rows that
    have already been appended. Finally, display any columns that are missing in the
    most recent DataFrame, or that are in the most recent DataFrame but not the previous
    ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the function we just created to read all of the country CSV files in a
    subfolder, show the number of rows, and check column names. We see again that
    the `ltoman` DataFrame is missing the `latabs` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Show some of the combined data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Check the values in the concatenated data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Notice that the values for `latabs` for Oman are all missing. This is because
    `latabs` is missing in the DataFrame for Oman (`latabs` is the absolute value
    of the latitude for each station):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Fix the missing values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set the value of `latabs` to the value of `latitude` for Oman. (All of the
    `latitude` values for stations in Oman are above the equator and positive. In
    the Global Historical Climatology Network integrated database, latitude values
    above the equator are positive, while all the latitude values below the equator
    are negative). Do this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: With that, we have combined the data for the seven CSV files we found in the
    selected folder. We have also confirmed that we have appended the correct number
    of rows, identified columns that are missing in some files, and fixed missing
    values.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We passed a list of pandas DataFrames to the pandas `concat` function in *step
    3*. The rows from the second DataFrame were appended to the bottom of the first
    DataFrame. If we had listed a third DataFrame, those rows would have been appended
    to the combined rows of the first two DataFrames. Before concatenating, we used
    the `shape` attribute to check the number of rows in *step 2* and checked the
    column names. After concatenation in *step 3*, we confirmed that the resulting
    DataFrame contained the number of expected rows for each country.
  prefs: []
  type: TYPE_NORMAL
- en: We sometimes have to concatenate more than two or three files. *Steps 4* through
    *6* walked us through handling many files by defining a function to repeat the
    code. In *step 4*, we passed a list of filenames to that function.
  prefs: []
  type: TYPE_NORMAL
- en: In *steps 5* and *6*, we looked for all the CSV files in a specified folder,
    loaded each file that was found into memory, and then appended the rows of each
    file to a DataFrame. We printed the number of rows for each data file we loaded
    so that we could check those numbers against the totals in the concatenated data
    later. We also identified any DataFrames with different columns compared to the
    others. We used `value_counts` in *step 8* to confirm that there were the right
    number of rows for each country.
  prefs: []
  type: TYPE_NORMAL
- en: The pandas `groupby` method can be used to check column values from each of
    the original DataFrames. We group by country since that identifies the rows from
    each of the original DataFrames—all the rows for each DataFrame have the same
    value for country. (It is helpful to always have a column that identifies the
    original DataFrames in the concatenated DataFrame, even if that information is
    not needed for subsequent analysis.) In *step 8*, this helped us notice that there
    were no values for the `latabs` column for Oman. We replaced the missing values
    for `latabs` for Oman in *step 9*.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Depending on the size of the DataFrames you are appending, and the available
    memory of your workstation, combining DataFrames may tax your machine’s resources,
    or even cause the code to end prematurely once RAM usage exceeds a certain amount
    of your resources. It is always a good idea to make sure that your data files
    store data as efficiently as possible. For example, downcasting numeric values
    and making character data categorical when appropriate are good practices.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We went over the powerful pandas `groupby` method in some detail in *Chapter
    9*, *Fixing Messy Data When Aggregating.*
  prefs: []
  type: TYPE_NORMAL
- en: We examined NumPy’s `where` function in *Chapter 6*, *Cleaning and Exploring
    Data with Series Operations*.
  prefs: []
  type: TYPE_NORMAL
- en: Doing one-to-one merges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The remainder of this chapter will explore combining data horizontally; that
    is, merging columns from a data table with columns from another data table. Borrowing
    from SQL development, we typically talk about such operations as join operations:
    left joins, right joins, inner joins, and outer joins. This recipe examines one-to-one
    merges, where the merge-by values are unduplicated in both files. Subsequent recipes
    will demonstrate one-to-many merges, where the merge-by values are duplicated
    on the *right* data table, and many-to-many merges, where merge-by values are
    duplicated on both the *left and right* data tables.'
  prefs: []
  type: TYPE_NORMAL
- en: We often speak of the left and right sides of a merge, a convention that we
    will follow throughout this chapter. But this is of no real consequence, other
    than for clarity of exposition. We can accomplish exactly the same thing with
    a merge if A were the left data table and B were the right data table, as we could
    if the reverse were true.
  prefs: []
  type: TYPE_NORMAL
- en: I am using the expressions merge-by column and merge-by value in this chapter,
    rather than key column or index column. This avoids possible confusion with pandas
    index alignment. An index may be used as the merge-by column, but other columns
    may also be used. I also want to avoid relying on relational database concepts
    such as primary or foreign keys in this discussion. It is helpful to be aware
    of which data columns function as primary or foreign keys when we’re extracting
    data from relational systems, and we should take this into account when setting
    indexes in pandas. But the merging we do for most data cleaning projects often
    goes beyond these keys.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the straightforward case of a one-to-one merge, each row in the left data
    table is matched with one (and only one) row on the right data table, according
    to the merge-by value. What happens when a merge-by value appears on one, but
    not the other, data table is determined by the type of join that’s specified.
    The following diagram illustrates the four different types of joins:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18596_10_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.1: A diagram illustrating the four different types of joins'
  prefs: []
  type: TYPE_NORMAL
- en: When two data tables are merged with an inner join, rows are retained when the
    merge-by values appear in both the left and right data tables. This is the intersection
    of the left and right data tables, represented by **B** in the preceding diagram.
    Outer joins return all rows; that is, rows where the merge-by values appear in
    both data tables, rows where those values appear in the left data table but not
    the right, and rows where those values appear in the right but not the left—**B**,
    **A**, and **C**, respectively. This is known as the union. Left joins return
    rows where the merge-by values are present on the left data table, regardless
    of whether they are present on the right data table. This is **A** and **B**.
    Right joins return rows where the merge-by values are present on the right data
    table, regardless of whether they are present on the left data table.
  prefs: []
  type: TYPE_NORMAL
- en: Missing values may result from outer joins, left joins, or right joins. This
    is because the returned merged data table will have missing values for columns
    when the merge-by value is not found. For example, when performing a left join,
    there may be merge-by values from the left dataset that do not appear on the right
    dataset. In this case, the columns from the right dataset will all be missing.
    (I say *may* here because it is possible to do an outer, left, or right join that
    returns the same results as an inner join because the same merge-by values appear
    on both sides. Sometimes, a left join is done so that we’re certain that all the
    rows on the left dataset, and only those rows, are returned.)
  prefs: []
  type: TYPE_NORMAL
- en: We will look at all four types of joins in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will work with two files from the **National Longitudinal Surveys** (**NLS**).
    Both files contain one row per person. One contains employment, educational attainment,
    and income data, while the other file contains data on the income and educational
    attainment of the respondents’ parents.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data note**'
  prefs: []
  type: TYPE_NORMAL
- en: The **National Longitudinal Surveys** (**NLS**), administered by the United
    States Bureau of Labor Statistics, are longitudinal surveys of individuals who
    were in high school in 1997 when the surveys started. Participants were surveyed
    each year through 2023\. The surveys are available for public use at [nlsinfo.org](https://nlsinfo.org).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we will perform left, right, inner, and outer joins on two
    DataFrames that have one row for each merge-by value. Let’s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and load the two NLS DataFrames:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Look at some of the NLS data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Check that the number of unique values for `originalid` is equal to the number
    of rows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We will use `originalid` for our merge-by column later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Create some mismatched IDs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Unfortunately, the NLS data is a little too clean for our purposes. Due to
    this, we will mess up a couple of values for `originalid`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Use `join` to perform a left join.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`nls97` is the left DataFrame and `nls97add` is the right DataFrame when we
    use `join` in this way. Show the values for the mismatched IDs. Notice that the
    values for the columns from the right DataFrame are all missing when there is
    no matching ID on that DataFrame (the `orignalid` values 10001 and 10002 appear
    on the left DataFrame but not on the right DataFrame):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Perform a left join with `merge`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The first DataFrame is the left DataFrame, while the second DataFrame is the
    right DataFrame. Use the `on` parameter to indicate the merge-by column. Set the
    value of the `how` parameter to `left` to do a left join. We get the same results
    that we get when using `join`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Perform a right join.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'With a right join, the values from the left DataFrame are missing when there
    is no matching ID on the left DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Perform an inner join.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'None of the mismatched IDs (that have values over `9999`) appear after the
    inner join. This is because they do not appear on both DataFrames:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Perform an outer join.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This retains all the rows, so rows with merge-by values in the left DataFrame
    but not in the right are retained (`originalid` values `10001` and `10002`), and
    rows with merge-by values in the right DataFrame but not in the left are also
    retained (`originalid` values `20001` and `20002`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Create a function to check for ID mismatches.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The function takes a left and right DataFrame, as well as a merge-by column.
    It performs an outer join because we want to see which merge-by values are present
    in either DataFrame, or both of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: With that, we have demonstrated how to perform the four types of joins with
    a one-to-one merge.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One-to-one merges are fairly straightforward. The merge-by column values only
    appear once on the left and right DataFrames. However, some merge-by column values
    may appear on only one DataFrame. This is what makes the type of join important.
    If all merge-by column values appeared on both DataFrames, then a left join, right
    join, inner join, or outer join would return the same result. We took a look at
    the two DataFrames in the first few steps.
  prefs: []
  type: TYPE_NORMAL
- en: In *step 3*, we confirmed that the number of unique values for the merge-by
    column (`originalid`) is equal to the number of rows in both DataFrames. This
    tells us that we will be doing a one-to-one merge.
  prefs: []
  type: TYPE_NORMAL
- en: If the merge-by column is the index, then the easiest way to perform a left
    join is to use the `join` DataFrame method. We did this in *step 5*. We passed
    the right DataFrame to the `join` method of the left DataFrame. The same result
    was returned when we performed a left join using the pandas `merge` function in
    *step 6*. We used the `how` parameter to specify a left join and indicated the
    merge-by column using `on`.
  prefs: []
  type: TYPE_NORMAL
- en: In *steps 7* to *9*, we performed the right, inner, and outer joins, respectively.
    This is specified by the `how` value, which is the only part of the code that
    is different across these steps.
  prefs: []
  type: TYPE_NORMAL
- en: The simple `checkmerge` function we created in *step 10* counted the number
    of rows with merge-by column values on one DataFrame but not the other, and the
    number of values on both. Passing copies of the two DataFrames to this function
    tells us that two rows are in the left DataFrame and not in the right, two rows
    are in the right DataFrame but not the left, and 8,982 rows are in both.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You should run a function similar to the `checkmerge` function we created in
    *step 10* before you do any non-trivial merge—which, in my opinion, is pretty
    much all merges.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `merge` function is more flexible than the examples I have used in this
    recipe suggest. For example, in *step 6*, we did not have to specify the left
    DataFrame as the first parameter. I could have indicated the left and right DataFrames
    explicitly, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also specify different merge-by columns for the left and right DataFrames
    by using `left_on` and `right_on` instead of `on`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: The flexibility of the `merge` function makes it a great tool any time we need
    to combine data horizontally.
  prefs: []
  type: TYPE_NORMAL
- en: Doing one-to-one merges by multiple columns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The same logic we used to perform one-to-one merges with one merge-by column
    applies to merges we perform with multiple merge-by columns. Inner, outer, left,
    and right joins work the same way when you have two or more merge-by columns.
    We will demonstrate this in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will work with the NLS data in this recipe, specifically weeks worked and
    college enrollment from 2017 through 2021\. Both the weeks worked and college
    enrollment files contain one row per person, per year.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will do a one-to-one merge with two DataFrames using multiple merge-by columns
    on each DataFrame. Let’s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and load the NLS weeks worked and college enrollment data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Look at some of the NLS weeks worked data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Look at some of the NLS college enrollment data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Check for unique values in the merge-by columns.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We get the same number of merge-by column value combinations (`44,920`) as
    the number of rows in both DataFrames:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Check for mismatches in the merge-by columns. All `originalid` and `year` combinations
    appear on both files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Perform a merge with multiple merge-by columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: These steps demonstrate that the syntax for running merges changes very little
    when there are multiple merge-by columns.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every person in the NLS data has five rows for both the weeks worked and college
    enrollment DataFrames, with one for each year between 2017 and 2021\. Both files
    contain 44,920 rows with 8,984 unique individuals (indicated by `originalid`).
    This all makes sense (8,984*5=44,920).
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 4* confirmed that the combination of columns we will be using for the
    merge-by columns will not be duplicated, even if individuals are duplicated. Each
    person has only one row for each year. This means that the merging of the weeks
    worked and college enrollment data will be a one-to-one merge. In *step 5*, we
    checked to see whether there were any individual and year combinations that were
    in one DataFrame but not the other. There were none.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we were ready to do the merge in *step 6*. We set the `on` parameter
    to a list with two column names (`['originalid','year']`) to tell the merge function
    to use both columns in the merge. We specified an inner join, even though we would
    get the same results with any join. This is because the same merge-by values are
    present in both files.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All the logic and potential issues in merging data that we discussed in the
    previous recipe apply, regardless of whether we are merging with one merge-by
    column or several. Inner, outer, right, and left joins work the same way. We can
    still calculate the number of rows that will be returned before doing the merge.
    We should also check for the number of unique merge-by values and for matches
    between the DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: If you have worked with recipes in earlier chapters that used the NLS weeks
    worked and college enrollment data, you probably noticed that it is structured
    differently here. In previous recipes, there was one row per person, with multiple
    columns for weeks worked and college enrollment, representing weeks worked and
    college enrollment for multiple years. For example, `weeksworked21` is the number
    of weeks worked in 2021\. The structure of the weeks worked and college enrollment
    DataFrames we used in this recipe is considered *tidier* than the NLS DataFrame
    we used in earlier recipes. We’ll learn how to tidy data in *Chapter 11*, *Tidying
    and Reshaping Data*.
  prefs: []
  type: TYPE_NORMAL
- en: Doing one-to-many merges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In one-to-many merges, there are unduplicated values for the merge-by column
    or columns on the left data table and duplicated values for those columns on the
    right data table. For these merges, we usually do either an inner join or a left
    join. Which of those two join types we use matters when merge-by values are missing
    on the right data table. When performing a left join, all the rows that would
    be returned from an inner join will be returned, plus one row for each merge-by
    value present on the left dataset, but not the right. For those additional rows,
    values for all the columns on the right dataset will be missing in the resulting
    merged data. This relatively straightforward fact ends up mattering a fair bit
    and should be thought through carefully before you code a one-to-many merge.
  prefs: []
  type: TYPE_NORMAL
- en: This is where I start to get nervous, and where I think it makes sense to be
    a little nervous. When I do workshops on data cleaning, I pause before starting
    this topic and say, *“Do not start a one-to-many merge until you are able to bring
    a friend with you.”*
  prefs: []
  type: TYPE_NORMAL
- en: I am joking, of course… mostly. The point I am trying to make is that something
    should happen to get us to pause before doing a non-trivial merge, and one-to-many
    merges are never trivial. Too much about the structure of our data can change.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, there are several things we want to know about the two DataFrames
    we will be merging before starting. First, we should know what columns make sense
    as merge-by columns on each DataFrame. One-to-many merges are often used to recapture
    relationships from an enterprise database system and need to be consistent with
    the primary keys and foreign keys used. (The primary key on the left data table
    is often linked to the foreign key on the right data table in a relational database.)
    Second, we should know what kind of join we will be using and why.
  prefs: []
  type: TYPE_NORMAL
- en: Third, we should know how many rows are on both data tables. Fourth, we should
    have a good idea of how many rows will be retained based on the type of join,
    the number of rows in each dataset, and preliminary checks on how many of the
    merge-by values will match. If all the merge-by values are present on both datasets
    or if we are doing an inner join, then the number of rows will be equal to the
    number of rows of the right dataset of a one-to-many merge. But it is often not
    as straightforward as that. We frequently perform left joins with one-to-many
    merges. With a left join, the number of retained rows will be equal to the number
    of rows in the right dataset with a matching merge-by value, plus the number of
    rows in the left dataset with non-matching merge-by values.
  prefs: []
  type: TYPE_NORMAL
- en: This should be clearer once we’ve worked through the examples in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will be working with data based on weather stations from the Global Historical
    Climatology Network integrated database for this recipe. One of the DataFrames
    contains one row for each country. The other contains one row for each weather
    station. There are typically many weather stations for each country.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we will do a one-to-many merge of data for countries, which
    contains one row per country, with weather station data, which contains multiple
    stations for each country. Let’s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and load the weather station and country data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Set the index for the weather station (`locations`) and country data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Confirm that the merge-by values for the `countries` DataFrame are unique:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'Perform a left join of countries and locations using `join`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The join seemed to work fine. But let’s try using merge instead.
  prefs: []
  type: TYPE_NORMAL
- en: Check for merge-by column mismatches before doing the merge.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, reload the DataFrames since we have made some changes. The `checkmerge`
    function shows that there are `27,472` rows with merge-by values (from `countryid`)
    in both DataFrames and 2 in `countries` (the left DataFrame) but not in `locations`.
    This indicates that an inner join would return `27,472` rows and a left join would
    return `27,474` rows. The last statement in the function identifies the `countryid`
    values that appear in one DataFrame but not the other:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: Show the rows in one file but not the other.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The last statement in the previous step displays the two values of `countryid`
    in `countries` but not in `locations`, and the one in `locations` but not in `countries`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: Merge the `locations` and `countries` DataFrames.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Perform a left join. Also, count the number of missing values for each column,
    where merge-by values are present in the countries data but not in the weather
    station data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: The one-to-many merge returns the expected number of rows and new missing values.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In *step 3*, we used the `join` DataFrame method to perform a left join of the
    `countries` and `locations` DataFrames. This is the easiest way to do a merge.
    Since the `join` method uses the index of the DataFrames for the merge, we need
    to set the index first. We then passed the right DataFrame to the `join` method
    of the left DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Although `join` is a little more flexible than this example suggests (you can
    specify the type of join, for example), I prefer the more verbose pandas `merge`
    function for all but the simplest of merges. I can be confident when using the
    `merge` function that all the options I need are available to me. Before we used
    the `merge` function, we did some checks in *step 4*. This told us how many rows
    to expect in the merged DataFrame if we were to do an inner or left join; there
    would be 27,472 or 27,474 rows, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: We also displayed the rows with merge-by values in one DataFrame but not the
    other. If we are going to do a left join, we need to decide what to do with the
    missing values that will result from the right DataFrame. In this case, there
    were two merge-by values that were not found on the right DataFrame, giving us
    missing values for those columns.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You may have noticed that in our call to `checkmerge`, we passed copies of
    the `countries` and `locations` DataFrames:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: We use `copy` here because we do not want the `checkmerge` function to make
    any changes to our original DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We discussed join types in detail in the *Doing one-to-one merges* recipe in
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Doing many-to-many merges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many-to-many merges have duplicate merge-by values in both the left and right
    DataFrames. We should only rarely need to do a many-to-many merge. Even when data
    comes to us in that form, it is often because we are missing the central file
    in multiple one-to-many relationships. For example, there are donor, donor contributions,
    and donor contact information data tables, and the last two files contain multiple
    rows per donor. However, in this case, we do not have access to the donor file,
    which has a one-to-many relationship with both the contributions and contact information
    files. This happens more frequently than you may think. People sometimes give
    us data with little awareness of the underlying structure. When I do a many-to-many
    merge, it is typically because I am missing some key information rather than because
    that was how the database was designed.
  prefs: []
  type: TYPE_NORMAL
- en: Many-to-many merges return the Cartesian product of the merge-by column values.
    So, if a donor ID appears twice on the donor contact information file and five
    times on the donor contributions file, then the merge will return 10 rows. This
    is often quite problematic analytically. In this example, a many-to-many merge
    will duplicate the donor contributions, once for each address.
  prefs: []
  type: TYPE_NORMAL
- en: Often, when faced with a potential many-to-many merge situation, the solution
    is not to do it. Instead, we can recover the implied one-to-many relationships.
    With the donor example, we could remove all the rows except for the most recent
    contact information, thus ensuring that there is one row per donor. We could then
    do a one-to-many merge with the donor contributions file. But we are not always
    able to avoid doing a many-to-many merge. Sometimes, we must produce an analytical
    or flat file that keeps all of the data, without regard for duplication. This
    recipe demonstrates how to do those merges when that is required.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will work with data based on the Cleveland Museum of Art’s collections.
    We will use two CSV files: one containing each media citation for each item in
    the collection and another containing the creator(s) of each item.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data note**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Cleveland Museum of Art provides an API for public access to this data:
    [https://openaccess-api.clevelandart.org/](https://openaccess-api.clevelandart.org/).
    Much more than the citations and creators data is available in the API. The data
    in this recipe was downloaded in April 2024.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to complete this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load `pandas` and the **Cleveland Museum of Art** (**CMA**) collections data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Look at the `citations` data. The `itemid` is the identifier for a collection
    item. The first 10 citations are all for collection item `94979`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Look at the `creators` data. The `creatorid` is the identifier of the creator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE120]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE121]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE122]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Show duplicates of merge-by values in the `citations` data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'There are 182 media citations for collection item 148758:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: 'Show duplicates of the merge-by values in the `creators` data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE126]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Check the merge.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the `checkmerge` function we used in the *Doing one-to-many merges* recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: 'Show a merge-by value duplicated in both DataFrames:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE130]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE131]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE132]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Do a many-to-many merge:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE134]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that I have taken you through the messiness of a many-to-many merge, I’ll
    say a little more about how it works.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Step 2* told us that there were 16,053 citations for 974 unique items. There
    is a unique ID, `itemid`, for each item in the museum’s collection. On average,
    each item has 16 media citations (16,053/974). *Step 3* told us that there are
    694 creators over 618 items that have a creator, so there is only one creator
    for the overwhelming majority of pieces. But the fact that there are duplicated
    `itemid`s (our merge-by value) on both the `citations` and `creators` DataFrames
    means that our merge will be a many-to-many merge.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 4* gave us a sense of which `itemid`s are duplicated on the `citations`
    DataFrame. Some items in the museum’s collection have more than 100 citations.
    It is worth taking a closer look at the citations for those items to see whether
    they make sense. *Step 5* showed us that even when there is more than one creator,
    there are rarely more than three. In *step 6*, we saw that most `itemid`s appear
    in both the `citations` file and the `creators` file, but a fair number have `citations`
    rows but no `creators` rows. We will lose those 4,277 rows if we do an inner join
    or a right join, but not if we do a left join or an outer join. (This assumes
    that the `citations` DataFrame is the left DataFrame and the `creators` DataFrame
    is the right one.)'
  prefs: []
  type: TYPE_NORMAL
- en: We looked at an `itemid` value that is duplicated in both DataFrames in *step
    7*. There are 14 rows for this collection item in the `citations` DataFrame and
    2 in the `creators` DataFrame. This will result in 28 rows (2 * 14) with that
    `itemid` in the merged DataFrame. The `citations` data will be repeated for each
    row in `creators`.
  prefs: []
  type: TYPE_NORMAL
- en: This was confirmed when we looked at the results of the merge in *step 8*. We
    performed an outer join with `itemid` as the merge-by column. When we displayed
    the rows in the merged file for the same ID we used in *step 7*, we got the 28
    rows we were expecting (I removed the last 14 rows of output to save space).
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is good to understand what to expect when we do a many-to-many merge because
    there are times when it cannot be avoided. But even in this case, we can tell
    that the many-to-many relationship is really just two one-to-many relationships
    with the data file missing from the one side. There is likely a data table that
    contains one row per collection item that has a one-to-many relationship with
    both the `citations` data and the `creators` data. When we do not have access
    to a file like that, it is probably best to try to reproduce a file with that
    structure. With this data, we could have created a file containing `itemid` and
    maybe `title`, and then done one-to-many merges with the `citations` and `creators`
    data.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are occasions when we must produce a flat file for subsequent
    analysis. We might need to do that when we, or a colleague who is getting the
    cleaned data from us, are using software that cannot handle relational data well.
    For example, someone in another department might do a lot of data visualization
    work with Excel. As long as that person knows which analyses require them to remove
    duplicated rows, a file with a structure like the one we produced in *step 8*
    might work fine.
  prefs: []
  type: TYPE_NORMAL
- en: Developing a merge routine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I find it helpful to think of merging data as the parking lot of the data cleaning
    process. Merging data and parking may seem routine, but they are where a disproportionate
    number of accidents occur. One approach to getting in and out of parking lots
    without an incident occurring is to use a similar strategy each time you go to
    a particular lot. It could be that you always go to a relatively low-traffic area
    and you get to that area the same way most of the time.
  prefs: []
  type: TYPE_NORMAL
- en: I think a similar approach can be applied to getting in and out of merges with
    our data relatively unscathed. If we choose a general approach that works for
    us 80 to 90 percent of the time, we can focus on what is most important—the data,
    rather than the techniques for manipulating that data.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, I will demonstrate the general approach that works for me, but
    the particular techniques I will use are not very important. I think it is just
    helpful to have an approach that you understand well and that you become comfortable
    using.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will return to the objectives we focused on in the *Doing one-to-many merges*
    recipe of this chapter. We want to do a left join of the `countries` data with
    the `locations` data from the Global Historical Climatology Network integrated
    database.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we will do a left join of the `countries` and `locations` data
    after checking for merge-by value mismatches. Let’s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and load the weather station and country data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the merge-by column matches:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE137]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Merge the country and location data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE139]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE140]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE141]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, we got the expected number of rows from a left join: `27,472` rows with
    merge-by values in both DataFrames and two rows with merge-by values in the left
    DataFrame, but not the right.'
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the overwhelming majority of merges I do, something like the logic used
    in *steps 2* and *3* works well. We added a fourth argument to the `checkmerge`
    function we used in the previous recipe. This allows us to specify different merge-by
    columns for the left and right DataFrames. We do not need to recreate this function
    every time we do a merge. We can just include it in a module that we import. (We’ll
    go over adding helper functions to modules in the final chapter of this book.)
  prefs: []
  type: TYPE_NORMAL
- en: Calling the `checkmerge` function before running a merge gives us enough information
    so that we know what to expect when running the merge with different join types.
    We will know how many rows will be returned from an inner, outer, left, or right
    join. We will also know where new missing values will be generated before we run
    the actual merge. Of course, this is a fairly expensive operation, requiring us
    to run a merge twice each time—one diagnostic outer join followed by whatever
    join we subsequently choose. But I would argue that it is usually worth it, if
    for no other reason than that it helps us to stop and think about what we are
    doing.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we performed the merge in *step 3*. This is my preferred syntax. I
    always use the left DataFrame for the first argument and the right DataFrame for
    the second argument, though `merge` allows us to specify the left and right DataFrames
    in different ways. I also set values for `left_on` and `right_on`, even if the
    merge-by column is the same and I could use `on` instead (as we did in the previous
    recipe). This is so I will not have to change the syntax in cases where the merge-by
    column is different, and I like that it makes the merge-by column explicit for
    both DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: A somewhat more controversial routine is that I default to a left join, setting
    the `how` parameter to left initially. I make that my starting assumption and
    then ask myself if there is any reason to do a different join. The rows in the
    left DataFrame often represent my unit of analysis (students, patients, customers,
    and so on) and I am adding supplemental data from the right DataFrame (GPA, blood
    pressure, zip code, and so on). It may be problematic to remove rows from the
    unit of analysis because the merge-by value is not present on the right DataFrame,
    as would happen if I did an inner join instead. For example, in the *Doing one-to-one
    merges* recipe of this chapter, it probably would not have made sense to remove
    rows from the main NLS data because they did not appear on the supplemental data
    we have for parents.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will create modules with useful data cleaning functions in *Chapter 12*,
    *Automate Data Cleaning with User-Defined Functions, Classes and Pipelines*.
  prefs: []
  type: TYPE_NORMAL
- en: We have discussed the types of joins in the *Doing one-to-one merges* recipe
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We carefully examined combining data vertically, also known as concatenating,
    and combining data horizontally, also known as merging, in this chapter. We went
    over key data issues when concatenating data, including different columns across
    files. We also considered key issues with merging data, such as missing merge-by
    column values and the unexpected duplication of data. We looked at how those issues
    change with the type of join used. In the next chapter, we will learn about tidying
    and reshaping messy data.
  prefs: []
  type: TYPE_NORMAL
- en: Leave a review!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Enjoying this book? Help readers like you by leaving an Amazon review. Scan
    the QR code below to get a free eBook of your choice.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Review_copy.png)'
  prefs: []
  type: TYPE_IMG
