- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In today’s fast-paced data-driven world, it’s easy to be dazzled by the headlines
    about **artificial intelligence** (**AI**) breakthroughs and advanced **machine
    learning** (**ML**) models. But ask any seasoned data scientist or engineer, and
    they’ll tell you the same thing: *the true foundation of any successful data project
    is not the flashy algorithms or sophisticated models—it’s the data itself, and
    more importantly, how that data* *is prepared*.'
  prefs: []
  type: TYPE_NORMAL
- en: Throughout my career, I have learned that data preprocessing is the unsung hero
    of data science. It’s the meticulous, often complex process that turns raw data
    into a reliable asset, ready for analysis, modeling, and ultimately, decision-making.
    I’ve seen firsthand how the right preprocessing techniques can transform an organization’s
    approach to data, turning potential challenges into powerful opportunities.
  prefs: []
  type: TYPE_NORMAL
- en: Yet, despite its importance, data preprocessing is often overlooked or undervalued.
    Many see it as a tedious step, a bottleneck that slows down the exciting work
    of building models and delivering insights. But I’ve always believed that this
    phase is where the most critical work happens. After all, even the most sophisticated
    algorithms can’t make up for poor-quality data. That’s why I’ve dedicated much
    of my professional journey to mastering this art—exploring the best tools, techniques,
    and strategies to make preprocessing more efficient, scalable, and aligned with
    the ever-evolving landscape of AI.
  prefs: []
  type: TYPE_NORMAL
- en: This book aims to demystify the data preprocessing process, offering both a
    solid grounding in traditional methods and a forward-looking perspective on emerging
    techniques. We’ll explore how Python can be leveraged to clean, transform, and
    organize data more effectively. We’ll also look at how the advent of **large language
    models** (**LLMs**) is redefining what’s possible in this space. These models
    are already proving to be game changers, automating tasks that were once manual
    and time-consuming, and providing new ways to enhance data quality and usability.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the pages, I’ll share insights from my experiences, the challenges
    faced, and the lessons learned along the way. My hope is to provide you with not
    just a technical roadmap but also a deeper understanding of the strategic importance
    of data preprocessing in today’s data ecosystem. I strongly believe in the philosophy
    of “learning by doing,” so this book includes a wealth of code examples for you
    to follow along with. I encourage you to try these examples, experiment with the
    code, and challenge yourself to apply the techniques to your own datasets.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this book, you’ll be equipped with the knowledge and skills to
    approach data preprocessing not just as a necessary step but also as a critical
    component of your overall data strategy.
  prefs: []
  type: TYPE_NORMAL
- en: So, whether you’re a data scientist, engineer, analyst, or simply someone looking
    to enhance their understanding of data processes, I invite you to join me on this
    journey. Together, we will explore how to harness the power of data preprocessing
    to unlock the full potential of your data.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is for readers with a working knowledge of Python, a good grasp of
    statistical concepts, and some experience in manipulating data. This book will
    not start from scratch but will rather build on existing skills, introducing you
    to sophisticated preprocessing strategies, hands-on code examples, and practical
    exercises that require a degree of familiarity with the core principles of data
    science and analytics.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Chapter 1*](B19801_01.xhtml#_idTextAnchor014), *Data Ingestion Techniques*,
    provides a comprehensive overview of the data ingestion process, emphasizing its
    role in collecting and importing data from various sources into storage systems
    for analysis. You will explore different ingestion methods such as batch and streaming
    modes, compare real-time and semi-real-time ingestion, and understand the technologies
    behind data sources. The chapter highlights the advantages, disadvantages, and
    practical applications of these methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B19801_02.xhtml#_idTextAnchor044), *Importance of Data Quality*,
    emphasizes the critical role data quality plays in business decision-making. It
    highlights the risks of using inaccurate, inconsistent, or outdated data, which
    can lead to poor decisions, damaged reputations, and missed opportunities. You
    will explore why data quality is essential, how to measure it across different
    dimensions, and the impact of data silos on maintaining data quality.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B19801_03.xhtml#_idTextAnchor064), *Data Profiling – Understanding
    Data Structure, Quality, and Distribution*, explores data profiling and focuses
    on scrutinizing and validating datasets to understand their structure, patterns,
    and quality. You will learn how to perform data profiling using tools such as
    the pandas Profiler and Great Expectations and understand when to use each tool.
    Additionally, the chapter covers tactics for handling large data volumes and compares
    profiling methods to improve data validation.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B19801_04.xhtml#_idTextAnchor116), *Cleaning Messy Data and Data
    Manipulation*, focuses on the key strategies for cleaning and manipulating data,
    enabling efficient and accurate analysis. It covers techniques for renaming columns,
    removing irrelevant or redundant data, fixing inconsistent data types, and handling
    date and time formats. By mastering these methods, you will learn how to enhance
    the quality and reliability of your datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B19801_05.xhtml#_idTextAnchor136), *Data Transformation* *–*
    *Merging and Concatenating*, explores techniques for transforming and manipulating
    data through merging, joining, and concatenating datasets. It covers methods to
    combine multiple datasets from various sources, handle duplicates effectively,
    and improve merging performance. The chapter also provides practical tricks to
    streamline the merging process, ensuring efficient data integration for insightful
    analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B19801_06.xhtml#_idTextAnchor157), *Data Grouping, Aggregation,
    Filtering, and Applying Functions*, covers the essential techniques of data grouping
    and aggregation, which are vital for summarizing large datasets and generating
    meaningful insights. It discusses methods to handle missing or noisy data by aggregating
    values, reducing data volume, and enhancing processing efficiency. The chapter
    also focuses on grouping data by various keys, applying aggregate and custom functions,
    and filtering data to create valuable features for deeper analysis or ML.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B19801_07.xhtml#_idTextAnchor175), *Data Sinks*, focuses on the
    critical decisions involved in data processing, particularly the selection of
    appropriate data sinks for storage and processing needs. It delves into four essential
    pillars: choosing the right data sink, selecting the correct file type, optimizing
    partitioning strategies, and understanding how to design a scalable online retail
    data platform. The chapter equips you with the tools to enhance efficiency, scalability,
    and performance in data processing pipelines.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B19801_08.xhtml#_idTextAnchor195), *Detecting and Handling Missing
    Values and Outliers*, delves into techniques for identifying and managing missing
    values and outliers. It covers a range of methods, from statistical approaches
    to advanced ML models, to address these issues effectively. The key areas of focus
    include detecting and handling missing data, identifying univariate and multivariate
    outliers, and managing outliers in various datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B19801_09.xhtml#_idTextAnchor213), *Normalization and Standardization*,
    covers essential preprocessing techniques such as feature scaling, normalization,
    and standardization, which ensure that ML models can effectively learn from data.
    You will explore different techniques, including scaling features to a range,
    Z-score scaling, and using a robust scaler, to address various data challenges
    in ML tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B19801_10.xhtml#_idTextAnchor223), *Handling Categorical Features*,
    addresses the importance of managing categorical features, which represent non-numerical
    information in datasets. You will learn various encoding techniques, including
    label encoding, one-hot encoding, target encoding, frequency encoding, and binary
    encoding, to transform categorical data for ML models.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 11*](B19801_11.xhtml#_idTextAnchor246), *Consuming Time Series Data*,
    delves into the fundamentals of time series analysis, covering key concepts, methodologies,
    and applications across various industries. It includes understanding the components
    and types of time series data, identifying and handling missing values, and techniques
    for analyzing trends and patterns over time. The chapter also addresses dealing
    with outliers and feature engineering to enhance predictive modeling with time
    series data.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 12*](B19801_12.xhtml#_idTextAnchor277), *Text Preprocessing in the
    Era of LLMs*, focuses on mastering text preprocessing techniques that are essential
    for optimizing the performance of LLMs. It covers methods for cleaning text, handling
    rare words and spelling variations, chunking, and tokenization strategies. Additionally,
    it addresses the transformation of tokens into embeddings, highlighting the importance
    of adapting preprocessing approaches to maximize the potential of LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 13*](B19801_13.xhtml#_idTextAnchor302), *Image and Audio Preprocessing
    with LLMs*, examines preprocessing techniques for unstructured data, particularly
    images and audio, to extract meaningful information. It includes methods for image
    preprocessing, such as **optical character recognition** (**OCR**) and image caption
    generation with the BLIP model. The chapter also explores audio data handling,
    including converting audio to text using the Whisper model, providing a comprehensive
    overview of working with multimedia data in the context of LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To benefit fully from this book, you should have a good knowledge of Python
    and a grasp of data engineering and data science basics.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Software/hardware covered in** **the book** | **Operating** **system requirements**
    |'
  prefs: []
  type: TYPE_TB
- en: '| Python 3 | Windows, macOS, or Linux |'
  prefs: []
  type: TYPE_TB
- en: '| Visual Studio Code (or your preferred IDE) |  |'
  prefs: []
  type: TYPE_TB
- en: '**If you are using the digital version of this book, we advise you to type
    the code yourself or access the code from the book’s GitHub repository (a link
    is available in the next section). Doing so will help you avoid any potential
    errors related to the copying and pasting** **of code.**'
  prefs: []
  type: TYPE_NORMAL
- en: The GitHub repository follows the chapters of the book, and all the scripts
    are numbered according to the sections within each chapter. Each script is independent
    of the others, so you can move ahead without having to run all the scripts beforehand.
    However, it is critically recommended to follow the flow of the book so that you
    don’t miss any necessary information.
  prefs: []
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can download the example code files for this book from GitHub at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices).
    If there’s an update to the code, it will be updated in the GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: “The delete_entry() function is used to remove an
    entry, showing how data can be deleted from the store”'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For instance, words in menus or dialog boxes appear in **bold**. Here is an example:
    “It involves storing data on remote servers accessed from anywhere via the internet,
    **rather than on** **local devices**”'
  prefs: []
  type: TYPE_NORMAL
- en: Tips or important notes
  prefs: []
  type: TYPE_NORMAL
- en: Appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '**General feedback**: If you have questions about any aspect of this book,
    email us at [customercare@packtpub.com](mailto:customercare@packtpub.com) and
    mention the book title in the subject of your message.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    and fill in the form.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packt.com](mailto:copyright@packt.com)
    with a link to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  prefs: []
  type: TYPE_NORMAL
- en: Share your thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you’ve read *Python Data Cleaning and Preparation Best Practices*, we’d
    love to hear your thoughts! Please [click here to go straight to the Amazon review
    page](https://packt.link/r/1-837-63474-2) for this book and share your feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  prefs: []
  type: TYPE_NORMAL
- en: Download a free PDF copy of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thanks for purchasing this book!
  prefs: []
  type: TYPE_NORMAL
- en: Do you like to read on the go but are unable to carry your print books everywhere?
  prefs: []
  type: TYPE_NORMAL
- en: Is your eBook purchase not compatible with the device of your choice?
  prefs: []
  type: TYPE_NORMAL
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  prefs: []
  type: TYPE_NORMAL
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  prefs: []
  type: TYPE_NORMAL
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these simple steps to get the benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Scan the QR code or visit the link below
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B19801_QR_Free_PDF.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[https://packt.link/free-ebook/9781837634743](https://packt.link/free-ebook/9781837634743)'
  prefs: []
  type: TYPE_NORMAL
- en: 2. Submit your proof of purchase
  prefs: []
  type: TYPE_NORMAL
- en: 3. That’s it! We’ll send your free PDF and other benefits to your email directly
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 1: Upstream Data Ingestion and Cleaning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This part focuses on the foundational stages of data processing, starting from
    data ingestion to ensuring its quality and structure for downstream tasks. It
    guides readers through the essential steps of importing, cleaning, and transforming
    data, which lay the groundwork for effective data analysis. The chapters explore
    various methods for ingesting data, maintaining high-quality datasets, profiling
    data for better insights, and cleaning messy data to make it ready for analysis.
    Further, it covers advanced techniques like merging, concatenating, grouping,
    and filtering data, along with choosing appropriate data destinations or sinks
    to optimize processing pipelines. Each chapter in this part equips readers with
    the knowledge to handle raw data and turn it into a clean, structured, and usable
    form.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 1*](B19801_01.xhtml#_idTextAnchor014)*, Data Ingestion Techniques*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B19801_02.xhtml#_idTextAnchor044)*, Importance of Data Quality*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B19801_03.xhtml#_idTextAnchor064)*, Data Profiling* *–* *Understanding
    Data Structure, Quality, and Distribution*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B19801_04.xhtml#_idTextAnchor116)*, Cleaning Messy Data and Data
    Manipulation*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B19801_05.xhtml#_idTextAnchor136)*, Data Transformation* *–*
    *Merging and Concatenating*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B19801_06.xhtml#_idTextAnchor157)*, Data Grouping, Aggregation,
    Filtering, and Applying Functions*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B19801_07.xhtml#_idTextAnchor175)*, Data Sinks*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
