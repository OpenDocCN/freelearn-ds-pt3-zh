<html><head></head><body>
  <div id="sbo-rt-content"><div class="chapter" title="Chapter 10. Signal Processing"><div class="titlepage"><div><div><h1 class="title"><a id="ch10"/>Chapter 10. Signal Processing</h1></div></div></div><p>In this chapter, we will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Analyzing the frequency components of a signal with a Fast Fourier Transform</li><li class="listitem" style="list-style-type: disc">Applying a linear filter to a digital signal</li><li class="listitem" style="list-style-type: disc">Computing the autocorrelation of a time series</li></ul></div><div class="section" title="Introduction"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec88"/>Introduction</h1></div></div></div><p>Signals<a id="id1534" class="indexterm"/> are mathematical functions that describe the variation of a quantity across time or space. Time-dependent signals<a id="id1535" class="indexterm"/> are often called <a id="id1536" class="indexterm"/><span class="strong"><strong>time series</strong></span>. Examples of time series include share prices, which are typically presented as successive points in time spaced at uniform time intervals. In physics or biology, experimental devices record the evolution of variables such as electromagnetic waves or biological processes.</p><p>In signal processing, a general objective consists of extracting meaningful and relevant information from raw, noisy measurements. Signal processing topics include signal acquisition, transformation, compression, filtering, and feature extraction, among others. When dealing with a complex dataset, it can be beneficial to clean it before applying more advanced mathematical analysis methods (such as machine learning, for instance).</p><p>In this concise chapter, we will illustrate and explain the main foundations of signal processing. In the next chapter, <a class="link" href="ch11.html" title="Chapter 11. Image and Audio Processing">Chapter 11</a>, <span class="emphasis"><em>Image and Audio Processing</em></span>, we will see particular signal processing methods adapted to images and sounds.</p><p>First, we will give some important definitions in this introduction.</p><div class="section" title="Analog and digital signals"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec329"/>Analog and digital signals</h2></div></div></div><p>Signals can be time-dependent or space-dependent. In this chapter, we will focus on time-dependent signals.</p><p>Let <span class="emphasis"><em>x(t)</em></span> be a time-varying signal. We say that:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">This signal is <a id="id1537" class="indexterm"/><span class="strong"><strong>analog</strong></span><a id="id1538" class="indexterm"/> if <span class="emphasis"><em>t</em></span> is a continuous variable and <span class="emphasis"><em>x(t)</em></span> is a real number</li><li class="listitem" style="list-style-type: disc">This signal is <a id="id1539" class="indexterm"/><span class="strong"><strong>digital</strong></span> if <span class="emphasis"><em>t</em></span> is a discrete <a id="id1540" class="indexterm"/>variable (<span class="strong"><strong>discrete-time signal</strong></span>) and <span class="emphasis"><em>x(t)</em></span> can only <a id="id1541" class="indexterm"/>take a finite number of <a id="id1542" class="indexterm"/>values (<span class="strong"><strong>quantified signal</strong></span>)</li></ul></div><p>The following figure shows the difference between an analog signal (the continuous curve) and a digital signal (dots):</p><div class="mediaobject"><img src="images/4818OS_10_01.jpg" alt="Analog and digital signals"/><div class="caption"><p>Difference between the analog and digital (quantified) signals</p></div></div><p>Analog signals are found in mathematics and in most physical systems such as electric circuits. Yet, computers being discrete machines, they can only understand digital signals. This is why computational science especially deals with digital signals.</p><p>A digital signal recorded by an experimental device is typically characterized by two important quantities:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>The sampling rate</strong></span>: The<a id="id1543" class="indexterm"/> number of values (or samples) recorded every second (in Hertz)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>The resolution</strong></span>: The precision<a id="id1544" class="indexterm"/> of the quantization, usually in bits per sample (also known as <span class="strong"><strong>bit depth</strong></span>)</li></ul></div><p>Digital signals with high sampling rates and bit depths are more accurate, but they require more memory and processing power. These two parameters are limited by the experimental devices that record the signals.</p></div><div class="section" title="The Nyquist–Shannon sampling theorem"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec330"/>The Nyquist–Shannon sampling theorem</h2></div></div></div><p>Let's consider a continuous (analog) time-varying signal <span class="emphasis"><em>x(t)</em></span>. We record this physical signal with an experimental device, and we obtain a digital signal with a sampling rate of <span class="emphasis"><em>f<sub>s</sub></em></span>. As the original analog signal has an infinite precision, whereas the recorded signal has a finite precision, we expect to lose information in the analog-to-digital process.</p><p>The <span class="strong"><strong>Nyquist–Shannon sampling</strong></span> theorem<a id="id1545" class="indexterm"/> states that under certain conditions on the analog signal and the sampling rate, it is possible not to lose any information in the process. In other words, under these conditions, we can recover the original continuous signal from the sampled digital signal. For more details, refer <a id="id1546" class="indexterm"/>to <a class="ulink" href="http://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">http://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem</a>.</p><p>Let's define these conditions. The <a id="id1547" class="indexterm"/><span class="strong"><strong>Fourier transform</strong></span> <span class="inlinemediaobject"><img src="images/4818OS_10_20.jpg" alt="The Nyquist–Shannon sampling theorem"/></span> of <span class="emphasis"><em>x(t)</em></span> is defined by:</p><div class="mediaobject"><img src="images/4818OS_10_02.jpg" alt="The Nyquist–Shannon sampling theorem"/></div><p>Here, the Fourier transform is a representation of a time-dependent signal in the frequency domain. The <span class="strong"><strong>Nyquist criterion</strong></span><a id="id1548" class="indexterm"/> states that:</p><div class="mediaobject"><img src="images/4818OS_10_03.jpg" alt="The Nyquist–Shannon sampling theorem"/></div><p>In other words, the signal must be<a id="id1549" class="indexterm"/> <span class="strong"><strong>bandlimited</strong></span>, meaning that it must not contain any frequency higher than a certain cutoff frequency <span class="emphasis"><em>B</em></span>. Additionally, the sampling rate <span class="emphasis"><em>f<sub>s</sub></em></span> needs to be at least twice as large as this frequency <span class="emphasis"><em>B</em></span>. Here are a couple of definitions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <span class="strong"><strong>Nyquist rate</strong></span><a id="id1550" class="indexterm"/> is <span class="emphasis"><em>2B</em></span>. For a given bandlimited analog signal, it is the minimal sampling rate required to sample the signal without loss.</li><li class="listitem" style="list-style-type: disc">The <span class="strong"><strong>Nyquist frequency</strong></span><a id="id1551" class="indexterm"/> is <span class="emphasis"><em>f<sub>s</sub></em></span>/2. For a given sampling rate, it is the maximal frequency that the signal can contain in order to be sampled without loss.</li></ul></div><p>Under these conditions, we can theoretically reconstruct the original analog signal from the sampled digital signal.</p></div><div class="section" title="Compressed sensing"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec331"/>Compressed sensing</h2></div></div></div><p>Compressed sensing<a id="id1552" class="indexterm"/> is a modern and important approach to signal processing. It acknowledges that many real-world signals are intrinsically low dimensional. For example, speech signals have a very specific structure depending on the general physical constraints of the human vocal tract.</p><p>Even if a speech signal has many frequencies in the Fourier domain, it may be well approximated by a <span class="strong"><strong>sparse decomposition</strong></span><a id="id1553" class="indexterm"/> on an adequate basis (dictionary). By definition, a decomposition is sparse if most of the coefficients are zero. If the dictionary is chosen well, every signal is a combination of a small number of the basis signals.</p><p>This dictionary contains elementary signals that are specific to the signals considered in a given problem. This is different from the Fourier transform that decomposes a signal on a <span class="emphasis"><em>universal</em></span> basis of sine functions. In other words, with sparse representations, the Nyquist condition can be circumvented. We can precisely reconstruct a continuous signal from a sparse representation containing fewer samples than what the Nyquist condition requires.</p><p>Sparse decompositions can be found with sophisticated algorithms. In particular, these problems may be turned into convex optimization problems that can be tackled with specific numerical optimization methods.</p><p>Compressed sensing has many applications in signal compression, image processing, computer vision, biomedical imaging, and many other scientific and engineering areas.</p><p>Here are further references about <a id="id1554" class="indexterm"/>compressed sensing:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><a class="ulink" href="http://en.wikipedia.org/wiki/Compressed_sensing">http://en.wikipedia.org/wiki/Compressed_sensing</a></li><li class="listitem" style="list-style-type: disc"><a class="ulink" href="http://en.wikipedia.org/wiki/Sparse_approximation">http://en.wikipedia.org/wiki/Sparse_approximation</a></li></ul></div></div><div class="section" title="References"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec332"/>References</h2></div></div></div><p>Here are a few references:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="emphasis"><em>Understanding Digital Signal Processing</em></span>, <span class="emphasis"><em>Richard G. Lyons</em></span>, <span class="emphasis"><em>Pearson Education</em></span>, <span class="emphasis"><em>(2010)</em></span>.</li><li class="listitem" style="list-style-type: disc">For good coverage of <a id="id1555" class="indexterm"/>compressed sensing, refer to the book <span class="emphasis"><em>A Wavelet Tour of Signal Processing: The Sparse Way</em></span>, <span class="emphasis"><em>Mallat Stéphane</em></span>, <span class="emphasis"><em>Academic Press</em></span>, <span class="emphasis"><em>(2008)</em></span>.</li><li class="listitem" style="list-style-type: disc">The book <span class="emphasis"><em>Python for Signal Processing</em></span> by Jose Unpingco contains many more details than what we can cover in this chapter. The code is available as IPython notebooks on GitHub (<a class="ulink" href="http://python-for-signal-processing.blogspot.com">http://python-for-signal-processing.blogspot.com</a>).</li><li class="listitem" style="list-style-type: disc">Digital Signal Processing on WikiBooks available at <a class="ulink" href="http://en.wikibooks.org/wiki/Digital_Signal_Processing">http://en.wikibooks.org/wiki/Digital_Signal_Processing</a>.</li></ul></div></div></div></div></div>


  <div id="sbo-rt-content"><div class="section" title="Analyzing the frequency components of a signal with a Fast Fourier Transform"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec89"/>Analyzing the frequency components of a signal with a Fast Fourier Transform</h1></div></div></div><p>In this recipe, we will show how to use a <span class="strong"><strong>Fast Fourier Transform</strong></span> (<span class="strong"><strong>FFT</strong></span>)<a id="id1556" class="indexterm"/> to compute the spectral density of a signal. The spectrum represents the energy associated to frequencies (encoding periodic fluctuations in a signal). It is obtained with a Fourier transform, which is a frequency representation of a time-dependent signal. A signal can be transformed back and forth from one representation to the other without information loss.</p><p>In this recipe, we will <a id="id1557" class="indexterm"/>illustrate<a id="id1558" class="indexterm"/> several aspects of the Fourier Transform. We will apply this tool to weather data spanning 20 years in France obtained from the US National Climatic Data Center.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec333"/>Getting ready</h2></div></div></div><p>Download the <span class="emphasis"><em>Weather</em></span> dataset from the book's GitHub repository at <a class="ulink" href="http://github.com/ipython-books/cookbook-data">http://github.com/ipython-books/cookbook-data</a>, and extract it in the current directory.</p><p>The data has been obtained from <a class="ulink" href="http://www.ncdc.noaa.gov/cdo-web/datasets#GHCND">www.ncdc.noaa.gov/cdo-web/datasets#GHCND</a>.</p></div><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec334"/>How to do it...</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Let's import the packages, including <code class="literal">scipy.fftpack</code>, which includes many FFT-related routines:<div class="informalexample"><pre class="programlisting">In [1]: import datetime
        import numpy as np
        import scipy as sp
        import scipy.fftpack
        import pandas as pd
        import matplotlib.pyplot as plt
        %matplotlib inline</pre></div></li><li class="listitem">We import the data from the CSV file. The number <code class="literal">-9999</code> is used for N/A values. pandas can easily handle this. In addition, we tell pandas to parse dates contained in the <code class="literal">DATE</code> column:<div class="informalexample"><pre class="programlisting">In [2]: df0 = pd.read_csv('data/weather.csv', 
                          na_values=(-9999), 
                          parse_dates=['DATE'])
In [3]: df = df0[df0['DATE']&gt;='19940101']
In [4]: df.head()
Out[4]:  STATION                DATE  PRCP  TMAX  TMIN
365  FR013055001 1994-01-01 00:00:00     0   104    72
366  FR013055001 1994-01-02 00:00:00     4   128    49</pre></div></li><li class="listitem">Each row<a id="id1559" class="indexterm"/> contains <a id="id1560" class="indexterm"/>the precipitation and extreme temperatures recorded each day by one weather station in France. For every date in the calendar, we want to get a single average temperature for the whole country. The <code class="literal">groupby()</code> method provided by pandas lets us do this easily. We also remove any N/A value with <code class="literal">dropna()</code>:<div class="informalexample"><pre class="programlisting">In [5]: df_avg = df.dropna().groupby('DATE').mean()
In [6]: df_avg.head()
Out[6]:
      DATE        PRCP        TMAX       TMIN
1994-01-01  178.666667  127.388889  70.333333
1994-01-02  122.000000  152.421053  81.736842</pre></div></li><li class="listitem">Now, we get the list of dates and the list of corresponding temperatures. The unit is in tenths of a degree, and we get the average value between the minimal and maximal temperature, which explains why we divide by 20.<div class="informalexample"><pre class="programlisting">In [7]: date = df_avg.index.to_datetime()
        temp = (df_avg['TMAX'] + df_avg['TMIN']) / 20.
        N = len(temp)</pre></div></li><li class="listitem">Let's take a look at the evolution of the temperature:<div class="informalexample"><pre class="programlisting">In [8]: plt.plot_date(date, temp, '-', lw=.5)
        plt.ylim(-10, 40)
        plt.xlabel('Date')
        plt.ylabel('Mean temperature')</pre></div><div class="mediaobject"><img src="images/4818OS_10_04.jpg" alt="How to do it..."/></div></li><li class="listitem">We now compute the Fourier transform and the spectral density of the signal. The first step is to compute the FFT of the signal using the <code class="literal">fft()</code> function:<div class="informalexample"><pre class="programlisting">In [9]: temp_fft = sp.fftpack.fft(temp)</pre></div></li><li class="listitem">Once the FFT has<a id="id1561" class="indexterm"/> been obtained, we need to take the square of its absolute value in order to get the <a id="id1562" class="indexterm"/><span class="strong"><strong>power spectral density</strong></span> (<span class="strong"><strong>PSD</strong></span>):<div class="informalexample"><pre class="programlisting">In [10]: temp_psd = np.abs(temp_fft) ** 2</pre></div></li><li class="listitem">The next step is to get<a id="id1563" class="indexterm"/> the frequencies corresponding to the values of the PSD. The <code class="literal">fftfreq()</code> utility<a id="id1564" class="indexterm"/> function does just that. It takes the length of the PSD vector as input as well as the frequency unit. Here, we choose an annual unit: a frequency of 1 corresponds to 1 year (365 days). We provide <span class="emphasis"><em>1/365</em></span> because the original unit is in days.<div class="informalexample"><pre class="programlisting">In [11]: fftfreq = sp.fftpack.fftfreq(len(temp_psd), 
                                      1./365)</pre></div></li><li class="listitem">The <code class="literal">fftfreq()</code> function returns positive and negative frequencies. We are only interested in positive frequencies here, as we have a real signal (this will be explained in the <span class="emphasis"><em>How it works...</em></span> section of this recipe).<div class="informalexample"><pre class="programlisting">In [12]: i = fftfreq&gt;0</pre></div></li><li class="listitem">We now plot the power spectral density of our signal, as a function of the frequency (in unit of <span class="emphasis"><em>1/year</em></span>). We choose a logarithmic scale for the <span class="emphasis"><em>y</em></span> axis (<span class="strong"><strong>decibels</strong></span>).<div class="informalexample"><pre class="programlisting">In [13]: plt.plot(fftfreq[i], 10*np.log10(temp_psd[i]))
         plt.xlim(0, 5)
         plt.xlabel('Frequency (1/year)')
         plt.ylabel('PSD (dB)')</pre></div><div class="mediaobject"><img src="images/4818OS_10_05.jpg" alt="How to do it..."/></div><p>Because the fundamental frequency of the signal is the yearly variation of the temperature, we observe a peak for <span class="emphasis"><em>f=1</em></span>.</p></li><li class="listitem">Now, we cut out <a id="id1565" class="indexterm"/>frequencies higher than the fundamental frequency:<div class="informalexample"><pre class="programlisting">In [14]: temp_fft_bis = temp_fft.copy()
         temp_fft_bis[np.abs(fftfreq) &gt; 1.1] = 0</pre></div></li><li class="listitem">Next, we <a id="id1566" class="indexterm"/>perform an <span class="strong"><strong>inverse FFT</strong></span><a id="id1567" class="indexterm"/> to convert the modified Fourier transform back to the temporal domain. This way, we recover a signal that mainly contains the fundamental frequency, as shown in the following figure:<div class="informalexample"><pre class="programlisting">In [15]: temp_slow = np.real(sp.fftpack.ifft(temp_fft_bis))
In [16]: plt.plot_date(date, temp, '-', lw=.5)
         plt.plot_date(date, temp_slow, '-')
         plt.xlim(datetime.date(1994, 1, 1),
                  datetime.date(2000, 1, 1))
         plt.ylim(-10, 40)
         plt.xlabel('Date')
         plt.ylabel('Mean temperature')</pre></div><div class="mediaobject"><img src="images/4818OS_10_06.jpg" alt="How to do it..."/></div><p>We get a smoothed version of the signal, because the fast variations have been lost when we have removed the high frequencies in the Fourier transform.</p></li></ol></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec335"/>How it works...</h2></div></div></div><p>Broadly <a id="id1568" class="indexterm"/>speaking, the <a id="id1569" class="indexterm"/>Fourier transform is an alternative representation of a signal as a superposition of periodic components. It is an important mathematical result that any well-behaved function can be represented under this form. Whereas a time-varying signal is most naturally considered as a function of time, the Fourier transform represents it as a function of the frequency. A magnitude and a phase, which are both encoded in a single complex number, are associated to each frequency.</p><div class="section" title="The Discrete Fourier Transform"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec64"/>The Discrete Fourier Transform</h3></div></div></div><p>Let's consider a digital signal <span class="emphasis"><em>x</em></span> represented by a vector <span class="emphasis"><em>(x<sub>0</sub>, ..., x<sub>(N-1)</sub>)</em></span>. We assume that this signal is regularly sampled. The <span class="strong"><strong>Discrete Fourier Transform</strong></span> (<span class="strong"><strong>DFT</strong></span>)<a id="id1570" class="indexterm"/> of <span class="emphasis"><em>x</em></span> is <span class="emphasis"><em>X = (X<sub>0</sub>, ..., X<sub>(N-1)</sub>)</em></span> defined as:</p><div class="mediaobject"><img src="images/4818OS_10_07.jpg" alt="The Discrete Fourier Transform"/></div><p>The DFT can be computed efficiently with the Fast Fourier Transform (FFT), an algorithm that exploits symmetries and redundancies in this definition to considerably speed up the computation. The complexity of the FFT is <span class="emphasis"><em>O(N</em></span> log <span class="emphasis"><em>N)</em></span> instead of <span class="emphasis"><em>O(N<sup>2</sup>)</em></span> for the naive DFT. The FFT is one of the most important algorithms of the digital universe.</p><p>Here is an intuitive <a id="id1571" class="indexterm"/>explanation of what the DFT describes. Instead of representing our signal on a real line, let's represent it on a circle. We can play the whole signal by making 1, 2, or any number <span class="emphasis"><em>k</em></span> of laps on the circle. Therefore, when <span class="emphasis"><em>k</em></span> is fixed, we represent each value <span class="emphasis"><em>x<sub>n</sub></em></span> of the signal with an angle <span class="inlinemediaobject"><img src="images/4818OS_10_22.jpg" alt="The Discrete Fourier Transform"/></span> and a distance from the original equal to <span class="emphasis"><em>x<sub>n</sub></em></span>.</p><p>If the signal shows a certain periodicity of <span class="emphasis"><em>k</em></span> laps, it means that many correlated values will superimpose at that exact frequency so that the coefficient <span class="emphasis"><em>X<sub>k</sub></em></span> will be large. In other words, the modulus <span class="emphasis"><em>|X<sub>k</sub>|</em></span> of the <span class="emphasis"><em>k</em></span>-th coefficient represents the <span class="emphasis"><em>energy</em></span> of the signal associated to this frequency.</p><p>In the following figure, the signal is a sine wave at the frequency <span class="emphasis"><em>f=3 Hz</em></span>. The points of this signal are in blue, positioned at an angle <span class="inlinemediaobject"><img src="images/4818OS_10_22.jpg" alt="The Discrete Fourier Transform"/></span>. Their algebraic sum in the complex plane is in red. These vectors represent the different coefficients of the signal's DFT.</p><div class="mediaobject"><img src="images/4818OS_10_08.jpg" alt="The Discrete Fourier Transform"/><div class="caption"><p>An illustration of the DFT</p></div></div><p>The next figure represents the previous signal's <a id="id1572" class="indexterm"/><span class="strong"><strong>power spectral density</strong></span> (<span class="strong"><strong>PSD</strong></span>):</p><div class="mediaobject"><img src="images/4818OS_10_09.jpg" alt="The Discrete Fourier Transform"/><div class="caption"><p>The PSD of the signal in the previous example</p></div></div></div><div class="section" title="Inverse Fourier Transform"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec65"/>Inverse Fourier Transform</h3></div></div></div><p>By considering all possible <a id="id1573" class="indexterm"/>frequencies, we have an exact representation of our digital signal in the frequency domain. We can recover the initial signal with an <span class="strong"><strong>Inverse Fast Fourier Transform</strong></span><a id="id1574" class="indexterm"/> that computes an<a id="id1575" class="indexterm"/> <span class="strong"><strong>Inverse Discrete Fourier Transform</strong></span>. The formula is very similar to the DFT:</p><div class="mediaobject"><img src="images/4818OS_10_10.jpg" alt="Inverse Fourier Transform"/></div><p>The DFT is useful when periodic patterns are to be found. However, generally speaking, the Fourier transform cannot detect <span class="emphasis"><em>transient</em></span> changes at specific frequencies. More local spectral methods are required, such as the <a id="id1576" class="indexterm"/><span class="strong"><strong>wavelet transform</strong></span>.</p></div></div><div class="section" title="There's more..."><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec336"/>There's more...</h2></div></div></div><p>The following links contain more details <a id="id1577" class="indexterm"/>about Fourier transforms:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Introduction to the FFT with SciPy, available at <a class="ulink" href="http://scipy-lectures.github.io/intro/scipy.html#fast-fourier-transforms-scipy-fftpack">http://scipy-lectures.github.io/intro/scipy.html#fast-fourier-transforms-scipy-fftpack</a></li><li class="listitem" style="list-style-type: disc">Reference documentation for the fftpack in SciPy, available at <a class="ulink" href="http://docs.scipy.org/doc/scipy/reference/fftpack.html">http://docs.scipy.org/doc/scipy/reference/fftpack.html</a></li><li class="listitem" style="list-style-type: disc">Fourier Transform on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Fourier_transform">http://en.wikipedia.org/wiki/Fourier_transform</a></li><li class="listitem" style="list-style-type: disc">Discrete Fourier Transform on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Discrete_Fourier_transform">http://en.wikipedia.org/wiki/Discrete_Fourier_transform</a></li><li class="listitem" style="list-style-type: disc">Fast Fourier Transform on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Fast_Fourier_transform">http://en.wikipedia.org/wiki/Fast_Fourier_transform</a></li><li class="listitem" style="list-style-type: disc">Decibel on <a id="id1578" class="indexterm"/>Wikipedia, available at <a class="ulink" href="https://en.wikipedia.org/wiki/Decibel">https://en.wikipedia.org/wiki/Decibel</a></li></ul></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec337"/>See also</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <span class="emphasis"><em>Applying a linear filter to a digital signal</em></span> recipe</li><li class="listitem" style="list-style-type: disc">The <span class="emphasis"><em>Computing the autocorrelation of a time series</em></span> recipe</li></ul></div></div></div></div>


  <div id="sbo-rt-content"><div class="section" title="Applying a linear filter to a digital signal"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec90"/>Applying a linear filter to a digital signal</h1></div></div></div><p>Linear filters <a id="id1579" class="indexterm"/>play a fundamental role in signal processing. With a linear filter, one can extract meaningful information from a digital signal.</p><p>In this recipe, we will show two examples using stock market data (the NASDAQ stock exchange). First, we will smooth out a very noisy signal with a low-pass filter to extract its slow variations. We will also apply a high-pass filter on the original time series to extract the fast variations. These are just two common examples among a wide variety of applications of linear filters.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec338"/>Getting ready</h2></div></div></div><p>Download the <span class="emphasis"><em>Nasdaq</em></span> dataset from the book's GitHub repository at <a class="ulink" href="https://github.com/ipython-books/cookbook-data">https://github.com/ipython-books/cookbook-data</a> and extract it in the current directory.</p><p>The data<a id="id1580" class="indexterm"/> has been <a id="id1581" class="indexterm"/>obtained from <a class="ulink" href="http://finance.yahoo.com/q/hp?s=%5EIXIC&amp;a=00&amp;b=1&amp;c=1990&amp;d=00&amp;e=1&amp;f=2014&amp;g=d">http://finance.yahoo.com/q/hp?s=^IXIC&amp;a=00&amp;b=1&amp;c=1990&amp;d=00&amp;e=1&amp;f=2014&amp;g=d</a>.</p></div><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec339"/>How to do it...</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Let's import the packages:<div class="informalexample"><pre class="programlisting">In [1]: import numpy as np
        import scipy as sp
        import scipy.signal as sg
        import pandas as pd
        import matplotlib.pyplot as plt
        %matplotlib inline</pre></div></li><li class="listitem">We load the NASDAQ data with pandas:<div class="informalexample"><pre class="programlisting">In [2]: nasdaq_df = pd.read_csv('data/nasdaq.csv')
In [3]: nasdaq_df.head()
Out[3]:  Date     Open     High      Low    Close
0  2013-12-31  4161.51  4177.73  4160.77  4176.59 
1  2013-12-30  4153.58  4158.73  4142.18  4154.20 </pre></div></li><li class="listitem">Let's extract two columns: the date and the daily closing value:<div class="informalexample"><pre class="programlisting">In [4]: date = pd.to_datetime(nasdaq_df['Date'])
        nasdaq = nasdaq_df['Close']</pre></div></li><li class="listitem">Let's take a look at the raw signal:<div class="informalexample"><pre class="programlisting">In [5]: plt.plot_date(date, nasdaq, '-')</pre></div><div class="mediaobject"><img src="images/4818OS_10_11.jpg" alt="How to do it..."/></div></li><li class="listitem">Now, we<a id="id1582" class="indexterm"/> will follow the first approach to get the<a id="id1583" class="indexterm"/> slow variations of the signal. We will convolve the signal with a triangular window, which corresponds to a<a id="id1584" class="indexterm"/> <span class="strong"><strong>FIR filter</strong></span>. We will explain the idea behind this method in the <span class="emphasis"><em>How it works...</em></span> section of this recipe. For now, let's just say that we replace each value with a weighted mean of the signal around this value:<div class="informalexample"><pre class="programlisting">In [6]: # We get a triangular window with 60 samples.
        h = sg.get_window('triang', 60)
        # We convolve the signal with this window.
        fil = sg.convolve(nasdaq, h/h.sum())
In [7]: # We plot the original signal...
        plt.plot_date(date, nasdaq, '-', lw=1)
        # ... and the filtered signal.
        plt.plot_date(date, fil[:len(nasdaq)-1], '-')</pre></div><div class="mediaobject"><img src="images/4818OS_10_12.jpg" alt="How to do it..."/></div></li><li class="listitem">Now, let's <a id="id1585" class="indexterm"/>use another method. We create <a id="id1586" class="indexterm"/>an IIR Butterworth low-pass filter to extract the slow variations of the signal. The <code class="literal">filtfilt()</code> method allows us to apply a filter forward and backward in order to avoid phase delays:<div class="informalexample"><pre class="programlisting">In [8]: plt.plot_date(date, nasdaq, '-', lw=1)
        # We create a 4-th order Butterworth low-pass
        # filter.
        b, a = sg.butter(4, 2./365)
        # We apply this filter to the signal.
        plt.plot_date(date, sg.filtfilt(b, a, nasdaq), 
                      '-')</pre></div><div class="mediaobject"><img src="images/4818OS_10_13.jpg" alt="How to do it..."/></div></li><li class="listitem">Finally, we use the same method to create a high-pass filter and extract the <span class="emphasis"><em>fast</em></span> variations of the signal:<div class="informalexample"><pre class="programlisting">In [9]: plt.plot_date(date, nasdaq, '-', lw=1)
        b, a = sg.butter(4, 2*5./365, btype='high')
        plt.plot_date(date, sg.filtfilt(b, a, nasdaq),
                      '-', lw=.5)</pre></div><div class="mediaobject"><img src="images/4818OS_10_14.jpg" alt="How to do it..."/></div><p>The<a id="id1587" class="indexterm"/> fast variations around<a id="id1588" class="indexterm"/> 2000 correspond to the dot-com bubble burst, reflecting the high-market volatility and the fast fluctuations of the stock market indices at that time. For more details, refer to <a class="ulink" href="http://en.wikipedia.org/wiki/Dot-com_bubble">http://en.wikipedia.org/wiki/Dot-com_bubble</a>.</p></li></ol></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec340"/>How it works...</h2></div></div></div><p>In this section, we explain the very basics of linear filters in the context of digital signals.</p><p>A <span class="strong"><strong>digital signal</strong></span><a id="id1589" class="indexterm"/> is a discrete sequence <span class="emphasis"><em>(x<sub>n</sub>)</em></span> indexed by <span class="emphasis"><em>n</em></span> <span class="inlinemediaobject"><img src="images/4818OS_10_26.jpg" alt="How it works..."/></span>
<span class="emphasis"><em> 0</em></span>. Although we often assume infinite sequences, in practice, a signal is represented by a <span class="emphasis"><em>vector</em></span> of the finite size <span class="emphasis"><em>N</em></span>.</p><p>In the continuous case, we would rather manipulate time-dependent functions <span class="emphasis"><em>f(t)</em></span>. Loosely stated, we can go from continuous signals to discrete signals by discretizing time and transforming integrals into sums.</p><div class="section" title="What are linear filters?"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec66"/>What are linear filters?</h3></div></div></div><p>A <span class="strong"><strong>linear filter</strong></span><a id="id1590" class="indexterm"/> <span class="emphasis"><em>F</em></span> transforms an input signal <span class="emphasis"><em>x = (x<sub>n</sub>)</em></span> to an output signal <span class="emphasis"><em>y = (y<sub>n</sub>)</em></span>. This transformation is <span class="emphasis"><em>linear</em></span>—the transformation of the sum of two signals is the sum of the transformed signals: <span class="emphasis"><em>F(x+y) = F(x)+F(y)</em></span>.</p><p>In addition to this, multiplying the input signal by a constant <span class="inlinemediaobject"><img src="images/4818OS_10_25.jpg" alt="What are linear filters?"/></span> yields the same output as multiplying the original output signal by the same constant: <span class="inlinemediaobject"><img src="images/4818OS_10_23.jpg" alt="What are linear filters?"/></span>.</p><p>A <span class="strong"><strong>Linear Time-Invariant</strong></span> (<span class="strong"><strong>LTI</strong></span>)<a id="id1591" class="indexterm"/> filter has an additional property: if the signal <span class="emphasis"><em>(x<sub>n</sub>)</em></span> is transformed to <span class="emphasis"><em>(y<sub>n</sub>)</em></span>, then the <span class="emphasis"><em>shifted</em></span> signal <span class="emphasis"><em>(x<sub>(n-k)</sub>)</em></span> is transformed to <span class="emphasis"><em>(y<sub>(n-k)</sub>)</em></span>, for any fixed <span class="emphasis"><em>k</em></span>. In other words, the system is time-invariant because the output does not depend on the particular time the input is applied.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note32"/>Note</h3><p>From now on, we will only consider LTI filters.</p></div></div></div><div class="section" title="Linear filters and convolutions"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec67"/>Linear filters and convolutions</h3></div></div></div><p>A very important result in the LTI <a id="id1592" class="indexterm"/>system theory is that LTI filters can be described by a single signal: the impulse response <span class="emphasis"><em>h</em></span>. This is the output of the filter in response to an impulse signal. For digital filters, the impulse signal is <span class="emphasis"><em>(1, 0, 0, 0, ...)</em></span>.</p><p>It can be shown that <span class="emphasis"><em>x = (x<sub>n</sub>)</em></span> is transformed to <span class="emphasis"><em>y = (y<sub>n</sub>)</em></span> defined by the <span class="strong"><strong>convolution</strong></span><a id="id1593" class="indexterm"/> of the impulse response <span class="emphasis"><em>h</em></span> with the signal <span class="emphasis"><em>x</em></span>:</p><div class="mediaobject"><img src="images/4818OS_10_15.jpg" alt="Linear filters and convolutions"/></div><p>The convolution is a fundamental mathematical operation in signal processing. Intuitively, and considering a convolution function peaking around zero, the convolution is equivalent to taking a local average of the signal (<span class="emphasis"><em>x</em></span> here), weighted by a given window (<span class="emphasis"><em>h</em></span> here).</p><p>It is implied, by our notations, that we restrict ourselves to <span class="strong"><strong>causal</strong></span> filters<a id="id1594" class="indexterm"/> (<span class="emphasis"><em>h<sub>n</sub> = 0</em></span> for <span class="emphasis"><em>n &lt; 0</em></span>). This property means that the output of the signal only depends on the present and the past of the input, not the future. This is a natural property in many situations.</p></div><div class="section" title="The FIR and IIR filters"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec68"/>The FIR and IIR filters</h3></div></div></div><p>The <span class="strong"><strong>support</strong></span> of a signal <span class="emphasis"><em>(h<sub>n</sub>)</em></span> is the set of <span class="emphasis"><em>n</em></span> such that <span class="inlinemediaobject"><img src="images/4818OS_10_24.jpg" alt="The FIR and IIR filters"/></span>. LTI filters can be classified into two categories:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A <span class="strong"><strong>Finite Impulse Response</strong></span> (FIR) filter<a id="id1595" class="indexterm"/> has an impulse response with finite support</li><li class="listitem" style="list-style-type: disc">A <span class="strong"><strong>Infinite Impulse Response</strong></span> (IIR) filter<a id="id1596" class="indexterm"/> has an impulse response with infinite support</li></ul></div><p>A FIR filter can be described by a finite impulse response of size <span class="emphasis"><em>N</em></span> (a vector). It works by convolving a signal with its impulse response. Let's define <span class="emphasis"><em>b<sub>n</sub> = h<sub>n</sub></em></span> for <span class="emphasis"><em>n </em></span><span class="inlinemediaobject"><img src="images/4818OS_10_40.jpg" alt="The FIR and IIR filters"/></span>
<span class="emphasis"><em> N</em></span>. Then, <span class="emphasis"><em>y<sub>n</sub></em></span> is a linear combination of the last <span class="emphasis"><em>N+1</em></span> values of the input signal:</p><div class="mediaobject"><img src="images/4818OS_10_16.jpg" alt="The FIR and IIR filters"/></div><p>On the other hand, an <a id="id1597" class="indexterm"/>IIR filter is described by an infinite <a id="id1598" class="indexterm"/>impulse response that cannot be represented exactly under this form. For this reason, we often use an alternative representation:</p><div class="mediaobject"><img src="images/4818OS_10_17.jpg" alt="The FIR and IIR filters"/></div><p>This <span class="strong"><strong>difference equation</strong></span><a id="id1599" class="indexterm"/> expresses <span class="emphasis"><em>y<sub>n</sub></em></span> as a linear combination of the last <span class="emphasis"><em>N+1</em></span> values of the <span class="emphasis"><em>input</em></span> signal (the <a id="id1600" class="indexterm"/><span class="strong"><strong>feedforward</strong></span> term, like for a FIR filter) <span class="emphasis"><em>and</em></span> a linear combination of the last <span class="emphasis"><em>M</em></span> values of the <span class="emphasis"><em>output</em></span> signal (<span class="strong"><strong>feedback</strong></span> term). The<a id="id1601" class="indexterm"/> feedback term makes the IIR filter more complex than a FIR filter in that the output depends not only on the input but also on the previous values of the output (dynamics).</p></div><div class="section" title="Filters in the frequency domain"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec69"/>Filters in the frequency domain</h3></div></div></div><p>We only described filters in the<a id="id1602" class="indexterm"/> temporal domain. Alternate representations in other domains exist such as Laplace transforms, Z-transforms, and Fourier transforms.</p><p>In particular, the <span class="emphasis"><em>Fourier transform</em></span> has a very convenient property: it transforms convolutions into multiplications in the frequency domain. In other words, in the frequency domain, an LTI filter multiplies the Fourier transform of the input signal by the Fourier transform of the impulse response.</p></div><div class="section" title="The low-, high-, and band-pass filters"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec70"/>The low-, high-, and band-pass filters</h3></div></div></div><p>Filters can be characterized by their effects on the amplitude of the input signal's frequencies. They are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A <span class="strong"><strong>low-pass filter</strong></span><a id="id1603" class="indexterm"/> attenuates the components of the signal at frequencies <span class="emphasis"><em>higher</em></span> than a <a id="id1604" class="indexterm"/><span class="strong"><strong>cutoff frequency</strong></span></li><li class="listitem" style="list-style-type: disc">A <span class="strong"><strong>high-pass filter</strong></span><a id="id1605" class="indexterm"/> attenuates the components of the signal at frequencies <span class="emphasis"><em>lower</em></span> than a <span class="strong"><strong>cutoff frequency</strong></span></li><li class="listitem" style="list-style-type: disc">A <span class="strong"><strong>band-pass filter</strong></span><a id="id1606" class="indexterm"/> passes the components of the signal at frequencies within a certain range and attenuates those outside</li></ul></div><p>In this recipe, we first convolved the input signal with a triangular window (with finite support). It can be shown that this operation corresponds to a low-pass FIR filter. It is a particular case of the<a id="id1607" class="indexterm"/> <span class="strong"><strong>moving average</strong></span> method, which computes a local weighted average of every value in order to smooth out the signal.</p><p>Then, we applied two instances of the <a id="id1608" class="indexterm"/><span class="strong"><strong>Butterworth filter</strong></span>, a particular kind of IIR filter that can act as a low-pass, high-pass, or band-pass filter. In this recipe, we first used it as a low-pass filter to smooth out the signal, before using it as a high-pass filter to extract fast variations of the signal.</p></div></div><div class="section" title="There's more..."><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec341"/>There's more...</h2></div></div></div><p>Here are some general references about digital signal processing<a id="id1609" class="indexterm"/> and<a id="id1610" class="indexterm"/> linear filters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Digital signal processing on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Digital_signal_processing">http://en.wikipedia.org/wiki/Digital_signal_processing</a></li><li class="listitem" style="list-style-type: disc">Linear filters on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Linear_filter">http://en.wikipedia.org/wiki/Linear_filter</a></li><li class="listitem" style="list-style-type: disc">LTI filters on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/LTI_system_theory">http://en.wikipedia.org/wiki/LTI_system_theory</a></li></ul></div><p>Here are<a id="id1611" class="indexterm"/> some references <a id="id1612" class="indexterm"/>about impulse responses, <a id="id1613" class="indexterm"/>convolutions, and<a id="id1614" class="indexterm"/> FIR/IIR filters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Impulse responses described at <a class="ulink" href="http://en.wikipedia.org/wiki/Impulse_response">http://en.wikipedia.org/wiki/Impulse_response</a></li><li class="listitem" style="list-style-type: disc">Convolution described at <a class="ulink" href="http://en.wikipedia.org/wiki/Convolution">http://en.wikipedia.org/wiki/Convolution</a></li><li class="listitem" style="list-style-type: disc">FIR filters described at <a class="ulink" href="http://en.wikipedia.org/wiki/Finite_impulse_response">http://en.wikipedia.org/wiki/Finite_impulse_response</a></li><li class="listitem" style="list-style-type: disc">IIR filters described at <a class="ulink" href="http://en.wikipedia.org/wiki/Infinite_impulse_response">http://en.wikipedia.org/wiki/Infinite_impulse_response</a></li><li class="listitem" style="list-style-type: disc">Low-pass filters <a id="id1615" class="indexterm"/>described at <a class="ulink" href="http://en.wikipedia.org/wiki/Low-pass_filter">http://en.wikipedia.org/wiki/Low-pass_filter</a></li><li class="listitem" style="list-style-type: disc">High-pass filters<a id="id1616" class="indexterm"/> described at <a class="ulink" href="http://en.wikipedia.org/wiki/High-pass_filter">http://en.wikipedia.org/wiki/High-pass_filter</a></li><li class="listitem" style="list-style-type: disc">Band-pass <a id="id1617" class="indexterm"/>filters described at <a class="ulink" href="http://en.wikipedia.org/wiki/Band-pass_filter">http://en.wikipedia.org/wiki/Band-pass_filter</a></li></ul></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec342"/>See also</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <span class="emphasis"><em>Analyzing the frequency components of a signal with a Fast Fourier Transform</em></span> recipe</li></ul></div></div></div></div>


  <div id="sbo-rt-content"><div class="section" title="Computing the autocorrelation of a time series"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec91"/>Computing the autocorrelation of a time series</h1></div></div></div><p>The autocorrelation of a<a id="id1618" class="indexterm"/> time series can inform us about <a id="id1619" class="indexterm"/>repeating patterns or serial correlation. The latter refers to the correlation between the signal at a given time and at a later time. The analysis of the autocorrelation can thereby inform us about the timescale of the fluctuations. Here, we use this tool to analyze the evolution of baby names in the US, based on the data provided by the United States Social Security Administration.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec343"/>Getting ready</h2></div></div></div><p>Download the <span class="emphasis"><em>Babies</em></span> dataset from the book's GitHub repository at <a class="ulink" href="https://github.com/ipython-books/cookbook-data">https://github.com/ipython-books/cookbook-data</a>, and extract it in the current directory.</p><p>The data has been obtained from <a class="ulink" href="http://www.data.gov">www.data.gov</a> (<a class="ulink" href="http://catalog.data.gov/dataset/baby-names-from-social-security-card-applications-national-level-data-6315b">http://catalog.data.gov/dataset/baby-names-from-social-security-card-applications-national-level-data-6315b</a>).</p></div><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec344"/>How to do it...</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">We import the following packages:<div class="informalexample"><pre class="programlisting">In [1]: import os
        import numpy as np
        import pandas as pd
        import matplotlib.pyplot as plt
        %matplotlib inline</pre></div></li><li class="listitem">We read the data with pandas. The dataset contains one CSV file per year. Each file contains all baby names given that year with the respective frequencies. We load the data in a dictionary, containing one <code class="literal">DataFrame</code> per year:<div class="informalexample"><pre class="programlisting">In [2]: files = [file for file in os.listdir('data/') 
                 if file.startswith('yob')]
In [3]: years = np.array(sorted([int(file[3:7]) 
                                 for file in files]))
In [4]: data = {year: 
                pd.read_csv(
                 'data/yob{y:d}.txt'.format(y=year),
                  index_col=0, header=None, 
                  names=['First name', 'Gender', 'Number']) 
                                         for year in years}
In [5]: data[2012].head()
Out[5]:    Gender  Number
First name               
Sophia          F   22158
Emma            F   20791
Isabella        F   18931
Olivia          F   17147
Ava             F   15418</pre></div></li><li class="listitem">We write functions to retrieve the frequencies of baby names as a function of the name, gender, and birth year:<div class="informalexample"><pre class="programlisting">In [6]: def get_value(name, gender, year):
            """Return the number of babies born a given 
            year, with a given gender and a given name."""
            try:
                return data[year] \
                       [data[year]['Gender'] == gender] \
                       ['Number'][name]
            except KeyError:
                return 0
In [7]: def get_evolution(name, gender):
            """Return the evolution of a baby name over the
            years."""
            return np.array([get_value(name, gender, year) 
                             for year in years])</pre></div></li><li class="listitem">Let's define a <a id="id1620" class="indexterm"/>function that computes the <a id="id1621" class="indexterm"/>autocorrelation of a signal. This function is essentially based on NumPy's <code class="literal">correlate()</code> function.<div class="informalexample"><pre class="programlisting">In [8]: def autocorr(x):
            result = np.correlate(x, x, mode='full')
            return result[result.size/2:]</pre></div></li><li class="listitem">Now, we create a function that displays the evolution of a baby name as well as its (normalized) autocorrelation:<div class="informalexample"><pre class="programlisting">In [9]: def autocorr_name(name, gender):
            x = get_evolution(name, gender)
            z = autocorr(x)
            # Evolution of the name.
            plt.subplot(121)
            plt.plot(years, x, '-o', label=name)
            plt.title("Baby names")
            # Autocorrelation.
            plt.subplot(122)
            plt.plot(z / float(z.max()), '-', label=name)
            plt.legend()
            plt.title("Autocorrelation")</pre></div></li><li class="listitem">Let's take a look at two female names:<div class="informalexample"><pre class="programlisting">In [10]: autocorr_name('Olivia', 'F')
         autocorr_name('Maria', 'F')</pre></div><div class="mediaobject"><img src="images/4818OS_10_18.jpg" alt="How to do it..."/></div><p>The <a id="id1622" class="indexterm"/>autocorrelation of Olivia<a id="id1623" class="indexterm"/> is decaying much faster than Maria's. This is mainly because of the steep increase of the name Olivia at the end of the twentieth century. By contrast, the name Maria is varying more slowly globally, and its autocorrelation is decaying somewhat slower.</p></li></ol></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec345"/>How it works...</h2></div></div></div><p>A <span class="strong"><strong>time series</strong></span><a id="id1624" class="indexterm"/> is a sequence indexed by time. Important applications include stock markets, product sales, weather forecasting, biological signals, and many others. Time series analysis is an important part of statistical data analysis, signal processing, and machine learning.</p><p>There are various definitions of the autocorrelation. Here, we define the autocorrelation of a time series <span class="emphasis"><em>(x<sub>n</sub>)</em></span> as:</p><div class="mediaobject"><img src="images/4818OS_10_19.jpg" alt="How it works..."/></div><p>In the <a id="id1625" class="indexterm"/>previous plot, we normalized the autocorrelation<a id="id1626" class="indexterm"/> by its maximum so as to compare the autocorrelation of two signals. The autocorrelation quantifies the average similarity between the signal and a shifted version of the same signal, as a function of the delay between the two. In other words, the autocorrelation can give us information about repeating patterns as well as the timescale of the signal's fluctuations. The faster the autocorrelation decays to zero, the faster the signal varies.</p></div><div class="section" title="There's more..."><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec346"/>There's more...</h2></div></div></div><p>Here are a few references:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">NumPy's correlation function<a id="id1627" class="indexterm"/> documentation, available at <a class="ulink" href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.correlate.html">http://docs.scipy.org/doc/numpy/reference/generated/numpy.correlate.html</a></li><li class="listitem" style="list-style-type: disc">Autocorrelation function in <a id="id1628" class="indexterm"/>statsmodels, documented at <a class="ulink" href="http://statsmodels.sourceforge.net/stable/tsa.html">http://statsmodels.sourceforge.net/stable/tsa.html</a></li><li class="listitem" style="list-style-type: disc">Time series<a id="id1629" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Time_series">http://en.wikipedia.org/wiki/Time_series</a></li><li class="listitem" style="list-style-type: disc">Serial dependence<a id="id1630" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Serial_dependence">http://en.wikipedia.org/wiki/Serial_dependence</a></li><li class="listitem" style="list-style-type: disc">Autocorrelation <a id="id1631" class="indexterm"/>on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Autocorrelation">http://en.wikipedia.org/wiki/Autocorrelation</a></li></ul></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec347"/>See also</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <span class="emphasis"><em>Analyzing the frequency components of a signal with a Fast Fourier Transform</em></span> recipe</li></ul></div></div></div></div>
</body></html>