<html><head></head><body>
  <div id="_idContainer117" class="Basic-Text-Frame">
    <h1 class="chapterNumber">9</h1>
    <h1 id="_idParaDest-321" class="chapterTitle">Fixing Messy Data When Aggregating</h1>
    <p class="normal">Earlier chapters of this book introduced techniques to generate summary statistics on a whole DataFrame. We used methods such as <code class="inlineCode">describe</code>, <code class="inlineCode">mean</code>, and <code class="inlineCode">quantile</code> to do that. This chapter covers more complicated aggregation tasks: aggregating by categorical variables and using aggregation to change the structure of DataFrames.</p>
    <p class="normal">After the initial stages of data cleaning, analysts spend a substantial amount of their time doing what Hadley Wickham has called <em class="italic">splitting-applying-combining</em>—that is, we subset data by groups, apply some operation to those subsets, and then draw conclusions about a dataset as a whole. In slightly more specific terms, this involves generating descriptive statistics by key categorical variables. For the <code class="inlineCode">nls97</code> dataset, this might be gender, marital status, and the highest degree received. For the COVID-19 data, we might segment the data by country or date.</p>
    <p class="normal">Often, we need to aggregate data to prepare it for subsequent analysis. Sometimes, the rows of a DataFrame are disaggregated beyond the desired unit of analysis, and some aggregation has to be done before analysis can begin. For example, our DataFrame might have bird sightings by species per day over the course of many years. Since those values jump around, we might decide to smooth that out by working only with the total sightings by species per month, or even per year. Another example is household and car repair expenditures. We might need to summarize those expenditures over a year.</p>
    <p class="normal">There are several ways to aggregate data using NumPy and pandas, each with particular strengths. We explore the most useful approaches in this chapter: from looping with <code class="inlineCode">itertuples</code>, to navigating over NumPy arrays, to several techniques using the DataFrame <code class="inlineCode">groupby</code> method, and pivot tables. It is helpful to have a good understanding of the full range of tools available in pandas and NumPy, since almost all data analysis projects require some aggregation, aggregation is among the most consequential steps we take in the data cleaning process, and the best tool for the job is determined more by the attributes of the data than by our personal preferences.</p>
    <p class="normal">Specifically, the recipes in this chapter examine the following:</p>
    <ul>
      <li class="bulletList">Looping through data with <code class="inlineCode">itertuples</code> (an anti-pattern)</li>
      <li class="bulletList">Calculating summaries by group with NumPy arrays</li>
      <li class="bulletList">Using <code class="inlineCode">groupby</code> to organize data by groups</li>
      <li class="bulletList">Using more complicated aggregation functions with <code class="inlineCode">groupby</code></li>
      <li class="bulletList">Using user-defined functions and apply with <code class="inlineCode">groupby</code></li>
      <li class="bulletList">Using <code class="inlineCode">groupby</code> to change the unit of analysis of a DataFrame</li>
      <li class="bulletList">Using the pandas <code class="inlineCode">pivot_table</code> function to change the unit of analysis</li>
    </ul>
    <h1 id="_idParaDest-322" class="heading-1">Technical requirements</h1>
    <p class="normal">You will need pandas, NumPy, and Matplotlib to complete the recipes in this chapter. I used pandas 2.1.4, but the code will run on pandas 1.5.3 or later.</p>
    <p class="normal">The code in this chapter can be downloaded from the book’s GitHub repository, <a href="https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition"><span class="url">https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition</span></a>.</p>
    <h1 id="_idParaDest-323" class="heading-1">Looping through data with itertuples (an anti-pattern)</h1>
    <p class="normal">In this recipe, we will iterate<a id="_idIndexMarker721"/> over the rows of a DataFrame and generate <a id="_idIndexMarker722"/>our own totals for a variable. In subsequent recipes in this chapter, we will use NumPy arrays, and then some pandas-specific techniques, to accomplish the same tasks.</p>
    <p class="normal">It may seem odd to begin this chapter with a technique that we are often cautioned against using. But I used to do the equivalent of looping every day 35 years ago in SAS, and on select occasions as recently as 10 years ago in R. That is why I still find myself thinking conceptually about iterating over rows of data, sometimes sorted by groups, even though I rarely implement my code in this manner. I think it is good to hold onto that conceptualization, even when using other pandas methods that work for us more efficiently.</p>
    <p class="normal">I do not want to leave the impression that pandas-specific techniques are always markedly more efficient either. pandas users probably find themselves using <code class="inlineCode">apply</code> more than they would like, an approach that is only somewhat faster than looping.</p>
    <h2 id="_idParaDest-324" class="heading-2">Getting ready</h2>
    <p class="normal">We will work with the COVID-19 case<a id="_idIndexMarker723"/> daily data in this recipe. It has one row<a id="_idIndexMarker724"/> per day per country, each row having the number of new cases and new deaths for that day. It reflects totals as of March 2024.</p>
    <p class="normal">We will also be working with land temperature data from 87 weather stations in Brazil in 2023. Most weather stations had one temperature reading for each month.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Data note</strong></p>
      <p class="normal">Our World in Data provides COVID-19 public use data at <a href="https://ourworldindata.org/covid-cases"><span class="url">https://ourworldindata.org/covid-cases</span></a>. The dataset includes total cases and deaths, tests administered, hospital beds, and demographic data such as median age, gross domestic product, and diabetes prevalence. The dataset used in this recipe was downloaded on March 3, 2024.</p>
      <p class="normal">The land temperature DataFrame has the average temperature reading (in <sup class="superscript">°</sup>C) in 2023 from over 12,000 stations across the world, although a majority of the stations are in the United States. The raw data was retrieved from the Global Historical Climatology Network integrated database. It is made available for public use by the United States National Oceanic and Atmospheric Administration at <a href="https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-monthly"><span class="url">https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-monthly</span></a>.</p>
    </div>
    <h2 id="_idParaDest-325" class="heading-2">How to do it…</h2>
    <p class="normal">We will use the <code class="inlineCode">itertuples</code> DataFrame method to loop over the rows of the COVID-19 daily data and the monthly land temperature data for Brazil. We add logic to handle missing data and unexpected changes in key variable values from one period to the next:</p>
    <ol>
      <li class="numberedList" value="1">Import <code class="inlineCode">pandas</code> and <code class="inlineCode">numpy</code>, and load the COVID-19 and land temperature data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
coviddaily = pd.read_csv(<span class="hljs-string">"data/coviddaily.csv"</span>, parse_dates=[<span class="hljs-string">"casedate"</span>])
ltbrazil = pd.read_csv(<span class="hljs-string">"</span><span class="hljs-string">data/ltbrazil.csv"</span>)
</code></pre>
      </li>
      <li class="numberedList">Sort data by location and date:
        <pre class="programlisting code-one"><code class="hljs-code">coviddaily = coviddaily.sort_values([<span class="hljs-string">'location'</span>,<span class="hljs-string">'casedate'</span>])
</code></pre>
      </li>
      <li class="numberedList">Iterate over rows with <code class="inlineCode">itertuples</code>.</li>
    </ol>
    <p class="normal-one">Use <code class="inlineCode">itertuples</code>, which allows<a id="_idIndexMarker725"/> us to iterate over all rows as named<a id="_idIndexMarker726"/> tuples. Sum new cases over all the dates for each country. With each change of country (<code class="inlineCode">location</code>), append the running total to <code class="inlineCode">rowlist</code>, and then set the count to <code class="inlineCode">0</code> (note that <code class="inlineCode">rowlist</code> is a list and we are appending a dictionary to <code class="inlineCode">rowlist</code> with each change of country. A list of dictionaries is a good place to temporarily store data you might eventually want to convert to a DataFrame):</p>
    <pre class="programlisting code-one"><code class="hljs-code">prevloc = <span class="hljs-string">'ZZZ'</span>
rowlist = []
casecnt = <span class="hljs-number">0</span>
<span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> coviddaily.itertuples():
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> (prevloc!=row.location):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> (prevloc!=<span class="hljs-string">'ZZZ'</span>):
<span class="hljs-meta">... </span>      rowlist.append({<span class="hljs-string">'location'</span>:prevloc, <span class="hljs-string">'casecnt'</span>:casecnt})
<span class="hljs-meta">... </span>    casecnt = <span class="hljs-number">0</span>
<span class="hljs-meta">... </span>    prevloc = row.location
<span class="hljs-meta">... </span>  casecnt += row.new_cases
...
rowlist.append({<span class="hljs-string">'location'</span>:prevloc, <span class="hljs-string">'casecnt'</span>:casecnt})
<span class="hljs-built_in">len</span>(rowlist)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">231
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">rowlist[<span class="hljs-number">0</span>:<span class="hljs-number">4</span>]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">[{'location': 'Afghanistan', 'casecnt': 231539.0},
 {'location': 'Albania', 'casecnt': 334863.0},
 {'location': 'Algeria', 'casecnt': 272010.0},
 {'location': 'American Samoa', 'casecnt': 8359.0}]
</code></pre>
    <ol>
      <li class="numberedList" value="4">Create a DataFrame from the list of summary values, <code class="inlineCode">rowlist</code>.</li>
    </ol>
    <p class="normal-one">Pass the list we created in the previous step to the pandas <code class="inlineCode">DataFrame</code> method:</p>
    <pre class="programlisting code-one"><code class="hljs-code">covidtotals = pd.DataFrame(rowlist)
covidtotals.head()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">             location      casecnt
0         Afghanistan      231,539
1             Albania      334,863
2             Algeria      272,010
3      American Samoa        8,359
4             Andorra       48,015
</code></pre>
    <ol>
      <li class="numberedList" value="5">Now, let’s do the same<a id="_idIndexMarker727"/> for the land temperature<a id="_idIndexMarker728"/> data. We start by sorting it by <code class="inlineCode">station</code> and <code class="inlineCode">month</code>.</li>
    </ol>
    <p class="normal-one">Also, drop rows with missing values for temperature:</p>
    <pre class="programlisting code-one"><code class="hljs-code">ltbrazil = ltbrazil.sort_values([<span class="hljs-string">'station'</span>,<span class="hljs-string">'month'</span>])
ltbrazil = ltbrazil.dropna(subset=[<span class="hljs-string">'temperature'</span>])
</code></pre>
    <ol>
      <li class="numberedList" value="6">Exclude rows where there is a large change from one period to the next.</li>
    </ol>
    <p class="normal-one">Calculate the average temperature for the year, excluding values for temperature more than 3°C greater than or less than the temperature for the previous month:</p>
    <pre class="programlisting code-one"><code class="hljs-code">prevstation = <span class="hljs-string">'ZZZ'</span>
prevtemp = <span class="hljs-number">0</span>
rowlist = []
tempcnt = <span class="hljs-number">0</span>
stationcnt = <span class="hljs-number">0</span>
<span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> ltbrazil.itertuples():
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> (prevstation!=row.station):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> (prevstation!=<span class="hljs-string">'ZZZ'</span>):
<span class="hljs-meta">... </span>      rowlist.append({<span class="hljs-string">'station'</span>:prevstation, <span class="hljs-string">'</span><span class="hljs-string">avgtemp'</span>:tempcnt/stationcnt, <span class="hljs-string">'stationcnt'</span>:stationcnt})
<span class="hljs-meta">... </span>    tempcnt = <span class="hljs-number">0</span>
<span class="hljs-meta">... </span>    stationcnt = <span class="hljs-number">0</span>
<span class="hljs-meta">... </span>    prevstation = row.station
<span class="hljs-meta">... </span>  <span class="hljs-comment"># choose only rows that are within 3 degrees of the previous temperature </span>
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> ((<span class="hljs-number">0</span> &lt;= <span class="hljs-built_in">abs</span>(row.temperature-prevtemp) &lt;= <span class="hljs-number">3</span>) <span class="hljs-keyword">or</span> (stationcnt==<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    tempcnt += row.temperature
<span class="hljs-meta">... </span>    stationcnt += <span class="hljs-number">1</span>
<span class="hljs-meta">... </span>  prevtemp = row.temperature
...
rowlist.append({<span class="hljs-string">'</span><span class="hljs-string">station'</span>:prevstation, <span class="hljs-string">'avgtemp'</span>:tempcnt/stationcnt, <span class="hljs-string">'stationcnt'</span>:stationcnt})
rowlist[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">[{'station': 'ALTAMIRA', 'avgtemp': 27.729166666666668, 'stationcnt': 12},
 {'station': 'ALTA_FLORESTA_AERO',
  'avgtemp': 32.49333333333333,
  'stationcnt': 9},
 {'station': 'ARAXA', 'avgtemp': 21.52142857142857, 'stationcnt': 7},
 {'station': 'BACABAL', 'avgtemp': 28.59166666666667, 'stationcnt': 6},
 {'station': 'BAGE', 'avgtemp': 19.615000000000002, 'stationcnt': 10}]
</code></pre>
    <ol>
      <li class="numberedList" value="7">Create a DataFrame from<a id="_idIndexMarker729"/> the summary<a id="_idIndexMarker730"/> values.</li>
    </ol>
    <p class="normal-one">Pass the list we created in the previous step to the pandas <code class="inlineCode">DataFrame</code> method:</p>
    <pre class="programlisting code-one"><code class="hljs-code">ltbrazilavgs = pd.DataFrame(rowlist)
ltbrazilavgs.head()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                  station      avgtemp      stationcnt
0                ALTAMIRA           28              12
1      ALTA_FLORESTA_AERO           32               9
2                   ARAXA           22               7
3                 BACABAL           29               6
4                    BAGE           20              10
</code></pre>
    <p class="normal">This gives us a DataFrame with average temperatures for 2023 and the number of observations for each station.</p>
    <h2 id="_idParaDest-326" class="heading-2">How it works...</h2>
    <p class="normal">After sorting the COVID-19 daily data by <code class="inlineCode">location</code> and <code class="inlineCode">casedate</code> in <em class="italic">step 2</em>, we loop through our data one row at a time and do a running tally of new cases in <em class="italic">step 3</em>. We set that tally back to <code class="inlineCode">0</code> when we get to a new country, and then resume counting. Notice that we do not actually append our summary of new cases until we get to the next country. This is because there is no way to tell that we are on the last row for any country until we get to the next country. That is not a problem because we append the summary to <code class="inlineCode">rowlist</code> right before we reset the value to <code class="inlineCode">0</code>. That also means that we need to do something special to output the totals for the last country, since there is no next country. We do this with a final append after the loop is complete. This is a fairly standard approach to looping through data and outputting totals by group.</p>
    <p class="normal">The summary DataFrame we create in <em class="italic">steps 3</em> and <em class="italic">4</em> can be created more efficiently, both in terms of the analyst’s time and our computer’s workload, with other pandas techniques that we cover in this chapter. But that becomes a more difficult call when we need to do more complicated calculations, particularly those that involve comparing values across rows.</p>
    <p class="normal"><em class="italic">Steps 6</em> and <em class="italic">7</em> provide an example of this. We want to calculate the average temperature for each station for the year. Most stations have one reading per month. However, we are concerned that there might be some outlier values for temperature, defined here by a change of more than 3°C from one month to the next. We want to exclude those readings from the calculation of the mean for each station. It is fairly straightforward to do that while iterating over the data, by storing the previous value<a id="_idIndexMarker731"/> of temperature (<code class="inlineCode">prevtemp</code>) and comparing<a id="_idIndexMarker732"/> it to the current value.</p>
    <h2 id="_idParaDest-327" class="heading-2">There’s more...</h2>
    <p class="normal">We could have used <code class="inlineCode">iterrows</code> in <em class="italic">step 3</em> rather than <code class="inlineCode">itertuples</code>, with almost exactly the same syntax. Since we do not need the functionality of <code class="inlineCode">iterrows</code> here, we use <code class="inlineCode">itertuples</code>. The <code class="inlineCode">itertuples</code> method is easier on system resources than <code class="inlineCode">iterrows</code>. This is because you iterate over tuples with <code class="inlineCode">itertuples</code>, but over Series, with the associated type checking, with <code class="inlineCode">iterrows</code>.</p>
    <p class="normal">The hardest tasks to complete when working with tabular data involve calculations across rows: summing data across rows, basing a calculation on values in a different row, and generating running totals. Such calculations are complicated to implement and resource-intensive, regardless of language. However, it is hard to avoid having to do them, particularly when working with panel data. Some values for variables in a given period might be determined by values in a previous period. This is often more complicated than the running totals we have done in this recipe.</p>
    <p class="normal">For decades, data analysts have tried to address these data-cleaning challenges by looping through rows, carefully inspecting categorical and summary variables for data problems, and then handling the summation accordingly. Although this continues to be the approach that provides the most flexibility, pandas provides a number of data aggregation tools that run more efficiently and are easier to code. The challenge is to match the ability of looping solutions to adjust for invalid, incomplete, or atypical data. We explore these tools later in this chapter.</p>
    <h1 id="_idParaDest-328" class="heading-1">Calculating summaries by group with NumPy arrays</h1>
    <p class="normal">We can accomplish much of what we did in the previous<a id="_idIndexMarker733"/> recipe with <code class="inlineCode">itertuples</code> using NumPy arrays. We can also use NumPy arrays to get summary values for subsets of our data.</p>
    <h2 id="_idParaDest-329" class="heading-2">Getting ready</h2>
    <p class="normal">We will work again with the COVID-19 daily data and the Brazil land temperature data.</p>
    <h2 id="_idParaDest-330" class="heading-2">How to do it…</h2>
    <p class="normal">We copy DataFrame values to a NumPy array. We then navigate over the array, calculating totals by group and checking for unexpected changes in values:</p>
    <ol>
      <li class="numberedList" value="1">Import <code class="inlineCode">pandas</code> and <code class="inlineCode">numpy</code>, and load the COVID-19 and land temperature data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
coviddaily = pd.read_csv(<span class="hljs-string">"data/coviddaily.csv"</span>, parse_dates=[<span class="hljs-string">"casedate"</span>])
ltbrazil = pd.read_csv(<span class="hljs-string">"data/ltbrazil.csv"</span>)
</code></pre>
      </li>
      <li class="numberedList">Create a list of locations:
        <pre class="programlisting code-one"><code class="hljs-code">loclist = coviddaily.location.unique().tolist()
</code></pre>
      </li>
      <li class="numberedList">Use a NumPy array to calculate sums by location.</li>
    </ol>
    <p class="normal-one">Create a NumPy array of the location<a id="_idIndexMarker734"/> and new cases data. We then can iterate over the location list we created in the previous step and select all new case values (<code class="inlineCode">casevalues[j][1]</code>) for each location (<code class="inlineCode">casevalues[j][0]</code>). We then sum the new case values for that location:</p>
    <pre class="programlisting code-one"><code class="hljs-code">rowlist = []
casevalues = coviddaily[[<span class="hljs-string">'location'</span>,<span class="hljs-string">'new_cases'</span>]].to_numpy()
<span class="hljs-keyword">for</span> locitem <span class="hljs-keyword">in</span> loclist:
<span class="hljs-meta">... </span>  cases = [casevalues[j][<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(casevalues))\
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> casevalues[j][<span class="hljs-number">0</span>]==locitem]
<span class="hljs-meta">... </span>  rowlist.append(<span class="hljs-built_in">sum</span>(cases))
...
<span class="hljs-built_in">len</span>(rowlist)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">231
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-built_in">len</span>(loclist)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">231
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">rowlist[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">[231539.0, 334863.0, 272010.0, 8359.0, 48015.0]
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">casetotals = pd.DataFrame(<span class="hljs-built_in">zip</span>(loclist,rowlist), columns=([<span class="hljs-string">'location'</span>,<span class="hljs-string">'casetotals'</span>]))
casetotals.head()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">             location      casetotals
0         Afghanistan         231,539
1             Albania         334,863
2             Algeria         272,010
3      American Samoa           8,359
4             Andorra          48,015
</code></pre>
    <ol>
      <li class="numberedList" value="4">Sort the land temperature data and drop rows with missing values for temperature:
        <pre class="programlisting code-one"><code class="hljs-code">ltbrazil = ltbrazil.sort_values([<span class="hljs-string">'station'</span>,<span class="hljs-string">'month'</span>])
ltbrazil = ltbrazil.dropna(subset=[<span class="hljs-string">'temperature'</span>])
</code></pre>
      </li>
      <li class="numberedList">Use a NumPy array to calculate the average temperature<a id="_idIndexMarker735"/> for the year.</li>
    </ol>
    <p class="normal-one">Exclude rows where there is a large change from one period to the next:</p>
    <pre class="programlisting code-one"><code class="hljs-code">prevstation = <span class="hljs-string">'ZZZ'</span>
prevtemp = <span class="hljs-number">0</span>
rowlist = []
tempvalues = ltbrazil[[<span class="hljs-string">'station'</span>,<span class="hljs-string">'temperature'</span>]].to_numpy()
tempcnt = <span class="hljs-number">0</span>
stationcnt = <span class="hljs-number">0</span>
<span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(tempvalues)):
<span class="hljs-meta">... </span>  station = tempvalues[j][<span class="hljs-number">0</span>]
<span class="hljs-meta">... </span>  temperature = tempvalues[j][<span class="hljs-number">1</span>]
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> (prevstation!=station):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> (prevstation!=<span class="hljs-string">'ZZZ'</span>):
<span class="hljs-meta">... </span>      rowlist.append({<span class="hljs-string">'station'</span>:prevstation, <span class="hljs-string">'avgtemp'</span>:tempcnt/stationcnt, <span class="hljs-string">'stationcnt'</span>:stationcnt})
<span class="hljs-meta">... </span>    tempcnt = <span class="hljs-number">0</span>
<span class="hljs-meta">... </span>    stationcnt = <span class="hljs-number">0</span>
<span class="hljs-meta">... </span>    prevstation = station
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> ((<span class="hljs-number">0</span> &lt;= <span class="hljs-built_in">abs</span>(temperature-prevtemp) &lt;= <span class="hljs-number">3</span>) <span class="hljs-keyword">or</span> (stationcnt==<span class="hljs-number">0</span>)):
<span class="hljs-meta">... </span>    tempcnt += temperature
<span class="hljs-meta">... </span>    stationcnt += <span class="hljs-number">1</span>
<span class="hljs-meta">... </span>  prevtemp = temperature
...
rowlist.append({<span class="hljs-string">'station'</span>:prevstation, <span class="hljs-string">'avgtemp'</span>:tempcnt/stationcnt, <span class="hljs-string">'stationcnt'</span>:stationcnt})
rowlist[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">[{'station': 'ALTAMIRA', 'avgtemp': 27.729166666666668, 'stationcnt': 12},
 {'station': 'ALTA_FLORESTA_AERO',
  'avgtemp': 32.49333333333333,
  'stationcnt': 9},
 {'station': 'ARAXA', 'avgtemp': 21.52142857142857, 'stationcnt': 7},
 {'station': 'BACABAL', 'avgtemp': 28.59166666666667, 'stationcnt': 6},
 {'station': 'BAGE', 'avgtemp': 19.615000000000002, 'stationcnt': 10}]
</code></pre>
    <ol>
      <li class="numberedList" value="6">Create a DataFrame of the land temperature averages:
        <pre class="programlisting code-one"><code class="hljs-code">ltbrazilavgs = pd.DataFrame(rowlist)
ltbrazilavgs.head()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                  station      avgtemp      stationcnt
0                ALTAMIRA           28              12
1      ALTA_FLORESTA_AERO           32               9
2                   ARAXA           22               7
3                 BACABAL           29               6
4                    BAGE           20              10
</code></pre>
      </li>
    </ol>
    <p class="normal">This gives us a DataFrame with the average temperature<a id="_idIndexMarker736"/> and number of observations per station. Notice that we get the same results as in the final step of the previous recipe.</p>
    <h2 id="_idParaDest-331" class="heading-2">How it works…</h2>
    <p class="normal">NumPy arrays can be quite useful when we are working with tabular data but need to do some calculations across rows. This is because accessing items over the equivalent of rows is not really that different from accessing items over the equivalent of columns in an array. For example, <code class="inlineCode">casevalues[5][0]</code> (the sixth “row” and first “column” of the array) is accessed in the same way as <code class="inlineCode">casevalues[20][1]</code>. Navigating over a NumPy array is also faster than iterating over a pandas DataFrame.</p>
    <p class="normal">We take advantage of this in <em class="italic">step 3</em>. We get all of the array rows for a given location (<code class="inlineCode">if casevalues[j][0]==locitem</code>) with a list comprehension. Since we also need the <code class="inlineCode">location</code> list in the DataFrame that we will create of summary values, we use <code class="inlineCode">zip</code> to combine the two lists.</p>
    <p class="normal">We start working with the land temperature data in <em class="italic">step 4</em>, first sorting it by <code class="inlineCode">station</code> and <code class="inlineCode">month</code>, and then dropping rows with missing values for temperature. The logic in <em class="italic">step 5</em> is almost identical to the logic in <em class="italic">step 6</em> in the previous recipe. The main difference is that we need to refer to the locations<a id="_idIndexMarker737"/> of station (<code class="inlineCode">tempvalues[j][0]</code>) and <a id="_idIndexMarker738"/>temperature (<code class="inlineCode">tempvalues[j][1]</code>) in the array.</p>
    <h2 id="_idParaDest-332" class="heading-2">There’s more…</h2>
    <p class="normal">When you need to iterate over data, NumPy arrays will generally be faster than iterating over a pandas DataFrame with <code class="inlineCode">itertuples</code> or <code class="inlineCode">iterrows</code>. Also, if you tried to run the list comprehension in <em class="italic">step 3</em> using <code class="inlineCode">itertuples</code>, which is possible, you would be waiting some time for it to finish. In general, if you want to do a quick summary of values for some segment of your data, using NumPy arrays is a reasonable choice.</p>
    <h2 id="_idParaDest-333" class="heading-2">See also</h2>
    <p class="normal">The remaining recipes in this chapter rely on the powerful <code class="inlineCode">groupby</code> method of pandas DataFrames to generate group totals.</p>
    <h1 id="_idParaDest-334" class="heading-1">Using groupby to organize data by groups</h1>
    <p class="normal">At a certain point in most data<a id="_idIndexMarker739"/> analysis projects, we have to generate<a id="_idIndexMarker740"/> summary statistics by groups. While this can be done using the approaches in the previous recipe, in most cases the pandas DataFrame <code class="inlineCode">groupby</code> method is a better choice. If <code class="inlineCode">groupby</code> can handle an aggregation task—and it usually can—it is likely the most efficient way to accomplish that task. We make good use of <code class="inlineCode">groupby</code> in the next few recipes. We go over the basics in this recipe.</p>
    <h2 id="_idParaDest-335" class="heading-2">Getting ready</h2>
    <p class="normal">We will work with the COVID-19 daily data in this recipe.</p>
    <h2 id="_idParaDest-336" class="heading-2">How to do it…</h2>
    <p class="normal">We will create a pandas <code class="inlineCode">groupby</code> DataFrame and use it to generate summary statistics by group:</p>
    <ol>
      <li class="numberedList" value="1">Import <code class="inlineCode">pandas</code> and <code class="inlineCode">numpy</code>, and load the COVID-19 daily data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
coviddaily = pd.read_csv(<span class="hljs-string">"data/coviddaily.csv"</span>, parse_dates=[<span class="hljs-string">"casedate"</span>])
</code></pre>
      </li>
      <li class="numberedList">Create a pandas <code class="inlineCode">groupby</code> DataFrame:
        <pre class="programlisting code-one"><code class="hljs-code">countrytots = coviddaily.groupby([<span class="hljs-string">'location'</span>])
<span class="hljs-built_in">type</span>(countrytots)
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">&lt;class 'pandas.core.groupby.generic.DataFrameGroupBy'&gt;
</code></pre>
      </li>
      <li class="numberedList">Create DataFrames for the first rows of each country.</li>
    </ol>
    <p class="normal-one">To save space, we just show <a id="_idIndexMarker741"/>the first five rows<a id="_idIndexMarker742"/> and the first five columns:</p>
    <pre class="programlisting code-one"><code class="hljs-code">countrytots.first().iloc[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>, <span class="hljs-number">0</span>:<span class="hljs-number">5</span>]
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">              iso_code     casedate     continent      new_cases  \
location                                                 
Afghanistan        AFG   2020-03-01          Asia              1  
Albania            ALB   2020-03-15        Europe             33  
Algeria            DZA   2020-03-01        Africa              1  
American Samoa     ASM   2021-09-19       Oceania              1  
Andorra            AND   2020-03-08        Europe              1  
                    new_deaths 
location                   
Afghanistan                  0 
Albania                      1 
Algeria                      0 
American Samoa               0 
Andorra                      0
</code></pre>
    <ol>
      <li class="numberedList" value="4">Create DataFrames for the last rows of each country:
        <pre class="programlisting code-one"><code class="hljs-code">countrytots.last().iloc[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>, <span class="hljs-number">0</span>:<span class="hljs-number">5</span>]
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">               iso_code       casedate     continent      new_cases  \
location                                                 
Afghanistan         AFG     2024-02-04          Asia            210  
Albania             ALB     2024-01-28        Europe             45  
Algeria             DZA     2023-12-03        Africa             19  
American Samoa      ASM     2023-09-17       Oceania             18  
Andorra             AND     2023-05-07        Europe             41  
                    new_deaths 
location                   
Afghanistan                  0 
Albania                      0 
Algeria                      0 
American Samoa               0 
Andorra                      0
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-built_in">type</span>(countrytots.last())
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">&lt;class 'pandas.core.frame.DataFrame'&gt;
</code></pre>
      </li>
      <li class="numberedList">Get all the<a id="_idIndexMarker743"/> rows for<a id="_idIndexMarker744"/> a country:
        <pre class="programlisting code-one"><code class="hljs-code">countrytots.get_group((<span class="hljs-string">'Zimbabwe'</span>)).iloc[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>, <span class="hljs-number">0</span>:<span class="hljs-number">5</span>]
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con"> iso_code       casedate      location     continent      new_cases
36305 ZWE     2020-03-22      Zimbabwe        Africa              2
36306 ZWE     2020-03-29      Zimbabwe        Africa              5
36307 ZWE     2020-04-05      Zimbabwe        Africa              2
36308 ZWE     2020-04-12      Zimbabwe        Africa              7
36309 ZWE     2020-04-19      Zimbabwe        Africa             10
</code></pre>
      </li>
      <li class="numberedList">Loop through the groups.</li>
    </ol>
    <p class="normal-one">Only display rows for Malta and Kuwait:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">for</span> name, group <span class="hljs-keyword">in</span> countrytots:
<span class="hljs-meta">... </span>  <span class="hljs-keyword">if</span> (name[<span class="hljs-number">0</span>] <span class="hljs-keyword">in</span> [<span class="hljs-string">'Malta'</span>,<span class="hljs-string">'Kuwait'</span>]):
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(group.iloc[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>, <span class="hljs-number">0</span>:<span class="hljs-number">5</span>])
...
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">   iso_code       casedate     location     continent      new_cases
17818   KWT     2020-03-01       Kuwait          Asia             45
17819   KWT     2020-03-08       Kuwait          Asia             16
17820   KWT     2020-03-15       Kuwait          Asia             43
17821   KWT     2020-03-22       Kuwait          Asia             72
17822   KWT     2020-03-29       Kuwait          Asia             59
   iso_code       casedate     location     continent      new_cases
20621   MLT     2020-03-08        Malta        Europe              3
20622   MLT     2020-03-15        Malta        Europe             28
20623   MLT     2020-03-22        Malta        Europe             78
20624   MLT     2020-03-29        Malta        Europe             50
20625   MLT     2020-04-05        Malta        Europe             79
</code></pre>
    <ol>
      <li class="numberedList" value="7">Show the number of rows for each country:
        <pre class="programlisting code-one"><code class="hljs-code">countrytots.size()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">location
Afghanistan              205
Albania                  175
Algeria                  189
American Samoa            58
Andorra                  158
Vietnam                  192
Wallis and Futuna         23
Yemen                    122
Zambia                   173
Zimbabwe                 196
Length: 231, dtype: int64
</code></pre>
      </li>
      <li class="numberedList">Show summary statistics by country:
        <pre class="programlisting code-one"><code class="hljs-code">countrytots.new_cases.describe().head(<span class="hljs-number">3</span>).T
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">location      Afghanistan      Albania      Algeria
count                 205          175          189
mean                1,129        1,914        1,439
std                 1,957        2,637        2,205
min                     1           20            1
25%                   242          113           30
50%                   432          522          723
75%                 1,106        3,280        1,754
max                12,314       15,405       14,774
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">countrytots.new_cases.<span class="hljs-built_in">sum</span>().head()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">location
Afghanistan          231,539
Albania              334,863
Algeria              272,010
American Samoa         8,359
Andorra               48,015
Name: new_cases, dtype: float64
</code></pre>
      </li>
    </ol>
    <p class="normal">These steps demonstrate how remarkably useful the <code class="inlineCode">groupby</code> DataFrame object is when we want to generate summary statistics by categorical variables.</p>
    <h2 id="_idParaDest-337" class="heading-2">How it works...</h2>
    <p class="normal">In <em class="italic">step 2</em>, we create a pandas DataFrame <code class="inlineCode">groupby</code> object<a id="_idIndexMarker745"/> using the pandas<a id="_idIndexMarker746"/> DataFrame <code class="inlineCode">groupby</code> method, passing it a column or list of columns for the grouping. Once we have a <code class="inlineCode">groupby</code> DataFrame, we can generate statistics by group with the same tools that we use to generate summary statistics for the whole DataFrame. <code class="inlineCode">describe</code>, <code class="inlineCode">mean</code>, <code class="inlineCode">sum</code>, and similar methods work on the <code class="inlineCode">groupby</code> DataFrame—or series created from it—as expected, except the summary is run for each group.</p>
    <p class="normal">In <em class="italic">steps 3 and 4</em>, we use <code class="inlineCode">first</code> and <code class="inlineCode">last</code> to create DataFrames with the first and last occurrence of each group. We use <code class="inlineCode">get_group</code> to get all the rows for a particular group in <em class="italic">step 5</em>. We can also loop over the groups and use <code class="inlineCode">size</code> to count the number of rows for each group.</p>
    <p class="normal">In <em class="italic">step 8</em>, we create a Series <code class="inlineCode">groupby</code> object from the DataFrame <code class="inlineCode">groupby</code> object. Using the resulting object’s aggregation methods gives us summary statistics for a Series by group. One thing is clear about the distribution of <code class="inlineCode">new_cases</code> from this output: it varies quite a bit by country. For example, we can see right away that the interquartile range is quite different, even for the first three countries.</p>
    <h2 id="_idParaDest-338" class="heading-2">There’s more...</h2>
    <p class="normal">The output from <em class="italic">step 8</em> is quite useful. It is worth saving output such as that for each important continuous variable where the distribution is meaningfully different by group.</p>
    <p class="normal">pandas <code class="inlineCode">groupby</code> DataFrames are extraordinarily powerful and easy to use. <em class="italic">step 8</em> shows just how easy it is to create the summaries by group that we created in the first two recipes in this chapter. Unless the DataFrame we are working with is small, or the task involves very complicated calculations across rows, the <code class="inlineCode">groupby</code> method is a superior choice to looping.</p>
    <h1 id="_idParaDest-339" class="heading-1">Using more complicated aggregation functions with groupby</h1>
    <p class="normal">In the previous recipe, we<a id="_idIndexMarker747"/> created a <code class="inlineCode">groupby</code> DataFrame object<a id="_idIndexMarker748"/> and used it to run summary statistics by groups. We use chaining in this recipe to create the groups, choose the aggregation variable(s), and select the aggregation function(s), all in one line. We also take advantage of the flexibility of the <code class="inlineCode">groupby</code> object, which allows us to choose the aggregation columns and functions in a variety of ways.</p>
    <h2 id="_idParaDest-340" class="heading-2">Getting ready</h2>
    <p class="normal">We will work<a id="_idIndexMarker749"/> with the <strong class="keyWord">National Longitudinal Survey of Youth</strong> (<strong class="keyWord">NLS</strong>) data in this recipe. </p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Data note</strong></p>
      <p class="normal">The <strong class="keyWord">National Longitudinal Surveys</strong>, administered by the United<a id="_idIndexMarker750"/> States Bureau of Labor Statistics, are longitudinal surveys of individuals who were in high school in 1997 when the surveys started. Participants were surveyed each year through 2023. The surveys are available for public use at <a href="https://nlsinfo.org"><span class="url">nlsinfo.org</span></a>.</p>
    </div>
    <h2 id="_idParaDest-341" class="heading-2">How to do it…</h2>
    <p class="normal">We do more complicated aggregations with <code class="inlineCode">groupby</code> than we did in the previous recipe, taking advantage of its flexibility:</p>
    <ol>
      <li class="numberedList" value="1">Import <code class="inlineCode">pandas</code> and load the NLS data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
nls97 = pd.read_csv(<span class="hljs-string">"data/nls97g.csv"</span>, low_memory=<span class="hljs-literal">False</span>)
nls97.set_index(<span class="hljs-string">"personid"</span>, inplace=<span class="hljs-literal">True</span>)
</code></pre>
      </li>
      <li class="numberedList">Review the structure of the data:
        <pre class="programlisting code-one"><code class="hljs-code">nls97.iloc[:,<span class="hljs-number">0</span>:<span class="hljs-number">7</span>].info()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">&lt;class 'pandas.core.frame.DataFrame'&gt;
Index: 8984 entries, 135335 to 713757
Data columns (total 7 columns):
 #   Column                 Non-Null Count  Dtype 
---  ------                 --------------  ----- 
 0   gender                 8984 non-null   object
 1   birthmonth             8984 non-null   int64 
 2   birthyear              8984 non-null   int64 
 3   sampletype             8984 non-null   object
 4   ethnicity              8984 non-null   object
 5   highestgradecompleted  6663 non-null   float64
 6   maritalstatus          6675 non-null   object
dtypes: float64(1), int64(2), object(4)
memory usage: 561.5+ KB
</code></pre>
      </li>
      <li class="numberedList">Review some<a id="_idIndexMarker751"/> of the categorical<a id="_idIndexMarker752"/> data:
        <pre class="programlisting code-one"><code class="hljs-code">catvars = [<span class="hljs-string">'gender'</span>,<span class="hljs-string">'maritalstatus'</span>,<span class="hljs-string">'highestdegree'</span>]
<span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> catvars:
<span class="hljs-meta">... </span>  <span class="hljs-built_in">print</span>(col, nls97[col].value_counts().\
<span class="hljs-meta">... </span>    sort_index(), sep=<span class="hljs-string">"\n\n"</span>, end=<span class="hljs-string">"\n\n\n"</span>)
...
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">gender
Female    4385
Male      4599
Name: count, dtype: int64
maritalstatus
Divorced          669
Married          3068
Never-married    2767
Separated         148
Widowed            23
Name: count, dtype: int64
highestdegree
0. None             877
1. GED             1167
2. High School     3531
3. Associates       766
4. Bachelors       1713
5. Masters          704
6. PhD               64
7. Professional     130
Name: count, dtype: int64
</code></pre>
      </li>
      <li class="numberedList">Review some <a id="_idIndexMarker753"/>descriptive <a id="_idIndexMarker754"/>statistics:
        <pre class="programlisting code-one"><code class="hljs-code">contvars = [<span class="hljs-string">'satmath'</span>,<span class="hljs-string">'satverbal'</span>,
<span class="hljs-meta">... </span>  <span class="hljs-string">'weeksworked06'</span>,<span class="hljs-string">'gpaoverall'</span>,<span class="hljs-string">'childathome'</span>]
nls97[contvars].describe()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">        satmath   satverbal   weeksworked06   gpaoverall    childathome
count     1,407       1,406           8,419        6,004          4,791
mean        501         500              38          282              2
std         115         112              19           62              1
min           7          14               0           10              0
25%         430         430              27          243              1
50%         500         500              51          286              2
75%         580         570              52          326              3
max         800         800              52          417              9
</code></pre>
      </li>
      <li class="numberedList">Look at <strong class="keyWord">Scholastic Assessment Test</strong> (<strong class="keyWord">SAT</strong>) math scores by<a id="_idIndexMarker755"/> gender.</li>
    </ol>
    <p class="normal-one">We pass the column name to <code class="inlineCode">groupby</code> to group by that column:</p>
    <pre class="programlisting code-one"><code class="hljs-code">nls97.groupby(<span class="hljs-string">'gender'</span>)[<span class="hljs-string">'satmath'</span>].mean()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">gender
Female	487
Male	517
Name: satmath, dtype: float64
</code></pre>
    <ol>
      <li class="numberedList" value="6">Look at SAT math scores by gender and the highest degree earned.</li>
    </ol>
    <p class="normal-one">We can pass a list<a id="_idIndexMarker756"/> of column names<a id="_idIndexMarker757"/> to <code class="inlineCode">groupby</code> to group by more than one column:</p>
    <pre class="programlisting code-one"><code class="hljs-code">nls97.groupby([<span class="hljs-string">'gender'</span>,<span class="hljs-string">'highestdegree'</span>])[<span class="hljs-string">'satmath'</span>].\
  mean()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">gender  highestdegree 
Female  0. None           414
        1. GED            405
        2. High School    426
        3. Associates     448
        4. Bachelors      503
        5. Masters        504
        6. PhD            569
        7. Professional   593
Male    0. None           545
        1. GED            320
        2. High School    465
        3. Associates     490
        4. Bachelors      536
        5. Masters        568
        6. PhD            624
        7. Professional   594
Name: satmath, dtype: float64
</code></pre>
    <ol>
      <li class="numberedList" value="7">Look at SAT math and verbal scores by gender and the highest degree earned.</li>
    </ol>
    <p class="normal-one">We can use a list to summarize values for more than one variable, in this case <code class="inlineCode">satmath</code> and <code class="inlineCode">satverbal</code>:</p>
    <pre class="programlisting code-one"><code class="hljs-code">nls97.groupby([<span class="hljs-string">'gender'</span>,<span class="hljs-string">'highestdegree'</span>])[[<span class="hljs-string">'satmath'</span>,<span class="hljs-string">'satverbal'</span>]].mean()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                        satmath  satverbal
gender highestdegree                     
Female 0. None              414        408
       1. GED               405        390
       2. High School       426        440
       3. Associates        448        453
       4. Bachelors         503        508
       5. Masters           504        529
       6. PhD               569        561
       7. Professional      593        584
Male   0. None              545        515
       1. GED               320        360
       2. High School       465        455
       3. Associates        490        469
       4. Bachelors         536        521
       5. Masters           568        540
       6. PhD               624        627
       7. Professional      594        599
</code></pre>
    <ol>
      <li class="numberedList" value="8">Do multiple aggregation functions for one variable.</li>
    </ol>
    <p class="normal-one">Use the <code class="inlineCode">agg</code> function<a id="_idIndexMarker758"/> to return several summary<a id="_idIndexMarker759"/> statistics:</p>
    <pre class="programlisting code-one"><code class="hljs-code">nls97.groupby([<span class="hljs-string">'gender'</span>,<span class="hljs-string">'highestdegree'</span>])\
  [<span class="hljs-string">'gpaoverall'</span>].agg([<span class="hljs-string">'count'</span>,<span class="hljs-string">'mean'</span>,<span class="hljs-string">'max'</span>,<span class="hljs-string">'std'</span>])
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                          count    mean    max    std
gender highestdegree                        
Female 0. None              134     243    400     66
       1. GED               231     230    391     66
       2. High School      1152     277    402     53
       3. Associates        294     291    400     50
       4. Bachelors         742     322    407     48
       5. Masters           364     329    417     43
       6. PhD                26     345    400     44
       7. Professional       55     353    411     41
Male   0. None              180     222    400     65
       1. GED               346     223    380     63
       2. High School      1391     263    396     49
       3. Associates        243     272    383     49
       4. Bachelors         575     309    405     49
       5. Masters           199     324    404     50
       6. PhD                23     342    401     55
       7. Professional       41     345    410     35
</code></pre>
    <ol>
      <li class="numberedList" value="9">Use a dictionary for more complicated aggregations:
        <pre class="programlisting code-one"><code class="hljs-code">pd.options.display.float_format = <span class="hljs-string">'{:,.1f}'</span>.<span class="hljs-built_in">format</span>
aggdict = {<span class="hljs-string">'weeksworked06'</span>:[<span class="hljs-string">'count'</span>, <span class="hljs-string">'mean'</span>,
<span class="hljs-meta">... </span> <span class="hljs-string">'max'</span>,<span class="hljs-string">'std'</span>], <span class="hljs-string">'childathome'</span>:[<span class="hljs-string">'count'</span>, <span class="hljs-string">'mean'</span>,
<span class="hljs-meta">... </span> <span class="hljs-string">'max'</span>, <span class="hljs-string">'std'</span>]}
nls97.groupby([<span class="hljs-string">'highestdegree'</span>]).agg(aggdict)
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                weeksworked06                 \
                        count  mean   max    std  
highestdegree                                 
0. None                   666  29.7   52.0   21.6  
1. GED                   1129  32.9   52.0   20.7  
2. High School           3262  39.4   52.0   18.6  
3. Associates             755  40.2   52.0   18.0  
4. Bachelors             1683  42.3   52.0   16.2  
5. Masters                703  41.8   52.0   16.6   
6. PhD                     63  38.5   52.0   18.4  
7. Professional           127  27.8   52.0   20.4  
                childathome              
                      count   mean   max   std 
highestdegree                            
0. None                 408    1.8   8.0   1.6 
1. GED                  702    1.7   9.0   1.5 
2. High School         1881    1.9   7.0   1.3 
3. Associates           448    1.9   6.0   1.1 
4. Bachelors            859    1.9   8.0   1.1 
5. Masters              379    1.9   6.0   0.9 
6. PhD                   33    1.9   3.0   0.8 
7. Professional          60    1.8   4.0   0.8
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">nls97.groupby([<span class="hljs-string">'maritalstatus'</span>]).agg(aggdict)
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">              weeksworked06                 \
                      count   mean    max    std  
maritalstatus                               
Divorced                666   37.5   52.0   19.0  
Married                3035   40.3   52.0   17.9  
Never-married          2735   37.2   52.0   19.1  
Separated               147   33.6   52.0   20.3  
Widowed                  23   37.1   52.0   19.3  
              childathome              
                      count   mean    max    std 
maritalstatus                          
Divorced                530   1.5     5.0    1.2 
Married                2565   2.1     8.0    1.1 
Never-married          1501   1.6     9.0    1.3 
Separated               132   1.5     8.0    1.4 
Widowed                  18   1.8     5.0    1.4
</code></pre>
      </li>
    </ol>
    <p class="normal">We display the same summary statistics for <code class="inlineCode">weeksworked06</code> and <code class="inlineCode">childathome</code>, but we could have specified different aggregation functions for each using the same syntax that we used in <em class="italic">step 9</em>.</p>
    <h2 id="_idParaDest-342" class="heading-2">How it works…</h2>
    <p class="normal">We first take a look at some summary<a id="_idIndexMarker760"/> statistics for key columns<a id="_idIndexMarker761"/> in the DataFrame. We get frequencies for the categorical variables in <em class="italic">step 3</em>, and some descriptives for the continuous variables in <em class="italic">step 4</em>. It is a good idea to have summary values for the DataFrame as a whole in front of us before generating statistics by group.</p>
    <p class="normal">We are then ready to create summary statistics using <code class="inlineCode">groupby</code>. This involves three steps:</p>
    <ol>
      <li class="numberedList" value="1">Creating a <code class="inlineCode">groupby</code> DataFrame based on one or more categorical variables.</li>
      <li class="numberedList">Selecting the column(s) to be used for the summary statistics.</li>
      <li class="numberedList">Choosing the aggregation function(s).</li>
    </ol>
    <p class="normal">We use chaining in this recipe to do all three in one line. So, <code class="inlineCode">nls97.groupby('gender')['satmath'].mean()</code> in <em class="italic">step 5</em> does three things: <code class="inlineCode">nls97.groupby('gender')</code> creates the <code class="inlineCode">groupby</code> DataFrame object, <code class="inlineCode">['satmath']</code> chooses the aggregation column, and <code class="inlineCode">mean()</code> is the aggregation function.</p>
    <p class="normal">We can pass a column name (as in <em class="italic">step 5</em>) or a list of column names (as in <em class="italic">step 6</em>) to <code class="inlineCode">groupby</code> to create groupings by one or more columns. We can select multiple variables for aggregation with a list of those variables, as we do in <em class="italic">step 7</em> with <code class="inlineCode">[['satmath','satverbal']]</code>.</p>
    <p class="normal">We can chain a specific summary function such as <code class="inlineCode">mean</code>, <code class="inlineCode">count</code>, or <code class="inlineCode">max</code>. Alternatively, we could pass a list to <code class="inlineCode">agg</code> to choose multiple aggregation functions, such as with <code class="inlineCode">agg(['count','mean','max','std'])</code> in <em class="italic">step 8</em>. We can use the familiar pandas and NumPy aggregation functions or a user-defined function, which we explore in the next recipe.</p>
    <p class="normal">Another important takeaway from <em class="italic">step 8</em> is that <code class="inlineCode">agg</code> sends the aggregation columns to each function a group at a time. The calculations in each aggregation function are run for each group in the <code class="inlineCode">groupby</code> DataFrame. Another way to conceptualize this is that it allows us to run the same functions we are used to running across a whole DataFrame for one group at a time, accomplishing this by automating the process <a id="_idIndexMarker762"/>of sending the data for each group<a id="_idIndexMarker763"/> to the aggregation functions.</p>
    <h2 id="_idParaDest-343" class="heading-2">There’s more…</h2>
    <p class="normal">We first get a sense of how the categorical and continuous variables in the DataFrame are distributed. Often, we group data to see how a distribution of a continuous variable, such as weeks worked, differs by a categorical variable, such as marital status. Before doing that, it is helpful to have a good idea of how those variables are distributed across the whole dataset.</p>
    <p class="normal">The <code class="inlineCode">nls97</code> dataset only has SAT scores for about 1,400 of 8,984 respondents, so we need to be careful when examining SAT scores by different groups. This means that some of the counts by gender and highest degree, especially for PhD recipients, are a little too small to be reliable. There are outliers for SAT math and verbal (if we define outliers as 1.5 times the interquartile range above the third quartile or below the first quartile).</p>
    <p class="normal">We have acceptable counts for weeks worked and the number of children living at home for all values of the highest degree, and values of marital status except for widowed. The average weeks worked for folks who received a professional degree is unexpected. It is lower than for any other group. A good next step would be to see how persistent this is over the years. (We are just looking at 2006 weeks worked here, but there are 20 years of data on weeks worked.)</p>
    <h2 id="_idParaDest-344" class="heading-2">See also</h2>
    <p class="normal">The <code class="inlineCode">nls97</code> file is panel data masquerading as individual-level data. The panel data structure can be recovered, facilitating analysis over time of areas such as employment and school enrollment. We do this in the recipes in <em class="italic">Chapter 11</em>, <em class="italic">Tidying and Reshaping Data</em>.</p>
    <h1 id="_idParaDest-345" class="heading-1">Using user-defined functions and apply with groupby</h1>
    <p class="normal">Despite the numerous<a id="_idIndexMarker764"/> aggregation functions available<a id="_idIndexMarker765"/> in pandas and NumPy, we sometimes have to write our<a id="_idIndexMarker766"/> own to get <a id="_idIndexMarker767"/>the results we need. In some cases, this requires the use of <code class="inlineCode">apply</code>.</p>
    <h2 id="_idParaDest-346" class="heading-2">Getting ready</h2>
    <p class="normal">We will work with the NLS data in this recipe.</p>
    <h2 id="_idParaDest-347" class="heading-2">How to do it…</h2>
    <p class="normal">We will create our own functions to define the summary statistics we want by group:</p>
    <ol>
      <li class="numberedList" value="1">Import <code class="inlineCode">pandas</code> and the NLS data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
nls97 = pd.read_csv(<span class="hljs-string">"data/nls97g.csv"</span>, low_memory=<span class="hljs-literal">False</span>)
nls97.set_index(<span class="hljs-string">"personid"</span>, inplace=<span class="hljs-literal">True</span>)
</code></pre>
      </li>
      <li class="numberedList">Create a function to define the interquartile range:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">iqr</span>(<span class="hljs-params">x</span>):
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> x.quantile(<span class="hljs-number">0.75</span>) - x.quantile(<span class="hljs-number">0.25</span>)
</code></pre>
      </li>
      <li class="numberedList">Run the interquartile range function.</li>
    </ol>
    <p class="normal-one">Create a dictionary that specifies which aggregation functions to run on each analysis variable:</p>
    <pre class="programlisting code-one"><code class="hljs-code">aggdict = {<span class="hljs-string">'weeksworked06'</span>:[<span class="hljs-string">'count'</span>, <span class="hljs-string">'mean'</span>, iqr], <span class="hljs-string">'childathome'</span>:[<span class="hljs-string">'count'</span>, <span class="hljs-string">'mean'</span>, iqr]}
nls97.groupby([<span class="hljs-string">'highestdegree'</span>]).agg(aggdict)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                           weeksworked06           childathome
                      count   mean    iqr       count   mean    iqr  
highestdegree                            
0. None                 666   29.7    47.0        408    1.8   3.0
1. GED                 1129   32.9    40.0        702    1.7   3.0
2. High School         3262   39.4    21.0       1881    1.9   2.0
3. Associates           755   40.2    19.0        448    1.9   2.0
4. Bachelors           1683   42.3    13.5        859    1.9   1.0
5. Masters              703   41.8    13.5        379    1.9   1.0
6. PhD                   63   38.5    22.0         33    1.9   2.0
7. Professional         127   27.8    43.0         60    1.8   1.0
</code></pre>
    <ol>
      <li class="numberedList" value="4">Define a function<a id="_idIndexMarker768"/> to return <a id="_idIndexMarker769"/>selected<a id="_idIndexMarker770"/> summary <a id="_idIndexMarker771"/>statistics:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">gettots</span>(<span class="hljs-params">x</span>):
<span class="hljs-meta">... </span>  out = {}
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'qr1'</span>] = x.quantile(<span class="hljs-number">0.25</span>)
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'med'</span>] = x.median()
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'qr3'</span>] = x.quantile(<span class="hljs-number">0.75</span>)
<span class="hljs-meta">... </span>  out[<span class="hljs-string">'count'</span>] = x.count()
<span class="hljs-meta">... </span>  <span class="hljs-keyword">return</span> out
</code></pre>
      </li>
      <li class="numberedList">Use <code class="inlineCode">apply</code> to run the function.</li>
    </ol>
    <p class="normal-one">This will create a series with a multi-index, based on the <code class="inlineCode">highestdegree</code> values and the desired summary statistics:</p>
    <pre class="programlisting code-one"><code class="hljs-code">nls97.groupby([<span class="hljs-string">'highestdegree'</span>])[<span class="hljs-string">'weeksworked06'</span>].\
  apply(gettots)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">highestdegree        
0. None          qr1         5
                 med        35
                 qr3        52
                 count     666
1. GED           qr1        12
                 med        42
                 qr3        52
                 count   1,129
2. High School   qr1        31
                 med        52
                 qr3        52
                 count   3,262
3. Associates    qr1        33
                 med        52
                 qr3        52
                 count     755
4. Bachelors     qr1        38
                 med        52
                 qr3        52
                 count   1,683
5. Masters       qr1        38
                 med        52
                 qr3        52
                 count     703
6. PhD           qr1        30
                 med        50
                 qr3        52
                 count      63
7. Professional  qr1         6
                 med        30
                 qr3        49
                 count     127
Name: weeksworked06, dtype: float64
</code></pre>
    <ol>
      <li class="numberedList" value="6">Use <code class="inlineCode">reset_index</code> to use<a id="_idIndexMarker772"/> the default<a id="_idIndexMarker773"/> index instead<a id="_idIndexMarker774"/> of the index created<a id="_idIndexMarker775"/> from the <code class="inlineCode">groupby</code> DataFrame:
        <pre class="programlisting code-one"><code class="hljs-code">nls97.groupby([<span class="hljs-string">'highestdegree'</span>])[<span class="hljs-string">'weeksworked06'</span>].\
  apply(gettots).reset_index()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">      highestdegree   level_1    weeksworked06
0           0. None       qr1                5
1           0. None       med               35
2           0. None       qr3               52
3           0. None     count              666
4            1. GED       qr1               12
5            1. GED       med               42
6            1. GED       qr3               52
7            1. GED     count            1,129
8    2. High School       qr1               31
9    2. High School       med               52
10   2. High School       qr3               52
11   2. High School     count            3,262
12    3. Associates       qr1               33
13    3. Associates       med               52
14    3. Associates       qr3               52
15    3. Associates     count              755
16     4. Bachelors       qr1               38
17     4. Bachelors       med               52
18     4. Bachelors       qr3               52
19     4. Bachelors     count            1,683
20       5. Masters       qr1               38
21       5. Masters       med               52
22       5. Masters       qr3               52
23       5. Masters     count              703
24           6. PhD       qr1               30
25           6. PhD       med               50
26           6. PhD       qr3               52
27           6. PhD     count               63
28  7. Professional       qr1                6
29  7. Professional       med               30
30  7. Professional       qr3               49
31  7. Professional     count              127
</code></pre>
      </li>
      <li class="numberedList">Chain with <code class="inlineCode">unstack</code> instead<a id="_idIndexMarker776"/> to create<a id="_idIndexMarker777"/> columns based<a id="_idIndexMarker778"/> on the summary<a id="_idIndexMarker779"/> variables.</li>
    </ol>
    <p class="normal-one">This will create a DataFrame, with the <code class="inlineCode">highestdegree</code> values as the index and aggregation values in the columns:</p>
    <pre class="programlisting code-one"><code class="hljs-code">nlssums = nls97.groupby([<span class="hljs-string">'highestdegree'</span>])\
  [<span class="hljs-string">'weeksworked06'</span>].apply(gettots).unstack()
nlssums
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">                 qr1   med   qr3   count
highestdegree                       
0. None            5    35    52     666
1. GED            12    42    52   1,129
2. High School    31    52    52   3,262
3. Associates     33    52    52     755
4. Bachelors      38    52    52   1,683
5. Masters        38    52    52     703
6. PhD            30    50    52      63
7. Professional    6    30    49     127
</code></pre>
    <pre class="programlisting code-one"><code class="hljs-code">nlssums.info()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">&lt;class 'pandas.core.frame.DataFrame'&gt;
Index: 8 entries, 0. None to 7. Professional
Data columns (total 4 columns):
 #   Column  Non-Null Count  Dtype 
---  ------  --------------  ----- 
 0   qr1     8 non-null      float64
 1   med     8 non-null      float64
 2   qr3     8 non-null      float64
 3   count   8 non-null      float64
dtypes: float64(4)
memory usage: 320.0+ bytes
</code></pre>
    <p class="normal"><code class="inlineCode">unstack</code> is useful when we want to rotate parts of the index to the columns’ axis.</p>
    <h2 id="_idParaDest-348" class="heading-2">How it works...</h2>
    <p class="normal">We defined a very simple function to calculate interquartile ranges by group in <em class="italic">step 2</em>. We then included calls to that function in our list of aggregation functions in <em class="italic">step 3</em>.</p>
    <p class="normal"><em class="italic">Steps 4</em> and <em class="italic">5</em> are a little more complicated. We define a function that calculates the first and third quartiles and median and counts the number of rows. It returns a Series with these values. By combining a <code class="inlineCode">groupby</code> DataFrame with <code class="inlineCode">apply</code> in <em class="italic">step 5</em>, we get the <code class="inlineCode">gettots</code> function to return that Series for each group.</p>
    <p class="normal"><em class="italic">Step 5</em> gives us the numbers we want, but maybe not in the best format. If, for example, we want to use the data for another operation—say, a visualization—we need to chain some additional methods. One possibility<a id="_idIndexMarker780"/> is to use <code class="inlineCode">reset_index</code>. This will replace the multi-index with the default<a id="_idIndexMarker781"/> index. Another<a id="_idIndexMarker782"/> option is to use <code class="inlineCode">unstack</code>. This will create columns from the second<a id="_idIndexMarker783"/> level of the index (having <code class="inlineCode">qr1</code>, <code class="inlineCode">med</code>, <code class="inlineCode">qr3</code>, and <code class="inlineCode">count</code> values).</p>
    <h2 id="_idParaDest-349" class="heading-2">There’s more...</h2>
    <p class="normal">Interestingly, the interquartile ranges for weeks worked and the number of children at home drop substantially as education increases. There seems to be a higher variation in those variables among groups with less education. This should be examined more closely and has implications for statistical testing, which assumes common variances across groups.</p>
    <h2 id="_idParaDest-350" class="heading-2">See also</h2>
    <p class="normal">We do much more with <code class="inlineCode">stack</code> and <code class="inlineCode">unstack</code> in <em class="chapterRef">Chapter 11</em>, <em class="italic">Tidying and Reshaping Data</em>.</p>
    <h1 id="_idParaDest-351" class="heading-1">Using groupby to change the unit of analysis of a DataFrame</h1>
    <p class="normal">The DataFrame that we created<a id="_idIndexMarker784"/> in the last step of the previous<a id="_idIndexMarker785"/> recipe was something of a fortunate by-product of our efforts to generate multiple summary statistics by groups. There are times when we really do need to aggregate data to change the unit of analysis—say, from monthly utility expenses per family to annual utility expenses per family, or from <a id="_idIndexMarker786"/>students’ grades per course to students’ overall <strong class="keyWord">Grade Point Average</strong> (<strong class="keyWord">GPA</strong>).</p>
    <p class="normal"><code class="inlineCode">groupby</code> is a good tool for collapsing the unit of analysis, particularly when summary operations are required. When we only need to select unduplicated rows—perhaps the first or last row for each individual over a given interval—then the combination of <code class="inlineCode">sort_values</code> and <code class="inlineCode">drop_duplicates</code> will do the trick. But we often need to do some calculation across the rows for each group before collapsing. That is when <code class="inlineCode">groupby</code> comes in very handy.</p>
    <h2 id="_idParaDest-352" class="heading-2">Getting ready</h2>
    <p class="normal">We will work with the COVID-19 case daily data, which has one row per country per day. We will also work with the Brazil land temperature data, which has one row per month per weather station.</p>
    <h2 id="_idParaDest-353" class="heading-2">How to do it...</h2>
    <p class="normal">We will use <code class="inlineCode">groupby</code> to create<a id="_idIndexMarker787"/> a DataFrame of summary<a id="_idIndexMarker788"/> values by group:</p>
    <ol>
      <li class="numberedList" value="1">Import <code class="inlineCode">pandas</code> and load the COVID-19 and land temperature data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
coviddaily = pd.read_csv(<span class="hljs-string">"data/coviddaily.csv"</span>, parse_dates=[<span class="hljs-string">"casedate"</span>])
ltbrazil = pd.read_csv(<span class="hljs-string">"data/ltbrazil.csv"</span>)
</code></pre>
      </li>
      <li class="numberedList">Let’s view a sample of the data to remind ourselves of its structure. There is one row per country (<code class="inlineCode">location</code>) per date, with the number of new cases and deaths for that day (we provide a seed to random state to generate the same values each time):
        <pre class="programlisting code-one"><code class="hljs-code">coviddaily[[<span class="hljs-string">'location'</span>,<span class="hljs-string">'casedate'</span>,
  <span class="hljs-string">'new_cases'</span>,<span class="hljs-string">'new_deaths'</span>]]. \
  set_index([<span class="hljs-string">'location'</span>,<span class="hljs-string">'</span><span class="hljs-string">casedate'</span>]). \
  sample(<span class="hljs-number">10</span>, random_state=<span class="hljs-number">1</span>)
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                                      new_cases  \
location                 casedate               
Andorra                  2020-03-15           1  
Portugal                 2022-12-04       3,963  
Eswatini                 2022-08-07          22  
Singapore                2020-08-30         451  
Georgia                  2020-08-02          46  
British Virgin Islands   2020-08-30          14  
Thailand                 2023-01-29         472  
Bolivia                  2023-12-17         280  
Montenegro               2021-08-15       2,560  
Eswatini                 2022-04-17         132  
                                     new_deaths 
location                 casedate               
Andorra                  2020-03-15           0 
Portugal                 2022-12-04          69 
Eswatini                 2022-08-07           2 
Singapore                2020-08-30           0 
Georgia                  2020-08-02           1 
British Virgin Islands   2020-08-30           0 
Thailand                 2023-01-29          29 
Bolivia                  2023-12-17           0 
Montenegro               2021-08-15           9 
Eswatini                 2022-04-17           0
</code></pre>
      </li>
      <li class="numberedList">We can now convert the COVID-19 data<a id="_idIndexMarker789"/> from one country<a id="_idIndexMarker790"/> per day to summaries across all countries by day. To limit the amount of data to process, we only include dates between February 2023 and January 2024:
        <pre class="programlisting code-one"><code class="hljs-code">coviddailytotals = coviddaily.loc[coviddaily.\
  casedate.between(<span class="hljs-string">'2023-02-01'</span>,<span class="hljs-string">'2024-01-31'</span>)].\
  groupby([<span class="hljs-string">'casedate'</span>], as_index=<span class="hljs-literal">False</span>)\
  [[<span class="hljs-string">'</span><span class="hljs-string">new_cases'</span>,<span class="hljs-string">'new_deaths'</span>]].\
  <span class="hljs-built_in">sum</span>()
coviddailytotals.head(<span class="hljs-number">10</span>)
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">    casedate  new_cases  new_deaths
0 2023-02-05  1,385,583      69,679
1 2023-02-12  1,247,389      10,105
2 2023-02-19  1,145,666       8,539
3 2023-02-26  1,072,712       7,771
4 2023-03-05  1,028,278       7,001
5 2023-03-12    894,678       6,340
6 2023-03-19    879,074       6,623
7 2023-03-26    833,043       6,711
8 2023-04-02    799,453       5,969
9 2023-04-09    701,000       5,538
</code></pre>
      </li>
      <li class="numberedList">Let’s take a look at a couple of rows of the average temperature data for Brazil:
        <pre class="programlisting code-one"><code class="hljs-code">ltbrazil.head(<span class="hljs-number">2</span>).T
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                               0                1
locationid           BR000082400      BR000082704
year                        2023             2023
month                          1                1
temperature                   27               27
latitude                      -4               -8
longitude                    -32              -73
elevation                     59              194
station      FERNANDO_DE_NORONHA  CRUZEIRO_DO_SUL
countryid                     BR               BR
country                   Brazil           Brazil
latabs                         4                8
</code></pre>
      </li>
      <li class="numberedList">Create a DataFrame with average<a id="_idIndexMarker791"/> temperatures for each station<a id="_idIndexMarker792"/> in Brazil.</li>
    </ol>
    <p class="normal-one">Remove rows with missing temperature values first:</p>
    <pre class="programlisting code-one"><code class="hljs-code">ltbrazil = ltbrazil.dropna(subset=[<span class="hljs-string">'temperature'</span>])
ltbrazilavgs = ltbrazil.groupby([<span class="hljs-string">'</span><span class="hljs-string">station'</span>],
<span class="hljs-meta">... </span>  as_index=<span class="hljs-literal">False</span>).\
<span class="hljs-meta">... </span>  agg({<span class="hljs-string">'latabs'</span>:<span class="hljs-string">'first'</span>,<span class="hljs-string">'elevation'</span>:<span class="hljs-string">'first'</span>,
<span class="hljs-meta">... </span>  <span class="hljs-string">'temperature'</span>:<span class="hljs-string">'</span><span class="hljs-string">mean'</span>})
ltbrazilavgs.head(<span class="hljs-number">10</span>)
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">               station  latabs  elevation  temperature
0             ALTAMIRA       3        112           28
1   ALTA_FLORESTA_AERO      10        289           32
2                ARAXA      20      1,004           22
3              BACABAL       4         25           29
4                 BAGE      31        242           20
5       BARRA_DO_CORDA       6        153           28
6            BARREIRAS      12        439           27
7  BARTOLOMEU_LISANDRO      22         17           26
8                BAURU      22        617           25
9                BELEM       1         10           28
</code></pre>
    <p class="normal">Let’s take a closer look at how the aggregation functions in these examples work.</p>
    <h2 id="_idParaDest-354" class="heading-2">How it works…</h2>
    <p class="normal">In <em class="italic">step 3</em>, we first select the dates that we want. We create a DataFrame <code class="inlineCode">groupby</code> object based on <code class="inlineCode">casedate</code>, choose <code class="inlineCode">new_cases</code> and <code class="inlineCode">new_deaths</code> as the aggregation variables, and select <code class="inlineCode">sum</code> for the aggregation function. This produces a sum for both <code class="inlineCode">new_cases</code> and <code class="inlineCode">new_deaths</code> for each group (<code class="inlineCode">casedate</code>). Depending on your purposes, you may not want <code class="inlineCode">casedate</code> to be the index, which would happen if we did not set <code class="inlineCode">as_index</code> to <code class="inlineCode">False</code>.</p>
    <p class="normal">We often need to use a different aggregation function with different aggregation variables. We might want to take the first (or last) value for one variable and get the mean of the values of another variable by group. This is what we do in <em class="italic">step 5</em>. We do this by passing a dictionary to the <code class="inlineCode">agg</code> function, with our aggregation<a id="_idIndexMarker793"/> variables as keys and the aggregation<a id="_idIndexMarker794"/> function to use as values.</p>
    <h1 id="_idParaDest-355" class="heading-1">Using pivot_table to change the unit of analysis of a DataFrame</h1>
    <p class="normal">We could have used<a id="_idIndexMarker795"/> the pandas <code class="inlineCode">pivot_table</code> function<a id="_idIndexMarker796"/> instead of <code class="inlineCode">groupby</code> in the previous recipe. <code class="inlineCode">pivot_table</code> can be used to generate summary statistics by the values of a categorical variable, just as we did with <code class="inlineCode">groupby</code>. The <code class="inlineCode">pivot_table</code> function can also return a DataFrame, as we will see in this recipe.</p>
    <h2 id="_idParaDest-356" class="heading-2">Getting ready</h2>
    <p class="normal">We will work with the COVID-19 case daily data and the Brazil land temperature data again. The temperature data has one row per month per weather station.</p>
    <h2 id="_idParaDest-357" class="heading-2">How to do it...</h2>
    <p class="normal">Let’s create a DataFrame from the COVID-19 data that has the total number of cases and deaths for each day across all countries:</p>
    <ol>
      <li class="numberedList" value="1">We start by loading the COVID-19 and temperature data again:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
coviddaily = pd.read_csv(<span class="hljs-string">"data/coviddaily.csv"</span>, parse_dates=[<span class="hljs-string">"casedate"</span>])
ltbrazil = pd.read_csv(<span class="hljs-string">"data/ltbrazil.csv"</span>)
</code></pre>
      </li>
      <li class="numberedList">Now, we are ready to call the <code class="inlineCode">pivot_table</code> function. We pass a list to <code class="inlineCode">values</code> to indicate the variables for the summary calculations. We use the <code class="inlineCode">index</code> parameter to indicate that we want totals by <code class="inlineCode">casedate</code>, and we indicate that we only want sums by passing that to <code class="inlineCode">aggfunc</code>. Notice that we get the same totals as in the previous recipe when we used <code class="inlineCode">groupby</code>:
        <pre class="programlisting code-one"><code class="hljs-code">coviddailytotals = \
  pd.pivot_table(coviddaily.loc[coviddaily.casedate. \
  between(<span class="hljs-string">'2023-02-01'</span>,<span class="hljs-string">'2024-01-31'</span>)],
  values=[<span class="hljs-string">'new_cases'</span>,<span class="hljs-string">'new_deaths'</span>], index=<span class="hljs-string">'casedate'</span>,
  aggfunc=<span class="hljs-string">'sum'</span>)
coviddailytotals.head(<span class="hljs-number">10</span>)
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">            new_cases  new_deaths
casedate                        
2023-02-05  1,385,583      69,679
2023-02-12  1,247,389      10,105
2023-02-19  1,145,666       8,539
2023-02-26  1,072,712       7,771
2023-03-05  1,028,278       7,001
2023-03-12    894,678       6,340
2023-03-19    879,074       6,623
2023-03-26    833,043       6,711
2023-04-02    799,453       5,969
2023-04-09    701,000       5,538
</code></pre>
      </li>
      <li class="numberedList">Let’s try <code class="inlineCode">pivot_table</code> with the land<a id="_idIndexMarker797"/> temperature data<a id="_idIndexMarker798"/> and do a more complicated aggregation. We want the first value for latitude (<code class="inlineCode">latabs</code>) and elevation for each station and the mean temperature. Recall that latitude and elevation values do not change for a station. We pass the aggregations we want as a dictionary to <code class="inlineCode">aggfunc</code>. Again, we get the same results as in the previous recipe:
        <pre class="programlisting code-one"><code class="hljs-code">ltbrazil = ltbrazil.dropna(subset=[<span class="hljs-string">'temperature'</span>])
ltbrazilavgs = \
  pd.pivot_table(ltbrazil, index=[<span class="hljs-string">'station'</span>],
  aggfunc={<span class="hljs-string">'latabs'</span>:<span class="hljs-string">'first'</span>,<span class="hljs-string">'elevation'</span>:<span class="hljs-string">'first'</span>,
  <span class="hljs-string">'temperature'</span>:<span class="hljs-string">'mean'</span>})
ltbrazilavgs.head(<span class="hljs-number">10</span>)
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                     elevation  latabs  temperature
station                                           
ALTAMIRA                   112       3           28
ALTA_FLORESTA_AERO         289      10           32
ARAXA                    1,004      20           22
BACABAL                     25       4           29
BAGE                       242      31           20
BARRA_DO_CORDA             153       6           28
BARREIRAS                  439      12           27
BARTOLOMEU_LISANDRO         17      22           26
BAURU                      617      22           25
BELEM                       10       1           28
</code></pre>
      </li>
    </ol>
    <h2 id="_idParaDest-358" class="heading-2">How it works...</h2>
    <p class="normal">As we have seen, we get the same results whether we use <code class="inlineCode">groupby</code> or <code class="inlineCode">pivot_table</code>. Analysts should probably choose the approach that they, and members of their team, find most intuitive. Since my workflow more frequently has me using <code class="inlineCode">groupby</code>, I am much more likely to use that approach<a id="_idIndexMarker799"/> when aggregating data to create<a id="_idIndexMarker800"/> a new DataFrame.</p>
    <h1 id="_idParaDest-359" class="heading-1">Summary</h1>
    <p class="normal">We stepped through a wide range of strategies for aggregating data using NumPy and pandas in this chapter. We also discussed advantages and disadvantages of each technique, including how to select the most efficient and intuitive approach given your data and the aggregation task. Since most data cleaning and manipulation projects will involve some splitting-applying-combining, it is a good idea to become comfortable with each of these approaches. In the next chapter, we will learn how to combine DataFrames and deal with subsequent data issues.</p>
    <h1 class="heading-1">Join our community on Discord</h1>
    <p class="normal">Join our community’s Discord space for discussions with the author and other readers:</p>
    <p class="normal"><a href="https://discord.gg/p8uSgEAETX "><span class="url">https://discord.gg/p8uSgEAETX</span></a></p>
    <p class="normal"><img src="../Images/QR_Code10336218961138498953.png" alt="" role="presentation"/></p>
  </div>
</body></html>