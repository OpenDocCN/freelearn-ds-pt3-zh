["```py\nsales_data = pd.read_csv(\"salesdata.csv\", encoding = \"ISO-8859-1\")\n```", "```py\nsales_data.head()\n```", "```py\ncategory_grouped = sales_data.groupby(\"Category\")\ntype(category_grouped)\npandas.core.groupby. DataFrameGroupBy\n```", "```py\ncategory_grouped.groups\n```", "```py\nsales_data.groupby(\"Category\").sum()\n```", "```py\nsales_data[[\"Category\", \"Sales\"]].groupby(\"Category\").sum()\n```", "```py\nsales_data[[\"Category\", \"Country\"]].groupby(\"Category\").first()\n```", "```py\nsales_data.groupby(\"Category\").size().sort_values(ascending = True)\n```", "```py\nindex_by_date = sales_data.set_index('OrderDate')\nindex_by_date.groupby(lambda OrderDate: OrderDate.split('-')[2]).sum()\n```", "```py\nsales_data.groupby([\"ShipMode\",\"Category\"]).size()\n```", "```py\nsales_data.groupby(\"ShipMode\").get_group(\"Same Day\")\n```", "```py\nfor name, group in sales_data.groupby(\"ShipMode\"):\nprint(name)\nprint(group.iloc[0:5,0:5])\n```", "```py\nregion_index_df = sales_data.set_index(\"Region\", drop = True)\nregion_index_df.groupby(level = 0).sum()\n```", "```py\nsales_data.groupby(\"ShipMode\", axis = 0).size()\n```", "```py\nmultiindex_df = sales_data.set_index([\"ShipMode\", \"Category\"])\nmultiindex_df.head()\n```", "```py\nmultiindex_df.groupby(level = 0).sum()\n```", "```py\nmultiindex_df.groupby(level = \"Category\").sum()\n```", "```py\nmultiindex_df.groupby(\"Category\").sum()\n```", "```py\nmultiindex_df.groupby(level = [\"ShipMode\", \"Category\"]).sum()\n```", "```py\nmultiindex_df.sum(level = [0, 1])\n```", "```py\nmultiindex_df.groupby([pd.Grouper(level = 1), \"Region\"]).size()\nmultiindex_df.groupby([\"Category\", \"Region\"]).size()\n```", "```py\nsum_all = multiindex_df.groupby(level = 1).sum()\n\nsum_all.ix[\"Furniture\"]/(sum_all.ix[\"Furniture\"] + sum_all.ix[\"Technology\"] + sum_all.ix[\"Office Supplies\"])\n```", "```py\nfurniture_ratio = sum_all.ix[\"Furniture\"]/(sum_all.ix[\"Furniture\"] + sum_all.ix[\"Technology\"] + sum_all.ix[\"Office Supplies\"])\n\npd.DataFrame(furniture_ratio).T\n```", "```py\nfurniture_ratio_df = pd.DataFrame(furniture_ratio).T\nfurniture_ratio_df.rename(index = {0 : \"FurniturePercent\"})\n```", "```py\nsales_data.groupby(\"Category\").aggregate(np.sum)\n```", "```py\nsales_data.groupby([\"ShipMode\", \"Category\"]).aggregate(np.sum)\n```", "```py\nsales_data.groupby([\"ShipMode\", \"Category\"]).aggregate(np.sum).reset_index()\n```", "```py\nsales_data.groupby([\"ShipMode\", \"Category\"], as_index = False).aggregate(np.sum)\n```", "```py\nsales_data[[\"Sales\", \"Quantity\", \"Category\"]].groupby(\"Category\").agg([np.mean, np.std])\n```", "```py\nsales_data[[\"Sales\", \"Quantity\", \"Category\"]].groupby(\"Category\").agg([np.mean, np.std]).rename(columns = {\"mean\": \"Mean\", \"std\": \"SD\"})\n```", "```py\nsales_data[[\"Sales\", \"Quantity\", \"Category\"]].groupby(\"Category\").agg({\"Sales\":\"sum\", \"Quantity\":\"mean\"})\n```", "```py\nna_df = sales_data[[\"Sales\", \"Quantity\", \"Discount\", \"Profit\", \"Category\"]].set_index(\"Category\").mask(np.random.random(sales_data[[\"Sales\", \"Quantity\", \"Discount\", \"Profit\"]].shape) &amp;lt; .25)\n\nna_df.head(10)\n```", "```py\nna_df.groupby(\"Category\").count()\n```", "```py\ntransformed = na_df.groupby(\"Category\").transform(lambda x: x.fillna(x.mean()))\ntransformed.head(10)\n```", "```py\ntransformed.groupby(\"Category\").count()\n```", "```py\nna_df.groupby(\"Category\").mean()\n```", "```py\ntransformed.groupby(\"Category\").mean()\n```", "```py\nna_df.groupby(\"Category\").bfill()\n```", "```py\nsales_data[[\"Sales\", \"Category\"]].groupby(\"Category\").expanding().sum()\n```", "```py\nfiltered_df = sales_data[[\"Category\", \"Quantity\"]].set_index(\"Category\").groupby(\"Category\").filter(lambda x: len(x) &amp;gt; 10000)\nfiltered_df.groupby(\"Category\").sum()\n```", "```py\nconcat(objs, axis=0, , join='outer', join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False)\n```", "```py\n    In [53]: stockDataDF=pd.read_csv('./tech_stockprices.csv').set_index(\n ['Symbol']);stockDataDF\n    Out[53]:\n         Closing price  EPS  Shares Outstanding(M) P/E Market Cap(B) Beta\n    Symbol\n    AAPL   501.53  40.32  892.45          12.44  447.59    0.84\n    AMZN   346.15  0.59   459.00         589.80  158.88    0.52\n    FB   61.48        0.59  2450.00         104.93  150.92    NaN\n    GOOG   1133.43    36.05   335.83          31.44  380.64    0.87\n    TWTR   65.25        -0.30   555.20            NaN   36.23    NaN\n    YHOO   34.90         1.27     1010.00          27.48   35.36    0.66\n\n```", "```py\n    In [83]: A=stockDataDF.ix[:4, ['Closing price', 'EPS']]; A\n    Out[83]:  Closing price  EPS\n     Symbol\n      AAPL     501.53      40.32\n      AMZN     346.15     0.59\n      FB      61.48     0.59\n       GOOG    1133.43    36.05\n\n    In [84]: B=stockDataDF.ix[2:-2, ['P/E']];B\n    Out[84]:         P/E\n            Symbol\n           FB   104.93\n           GOOG   31.44\n\n    In [85]: C=stockDataDF.ix[1:5, ['Market Cap(B)']];C\n    Out[85]:         Market Cap(B)\n            Symbol\n           AMZN   158.88\n           FB   150.92\n           GOOG   380.64\n           TWTR   36.23\n```", "```py\n    In [86]: pd.concat([A,B,C],axis=1) # outer join\n    Out[86]:  Closing price  EPS    P/E   Market Cap(B)\n      AAPL   501.53     40.32  NaN   NaN\n      AMZN   346.15     0.59   NaN   158.88\n       FB   61.48           0.59  104.93 150.92\n       GOOG   1133.43       36.05  31.44 380.64\n       TWTR   NaN            NaN    NaN    36.23\n```", "```py\n    In [87]: pd.concat([A,B,C],axis=1, join='inner') # Inner join\n    Out[87]:        Closing price  EPS  P/E   Market Cap(B)\n             Symbol\n             FB      61.48    0.59 104.93  150.92\n          GOOG    1133.43   36.05   31.44   380.64\n\n```", "```py\n    In [102]: pd.concat([A,B,C], axis=1, join_axes=[stockDataDF.index])\n    Out[102]:       Closing price  EPS    P/E   Market Cap(B)\n          Symbol\n             AAPL   501.53     40.32  NaN   NaN\n            AMZN   346.15     0.59   NaN   158.88\n             FB   61.48           0.59  104.93 150.92\n             GOOG   1133.43       36.05  31.44 380.64\n             TWTR   NaN            NaN    NaN    36.23\n            YHOO   NaN            NaN    NaN    NaN\n\n```", "```py\n    In[135]: np.random.seed(100)\n            normDF=pd.DataFrame(np.random.randn(3,4));normDF\n    Out[135]:    0    1      2    3\n      0  -1.749765  0.342680  1.153036  -0.252436\n      1   0.981321  0.514219  0.221180  -1.070043\n      2  -0.189496  0.255001 -0.458027   0.435163\n\n    In [136]: binomDF=pd.DataFrame(np.random.binomial(100,0.5,(3,4)));binomDF\n    Out[136]:  0  1  2  3\n      0  57  50  57     50\n      1  48  56  49     43\n      2  40  47  49     55\n\n    In [137]: poissonDF=pd.DataFrame(np.random.poisson(100,(3,4)));poissonDF\n    Out[137]:  0  1  2  3\n       0  93  96  96  89\n       1  76  96  104  103\n       2  96  93  107   84\n\n    In [138]: rand_distribs=[normDF,binomDF,poissonDF]\n    In [140]: rand_distribsDF=pd.concat(rand_distribs,keys=['Normal', 'Binomial', 'Poisson']);rand_distribsDF\n    Out[140]:         0        1       2          3\n      Normal     0  -1.749765   0.342680  1.153036  -0.252436\n           1   0.981321   0.514219  0.221180  -1.070043\n           2  -0.189496   0.255001 -0.458027   0.435163\n      Binomial 0   57.00       50.00     57.00      50.00\n           1   48.00       56.00     49.00      43.00\n           2   40.00       47.00     49.00      55.00\n      Poisson  0   93.00       96.00     96.00      89.00\n           1   76.00       96.00    104.00     103.00\n           2   96.00       93.00    107.00      84.00\n```", "```py\n    In [145]: stockDataA=stockDataDF.ix[:2,:3]\n                stockDataA\n    Out[145]:  Closing price  EPS   Shares Outstanding(M)\n      Symbol\n      AAPL     501.53   40.32   892.45\n      AMZN     346.15   0.59   459.00\n\n```", "```py\n    In [147]: stockDataB=stockDataDF[2:]\n             stockDataB\n    Out[147]:\n         Closing price EPS Shares Outstanding(M)  P/E  Market Cap(B) Beta\n    Symbol\n    FB   61.48         0.59  2450.00          104.93 150.92   NaN\n    GOOG   1133.43    36.05   335.83          31.44  380.64   0.87\n    TWTR     65.25    -0.30   555.20           NaN     36.23   NaN\n    YHOO     34.90  1.27  1010.00       27.48  35.36   0.66\n\n```", "```py\n    In [161]:stockDataA.append(stockDataB)\n    Out[161]:\n        Beta Closing price EPS MarketCap(B) P/E     Shares Outstanding(M)\n    Symbol\n    AMZN  NaN  346.15    0.59  NaN   NaN    459.00\n    GOOG  NaN  1133.43   36.05  NaN   NaN    335.83\n    FB  NaN  61.48      0.59  150.92 104.93 2450.00\n    YHOO  27.48  34.90      1.27  35.36   0.66   1010.00\n    TWTR  NaN  65.25     -0.30  36.23   NaN    555.20\n    AAPL  12.44  501.53     40.32  0.84   447.59 892.45\n\n```", "```py\n    In [151]: stockDataA.append(stockDataB).reindex_axis(stockDataDF.columns, axis=1)\n    Out[151]:\n      Closing price EPS Shares Outstanding(M)  P/E Market Cap(B) Beta\n    Symbol\n    AAPL   501.53  40.32  892.45         NaN  NaN      NaN\n    AMZN   346.15   0.59  459.00          NaN  NaN      NaN\n    FB   61.48     0.59  2450.00          104.93  150.92      NaN\n    GOOG  1133.43  36.05  335.83        31.44  380.64     0.87\n    TWTR    65.25  -0.30  555.20          NaN   36.23      NaN\n    YHOO   34.90     1.27  1010.00            27.48  35.36     0.66\n\n```", "```py\n    In [152]: \n    algos={'search':['DFS','BFS','Binary Search','Linear'],\n            'sorting': ['Quicksort','Mergesort','Heapsort','Bubble Sort'],\n           'machine learning':['RandomForest','K Nearest Neighbor','Logistic Regression','K-Means Clustering']}\n    algoDF=pd.DataFrame(algos);algoDF\n    Out[152]: machine learning    search      sorting\n    0    RandomForest        DFS      Quicksort\n    1    K Nearest Neighbor   BFS      Mergesort\n    2    Logistic Regression  Binary Search Heapsort\n    3    K-Means Clustering   Linear       Bubble Sort\n\n    In [154]: \n    moreAlgos={'search': 'ShortestPath'  , 'sorting': 'Insertion Sort',\n                'machine learning': 'Linear Regression'}\n    algoDF.append(moreAlgos,ignore_index=True) \n    Out[154]: machine learning    search      sorting\n    0    RandomForest        DFS      Quicksort\n    1    K Nearest Neighbor    BFS      Mergesort\n    2    Logistic Regression Binary Search Heapsort\n    3    K-Means Clustering  Linear       Bubble Sort\n    4    Linear Regression   ShortestPath  Insertion Sort\n\n```", "```py\n    merge(left, right, how='inner', on=None, left_on=None,\n    right_on=None, left_index=False, right_index=False, \n          sort=True, suffixes=('_x', '_y'), copy=True)\n```", "```py\nleft\n```", "```py\nright\n```", "```py\npd.merge(left, right, on = [\"Category\", \"Region\"])\n```", "```py\npd.merge(left, right, how = \"left\", on = [\"Category\", \"Region\"])\n```", "```py\npd.merge(left, right, how = \"right\", on = [\"Category\", \"Region\"])\n```", "```py\npd.merge(left, right, how = \"outer\", on = [\"Category\", \"Region\"])\n```", "```py\nleft.loc[5,:] =[\"Office Supplies\", \"Canada\", 111, 111]\nleft\n```", "```py\npd.merge(left, right, how = \"outer\", on = [\"Category\", \"Region\"])\n```", "```py\npd.merge(left, right, how = \"outer\", on = [\"Category\", \"Region\"], validate = \"one_to_one\")\n```", "```py\npd.merge(left, right, how = \"outer\", on = [\"Category\", \"Region\"], indicator = \"Indicator\")\n```", "```py\ndf_1 = sales_data.iloc[0:5, 0:3]\ndf_2 = sales_data.iloc[3:8, 3:6]\ndf_1.join(df_2)\n```", "```py\ndf_1.join(df_2, how = \"right\")\n```", "```py\ndf_1.join(df_2, how = \"inner\")\n```", "```py\ndf_1.join(df_2, how = \"outer\")\n```", "```py\n    In [344]: plantGrowthRawDF=pd.read_csv('./PlantGrowth.csv')\n           plantGrowthRawDF\n    Out[344]:   observation   weight  group\n            0   1      4.17  ctrl\n            1   2      5.58  ctrl\n            2   3      5.18  ctrl\n            ...\n            10       1        4.81    trt1\n            11       2        4.17    trt1\n            12       3        4.41    trt1\n    ... \n            20       1        6.31    trt2\n            21       2        5.12    trt2\n            22       3        5.54    trt2\n\n```", "```py\n    In [346]: plantGrowthRawDF[plantGrowthRawDF['group']=='ctrl']\n    Out[346]:   observation   weight  group\n            0     1      4.17   ctrl\n            1   2      5.58   ctrl\n            2   3      5.18   ctrl\n            3   4      6.11   ctrl\n           ...\n\n```", "```py\n    In [345]: plantGrowthRawDF.pivot(index='observation',columns='group',values='weight')\n    Out[345]: weight \n              group   ctrl  trt1  trt2\n          observation\n            1   4.17   4.81   6.31\n            2   5.58   4.17   5.12\n            3   5.18   4.41   5.54\n            4   6.11   3.59   5.50\n            5   4.50   5.87   5.37\n            6   4.61   3.83   5.29\n            7   5.17   6.03   4.92\n            8    4.53   4.89   6.15\n            9   5.33   4.32   5.80\n           10   5.14   4.69   5.26\n```", "```py\ndatastr=pd.read_csv('salesdata.csv')\ntable=pd.pivot_table(datastr,index=['Customer Segment'])# the aggregate values are average by default \n```", "```py\ntable2=pd.pivot_table(datastr,values='Sales',index=['Customer Segment'],columns=['Region'])\n```", "```py\ntable4=pd.pivot_table(datastr,values='Sales',index=['Customer Segment','Ship Mode'],columns=['Region'])\n```", "```py\ntable5=pd.pivot_table(datastr,values='Sales',index=['Customer Segment','Ship Mode'],columns=['Region'],aggfunc=sum)\n```", "```py\ntable4=pd.pivot_table(datastr,values='Sales',index=['Customer Segment','Ship Mode'],columns=['Region'],fill_values=0)\n```", "```py\ntable4=pd.pivot_table(datastr,values='Sales',index=['Customer Segment','Ship Mode'],columns=['Region'],fill_values=0,margins=TRUE)\n```", "```py\ntable6=pd.pivot_table(datastr,values=['Sales','Unit Price'],index=['Customer Segment','Ship Mode'],columns=['Region'],aggfunc={\"Sales\":sum,\"Unit Price\":len})\n```", "```py\nmulti_df = sales_data[[\"Sales\", \"Quantity\", \"Category\", \"ShipMode\"]].groupby([\"Category\", \"ShipMode\"]).agg([np.sum, np.mean])\nmulti_df\n```", "```py\nmulti_df.stack()\n```", "```py\nmulti_df.stack(level = 0)\n```", "```py\nmulti_df.stack(level = [0,1])\n```", "```py\nmulti_df.stack(level = 0).index\n```", "```py\nmulticol = pd.MultiIndex.from_tuples([('Male', 'M'),\n('Female', 'F')])\nmissing_info = pd.DataFrame([[20, None], [34, 78]],\nindex=['ClassA', 'ClassB'],\ncolumns=multicol)\nmissing_info\n```", "```py\nmissing_info.stack(dropna = False)\n```", "```py\nmissing_info.stack()\n```", "```py\nmulti_df.unstack()\n```", "```py\nmulti_df.iloc[[0,5,6],[0,2]]\n```", "```py\nmulti_df.iloc[[0,5,6],[0,2]].unstack()\n```", "```py\nmulti_df.iloc[[0,5,6],[0,2]].unstack(fill_value = 0)\n```", "```py\n    In [385]: from pandas.core.reshape import melt\n\n    In [401]: USIndexDataDF[:2] \n    Out[401]:  TradingDate   Nasdaq   S&amp;P 500   Russell 2000   DJIA\n       0      2014/01/30    4123.13   1794.19   1139.36   15848.61\n       1    2014/01/31    4103.88   1782.59   1130.88   15698.85\n\n    In [402]: melt(USIndexDataDF[:2], id_vars=['TradingDate'], var_name='Index Name', value_name='Index Value') \n    Out[402]:\n        TradingDate   Index Name    Index value\n      0  2014/01/30    Nasdaq      4123.13\n      1  2014/01/31    Nasdaq      4103.88\n      2  2014/01/30    S&amp;P 500      1794.19\n      3  2014/01/31    S&amp;P 500      1782.59\n      4  2014/01/30    Russell 2000  1139.36\n      5  2014/01/31    Russell 2000  1130.88\n      6  2014/01/30    DJIA           15848.61\n      7  2014/01/31    DJIA           15698.85\n\n```", "```py\nIn [408]: melted=melt(USIndexDataDF[:2], id_vars=['TradingDate'], var_name='Index Name', value_name='Index Value') melted \nOut[408]: TradingDate   Index Name  Index Value\n    0     2014/01/30   Nasdaq     4123.13\n    1     2014/01/31   Nasdaq     4103.88\n    2     2014/01/30   S&amp;P 500     1794.19\n    3     2014/01/31   S&amp;P 500     1782.59\n    4     2014/01/30   Russell 2000   1139.36\n    5     2014/01/31   Russell 2000   1130.88\n    6     2014/01/30   DJIA        15848.61\n    7     2014/01/31   DJIA        15698.85\n\n    In [413]: pd.get_dummies(melted['Index Name']) \n    Out[413]:         DJIA  Nasdaq  Russell 2000  S&amp;P 500\n            0   0   1      0            0\n            1   0   1      0            0\n            2   0   0      0            1\n            3   0   0      0            1\n            4   0   0      1            0\n            5   0   0      1            0\n            6   1   0      0            0\n            7   1   0      0            0\n\n```", "```py\npd.pivot_table(sales_data, values = \"Sales\", index = \"Category\", columns = \"ShipMode\")\n```", "```py\npd.pivot_table(sales_data, values = [\"Sales\", \"Quantity\"], index = \"Category\", columns = \"ShipMode\", aggfunc = {\"Sales\": np.mean, \"Quantity\": np.sum})\n```", "```py\nsales_data.groupby(\"Category\").sum()\n```", "```py\nsales_data.groupby(\"Category\").sum().transpose()\n```", "```py\nsales_data.groupby(\"Category\").sum().T\nSwaplevel and swapaxes\n```", "```py\nmulti_df\n```", "```py\nmulti_df.swaplevel(i = 1, j = 0, axis = 0)\n```", "```py\nmulti_df.swaplevel(i = 0, j = 1, axis = 1)\n```", "```py\nmulti_df.swapaxes(axis1 = 0, axis2 = 1)\n```", "```py\ndim1_df = sales_data[[\"Sales\",\"OrderID\"]].set_index(\"OrderID\")\ndim1_df\n```", "```py\ntype(dim1_df)\n```", "```py\ntype(dim1_df.squeeze())\n```", "```py\nsales_data.nsmallest(3, \"Profit\")\n```", "```py\nsales_data.nlargest(3, [\"Quantity\", \"Profit\"])\n```"]