["```py\n    preproc_data = spark.read.format(\"delta\").load(\"dbfs:/FileStore/shared_uploads/delta/retail_ml.delta\")\n    preproc_data.show()\n    ```", "```py\n    from pyspark.sql.functions import split, trim\n    from pyspark.ml.feature import CountVectorizer\n    cv_df = preproc_data.withColumn(\"desc_array\", split(trim(\"description\"), \" \")).where(\"description is NOT NULL\")\n    cv = CountVectorizer(inputCol=\"desc_array\", \n                         outputCol=\"description_vec\", \n                         vocabSize=2, minDF=2.0)\n    cv_model = cv.fit(cv_df)\n    train_df = model.transform(cv_df)\n    train_df.display()\n    ```", "```py\n    from pyspark.ml.feature import Word2Vec\n    w2v_df = preproc_data.withColumn(\"desc_array\", split(trim(\"description\"), \"\\t\")).where(\"description is NOT NULL\")\n    word2vec = Word2Vec(vectorSize=2, minCount=0, \n                        inputCol=\"desc_array\", \n                        outputCol=\"desc_vec\")\n    w2v_model = word2vec.fit(w2v_df)\n    train_df = w2v_model.transform(w2v_df)\n    ```", "```py\nfrom pyspark.ml.feature import Tokenizer\ntokenizer = Tokenizer(inputCol=\"description\", \n                      outputCol=\"desc_terms\")\ntokenized_df = tokenizer.transform(preproc_data)\ntokenized_df.show()\n```", "```py\nfrom pyspark.ml.feature import StopWordsRemover\nstops_remover = StopWordsRemover(inputCol=\"desc_terms\", \n                                 outputCol=\"desc_nostops\")\nstops_df = stops_remover.transform(tokenized_df)\nstops_df.select(\"desc_terms\", \"desc_nostops\").show()\n```", "```py\nfrom pyspark.ml.feature import StringIndexer\nstring_indexer = StringIndexer(inputCol=\"country_code\", \n                               outputCol=\"country_indexed\", \n                               handleInvalid=\"skip\" )\nindexed_df = string_indexer.fit(stops_df).transform(stops_df)\nindexed_df.select(\"country_code\", \"country_indexed\").show()\n```", "```py\nfrom pyspark.ml.feature import OneHotEncoder\nohe = OneHotEncoder(inputCol=\"country_indexed\", \n                    outputCol=\"country_ohe\")\nohe_df = ohe.fit(indexed_df).transform(indexed_df)\nohe_df.select(\"country_code\", \"country_ohe\").show()\n```", "```py\nfrom pyspark.ml.feature import Binarizer\nbinarizer = Binarizer(threshold=10, inputCol=\"unit_price\", \n                      outputCol=\"binarized_price\")\nbinarized_df = binarizer.transform(ohe_df)\nbinarized_df.select(\"quantity\", \"binarized_price\").show()\n```", "```py\nfrom pyspark.sql.functions import month\nmonth_df = binarized_df.withColumn(\"invoice_month\", \n                                   month(\"invoice_time\"))\nmonth_indexer = StringIndexer(inputCol=\"invoice_month\", \n                              outputCol=\"month_indexed\", \n                              handleInvalid=\"skip\" )\nmonth_df = month_indexer.fit(month_df).transform(month_df)\nmonth_df.select(\"invoice_month\", \"month_indexed\").show()\n```", "```py\nfrom pyspark.ml.feature import VectorAssembler\nvec_assembler = VectorAssembler(\n    inputCols=[\"desc_vec\", \"country_ohe\", \n               \"binarized_price\", \"month_indexed\", \n               \"quantity_indexed\"],\n    outputCol=\"features\")\nfeatures_df = vec_assembler.transform(month_df)\nfeatures_df.select(\"features\").show()\n```", "```py\nfrom pyspark.ml.feature import StandardScaler\nstd_scaler = StandardScaler(inputCol=\"features\", \n                            outputCol=\"scaled_features\")\nscaled_df = std_scaler.fit(features_df).transform(features_df)\nscaled_df.select(\"scaled_features\").show()\n```", "```py\nfrom pyspark.ml.feature import ChiSqSelector\nchisq_selector=ChiSqSelector(numTopFeatures=1, \n                             featuresCol=\"scaled_features\", \n                             outputCol=\"selected_features\", \n                             labelCol=\"cust_age\")\nresult_df = chisq_selector.fit(scaled_df).transform(scaled_df)\nresult_df.select(\"selected_features\").show()\n```", "```py\nfrom pyspark.ml.feature import VectorSlicer\nvec_slicer = VectorSlicer(inputCol=\"scaled_features\", \n                          outputCol=\"selected_features\", \n                          indices=[1])\nresult_df = vec_slicer.transform(scaled_df)\nresult_df.select(\"scaled_features\", \n                 \"selected_features\").display()\n```", "```py\nspark.sql(\"CREATE DATABASE feature_store\")\n(result_df\n   .write\n   .format(\"delta\")\n   .mode(\"append\")\n   .option(\"location\", \"/FileStore/shared_uploads/delta/retail_features.delta\")\n   .saveAsTable(\"feature_store.retail_features\"))\n```"]