<html><head></head><body>
		<div id="_idContainer222">
			<h1 class="chapter-number" id="_idParaDest-15"><a id="_idTextAnchor014"/>1</h1>
			<h1 id="_idParaDest-16"><a id="_idTextAnchor015"/>An Introduction to Basic Packages, Functions, and Concepts</h1>
			<p>Before getting started on any practical recipes, we’ll use this opening chapter to introduce several core mathematical concepts and structures and their Python representations. We’ll look at basic numerical types, basic mathematical functions (trigonometric functions, exponential function, and logarithms), and matrices. Matrices are fundamental in most computational applications because of the connection between matrices and solutions of systems of linear equations. We’ll explore some of these applications in this chapter, but matrices will play an important role throughout <span class="No-Break">this book.</span></p>
			<p>We’ll cover the following main topics in <span class="No-Break">this order:</span></p>
			<ul>
				<li>Exploring Python <span class="No-Break">numerical types</span></li>
				<li>Understanding basic <span class="No-Break">mathematical functions</span></li>
				<li>Diving into the world <span class="No-Break">of NumPy</span></li>
				<li>Working with matrices and <span class="No-Break">linear algebra</span></li>
			</ul>
			<p>NumPy arrays and the basic mathematical functions we will see in this chapter will be used throughout the rest of the book—they appear in essentially every recipe. Matrix theory, and other topics discussed here, underpin many of the computational methods that are used behind the scenes in packages discussed in this book. Some other topics are important to know about, though we will not necessarily use these in recipes in the book (for example, the alternative <span class="No-Break">numerical types).</span></p>
			<h1 id="_idParaDest-17"><a id="_idTextAnchor016"/>Technical requirements</h1>
			<p>In this chapter, and throughout this book, we will use Python version <strong class="source-inline">3.10</strong>, which is the most recent version of Python at the time of writing. Most of the code in this book will work on recent versions of Python from <strong class="source-inline">3.6</strong>. We will use features that were introduced in Python 3.6 at various points, including f-strings. This means that you may need to change <strong class="source-inline">python3.10</strong>, which appears in any terminal commands, to match your version of Python. This might be another version of Python, such as <strong class="source-inline">python3.6</strong> or <strong class="source-inline">python3.7</strong>, or a more general command such as <strong class="source-inline">python3</strong> or <strong class="source-inline">python</strong>. For the latter commands, you need to check that the version of Python is at least 3.6 by using the <span class="No-Break">following command:</span></p>
			<pre class="console">
python --version</pre>
			<p>Python has built-in numerical types and basic mathematical functions that suffice for small applications that involve only small calculations. The NumPy package provides a high-performance array type and associated routines (including basic mathematical functions that operate efficiently on arrays). This package will be used in many of the recipes in this chapter and the remainder of this book. We will also make use of the SciPy package in the latter recipes of this chapter. Both can be installed using your preferred package manager, such <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">pip</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
python3.10 -m pip install numpy scipy</pre>
			<p>By convention, we import these packages under a shorter alias. We import <strong class="source-inline">numpy</strong> as <strong class="source-inline">np</strong> and <strong class="source-inline">scipy</strong> as <strong class="source-inline">sp</strong> using the following <span class="No-Break"><strong class="source-inline">import</strong></span><span class="No-Break"> statements:</span></p>
			<pre class="source-code">
import numpy as np
import scipy as sp</pre>
			<p>These conventions are used in the official documentation (<a href="https://numpy.org/doc/stable/">https://numpy.org/doc/stable/</a> and <a href="https://docs.scipy.org/doc/scipy/">https://docs.scipy.org/doc/scipy/</a>) for these packages, along with many tutorials and other materials that use <span class="No-Break">these packages.</span></p>
			<p>The code for this chapter can be found in the <span class="No-Break"><strong class="source-inline">Chapter 01</strong></span> folder of the GitHub repository <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Applying-Math-with-Python-2nd-Edition/tree/main/Chapter%2001"><span class="No-Break">https://github.com/PacktPublishing/Applying-Math-with-Python-2nd-Edition/tree/main/Chapter%2001</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-18"><a id="_idTextAnchor017"/>Exploring Python numerical types</h1>
			<p>Python provides basic <a id="_idIndexMarker000"/>numerical types<a id="_idIndexMarker001"/> such as arbitrarily sized integers and floating-point numbers (double precision) as standard, but it also provides several additional types that are useful in specific applications where precision is especially important. Python also provides (built-in) support for complex numbers, which is useful for some more advanced mathematical applications. Let’s take a look at some of these different numerical<a id="_idIndexMarker002"/> types, starting with<a id="_idIndexMarker003"/> the <span class="No-Break"><strong class="source-inline">Decimal</strong></span><span class="No-Break"> type.</span></p>
			<h2 id="_idParaDest-19"><a id="_idTextAnchor018"/>Decimal type</h2>
			<p>For applications that require <a id="_idIndexMarker004"/>decimal digits with accurate arithmetic operations, use the <strong class="source-inline">Decimal</strong> type from the <strong class="source-inline">decimal</strong> module in the Python<a id="_idIndexMarker005"/> <span class="No-Break">Standard Library:</span></p>
			<pre class="source-code">
from decimal import Decimal
num1 = Decimal('1.1')
num2 = Decimal('1.563')
num1 + num2  # Decimal('2.663')</pre>
			<p>Performing this calculation with float objects gives the result 2.6630000000000003, which includes a small error arising from the fact that certain numbers cannot be represented exactly using a finite sum of powers of 2. For example, 0.1 has a binary expansion 0.000110011..., which does not terminate. Any floating-point representation of this number will therefore carry a small error. Note that the argument to <strong class="source-inline">Decimal</strong> is given as a string rather than <span class="No-Break">a float.</span></p>
			<p>The <strong class="source-inline">Decimal</strong> type<a id="_idIndexMarker006"/> is based on the IBM <em class="italic">General Decimal Arithmetic Specification</em> (<a href="http://speleotrove.com/decimal/decarith.html">http://speleotrove.com/decimal/decarith.html</a>), which is an alternative specification for floating-point arithmetic that represents decimal numbers exactly by using powers of 10 rather than powers of 2. This means that it can be safely used for calculations in finance where the accumulation of rounding errors would have dire consequences. However, the <strong class="source-inline">Decimal</strong> format is less memory efficient, since it must store decimal digits rather than binary digits (bits), and these are more computationally expensive than traditional <span class="No-Break">floating-point numbers.</span></p>
			<p>The <strong class="source-inline">decimal</strong> package also provides a <strong class="source-inline">Context</strong> object, which allows fine-grained control over the precision, display, and attributes of <strong class="source-inline">Decimal</strong> objects. The current (default) context can be accessed using the <strong class="source-inline">getcontext</strong> function from the <strong class="source-inline">decimal</strong> module. The <strong class="source-inline">Context</strong> object returned by <strong class="source-inline">getcontext</strong> has a number of attributes that can be modified. For example, we can set the precision for <span class="No-Break">arithmetic operations:</span></p>
			<pre class="source-code">
from decimal import getcontext
ctx = getcontext()
num = Decimal('1.1')
num**4  # Decimal('1.4641')
ctx.prec = 4 # set new precision
num**4  # Decimal('1.464')</pre>
			<p>When we set the precision to <strong class="source-inline">4</strong>, rather than the default <strong class="source-inline">28</strong>, we see that the fourth power of 1.1 is rounded to four <span class="No-Break">significant figures.</span></p>
			<p>The context can even be set locally by using the <strong class="source-inline">localcontext</strong> function, which returns a context manager that restores the original environment at the end of the <span class="No-Break"><strong class="source-inline">with</strong></span><span class="No-Break"> block:</span></p>
			<pre class="source-code">
from decimal import localcontext
num = Decimal("1.1")
with localcontext() as ctx:
    ctx.prec = 2
    num**4  # Decimal('1.5')
num**4  # Decimal('1.4641')</pre>
			<p>This means <a id="_idIndexMarker007"/>that the context can be freely modified inside <a id="_idIndexMarker008"/>the <strong class="source-inline">with</strong> block, and will be returned to the default at <span class="No-Break">the end.</span></p>
			<h2 id="_idParaDest-20"><a id="_idTextAnchor019"/>Fraction type</h2>
			<p>Alternatively, for working <a id="_idIndexMarker009"/>with applications that require accurate<a id="_idIndexMarker010"/> representations of integer fractions, such as when working with proportions or probabilities, there is the <strong class="source-inline">Fraction</strong> type from the <strong class="source-inline">fractions</strong> module in the Python Standard Library. The usage is similar, except that we typically give the numerator and denominator of the fraction <span class="No-Break">as arguments:</span></p>
			<pre class="source-code">
from fractions import Fraction
num1 = Fraction(1, 3)
num2 = Fraction(1, 7)
num1 * num2  # Fraction(1, 21)</pre>
			<p>The <strong class="source-inline">Fraction</strong> type<a id="_idIndexMarker011"/> simply stores two integers—the numerator<a id="_idIndexMarker012"/> and the denominator—and arithmetic is performed using the basic rules for the addition and multiplication <span class="No-Break">of fractions.</span></p>
			<h2 id="_idParaDest-21"><a id="_idTextAnchor020"/>Complex type</h2>
			<p>The square root function <a id="_idIndexMarker013"/>works fine for positive numbers but isn’t defined for negative numbers. However, we can extend the set of real numbers by formally adding a <a id="_idIndexMarker014"/>symbol, i—the <strong class="bold">imaginary unit</strong>—whose <a id="_idIndexMarker015"/>square is <img alt="" src="image/Formula_01_001.png"/> (that is, <img alt="" src="image/Formula_01_002.png"/>). A <strong class="bold">complex number</strong> is a number of the<a id="_idIndexMarker016"/> form <img alt="" src="image/Formula_01_003.png"/>, where <img alt="" src="image/Formula_01_004.png"/> and <img alt="" src="image/Formula_01_005.png"/> are <em class="italic">real numbers</em> (those that we are used to). In this form, the number <img alt="" src="image/Formula_01_006.png"/> is called the <strong class="bold">real part</strong>, and <img alt="" src="image/Formula_01_007.png"/> is called the <strong class="bold">imaginary part</strong>. Complex numbers have their own arithmetic (addition, subtraction, multiplication, division) that agrees with the arithmetic of real numbers when the imaginary part is zero. For example, we can add the complex numbers <img alt="" src="image/Formula_01_008.png"/> and <img alt="" src="image/Formula_01_009.png"/> to get <img alt="" src="image/Formula_01_010.png"/>, or multiply them together to get <span class="No-Break">the following:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer015">
					<img alt="" src="image/Formula_01_011.jpg"/>
				</div>
			</div>
			<p>Complex numbers appear more often than you might think, and are often found behind the scenes when there is some kind of cyclic or oscillatory behavior. This is because the <img alt="" src="image/Formula_01_012.png"/> and <img alt="" src="image/Formula_01_013.png"/> trigonometric functions are the real and imaginary parts, respectively, of the <span class="No-Break">complex exponential:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer018">
					<img alt="" src="image/Formula_01_014.jpg"/>
				</div>
			</div>
			<p>Here, <img alt="" src="image/Formula_01_015.png"/> is any real number. The details, and many more interesting facts and theories of complex numbers, can be found in many resources covering complex numbers. The following <em class="italic">Wikipedia</em> page is <a id="_idIndexMarker017"/>a good place to <span class="No-Break">start: </span><span class="No-Break">https://en.wikipedia.org/wiki/Complex_number</span><span class="No-Break">.</span></p>
			<p>Python has support for complex numbers, including a literal character to denote the complex unit <strong class="source-inline">1j</strong> in code. This might be different from the idiom for representing the complex unit that you are familiar with from other sources on complex numbers. Most mathematical texts will often use the <img alt="" src="image/Formula_01_016.png"/> symbol to represent the <span class="No-Break">complex unit:</span></p>
			<pre class="source-code">
z = 1 + 1j
z + 2  # 3 + 1j
z.conjugate()  # 1 - 1j</pre>
			<p>The <strong class="bold">complex conjugate</strong> of a <a id="_idIndexMarker018"/>complex number is the result of making the imaginary part negative. This has the effect of swapping between two possible solutions to the <span class="No-Break">equation <img alt="" src="image/Formula_01_017.png"/>.</span></p>
			<p>Special <em class="italic">complex number</em>-aware mathematical functions are provided in the <strong class="source-inline">cmath</strong> module of the Python<a id="_idIndexMarker019"/> <span class="No-Break">Standard Library.</span></p>
			<p>Now that we have seen some of the basic mathematical types that Python has to offer, we can start to explore some of the mathematical functions that <span class="No-Break">it provides.</span></p>
			<h1 id="_idParaDest-22"><a id="_idTextAnchor021"/>Understanding basic mathematical functions</h1>
			<p>Basic mathematical functions <a id="_idIndexMarker020"/>appear in many applications. For example, logarithms can be used to scale data that grows exponentially to give linear data. The exponential function and trigonometric functions are common fixtures when working with geometric information, the <em class="italic">gamma function</em> appears in combinatorics, and the <em class="italic">Gaussian error function</em> is important <span class="No-Break">in statistics.</span></p>
			<p>The <strong class="source-inline">math</strong> module<a id="_idIndexMarker021"/> in the Python Standard Library provides all of the standard mathematical functions, along with common constants and some utility functions, and it can be imported using the <span class="No-Break">following command:</span></p>
			<pre class="source-code">
import math</pre>
			<p>Once it’s imported, we can use any of the mathematical functions that are contained in this module. For instance, to find the square root of a non-negative number, we would use the <strong class="source-inline">sqrt</strong> function<a id="_idIndexMarker022"/> <span class="No-Break">from </span><span class="No-Break"><strong class="source-inline">math</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
import math
math.sqrt(4)  #  2.0</pre>
			<p>Attempting to <a id="_idIndexMarker023"/>use the <strong class="source-inline">sqrt</strong> function with a negative argument will raise a value error. The square root of a negative number is not defined for this <strong class="source-inline">sqrt</strong> function, which deals only <a id="_idIndexMarker024"/>with <em class="italic">real numbers</em>. The square root of a negative number—this will be a complex number—can be found using the alternative <strong class="source-inline">sqrt</strong> function from the <strong class="source-inline">cmath</strong> module<a id="_idIndexMarker025"/> in the Python <span class="No-Break">Standard Library.</span></p>
			<p>The sine, cosine, and tangent<a id="_idIndexMarker026"/> trigonometric functions are available under <a id="_idIndexMarker027"/>their common<a id="_idIndexMarker028"/> abbreviations <strong class="source-inline">sin</strong>, <strong class="source-inline">cos</strong>, and <strong class="source-inline">tan</strong>, respectively, in<a id="_idIndexMarker029"/> the <strong class="source-inline">math</strong> module. The <strong class="source-inline">pi</strong> constant holds the value of π, which is <a id="_idIndexMarker030"/><span class="No-Break">approximately 3.1416:</span></p>
			<pre class="source-code">
theta = math.pi/4
math.cos(theta)  # 0.7071067811865476
math.sin(theta)  # 0.7071067811865475
math.tan(theta)  # 0.9999999999999999</pre>
			<p>The <a id="_idIndexMarker031"/>inverse <a id="_idIndexMarker032"/>trigonometric functions are named <strong class="source-inline">acos</strong>, <strong class="source-inline">asin</strong>, and <strong class="source-inline">atan</strong> in<a id="_idIndexMarker033"/> the <span class="No-Break"><strong class="source-inline">math</strong></span><span class="No-Break"> module:</span></p>
			<pre class="source-code">
math.asin(-1)  # -1.5707963267948966
math.acos(-1)  # 3.141592653589793
math.atan(1)  # 0.7853981633974483</pre>
			<p>The <strong class="source-inline">log</strong> function<a id="_idIndexMarker034"/> in the <strong class="source-inline">math</strong> module performs logarithms. It has an optional argument to specify the base of the <a id="_idIndexMarker035"/>logarithm (note that the second argument is positional only). By default, without the optional argument, it is<a id="_idIndexMarker036"/> the <em class="italic">natural logarithm</em> with base <img alt="" src="image/Formula_01_018.png"/>. The <img alt="" src="image/Formula_01_019.png"/> constant can be accessed <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">math.e</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
math.log(10) # 2.302585092994046
math.log(10, 10) # 1.0</pre>
			<p>The <strong class="source-inline">math</strong> module also contains the <strong class="source-inline">gamma</strong> function, which is the gamma function, and the <strong class="source-inline">erf</strong> function, the Gaussian <a id="_idIndexMarker037"/>error function, which is important in<a id="_idIndexMarker038"/> statistics. Both functions are defined by integrals. The gamma function is defined by <span class="No-Break">this integral:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer024">
					<img alt="" src="image/Formula_01_020.jpg"/>
				</div>
			</div>
			<p>The Gaussian error function is defined by <span class="No-Break">this integral:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer025">
					<img alt="" src="image/Formula_01_021.jpg"/>
				</div>
			</div>
			<p>The integral in the definition of the error function cannot be evaluated using calculus, and instead must be <span class="No-Break">computed numerically:</span></p>
			<pre class="source-code">
math.gamma(5) # 24.0
math.erf(2) # 0.9953222650189527</pre>
			<p>In addition to standard <a id="_idIndexMarker039"/>functions such as trigonometric functions, logarithms, and exponential functions, the <strong class="source-inline">math</strong> module <a id="_idIndexMarker040"/>contains various theoretic and combinatorial functions. These include the <strong class="source-inline">comb</strong> and <strong class="source-inline">factorial</strong> functions, which are useful in a variety of applications. The <strong class="source-inline">comb</strong> function<a id="_idIndexMarker041"/> called with arguments <img alt="" src="image/Formula_01_022.png"/> and <img alt="" src="image/Formula_01_023.png"/> returns the number of ways to choose <img alt="" src="image/Formula_01_024.png"/> items from a collection of <img alt="" src="image/Formula_01_025.png"/> without repeats if the order is not important. For example, picking 1 then 2 is the same as picking 2<a id="_idIndexMarker042"/> then 1. This number is sometimes written <img alt="" src="image/Formula_01_026.png"/>. The factorial called with argument <img alt="" src="image/Formula_01_027.png"/> returns the <span class="No-Break">factorial</span><span class="No-Break"> <img alt="" src="image/Formula_01_028.png"/>:</span></p>
			<pre class="source-code">
math.comb(5, 2)  # 10
math.factorial(5)  # 120</pre>
			<p>Applying the factorial to a negative number raises a <strong class="source-inline">ValueError</strong>. The factorial of an integer, <img alt="" src="image/Formula_01_029.png"/>, coincides with the value of the gamma function at <img alt="" src="image/Formula_01_030.png"/>; <span class="No-Break">that is:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer035">
					<img alt="" src="image/Formula_01_031.jpg"/>
				</div>
			</div>
			<p>The <strong class="source-inline">math</strong> module also contains a function that returns the <em class="italic">greatest common divisor</em> of its arguments called <strong class="source-inline">gcd</strong>. The greatest common divisor of <img alt="" src="image/Formula_01_032.png"/> and <img alt="" src="image/Formula_01_033.png"/> is the largest integer <img alt="" src="image/Formula_01_034.png"/> such that <img alt="" src="image/Formula_01_035.png"/> divides both <img alt="" src="image/Formula_01_036.png"/> and <img alt="" src="image/Formula_01_037.png"/> <span class="No-Break">exactly:</span></p>
			<pre class="source-code">
math.gcd(2, 4)  # 2
math.gcd(2, 3)  # 1</pre>
			<p>There are also a number of functions for working with floating-point numbers. The <strong class="source-inline">fsum</strong> function<a id="_idIndexMarker043"/> performs addition on an iterable of numbers and keeps track of the sums at each step to reduce the error in the result. This is nicely illustrated by the <span class="No-Break">following example:</span></p>
			<pre class="source-code">
nums = [0.1]*10  # list containing 0.1 ten times
sum(nums)  # 0.9999999999999999
math.fsum(nums)  # 1.0</pre>
			<p>The <strong class="source-inline">isclose</strong> function<a id="_idIndexMarker044"/> returns <strong class="source-inline">True</strong> if the difference between the arguments is smaller than the tolerance. This is especially useful in unit tests, where there may be small variations in results based on machine architecture or <span class="No-Break">data variability.</span></p>
			<p>Finally, the <strong class="source-inline">floor</strong> and <strong class="source-inline">ceil</strong> functions <a id="_idIndexMarker045"/>from <strong class="source-inline">math</strong> provide the floor and ceiling of their argument. The <strong class="bold">floor</strong> of a number <img alt="" src="image/Formula_01_038.png"/> is the <a id="_idIndexMarker046"/>largest integer <img alt="" src="image/Formula_01_039.png"/> with <img alt="" src="image/Formula_01_040.png"/>, and the <strong class="bold">ceiling</strong> of <img alt="" src="image/Formula_01_041.png"/> is the smallest integer <img alt="" src="image/Formula_01_042.png"/> with <img alt="" src="image/Formula_01_043.png"/>. These functions are useful when converting between a float obtained by dividing one number by another and <span class="No-Break">an integer.</span></p>
			<p>The <strong class="source-inline">math</strong> module<a id="_idIndexMarker047"/> contains functions that are implemented in C (assuming you are <a id="_idIndexMarker048"/>running CPython), and so are much faster than those implemented in Python. This module is a good choice if you need to apply a function to a relatively small collection of numbers. If you want to apply these functions to a large collection of data simultaneously, it is better to use their equivalents from the NumPy package, which is more efficient for working with arrays. In general, if you have imported the NumPy package already, then it is probably best to always use NumPy equivalents of these functions to limit the chance of error. With this in mind, let’s now introduce the NumPy package and its basic objects: <span class="No-Break">multi-dimensional arrays.</span></p>
			<h1 id="_idParaDest-23"><a id="_idTextAnchor022"/>Diving into the world of NumPy</h1>
			<p>NumPy<a id="_idIndexMarker049"/> provides high-performance array types and routines for manipulating these arrays in Python. These arrays are useful for processing large datasets where performance is crucial. NumPy forms the base for the numerical and scientific computing stack in Python. Under the hood, NumPy makes use of low-level libraries for working with vectors and <a id="_idIndexMarker050"/>matrices, such as the <strong class="bold">Basic Linear Algebra Subprograms</strong> (<strong class="bold">BLAS</strong>) package, to <span class="No-Break">accelerate computations.</span></p>
			<p>Traditionally, the NumPy package is imported under the shorter alias <strong class="source-inline">np</strong>, which can be accomplished using the following <span class="No-Break"><strong class="source-inline">import</strong></span><span class="No-Break"> statement:</span></p>
			<pre class="source-code">
import numpy as np</pre>
			<p>This convention is used in the NumPy documentation and in the wider scientific Python ecosystem (SciPy, pandas, and <span class="No-Break">so on).</span></p>
			<p>The basic type provided by the NumPy <a id="_idIndexMarker051"/>library is the <strong class="source-inline">ndarray</strong> type (henceforth referred to as a NumPy array). Generally, you won’t create your own instances of this type, and will instead use one of the helper routines such as <strong class="source-inline">array</strong> to set up the type correctly. The <strong class="source-inline">array</strong> routine creates NumPy arrays from an array-like object, which is typically a list of numbers or a list of lists (of numbers). For example, we can create a simple array by providing a list with the <span class="No-Break">required elements:</span></p>
			<pre class="source-code">
arr = np.array([1, 2, 3, 4])  # array([1, 2, 3, 4])</pre>
			<p>The NumPy array type (<strong class="source-inline">ndarray</strong>) is a Python wrapper around an underlying C array structure. The array operations are implemented in C and optimized for performance. NumPy arrays must consist of homogeneous data (all elements have the same type), although this type could be a pointer to an arbitrary Python object. NumPy will infer an appropriate data type during creation if one is not explicitly provided using the <strong class="source-inline">dtype</strong> <span class="No-Break">keyword argument:</span></p>
			<pre class="source-code">
np.array([1, 2, 3, 4], dtype=np.float32)
# array([1., 2., 3., 4.], dtype=float32)</pre>
			<p>NumPy <a id="_idIndexMarker052"/>offers type specifiers for numerous C-types that can be passed into the <strong class="source-inline">dtype</strong> parameter, such as <strong class="source-inline">np.float32</strong> used previously. Generally speaking, these type specifiers are of form <strong class="source-inline">namexx</strong> where the name is the name of a type—such as int, float, or complex—and <strong class="source-inline">xx</strong> is a number of bits—for example, 8, 16, 32, 64, 128. Usually, NumPy does a pretty good job of selecting a good type for the input given, but occasionally, you will want to override it. The preceding case is a good example— without the <strong class="source-inline">dtype=np.float32</strong> argument, NumPy would assume the type to <span class="No-Break">be </span><span class="No-Break"><strong class="source-inline">int64</strong></span><span class="No-Break">.</span></p>
			<p>Under the hood, a NumPy array of any shape is a buffer containing the raw data as a flat (one-dimensional) array and a collection of additional metadata that specifies details such as the type of <span class="No-Break">the elements.</span></p>
			<p>After creation, the data type can be accessed using the <strong class="source-inline">dtype</strong> attribute of the array. Modifying the <strong class="source-inline">dtype</strong> attribute will have undesirable consequences since the raw bytes that constitute the data in the array will simply be reinterpreted as the new data type. For example, if we create an array using Python integers, NumPy will convert those to 64-bit integers in the array. Changing the <strong class="source-inline">dtype</strong> value will cause NumPy to reinterpret these 64-bit integers to the new <span class="No-Break">data type:</span></p>
			<pre class="source-code">
arr = np.array([1, 2, 3, 4])
print(arr.dtype) # int64
arr.dtype = np.float32
print(arr)
# [1.e-45 0.e+00 3.e-45 0.e+00 4.e-45 0.e+00 6.e-45 0.e+00]</pre>
			<p>Each 64-bit integer has been re-interpreted as two 32-bit floating-point numbers, which clearly give nonsense values. Instead, if you wish to change the data type after creation, use the <strong class="source-inline">astype</strong> method to specify the new type. The correct way to change the data type is <span class="No-Break">shown here:</span></p>
			<pre class="source-code">
arr = arr.astype(np.float32)
print(arr)
# [1. 2. 3. 4.]</pre>
			<p>NumPy also <a id="_idIndexMarker053"/>provides a number of routines for creating various standard arrays. The <strong class="source-inline">zeros</strong> routine creates an array of the specified shape, in which every element is <strong class="source-inline">0</strong>, and the <strong class="source-inline">ones</strong> routine creates an array in which every element <span class="No-Break">is </span><span class="No-Break"><strong class="source-inline">1</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-24"><a id="_idTextAnchor023"/>Element access</h2>
			<p>NumPy arrays<a id="_idIndexMarker054"/> support the <strong class="source-inline">getitem</strong> protocol, so elements in an array can be accessed as if they were a list and support <a id="_idIndexMarker055"/>all of the arithmetic operations, which are performed component-wise. This means we can use the index notation and the index to retrieve the element from the specified index, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
arr = np.array([1, 2, 3, 4])
arr[0]  # 1
arr[2]  # 3</pre>
			<p>This also includes the usual slice syntax for extracting an array of data from an existing array. A slice of an array is again an array, containing the elements specified by the slice. For example, we can retrieve an array containing the first two elements of <strong class="source-inline">ary</strong>, or an array containing the elements at even indexes, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
first_two = arr[:2]  # array([1, 2])
even_idx = arr[::2]  # array([1, 3])</pre>
			<p>The syntax for a slice is <strong class="source-inline">start:stop:step</strong>. We can omit either, or both, of <strong class="source-inline">start</strong> and <strong class="source-inline">stop</strong> to take from the beginning or the end, respectively, of all elements. We can also omit the <strong class="source-inline">step</strong> parameter, in which case we also drop the trailing <strong class="source-inline">:</strong>.  The <strong class="source-inline">step</strong> parameter describes the elements from the chosen range that should be selected. A value of <strong class="source-inline">1</strong> selects every element or, as in the recipe, a value of <strong class="source-inline">2</strong> selects every second element (starting from <strong class="source-inline">0</strong> gives even-numbered elements). This syntax is the same as for slicing <span class="No-Break">Python lists.</span></p>
			<h2 id="_idParaDest-25"><a id="_idTextAnchor024"/>Array arithmetic and functions</h2>
			<p>NumPy provides a number<a id="_idIndexMarker056"/> of <strong class="bold">universal functions</strong> (<strong class="bold">ufuncs</strong>), which are routines that can operate efficiently on NumPy array types. In particular, all of the basic mathematical functions discussed in the <em class="italic">Understanding basic mathematical functions</em> section have analogs in NumPy that can operate on NumPy arrays. Universal functions can also perform <em class="italic">broadcasting</em>, to allow them to operate on arrays of <span class="No-Break">different—but compatible—shapes.</span></p>
			<p>The arithmetic operations<a id="_idIndexMarker057"/> on NumPy arrays are performed component-wise. This is best illustrated by the <span class="No-Break">following example:</span></p>
			<pre class="source-code">
arr_a = np.array([1, 2, 3, 4])
arr_b = np.array([1, 0, -3, 1])
arr_a + arr_b  # array([2, 2, 0, 5])
arr_a - arr_b  # array([0, 2, 6, 3])
arr_a * arr_b  # array([ 1, 0, -9, 4])
arr_b / arr_a  # array([ 1. , 0. , -1. , 0.25])
arr_b**arr_a  # array([1, 0, -27, 1])</pre>
			<p>Note that the arrays must be the same shape, which means they have the same length. Using an arithmetic operation on arrays of different shapes will result in a <strong class="source-inline">ValueError</strong>. Adding, subtracting, multiplying, or dividing by a number will result in an array where the operation has been applied to each component. For example, we can multiply all elements in an array by <strong class="source-inline">2</strong> by using the <span class="No-Break">following command:</span></p>
			<pre class="source-code">
arr = np.array([1, 2, 3, 4])
new = 2*arr
print(new)
# [2, 4, 6, 8]</pre>
			<p>As we can see, the printed array contains the numbers 2, 4, 6, and 8, which are the elements of the original array multiplied <span class="No-Break">by 2.</span></p>
			<p>In the next section, we’ll look at various ways that you can create NumPy arrays in addition to the <strong class="source-inline">np.array</strong> routine that we <span class="No-Break">used here.</span></p>
			<h2 id="_idParaDest-26"><a id="_idTextAnchor025"/>Useful array creation routines</h2>
			<p>To generate <a id="_idIndexMarker058"/>arrays of numbers <a id="_idIndexMarker059"/>at regular intervals between two given endpoints, you can use either<a id="_idIndexMarker060"/> the <strong class="source-inline">arange</strong> routine or<a id="_idIndexMarker061"/> the <strong class="source-inline">linspace</strong> routine. The difference between these two<a id="_idIndexMarker062"/> routines is that <strong class="source-inline">linspace</strong> generates a number (the default is 50) of values with equal spacing between the two endpoints, including both endpoints, while <strong class="source-inline">arange</strong> generates <a id="_idIndexMarker063"/>numbers at a given step size up to, but not including, the<a id="_idIndexMarker064"/> upper limit. The <strong class="source-inline">linspace</strong> routine<a id="_idIndexMarker065"/> generates values in the closed interval <img alt="" src="image/Formula_01_044.png"/>, and the <strong class="source-inline">arange</strong> routine generates values in the half-open <span class="No-Break">interval <img alt="" src="image/Formula_01_045.png"/>:</span></p>
			<pre class="source-code">
np.linspace(0, 1, 5)  # array([0., 0.25, 0.5, 0.75, 1.0])
np.arange(0, 1, 0.3)  # array([0.0, 0.3, 0.6, 0.9])</pre>
			<p>Note that the array generated using <strong class="source-inline">linspace</strong> has exactly five points, specified by the third argument, including the two endpoints, <strong class="source-inline">0</strong> and <strong class="source-inline">1</strong>. The array generated by <strong class="source-inline">arange</strong> has four points, and does not include the right endpoint, <strong class="source-inline">1</strong>; an additional step of <strong class="source-inline">0.3</strong> would equal <strong class="source-inline">1.2</strong>, which<a id="_idIndexMarker066"/> is larger <span class="No-Break">than </span><span class="No-Break"><strong class="source-inline">1</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-27"><a id="_idTextAnchor026"/>Higher-dimensional arrays</h2>
			<p>NumPy can create arrays with <a id="_idIndexMarker067"/>any number of dimensions, which are created using the same <strong class="source-inline">array</strong> routine as simple one-dimensional arrays. The number of dimensions of an array is specified by the number of nested lists provided to the <strong class="source-inline">array</strong> routine. For example, we can create a two-dimensional array by providing a list of lists, where each member of the inner list is a number, such as <span class="No-Break">the following:</span></p>
			<pre class="source-code">
mat = np.array([[1, 2], [3, 4]])</pre>
			<p>NumPy arrays have a <strong class="source-inline">shape</strong> attribute, which describes the arrangement of the elements in each dimension. For a two-dimensional array, the shape can be interpreted as the number of rows and the number of columns of <span class="No-Break">the array.</span></p>
			<p>Arrays with three or more dimensions are sometimes <a id="_idIndexMarker068"/>called <strong class="bold">tensors</strong>. (In fact, one might call any sized array a tensor: a vector (one-dimensional array) is a 1-tensor; a two-dimensional array is a 2-tensor or matrix—see the next section.) Common <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) frameworks such as TensorFlow and PyTorch implement their own class for tensors, which invariably behave in a similar way to <span class="No-Break">NumPy arrays.</span></p>
			<p>NumPy stores the shape as the <strong class="source-inline">shape</strong> attribute on the <strong class="source-inline">array</strong> object, which is a tuple. The number of elements in this tuple is the number <span class="No-Break">of dimensions:</span></p>
			<pre class="source-code">
vec = np.array([1, 2])
mat.shape  # (2, 2)
vec.shape  # (2,)</pre>
			<p>Since the data in a NumPy array is stored in a flat (one-dimensional) array, an array can be reshaped with little cost by simply changing the associated metadata. This is done using the <strong class="source-inline">reshape</strong> method on a <span class="No-Break">NumPy array:</span></p>
			<pre class="source-code">
mat.reshape(4,)  # array([1, 2, 3, 4])</pre>
			<p>Note that the total number of elements must remain unchanged. The <strong class="source-inline">mat</strong> matrix originally has shape <strong class="source-inline">(2, 2)</strong> with a total of four elements, and the latter is a one-dimensional array with shape <strong class="source-inline">(4,)</strong>, which again has a total of four elements. Attempting to reshape when there is a mismatch in the total number of elements will result in <span class="No-Break">a </span><span class="No-Break"><strong class="source-inline">ValueError</strong></span><span class="No-Break">.</span></p>
			<p>To create an array of higher<a id="_idIndexMarker069"/> dimensions, simply add more levels of nested lists. To make this clearer, in the following example, we separate out the lists for each element in the third dimension before we construct <span class="No-Break">the array:</span></p>
			<pre class="source-code">
mat1 = [[1, 2], [3, 4]]
mat2 = [[5, 6], [7, 8]]
mat3 = [[9, 10], [11, 12]]
arr_3d = np.array([mat1, mat2, mat3])
arr_3d.shape  # (3, 2, 2)</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">The first element of the shape is the outermost, and the last element is <span class="No-Break">the innermost.</span></p>
			<p>This means that adding a dimension to an array is a simple matter of providing the relevant metadata. Using the <strong class="source-inline">array</strong> routine, the <strong class="source-inline">shape</strong> metadata is described by the length of each list in the argument. The length of the outermost list defines the corresponding <strong class="source-inline">shape</strong> parameter for that dimension, and <span class="No-Break">so on.</span></p>
			<p>The size in memory of a NumPy array does not significantly depend on the number of dimensions, but only on the total number of elements, which is the product of the <strong class="source-inline">shape</strong> parameters. However, note that the total number of elements tends to be larger in <span class="No-Break">higher-dimensional arrays.</span></p>
			<p>To access an element in a multi-dimensional array, you use the usual index notation, but rather than providing a single number, you need to provide the index in each dimension. For a 2 × 2 matrix, this means specifying the row and column for the <span class="No-Break">desired element:</span></p>
			<pre class="source-code">
mat[0, 0]  # 1 - top left element
mat[1, 1]  # 4 - bottom right element</pre>
			<p>The index notation also supports slicing in each dimension, so we can extract all members of a single column by using the <strong class="source-inline">mat[:, 0]</strong> slice, <span class="No-Break">like so:</span></p>
			<pre class="source-code">
mat[:, 0]
# array([1, 3])</pre>
			<p>Note that the result of the slice is a <span class="No-Break">one-dimensional array.</span></p>
			<p>The array creation functions, <strong class="source-inline">zeros</strong> and <strong class="source-inline">ones</strong>, can create multi-dimensional arrays by simply specifying a shape<a id="_idIndexMarker070"/> with more than one <span class="No-Break">dimension parameter.</span></p>
			<p>In the next section, we will look at the special case of two-dimensional NumPy arrays, which serve as matrices <span class="No-Break">in Python.</span></p>
			<h1 id="_idParaDest-28"><a id="_idTextAnchor027"/>Working with matrices and linear algebra</h1>
			<p>NumPy arrays also serve as <em class="italic">matrices</em>, which are fundamental in mathematics and computational programming. A <strong class="bold">matrix</strong> is <a id="_idIndexMarker071"/>simply a two-dimensional array. Matrices are central in many applications, such as geometric transformations and simultaneous equations, but also appear as useful tools in other areas such as statistics. Matrices themselves are only distinctive (compared to any other array) once we equip them with <em class="italic">matrix arithmetic</em>. Matrices<a id="_idIndexMarker072"/> have element-wise addition and subtraction operations, just as for NumPy arrays, a third operation <a id="_idIndexMarker073"/>called <em class="italic">scalar multiplication</em>, where we multiply every element of the matrix by a constant number, and a different notion <a id="_idIndexMarker074"/>of <em class="italic">matrix multiplication</em>. Matrix multiplication is<a id="_idIndexMarker075"/> fundamentally different from other notions of multiplication, as we will <span class="No-Break">see later.</span></p>
			<p>One of the most important attributes of a matrix is its shape, defined exactly as for NumPy arrays. A <a id="_idIndexMarker076"/>matrix with <img alt="" src="image/Formula_01_046.png"/> rows and <img alt="" src="image/Formula_01_047.png"/> columns is usually described as an <img alt="" src="image/Formula_01_048.png"/> matrix. A matrix that has the same number of rows as columns is said to be a <em class="italic">square</em> matrix, and these matrices play a special role in the theory of vectors <span class="No-Break">and matrices.</span></p>
			<p>The <strong class="bold">identity matrix</strong> (of size <img alt="" src="image/Formula_01_049.png"/>) is a <img alt="" src="image/Formula_01_050.png"/> matrix where the <img alt="" src="image/Formula_01_051.png"/>-th entry is 1, and the <img alt="" src="image/Formula_01_052.png"/>-th entry is zero for <img alt="" src="image/Formula_01_053.png"/>. There<a id="_idIndexMarker077"/> is an array creation routine that gives an <img alt="" src="image/Formula_01_054.png"/> identity matrix for a specified <img alt="" src="image/Formula_01_055.png"/> <span class="No-Break">value:</span></p>
			<pre class="source-code">
np.eye(3)
# array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])</pre>
			<p>As the name suggests, the identity matrix is a special <span class="No-Break">matrix that</span></p>
			<h2 id="_idParaDest-29"><a id="_idTextAnchor028"/>Basic methods and properties</h2>
			<p>There are a <a id="_idIndexMarker078"/>large number of terms and quantities associated with matrices. We<a id="_idIndexMarker079"/> only mention two such properties here, since they will be useful later. These are the <em class="italic">transpose</em> of a matrix, where rows and columns are interchanged, and the <em class="italic">trace</em> of a square matrix, which is the sum of the elements along the <em class="italic">leading diagonal</em>. The leading diagonal consists of the elements <img alt="" src="image/Formula_01_056.png"/> along the line from the top left of the matrix to the <span class="No-Break">bottom right.</span></p>
			<p>NumPy arrays can be easily transposed by calling the <strong class="source-inline">transpose</strong> method<a id="_idIndexMarker080"/> on the <strong class="source-inline">array</strong> object. In fact, since this is such a common operation, arrays have a convenience property <strong class="source-inline">T</strong> that returns the transpose of the matrix. The transposition reverses the order of the shape of a matrix (array) so that rows become columns and columns become rows. For example, if we start with a 3 × 2 matrix (three rows, two columns), then its transpose will be a 2 × 3 matrix, such as in the <span class="No-Break">following example:</span></p>
			<pre class="source-code">
A = np.array([[1, 2], [3, 4]])
A.transpose()
# array([[1, 3],
#         [2, 4]])
A.T
# array([[1, 3],
#         [2, 4]])</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">The <strong class="source-inline">transpose</strong> function does not actually modify the data in the underlying array but instead changes the shape and an internal flag that indicates the order of stored values to be from row-contiguous (C style) to column-contiguous (F style). This makes the operation <span class="No-Break">very cheap.</span></p>
			<p>Another <a id="_idIndexMarker081"/>quantity associated with matrices that is occasionally useful is the <em class="italic">trace</em>. The trace of a square matrix <img alt="" src="image/Formula_01_057.png"/>, with entries as in the preceding code, is defined to be the sum of the elements along the leading diagonal, which consists of the elements starting from the top left diagonally to the bottom right. The formula for the trace is given <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer062">
					<img alt="" src="image/Formula_01_058.jpg"/>
				</div>
			</div>
			<p>NumPy arrays have a <strong class="source-inline">trace</strong> method that returns the trace of <span class="No-Break">a matrix:</span></p>
			<pre class="source-code">
A = np.array([[1, 2], [3, 4]])
A.trace()  # 5</pre>
			<p>The trace can also be accessed using the <strong class="source-inline">np.trace</strong> function, which is not bound to <span class="No-Break">the array.</span></p>
			<h2 id="_idParaDest-30"><a id="_idTextAnchor029"/>Matrix multiplication</h2>
			<p>Matrix multiplication<a id="_idIndexMarker082"/> is an operation performed on two matrices, which preserves some of the structure and character of both matrices. Formally, suppose we are given two matrices <img alt="" src="image/Formula_01_059.png"/>, an <img alt="" src="image/Formula_01_060.png"/> matrix, and <img alt="" src="image/Formula_01_061.png"/>, an <img alt="" src="image/Formula_01_062.png"/> matrix, <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer067">
					<img alt="" src="image/Formula_01_063.jpg"/>
				</div>
			</div>
			<p>The matrix product <img alt="" src="image/Formula_01_064.png"/> of <img alt="" src="image/Formula_01_065.png"/> and <img alt="" src="image/Formula_01_066.png"/> is an <img alt="" src="image/Formula_01_067.png"/> matrix whose <img alt="" src="image/Formula_01_068.png"/> -th entry is given by the <span class="No-Break">following equation:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer073">
					<img alt="" src="image/Formula_01_069.jpg"/>
				</div>
			</div>
			<p>Note that the number of columns of the first matrix <strong class="bold">must</strong> match the number of rows of the second matrix in order for matrix multiplication to be defined. We usually write <img alt="" src="image/Formula_01_070.png"/> for the matrix product of <img alt="" src="image/Formula_01_071.png"/> and <img alt="" src="image/Formula_01_072.png"/>, if it is defined. Matrix multiplication is a peculiar operation. It is not <em class="italic">commutative</em> like most other arithmetic operations: even if <img alt="" src="image/Formula_01_073.png"/> and <img alt="" src="image/Formula_01_074.png"/> can both be computed, there is no need for them to be equal. In practice, this means that the order of multiplication matters for matrices. This arises from the origins of matrix algebras as representations of linear maps, where multiplication corresponds to the composition <span class="No-Break">of functions.</span></p>
			<p>Python has an operator reserved for <a id="_idIndexMarker083"/>matrix multiplication, <strong class="source-inline">@</strong>, which was added in Python 3.5. NumPy arrays implement the operator to perform matrix multiplication. Note that this is fundamentally different from the component-wise multiplication of <span class="No-Break">arrays, </span><span class="No-Break"><strong class="source-inline">*</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
A = np.array([[1, 2], [3, 4]])
B = np.array([[-1, 1], [0, 1]])
A @ B
# array([[-1, 3],
#           [-3, 7]])
A * B # different from A @ B
# array([[-1, 2],
#           [ 0, 4]])</pre>
			<p>The identity matrix is a <em class="italic">neutral element</em> under matrix multiplication. That is, if <img alt="" src="image/Formula_01_075.png"/> is any <img alt="" src="image/Formula_01_076.png"/> matrix and <img alt="" src="image/Formula_01_077.png"/> is the <img alt="" src="image/Formula_01_078.png"/> identity matrix, then <img alt="" src="image/Formula_01_079.png"/>, and similarly, if <img alt="" src="image/Formula_01_080.png"/> is an <img alt="" src="image/Formula_01_081.png"/> matrix, then <img alt="" src="image/Formula_01_082.png"/>. This can be easily checked for specific examples using <span class="No-Break">NumPy arrays:</span></p>
			<pre class="source-code">
A = np.array([[1, 2], [3, 4]])
I = np.eye(2)
A @ I
# array([[1., 2.],
#           [3., 4.]])</pre>
			<p>You can see that the printed resulting <a id="_idIndexMarker084"/>matrix is equal to the original matrix. The same is true if we reversed the order of <img alt="" src="image/Formula_01_083.png"/> and <img alt="" src="image/Formula_01_084.png"/> and performed the multiplication <img alt="" src="image/Formula_01_085.png"/>. In the next section, we’ll look at matrix inverses; a matrix <img alt="" src="image/Formula_01_086.png"/> that when multiplied by <img alt="" src="image/Formula_01_087.png"/> gives the <span class="No-Break">identity matrix.</span></p>
			<h2 id="_idParaDest-31"><a id="_idTextAnchor030"/>Determinants and inverses</h2>
			<p>The <em class="italic">determinant</em> of a <a id="_idIndexMarker085"/>square matrix is important in most applications because of its strong link with finding the inverse of a matrix. A matrix is <em class="italic">square</em> if the number of rows and columns are equal. In particular, a matrix that has a nonzero determinant has a (unique) inverse, which translates to unique solutions of certain systems of equations. The determinant of a matrix is defined recursively. Suppose that we have a generic <img alt="" src="image/Formula_01_088.png"/> matrix, <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer093">
					<img alt="" src="image/Formula_01_089.jpg"/>
				</div>
			</div>
			<p>The <em class="italic">determinant</em> of this<a id="_idIndexMarker086"/> generic matrix <img alt="" src="image/Formula_01_090.png"/> is defined by the <span class="No-Break">following formula:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer095">
					<img alt="" src="image/Formula_01_091.jpg"/>
				</div>
			</div>
			<p>For a general <img alt="" src="image/Formula_01_092.png"/> matrix where <img alt="" src="image/Formula_01_093.png"/>, we define the determinant recursively. For <img alt="" src="image/Formula_01_094.png"/>, the <img alt="" src="image/Formula_01_095.png"/>--th submatrix <img alt="" src="image/Formula_01_097.png"/> is the result of deleting the <img alt="" src="image/Formula_01_098.png"/> th row and <img alt="" src="image/Formula_01_099.png"/>th column from <img alt="" src="image/Formula_01_100.png"/>. The submatrix <img alt="" src="image/Formula_01_101.png"/> is an <img alt="" src="image/Formula_01_102.png"/> matrix, and so we can compute the determinant. We then define the determinant of <img alt="" src="image/Formula_01_103.png"/> to be the <span class="No-Break">following quantity:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer107">
					<img alt="" src="image/Formula_01_104.jpg"/>
				</div>
			</div>
			<p>In fact, the index 1 that appears in the preceding equation can be replaced by any <img alt="" src="image/Formula_01_105.png"/> and the result will be <span class="No-Break">the same.</span></p>
			<p>The NumPy routine for computing the determinant of a matrix is contained in a separate module called <strong class="source-inline">linalg</strong>. This <a id="_idIndexMarker087"/>module contains many common routines for <em class="italic">linear algebra</em>, which<a id="_idIndexMarker088"/> is the branch of mathematics that covers vector and matrix algebra. The routine for computing the determinant of a square matrix is the <span class="No-Break"><strong class="source-inline">det</strong></span><span class="No-Break"> routine:</span></p>
			<pre class="source-code">
from numpy import linalg
linalg.det(A)  # -2.0000000000000004</pre>
			<p>Note that a floating-point rounding error has occurred in the calculation of <span class="No-Break">the determinant.</span></p>
			<p>The SciPy package, if installed, also offers a <strong class="source-inline">linalg</strong> module, which extends NumPy’s <strong class="source-inline">linalg</strong>. The SciPy version not only includes additional routines, but it is also always compiled with BLAS <a id="_idIndexMarker089"/>and <strong class="bold">Linear Algebra PACKage</strong> (<strong class="bold">LAPACK</strong>) support, while for the NumPy version, this is optional. Thus, the SciPy variant may be preferable, depending on how NumPy was compiled, if speed <span class="No-Break">is important.</span></p>
			<p>The <strong class="bold">inverse</strong> of an <img alt="" src="image/Formula_01_106.png"/> matrix <img alt="" src="image/Formula_01_107.png"/> is the (necessarily unique) <img alt="" src="image/Formula_01_108.png"/> matrix <img alt="" src="image/Formula_01_109.png"/>, such that <img alt="" src="image/Formula_01_110.png"/>, where <img alt="" src="image/Formula_01_111.png"/> denotes the <img alt="" src="image/Formula_01_112.png"/> identity matrix and the multiplication performed here is <a id="_idIndexMarker090"/>matrix multiplication. Not every square matrix has an inverse; those that do not are sometimes <a id="_idIndexMarker091"/>called <strong class="bold">singular</strong> matrices. In fact, a matrix is non-singular (that is, has an inverse) if, and only if, the determinant of that matrix is not 0. When <img alt="" src="image/Formula_01_113.png"/> has an inverse, it is customary to denote it <span class="No-Break">by <img alt="" src="image/Formula_01_114.png"/></span><span class="No-Break">.</span></p>
			<p>The <strong class="source-inline">inv</strong> routine from the <strong class="source-inline">linalg</strong> module computes the inverse of a matrix if <span class="No-Break">it exists:</span></p>
			<pre class="source-code">
linalg.inv(A)
# array([[-2. , 1. ],
#           [ 1.5, -0.5]])</pre>
			<p>We can check that the matrix given by the <strong class="source-inline">inv</strong> routine is indeed the matrix inverse of <strong class="source-inline">A</strong> by matrix multiplying (on either side) by the inverse and checking that we get the 2 × 2 <span class="No-Break">identity matrix:</span></p>
			<pre class="source-code">
Ainv = linalg.inv(A)
Ainv @ A
# Approximately
# array([[1., 0.],
#           [0., 1.]])
A @ Ainv
# Approximately
# array([[1., 0.],
#           [0., 1.]])</pre>
			<p>There will be a floating-point error in these computations, which has been hidden away behind the <strong class="source-inline">Approximately</strong> comment, due to the way that matrix inverses <span class="No-Break">are computed.</span></p>
			<p>The <strong class="source-inline">linalg</strong> package<a id="_idIndexMarker092"/> also contains a number of other methods such as <strong class="source-inline">norm</strong>, which computes various norms of a matrix. It also contains functions for decomposing matrices in various ways and solving systems <span class="No-Break">of equations.</span></p>
			<p>There are also the matrix analogs of the exponential function <strong class="source-inline">expm</strong>, the logarithm <strong class="source-inline">logm</strong>, sine <strong class="source-inline">sinm</strong>, cosine <strong class="source-inline">cosm</strong>, and tangent <strong class="source-inline">tanm</strong>. Note that these functions are not the same as the standard <strong class="source-inline">exp</strong>, <strong class="source-inline">log</strong>, <strong class="source-inline">sin</strong>, <strong class="source-inline">cos</strong>, and <strong class="source-inline">tan</strong> functions in the base NumPy package, which apply the corresponding function on an element-by-element basis. In contrast, the matrix exponential function is defined using a <em class="italic">power series</em> <span class="No-Break">of matrices:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer118">
					<img alt="" src="image/Formula_01_115.jpg"/>
				</div>
			</div>
			<p>This is defined for any <img alt="" src="image/Formula_01_116.png"/> matrix <img alt="" src="image/Formula_01_117.png"/>, and <img alt="" src="image/Formula_01_118.png"/> denotes the <img alt="" src="image/Formula_01_119.png"/>th <em class="italic">matrix power</em> of <img alt="" src="image/Formula_01_120.png"/>; that is, the <img alt="" src="image/Formula_01_121.png"/> matrix multiplied by itself <img alt="" src="image/Formula_01_122.png"/> times. Note that this “power series” always converges in an appropriate sense. By convention, we take <img alt="" src="image/Formula_01_123.png"/>, where <img alt="" src="image/Formula_01_124.png"/> is the <img alt="" src="image/Formula_01_125.png"/> identity matrix. This is completely analogous to the usual power series definition of the exponential function for real or complex numbers, but with matrices and matrix multiplication in place of numbers and (regular) multiplication. The other functions are defined in a similar fashion, but we will skip <span class="No-Break">the details.</span></p>
			<p>In the next section, we’ll see one area where matrices and their theory can be used to solve systems <span class="No-Break">of equations.</span></p>
			<h2 id="_idParaDest-32"><a id="_idTextAnchor031"/>Systems of equations</h2>
			<p>Solving systems of (linear) equations <a id="_idIndexMarker093"/>is one of the main motivations for studying matrices in mathematics. Problems of this type occur frequently in a variety of applications. We start with a system of linear equations written <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer129">
					<img alt="" src="image/Formula_01_126.jpg"/>
				</div>
			</div>
			<p>Here, <img alt="" src="image/Formula_01_127.png"/> is at least two, <img alt="" src="image/Formula_01_128.png"/> and <img alt="" src="image/Formula_01_129.png"/> are known values, and the <img alt="" src="image/Formula_01_130.png"/> values are the unknown values that we wish <span class="No-Break">to find.</span></p>
			<p>Before we can solve such a system of equations, we need to convert the problem into a matrix equation. This is achieved by collecting together the coefficients <img alt="" src="image/Formula_01_131.png"/> into an <img alt="" src="image/Formula_01_132.png"/> matrix and using the properties of matrix multiplication to relate this matrix to the system of equations. So, we construct the following matrix containing the coefficients taken from <span class="No-Break">the equations:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer136">
					<img alt="" src="image/Formula_01_133.jpg"/>
				</div>
			</div>
			<p>Then, if we take <img alt="" src="image/Formula_01_134.png"/> to be<a id="_idIndexMarker094"/> the unknown (column) vector containing the <img alt="" src="image/Formula_01_135.png"/> values and <img alt="" src="image/Formula_01_136.png"/> to be the (column) vector containing the known values <img alt="" src="image/Formula_01_137.png"/>, then we can rewrite the system of equations as the following single <span class="No-Break">matrix equation:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer141">
					<img alt="" src="image/Formula_01_138.jpg"/>
				</div>
			</div>
			<p>We can now solve this matrix equation using matrix techniques. In this situation, we view a column vector as an <img alt="" src="image/Formula_01_139.png"/> matrix, so the multiplication in the preceding equation is matrix multiplication. To solve this matrix equation, we use the <strong class="source-inline">solve</strong> routine in the <strong class="source-inline">linalg</strong> module. To illustrate the technique, we will solve the following system of equations as <span class="No-Break">an example:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer143">
					<img alt="" src="image/Formula_01_140.jpg"/>
				</div>
			</div>
			<p>These equations have three unknown values: <img alt="" src="image/Formula_01_141.png"/>, <img alt="" src="image/Formula_01_142.png"/>, and <img alt="" src="image/Formula_01_143.png"/>. First, we create a matrix of coefficients and the vector <img alt="" src="image/Formula_01_144.png"/>. Since we are using NumPy as our means of working with matrices and vectors, we create a two-dimensional NumPy array for the matrix <img alt="" src="image/Formula_01_145.png"/> and a one-dimensional array <span class="No-Break">for <img alt="" src="image/Formula_01_146.png"/>:</span></p>
			<pre class="source-code">
import numpy as np
from numpy import linalg
A = np.array([[3, -2, 1], [1, 1, -2], [-3, -2, 1]])
b = np.array([7, -4, 1])</pre>
			<p>Now, the solution to the system of equations can be found using the <span class="No-Break"><strong class="source-inline">solve</strong></span><span class="No-Break"> routine:</span></p>
			<pre class="source-code">
linalg.solve(A, b)  # array([ 1., -1., 2.])</pre>
			<p>This is indeed the solution to the system of equations, which can be easily verified by computing <strong class="source-inline">A @ x</strong> and checking the result against the <strong class="source-inline">b</strong> array. There may be a floating-point rounding error in <span class="No-Break">this computation.</span></p>
			<p>The <strong class="source-inline">solve</strong> function expects two inputs, which are the matrix of coefficients <img alt="" src="image/Formula_01_149.png"/> and the right-hand side vector <img alt="" src="image/Formula_01_148.png"/>. It solves the system of equations using routines that decompose matrix <img alt="" src="image/Formula_01_150.png"/> into simpler matrices to quickly reduce to an easier problem that can be solved by simple substitution. This technique for solving matrix equations is extremely powerful and efficient and is less prone to the floating-point rounding errors that dog some other methods. For instance, the solution to a system of equations could be computed by <a id="_idIndexMarker095"/>multiplying (on the left) by the inverse of the matrix <img alt="" src="image/Formula_01_151.png"/>, if the inverse is known. However, this is generally not as good as using the <strong class="source-inline">solve</strong> routine since it may be slower or result in larger <span class="No-Break">numerical errors.</span></p>
			<p>In the example we used, the coefficient matrix <img alt="" src="image/Formula_01_152.png"/> was square. That is, there is the same number of equations as there are unknown values. In this case, the system of equations has a unique solution if (and only if) the determinant of this matrix <img alt="" src="image/Formula_01_152.png"/> is not <img alt="" src="image/Formula_01_153.png"/>. In cases where the determinant of <img alt="" src="image/Formula_01_154.png"/> is <img alt="" src="image/Formula_01_155.png"/>, one of two things can happen: the system can have no solution, in which case we say that the system is <em class="italic">inconsistent</em>, or there can be infinitely many solutions. The difference between a consistent and inconsistent system is usually determined by the vector <img alt="" src="image/Formula_01_156.png"/>. For example, consider the following systems <span class="No-Break">of equations:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer160">
					<img alt="" src="image/Formula_01_157.jpg"/>
				</div>
			</div>
			<p>The left-hand system of equations is consistent and has infinitely many solutions; for instance, taking <img alt="" src="image/Formula_01_158.png"/> and <img alt="" src="image/Formula_01_159.png"/> or <img alt="" src="image/Formula_01_160.png"/> and <img alt="" src="image/Formula_01_161.png"/> are both solutions. The right-hand system of equations is inconsistent, and there are no solutions. In both of the preceding systems of equations, the <strong class="source-inline">solve</strong> routine will fail because the coefficient matrix <span class="No-Break">is singular.</span></p>
			<p>The coefficient matrix does not need to be square for the system to be solvable—for example, if there are more equations than there are unknown values (a coefficient matrix has more rows than columns). Such a system is said to be <em class="italic">over-specified</em> and, provided that it is consistent, it will have a solution. If there are fewer equations than there are unknown values, then the system is said to be <em class="italic">under-specified</em>. Under-specified systems of <a id="_idIndexMarker096"/>equations generally have infinitely many solutions if they are consistent since there is not enough information to uniquely specify all the unknown values. Unfortunately, the <strong class="source-inline">solve</strong> routine will not be able to find solutions for systems where the coefficient matrix is not square, even if the system does have <span class="No-Break">a solution.</span></p>
			<p>In the next section, we’ll discuss eigenvalues and eigenvectors, which arise by looking at a very specific kind of matrix equation, similar to those <span class="No-Break">seen previously.</span></p>
			<h2 id="_idParaDest-33"><a id="_idTextAnchor032"/>Eigenvalues and eigenvectors</h2>
			<p>Consider the matrix equation <img alt="" src="image/Formula_01_162.png"/>, where <img alt="" src="image/Formula_01_163.png"/> is a square (<img alt="" src="image/Formula_01_164.png"/>) matrix, <img alt="" src="image/Formula_01_165.png"/> is a vector, and <img alt="" src="image/Formula_01_166.png"/> is a number. Numbers <img alt="" src="image/Formula_01_167.png"/> for which there is an <img alt="" src="image/Formula_01_168.png"/> that solves this equation<a id="_idIndexMarker097"/> are called <em class="italic">eigenvalues</em>, and the corresponding vectors <img alt="" src="image/Formula_01_169.png"/> are<a id="_idIndexMarker098"/> called <em class="italic">eigenvectors</em>. Pairs of eigenvalues and corresponding eigenvectors encode information about the matrix <img alt="" src="image/Formula_01_170.png"/>, and are therefore important in many applications where <span class="No-Break">matrices appear.</span></p>
			<p>We will demonstrate computing eigenvalues and eigenvectors using the <span class="No-Break">following matrix:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer174">
					<img alt="" src="image/Formula_01_171.jpg"/>
				</div>
			</div>
			<p>We must first define this as a <span class="No-Break">NumPy array:</span></p>
			<pre class="source-code">
import numpy as np
from numpy import linalg
A = np.array([[3, -1, 4], [-1, 0, -1], [4, -1, 2]])</pre>
			<p>The <strong class="source-inline">eig</strong> routine in the <strong class="source-inline">linalg</strong> module is used to find the eigenvalues and eigenvectors of a square matrix. This routine returns a pair <strong class="source-inline">(v, B)</strong>, where <strong class="source-inline">v</strong> is a one-dimensional array containing the eigenvalues and <strong class="source-inline">B</strong> is a two-dimensional array whose columns are the <span class="No-Break">corresponding eigenvectors:</span></p>
			<pre class="source-code">
v, B = linalg.eig(A)</pre>
			<p>It is perfectly possible for a matrix with only real entries to have complex eigenvalues and eigenvectors. For this reason, the return type of the <strong class="source-inline">eig</strong> routine will sometimes be a complex number type such as <strong class="source-inline">complex32</strong> or <strong class="source-inline">complex64</strong>. In some applications, complex eigenvalues have a special meaning, while in others we only consider the <span class="No-Break">real eigenvalues.</span></p>
			<p>We can extract an<a id="_idIndexMarker099"/> eigenvalue/eigenvector pair from<a id="_idIndexMarker100"/> the output of <strong class="source-inline">eig</strong> using the <span class="No-Break">following sequence:</span></p>
			<pre class="source-code">
i = 0 # first eigenvalue/eigenvector pair
lambda0 = v[i]
print(lambda0)
# 6.823156164525971
x0 = B[:, i] # ith column of B
print(x0)
# [ 0.73271846, -0.20260301, 0.649672352]</pre>
			<p>The eigenvectors returned by the <strong class="source-inline">eig</strong> routine are <em class="italic">normalized</em> so that they have norm (length) 1. (The <em class="italic">Euclidean norm</em> is <a id="_idIndexMarker101"/>defined to be the square root of the sum of the squares of the members of the array.) We can check that this is the case by evaluating in the norm of the vector using the <strong class="source-inline">norm</strong> routine <span class="No-Break">from </span><span class="No-Break"><strong class="source-inline">linalg</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
linalg.norm(x0)  # 1.0  - eigenvectors are normalized.</pre>
			<p>Finally, we can check that these values do indeed satisfy the definition of an eigenvalue/eigenvector pair by computing the product <strong class="source-inline">A @ x0</strong> and checking that, up to floating-point precision, this is equal <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">lambda0*x0</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
lhs = A @ x0
rhs = lambda0*x0
linalg.norm(lhs - rhs)  # 2.8435583831733384e-15 - very small.</pre>
			<p>The norm computed here represents the <em class="italic">distance</em> between the left-hand side (<strong class="source-inline">lhs</strong>) and the right-hand side (<strong class="source-inline">rhs</strong>) of the equation <img alt="" src="image/Formula_01_172.png"/>. Since this distance is extremely small (0 to 14 decimal places), we can be fairly confident that they are actually the same. The fact that this is not zero is likely due to floating-point <span class="No-Break">precision error.</span></p>
			<p>The theoretical procedure for finding eigenvalues<a id="_idIndexMarker102"/> and eigenvectors is to first find the eigenvalues <img alt="" src="image/Formula_01_173.png"/> by <a id="_idIndexMarker103"/>solving the <span class="No-Break">following equation:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer177">
					<img alt="" src="image/Formula_01_174.jpg"/>
				</div>
			</div>
			<p>Here, <img alt="" src="image/Formula_01_175.png"/> is the appropriate identity matrix. The equation determined by the left-hand side is a polynomial in <img alt="" src="image/Formula_01_176.png"/> and is called <a id="_idIndexMarker104"/>the <strong class="bold">characteristic polynomial</strong> of <img alt="" src="image/Formula_01_177.png"/>. The eigenvector corresponding to the eigenvalue <img alt="" src="image/Formula_01_178.png"/> can then be found by solving the following <span class="No-Break">matrix equation:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer182">
					<img alt="" src="image/Formula_01_179.jpg"/>
				</div>
			</div>
			<p>In practice, this process is somewhat inefficient, and there are alternative strategies for computing eigenvalues and eigenvectors numerically <span class="No-Break">more efficiently.</span></p>
			<p>We can only compute eigenvalues and<a id="_idIndexMarker105"/> eigenvectors <a id="_idIndexMarker106"/>for square matrices; for non-square matrices, the definition does not make sense. There is a generalization of<a id="_idIndexMarker107"/> eigenvalues and eigenvectors to non-square matrices called <strong class="bold">singular values</strong>. The trade-off that we have to make in order to do this is that we must compute two vectors <img alt="" src="image/Formula_01_180.png"/> and <img alt="" src="image/Formula_01_181.png"/>, and a singular value <img alt="" src="image/Formula_01_182.png"/> that solves the <span class="No-Break">following equation:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer186">
					<img alt="" src="image/Formula_01_183.jpg"/>
				</div>
			</div>
			<p>If <img alt="" src="image/Formula_01_184.png"/> is an <img alt="" src="image/Formula_01_185.png"/> matrix, then <img alt="" src="image/Formula_01_186.png"/> will have <img alt="" src="image/Formula_01_187.png"/> elements and <img alt="" src="image/Formula_01_188.png"/> will have <img alt="" src="image/Formula_01_189.png"/> elements. The interesting <img alt="" src="image/Formula_01_190.png"/> vectors are actually the (orthonormal) eigenvectors of the symmetric matrix <img alt="" src="image/Formula_01_191.png"/> with the <a id="_idIndexMarker108"/>eigenvalue <img alt="" src="image/Formula_01_192.png"/>. From these values, we can find the <img alt="" src="image/Formula_01_193.png"/> vectors using the previous defining <a id="_idIndexMarker109"/>equation. This will generate all of the interesting combinations, but there are additional vectors <img alt="" src="image/Formula_01_194.png"/> and <img alt="" src="image/Formula_01_195.png"/> where <img alt="" src="image/Formula_01_196.png"/> <span class="No-Break">and <img alt="" src="image/Formula_01_197.png"/></span><span class="No-Break">.</span></p>
			<p>The utility of singular values (and vectors) comes from the <strong class="bold">singular value decomposition</strong> (<strong class="bold">SVD</strong>), which<a id="_idIndexMarker110"/> writes the matrix <img alt="" src="image/Formula_01_198.png"/> as <span class="No-Break">a product:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer202">
					<img alt="" src="image/Formula_01_199.jpg"/>
				</div>
			</div>
			<p>Here, <img alt="" src="image/Formula_01_200.png"/> has orthogonal columns and <img alt="" src="image/Formula_01_201.png"/> has orthogonal rows, and <img alt="" src="image/Formula_01_202.png"/> is a diagonal matrix, usually written so that the values decrease as one moves along the leading diagonal. We can write this formula out in a slightly different way, <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer206">
					<img alt="" src="image/Formula_01_203.jpg"/>
				</div>
			</div>
			<p>What this says is that any matrix can be decomposed into a weight sum of <em class="italic">outer products</em>—pretend <img alt="" src="image/Formula_01_204.png"/> and <img alt="" src="image/Formula_01_205.png"/> are matrices with <img alt="" src="image/Formula_01_206.png"/> rows and <img alt="" src="image/Formula_01_207.png"/> column and matrix multiply <img alt="" src="image/Formula_01_208.png"/> with the transpose of <img alt="" src="image/Formula_01_209.png"/> – <span class="No-Break">of vectors.</span></p>
			<p>Once we have <a id="_idIndexMarker111"/>performed this decomposition, we can look for <img alt="" src="image/Formula_01_210.png"/> values that are especially small, which contribute very little to the value of the matrix. If we throw away the terms with small <img alt="" src="image/Formula_01_211.png"/> values, then we can effectively approximate the original matrix by a simpler representation. This technique is used in <strong class="bold">principal component analysis</strong> (<strong class="bold">PCA</strong>)—for<a id="_idIndexMarker112"/> example, to reduce a complex, high-dimensional dataset to a few components that contribute the most to the overall character of <span class="No-Break">the data.</span></p>
			<p>In Python, we can use the <strong class="source-inline">linalg.svd</strong> function<a id="_idIndexMarker113"/> to compute the SVD of a matrix. This works in a similar way to the <strong class="source-inline">eig</strong> routine described previously, except it returns the three components of <span class="No-Break">the decomposition:</span></p>
			<pre class="source-code">
mat = np.array([[0., 1., 2., 3.], [4., 5., 6., 7.]])
U, s, VT = np.linalg.svd(mat)</pre>
			<p>The arrays returned from this function have shapes <strong class="source-inline">(2, 2)</strong>, <strong class="source-inline">(2,)</strong>, and <strong class="source-inline">(4, 4)</strong>, respectively. As the names suggest, the <strong class="source-inline">U</strong> matrix and <strong class="source-inline">VT</strong> matrices are those that appear in the decomposition, and <strong class="source-inline">s</strong> is a one-dimensional vector containing the nonzero singular values. We can check that decomposition is correct by reconstructing the <img alt="" src="image/Formula_01_212.png"/> matrix and evaluating the product of the <span class="No-Break">three matrices:</span></p>
			<pre class="source-code">
Sigma = np.zeros(mat.shape)
Sigma[:len(s), :len(s)] = np.diag(s)
# array([[11.73352876, 0., 0., 0.],
#        [0., 1.52456641, 0.,  0.]])
reconstructed = U @ Sigma @ VT
# array([[-1.87949788e-15, 1., 2., 3.],
#           [4., 5., 6., 7.]])</pre>
			<p>Notice that the matrix has been reconstructed almost exactly, except for the first entry. The value in the top-left entry is very close to zero—within floating point error—so can be <span class="No-Break">considered zero.</span></p>
			<p>Our method for constructing the matrix <img alt="" src="image/Formula_01_213.png"/> is rather inconvenient. The SciPy version of the <strong class="source-inline">linalg</strong> module contains a special routine for reconstructing this matrix from the one-dimensional array of singular values called <strong class="source-inline">linalg.diagsvd</strong>. This routine takes the array of singular values, <strong class="source-inline">s</strong>, and the shape of the original matrix and constructs the matrix <img alt="" src="image/Formula_01_214.png"/> with the <span class="No-Break">appropriate shape:</span></p>
			<pre class="source-code">
Sigma = sp.linalg.diagsvd(s, *mat.shape)</pre>
			<p>(Recall that the SciPy package is imported under the alias <strong class="source-inline">sp</strong>.) Now, let’s change pace and look at how we might be more efficient in the way we describe matrices in which most of the entries are zero. These are the so-called <span class="No-Break">sparse matrices.</span></p>
			<h2 id="_idParaDest-34"><a id="_idTextAnchor033"/>Sparse matrices</h2>
			<p>Systems of linear equations such as those discussed earlier are extremely common throughout mathematics and, in particular, in mathematical computing. In many applications, the coefficient matrix will be extremely large, with thousands of rows and columns, and will likely be obtained from an alternative source rather than simply entering by hand. In many cases, it will also<a id="_idIndexMarker114"/> be a <em class="italic">sparse</em> matrix, where most of the entries <span class="No-Break">are 0.</span></p>
			<p>A matrix is <strong class="bold">sparse</strong> if a large number of its elements are zero. The exact number of elements that need to be zero in order to call a matrix sparse is not well defined. Sparse matrices can be represented more efficiently—for example, by simply storing the indexes <img alt="" src="image/Formula_01_215.png"/> and the values <img alt="" src="image/Formula_01_216.png"/> that are nonzero. There are entire collections of algorithms for sparse matrices that offer great improvements in performance, assuming the matrix is indeed <span class="No-Break">sufficiently sparse.</span></p>
			<p>Sparse matrices appear in many applications, and often follow some kind of pattern. In particular, several techniques for<a id="_idIndexMarker115"/> solving <strong class="bold">partial differential equations</strong> (<strong class="bold">PDEs</strong>) involve solving sparse matrix equations (see <a href="B19085_03.xhtml#_idTextAnchor078"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Calculus and Differential Equations</em>), and matrices associated with networks are often sparse. There are additional routines for sparse matrices associated with networks (graphs) contained in the <strong class="source-inline">sparse.csgraph</strong> module. We will discuss these further in <a href="B19085_05.xhtml#_idTextAnchor178"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, <em class="italic">Working with Trees </em><span class="No-Break"><em class="italic">and Networks</em></span><span class="No-Break">.</span></p>
			<p>The <strong class="source-inline">sparse</strong> module contains several different classes representing the different means of storing a sparse matrix. The most basic means of storing a sparse matrix is to store three arrays, two containing integers representing the indices of nonzero elements, and the third the data of the corresponding element. This is the format of the <strong class="source-inline">coo_matrix</strong> class. Then, there are <a id="_idIndexMarker116"/>the <strong class="bold">compressed sparse column</strong> (<strong class="bold">CSC</strong>) (<strong class="source-inline">csc_matrix</strong>) and the <strong class="bold">compressed sparse row</strong> (<strong class="bold">CSR</strong>) (<strong class="source-inline">csr_matrix</strong>) formats, which provide <a id="_idIndexMarker117"/>efficient column or row slicing, respectively. There are three additional sparse matrix classes in <strong class="source-inline">sparse</strong>, including <strong class="source-inline">dia_matrix</strong>, which efficiently stores matrices where the nonzero entries appear along a <span class="No-Break">diagonal band.</span></p>
			<p>The <strong class="source-inline">sparse</strong> module from SciPy contains routines for creating and working with sparse matrices. We import the <strong class="source-inline">sparse</strong> module from SciPy using the following <span class="No-Break"><strong class="source-inline">import</strong></span><span class="No-Break"> statement:</span></p>
			<pre class="source-code">
import numpy as np
from scipy import sparse</pre>
			<p>A sparse<a id="_idIndexMarker118"/> matrix can be created from a full (dense) matrix or some other kind of data structure. This is done using the constructor for the specific format in which you wish to store the <span class="No-Break">sparse matrix.</span></p>
			<p>For example, we can take a dense matrix and store it in CSR format by using the <span class="No-Break">following command:</span></p>
			<pre class="source-code">
A = np.array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])
sp_A = sparse.csr_matrix(A)
print(sp_A)
#  (0, 0)  1.0
#  (1, 1)  1.0
#  (2, 2)  1.0</pre>
			<p>If you are generating a sparse matrix by hand, the matrix probably follows some kind of pattern, such as the following <span class="No-Break"><em class="italic">tridiagonal</em></span><span class="No-Break"> matrix:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer220">
					<img alt="" src="image/Formula_01_217.jpg"/>
				</div>
			</div>
			<p>Here, the nonzero entries appear on the diagonal and on either side of the diagonal, and the nonzero entries in each row follow the same pattern. To create such a matrix, we could use one of the array creation routines in <strong class="source-inline">sparse</strong> such as <strong class="source-inline">diags</strong>, which is a convenience routine for creating matrices with <span class="No-Break">diagonal patterns:</span></p>
			<pre class="source-code">
T = sparse.diags([-1, 2, -1], (-1, 0, 1),   
    shape=(5, 5), format="csr")</pre>
			<p>This will create a matrix <img alt="" src="image/Formula_01_218.png"/>, as described previously, and store it as a sparse matrix in CSR format. The first argument specifies the values that should appear in the output matrix, and the second argument is the positions relative to the diagonal position in which the values should be placed. So, the 0 index in the tuple represents the diagonal entry, -1 is to the left of the diagonal in the row, and +1 is to the right of the diagonal in the row. The <strong class="source-inline">shape</strong> keyword <a id="_idIndexMarker119"/>argument gives the dimensions of the matrix produced, and the <strong class="source-inline">format</strong> specifies the storage format for the matrix. If no format is provided using the optional argument, then a reasonable default will be used. The array <strong class="source-inline">T</strong> can be expanded to a full (<em class="italic">dense</em>) matrix using the <span class="No-Break"><strong class="source-inline">toarray</strong></span><span class="No-Break"> method:</span></p>
			<pre class="source-code">
T.toarray()
# array([[ 2, -1,  0,  0,  0],
#           [-1,  2, -1,  0,  0],
#           [ 0, -1,  2, -1,  0],
#           [ 0,  0, -1,  2, -1],
#           [ 0,  0,  0, -1,  2]])</pre>
			<p>When the matrix is small (as it is here), there is little difference in performance between the sparse solving routine and the usual <span class="No-Break">solving routines.</span></p>
			<p>Once a matrix is stored in a sparse format, we can use the sparse solving routines in the <strong class="source-inline">linalg</strong> submodule of <strong class="source-inline">sparse</strong>. For example, we can solve a matrix equation using the <strong class="source-inline">spsolve</strong> routine from this module. The <strong class="source-inline">spsolve</strong> routine will convert the matrix into CSR or CSC, which may add additional time to the computation if it is not provided in one of <span class="No-Break">these formats:</span></p>
			<pre class="source-code">
from scipy.sparse import linalg
linalg.spsolve(T.tocsr(), np.array([1, 2, 3, 4, 5]))
# array([ 5.83333333, 10.66666667, 13.5 , 13.33333333, 9.16666667])</pre>
			<p>The <strong class="source-inline">sparse.linalg</strong> module also contains many of the routines that can be found in the <strong class="source-inline">linalg</strong> module of NumPy (or SciPy) that accept sparse matrices instead of full NumPy arrays, such as <strong class="source-inline">eig</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">inv</strong></span><span class="No-Break">.</span></p>
			<p>This concludes our tour of the basic tools for mathematics available in Python and its ecosystem. Let’s summarize what <span class="No-Break">we’ve seen.</span></p>
			<h1 id="_idParaDest-35"><a id="_idTextAnchor034"/>Summary</h1>
			<p>Python offers built-in support for mathematics with some basic numerical types, arithmetic, extended precision numbers, rational numbers, complex numbers, and a variety of basic mathematical functions. However, for more serious computations involving large arrays of numerical values, you should use the NumPy and SciPy packages. NumPy provides high-performance array types and basic routines, while SciPy provides more specific tools for solving equations and working with sparse matrices (among many <span class="No-Break">other things).</span></p>
			<p>NumPy arrays can be multi-dimensional. Two-dimensional arrays have matrix properties that can be accessed using the <strong class="source-inline">linalg</strong> module from either NumPy or SciPy (the former is a subset of the latter). Moreover, there is a special operator in Python for matrix multiplication, <strong class="source-inline">@</strong>, which is implemented for NumPy arrays. SciPy also provides support for sparse matrices via the <strong class="source-inline">sparse</strong> module. We also touched on matrix theory and linear algebra, which underpins most of the numerical methods found in this book—often behind <span class="No-Break">the scenes.</span></p>
			<p>In the next chapter, we’ll get started looking at <span class="No-Break">some recipes.</span></p>
			<h1 id="_idParaDest-36"><a id="_idTextAnchor035"/>Further reading</h1>
			<p>There are many mathematical textbooks describing the basic properties of matrices and linear algebra, which is the study of vectors and matrices. The following are good introductory texts for <span class="No-Break">linear algebra:</span></p>
			<ul>
				<li><em class="italic">Strang, G.</em> (2016). <em class="italic">Introduction to Linear Algebra</em>. <em class="italic">Wellesley, MA: Wellesley-Cambridge Press, </em><span class="No-Break"><em class="italic">Fifth Edition</em></span><span class="No-Break">.</span></li>
				<li><em class="italic">Blyth, T.</em> and <em class="italic">Robertson, E.</em> (2013). <em class="italic">Basic Linear Algebra</em>. <em class="italic">London: Springer </em><span class="No-Break"><em class="italic">London, Limited</em></span><span class="No-Break">.</span></li>
			</ul>
			<p>NumPy and SciPy are part of the Python mathematical and scientific computing ecosystem and have extensive documentation that can be accessed from the official website, <a href="https://scipy.org">https://scipy.org</a>. We will see several other packages from this ecosystem throughout <span class="No-Break">this book.</span></p>
			<p>More information about the BLAS and LAPACK libraries that NumPy and SciPy use behind the scenes can be found at the <span class="No-Break">following links:</span></p>
			<ul>
				<li><span class="No-Break">BLAS: </span><a href="https://www.netlib.org/blas/"><span class="No-Break">https://www.netlib.org/blas/</span></a></li>
				<li><span class="No-Break">LAPACK: </span><a href="https://www.netlib.org/lapack/"><span class="No-Break">https://www.netlib.org/lapack/</span></a></li>
			</ul>
		</div>
	</body></html>