<html><head></head><body>
  <div id="_idContainer113" class="Basic-Text-Frame">
    <h1 class="chapterNumber">8</h1>
    <h1 id="_idParaDest-279" class="chapterTitle">Encoding, Transforming, and Scaling Features</h1>
    <p class="normal">Our data cleaning efforts are often intended to prepare that data for use with a machine learning algorithm. Machine learning algorithms typically require some form of encoding of variables. Our models also often perform better with some form of scaling so that features with higher variability do not overwhelm the optimization. We show examples of that in this chapter and of how standardizing addresses the issue.</p>
    <p class="normal">Machine learning algorithms typically require some form of encoding of variables. We almost always need to encode our features for algorithms to understand them correctly. For example, most algorithms cannot make sense of the values <em class="italic">female</em> or <em class="italic">male</em>, or know not to treat zip codes as ordinal. Although not typically necessary, scaling is often a very good idea when we have features with vastly different ranges. When we are using algorithms that assume a Gaussian distribution of our features, some form of transformation may be required for our features to be consistent with that assumption.</p>
    <p class="normal">Specifically, we explore the following in this chapter:</p>
    <ul>
      <li class="bulletList">Creating training datasets and avoiding data leakage</li>
      <li class="bulletList">Identifying irrelevant or redundant observations to be removed</li>
      <li class="bulletList">Encoding categorical features: one-hot encoding</li>
      <li class="bulletList">Encoding categorical features: ordinal encoding</li>
      <li class="bulletList">Encoding features with medium or high cardinality</li>
      <li class="bulletList">Transforming features</li>
      <li class="bulletList">Binning features</li>
      <li class="bulletList"><em class="italic">k</em>-means binning</li>
      <li class="bulletList">Scaling features</li>
    </ul>
    <h1 id="_idParaDest-280" class="heading-1">Technical requirements</h1>
    <p class="normal">You will need pandas, NumPy, and Matplotlib to complete the recipes in this chapter. I used pandas 2.1.4, but the code will run on pandas 1.5.3 or later.</p>
    <p class="normal">The code in this chapter can be downloaded from the book’s GitHub repository, <a href="https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition"><span class="url">https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition</span></a>.</p>
    <h1 id="_idParaDest-281" class="heading-1">Creating training datasets and avoiding data leakage</h1>
    <p class="normal">One of the biggest threats <a id="_idIndexMarker631"/>to the performance<a id="_idIndexMarker632"/> of our models is data leakage. <strong class="keyWord">Data leakage</strong> occurs whenever our models are informed by data<a id="_idIndexMarker633"/> that is not in the training dataset. We sometimes inadvertently assist our model training with information that cannot be gleaned from the training data alone, and we end up with a too-rosy assessment of our model’s accuracy.</p>
    <p class="normal">Data scientists do not really intend for this to happen, hence the term “leakage.” This is not a “<em class="italic">don’t do it</em>” kind of discussion. We all know not to do it. This is more of a “<em class="italic">which steps should I take to avoid the problem?</em>” discussion. It is actually quite easy to have some data leakage unless we develop routines to prevent it.</p>
    <p class="normal">For example, if we have missing values for a feature, we might impute the mean across the whole dataset for those values. However, in order to validate our model, we subsequently split our data into training and testing datasets. We would then have accidentally introduced data leakage into our training dataset, since information from the full dataset (the global mean) would have been used.</p>
    <p class="normal">Data leakage can significantly compromise our model evaluation, making it look like our predictions are much more reliable than they actually are. Among the practices that data scientists have adopted to avoid this is to establish separate training and testing datasets as close to the beginning of the analysis as possible.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Note</strong></p>
      <p class="normal">I have mainly<a id="_idIndexMarker634"/> used the term <em class="italic">variable</em> in this book when referring to some statistical property of something that can be counted or measured, such as age or duration of time. I have used <em class="italic">column</em> when referring to some specific<a id="_idIndexMarker635"/> operation or attribute of a column of data in a dataset. In this chapter, I will frequently use the word feature to refer to variables used for predictive analysis. In machine learning, we typically refer to features (also known<a id="_idIndexMarker636"/> as independent or predictor variables) and<a id="_idIndexMarker637"/> targets (also known as dependent or response variables).</p>
    </div>
    <h2 id="_idParaDest-282" class="heading-2">Getting ready</h2>
    <p class="normal">We will work extensively<a id="_idIndexMarker638"/> with the scikit-learn library throughout<a id="_idIndexMarker639"/> this chapter. You can use <code class="inlineCode">pip</code> to install scikit-learn with <code class="inlineCode">pip install scikit-learn</code>. The code in this chapter uses <code class="inlineCode">sklearn</code> version 0.24.2.</p>
    <p class="normal">We can use scikit-learn to create training<a id="_idIndexMarker640"/> and testing DataFrames for the <strong class="keyWord">National Longitudinal Survey of Youth</strong> (<strong class="keyWord">NLS</strong>) data.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Data note</strong></p>
      <p class="normal">The National Longitudinal Survey of Youth is conducted by the United States Bureau of Labor Statistics. This survey started with a cohort of individuals in 1997 who were born between 1980 and 1985, with annual follow-ups each year through 2023. For this recipe, I pulled 104 variables on grades, employment, income, and attitudes toward government from the hundreds of data items on the survey. The NLS data can be downloaded for public use from <code class="inlineCode">nlsinfo.org</code>.</p>
    </div>
    <h2 id="_idParaDest-283" class="heading-2">How to do it...</h2>
    <p class="normal">We will use scikit-learn to create training and testing data:</p>
    <ol>
      <li class="numberedList" value="1">First, we import the <code class="inlineCode">train_test_split</code> module from <code class="inlineCode">sklearn</code> and load the NLS data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
nls97 = pd.read_csv(<span class="hljs-string">"data/nls97g.csv"</span>, low_memory=<span class="hljs-literal">False</span>)
nls97.set_index(<span class="hljs-string">"personid"</span>, inplace=<span class="hljs-literal">True</span>)
</code></pre>
      </li>
      <li class="numberedList">Then, we can create training and testing DataFrames for the features (<code class="inlineCode">X_train</code> and <code class="inlineCode">X_test</code>) and the target (<code class="inlineCode">y_train</code> and <code class="inlineCode">y_test</code>). <code class="inlineCode">wageincome20</code> is the target variable in this example. We set the <code class="inlineCode">test_size</code> parameter to 0.3 to leave 30% of the observations<a id="_idIndexMarker641"/> for testing. We will only work with the <strong class="keyWord">Scholastic Assessment Test</strong> (<strong class="keyWord">SAT</strong>) and <strong class="keyWord">Grade Point Average</strong> (<strong class="keyWord">GPA</strong>) data from the NLS. We need<a id="_idIndexMarker642"/> to remember to set a value for <code class="inlineCode">random_state</code> to make sure we will get the same DataFrames should we need to rerun <code class="inlineCode">train_test_split</code> later:
        <pre class="programlisting code-one"><code class="hljs-code">feature_cols = [<span class="hljs-string">'satverbal'</span>,<span class="hljs-string">'satmath'</span>,<span class="hljs-string">'gpascience'</span>,
  <span class="hljs-string">'gpaenglish'</span>,<span class="hljs-string">'gpamath'</span>,<span class="hljs-string">'gpaoverall'</span>]
X_train, X_test, y_train, y_test =  \
  train_test_split(nls97[feature_cols],\
  nls97[[<span class="hljs-string">'wageincome20'</span>]], test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">0</span>)
</code></pre>
      </li>
      <li class="numberedList">Let’s take a look<a id="_idIndexMarker643"/> at the training<a id="_idIndexMarker644"/> DataFrames created with <code class="inlineCode">train_test_split</code>. We get the expected number of observations, 6,288, 70% of the total number of observations in the NLS DataFrame of 8,984:
        <pre class="programlisting code-one"><code class="hljs-code">nls97.shape[<span class="hljs-number">0</span>]
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">8984
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">X_train.info()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">&lt;class 'pandas.core.frame.DataFrame'&gt;
Index: 6288 entries, 639330 to 166002
Data columns (total 6 columns):
 #   Column      Non-Null Count  Dtype 
---  ------      --------------  ----- 
 0   satverbal   1010 non-null   float64
 1   satmath     1010 non-null   float64
 2   gpascience  4022 non-null   float64
 3   gpaenglish  4086 non-null   float64
 4   gpamath     4076 non-null   float64
 5   gpaoverall  4237 non-null   float64
dtypes: float64(6)
memory usage: 343.9 KB
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">y_train.info()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">&lt;class 'pandas.core.frame.DataFrame'&gt;
Index: 6288 entries, 639330 to 166002
Data columns (total 1 columns):
 #   Column        Non-Null Count  Dtype 
---  ------        --------------  ----- 
 0   wageincome20  3652 non-null   float64
dtypes: float64(1)
memory usage: 98.2 KB
</code></pre>
      </li>
      <li class="numberedList">Let’s also look at the testing DataFrames. We get 30% of the observations as we expected:
        <pre class="programlisting code-one"><code class="hljs-code">X_test.info()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">&lt;class 'pandas.core.frame.DataFrame'&gt;
Index: 2696 entries, 624557 to 201518
Data columns (total 6 columns):
 #   Column      Non-Null Count  Dtype 
---  ------      --------------  ----- 
 0   satverbal   396 non-null    float64
 1   satmath     397 non-null    float64
 2   gpascience  1662 non-null   float64
 3   gpaenglish  1712 non-null   float64
 4   gpamath     1690 non-null   float64
 5   gpaoverall  1767 non-null   float64
dtypes: float64(6)
memory usage: 147.4 KB
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">y_test.info()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">&lt;class 'pandas.core.frame.DataFrame'&gt;
Index: 2696 entries, 624557 to 201518
Data columns (total 1 columns):
 #   Column        Non-Null Count  Dtype 
---  ------        --------------  ----- 
 0   wageincome20  1549 non-null   float64
dtypes: float64(1)
memory usage: 42.1 KB
</code></pre>
      </li>
    </ol>
    <p class="normal">These steps demonstrated<a id="_idIndexMarker645"/> how to create training<a id="_idIndexMarker646"/> and testing DataFrames.</p>
    <h2 id="_idParaDest-284" class="heading-2">How it works...</h2>
    <p class="normal">For data scientists who use Python, and regularly use machine learning algorithms, <code class="inlineCode">train_test_split</code> is a very popular option to avoid data leakage while preparing data for analysis.</p>
    <p class="normal"><code class="inlineCode">train_test_split</code> will return four DataFrames: a DataFrame with training data consisting of the features or independent variables we intend to use in our analysis, a DataFrame with testing data for those same variables, a DataFrame with training data for our <a id="_idIndexMarker647"/>target variable (also known as a response or dependent variable), and<a id="_idIndexMarker648"/> a testing DataFrame with that target variable.</p>
    <p class="normal">The first arguments of <code class="inlineCode">test_train_split</code> can take DataFrames, NumPy arrays, or some other two-dimensional array-like structure. Here, we pass a pandas DataFrame with our features to the first argument, and then another pandas DataFrame with just our target variable. We also specify that we want the testing data to be 30% of our dataset’s rows.</p>
    <p class="normal">Rows are selected randomly by <code class="inlineCode">test_train_split</code>. We need to provide a value for <code class="inlineCode">random_state</code> if we want<a id="_idIndexMarker649"/> to reproduce<a id="_idIndexMarker650"/> the split.</p>
    <h2 id="_idParaDest-285" class="heading-2">See also</h2>
    <p class="normal">When our projects involve predictive modeling and evaluation of these models, our data preparation needs to be part of a machine learning pipeline, which often starts with splitting the data between training and testing data. Scikit-learn provides great tools for constructing machine learning pipelines that go from data preparation all the way through to model evaluation. A good resource for mastering those techniques is my book <em class="italic">Data Cleaning and Exploration with Machine Learning</em>.</p>
    <p class="normal">We will use <code class="inlineCode">sklearn</code>'s <code class="inlineCode">train_test_split</code> to create separate training and testing DataFrames in the rest of this chapter. Next, we begin our feature engineering work by removing features that are obviously unhelpful because they have the same data as another feature, or there is no variation in the responses.</p>
    <h1 id="_idParaDest-286" class="heading-1">Removing redundant or unhelpful features</h1>
    <p class="normal">During the process<a id="_idIndexMarker651"/> of data cleaning and manipulation, we often end up with data that is no longer meaningful. Perhaps we subsetted data based on a single feature value and we have retained that feature, even though it now has the same value for all observations. Alternatively, for the subset of the data that we are using, two features have the same value. Ideally, we catch those redundancies during our data cleaning. However, if we do not catch them during that process, we can use the open source <code class="inlineCode">feature-engine</code> package to help us with that.</p>
    <p class="normal">There also may be features that are so highly correlated that it is very unlikely that we could build a model that could use all of them effectively. <code class="inlineCode">feature-engine</code> has a method, <code class="inlineCode">DropCorrelatedFeatures</code>, that makes it easy to remove a feature when it is highly correlated with another feature.</p>
    <h2 id="_idParaDest-287" class="heading-2">Getting ready</h2>
    <p class="normal">We will work extensively with the <code class="inlineCode">feature-engine</code> and <code class="inlineCode">category_encoders</code> packages in this chapter. You can use pip to install these packages with <code class="inlineCode">pip install feature-engine</code> and <code class="inlineCode">pip install category_encoders</code>. The code in this chapter uses version 1.7.0 of <code class="inlineCode">feature-engine</code> and version 2.6.3 of <code class="inlineCode">category_encoders</code>. Note that either <code class="inlineCode">pip install feature-engine</code> or <code class="inlineCode">pip install feature_engine</code> will work.</p>
    <p class="normal">We will work with land temperature<a id="_idIndexMarker652"/> data, in addition to the NLS data, in this section. We will only load temperature data for Poland here.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Data note</strong></p>
      <p class="normal">The land temperature DataFrame has the average temperature reading (in <sup class="superscript">°</sup>C) in 2023 from over 12,000 stations across the world, although a majority of the stations are in the United States. The raw data was retrieved from the Global Historical Climatology Network integrated database. It is made available for public use by the United States National Oceanic and Atmospheric Administration at <a href="https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-monthly"><span class="url">https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-monthly</span></a>.</p>
    </div>
    <h2 id="_idParaDest-288" class="heading-2">How to do it...</h2>
    <ol>
      <li class="numberedList" value="1">Let’s import the modules we need from <code class="inlineCode">feature_engine</code> and <code class="inlineCode">sklearn</code>, and then load the NLS data and temperature data for Poland. The data from Poland was pulled from a larger dataset of 12,000 weather stations across the world. We use <code class="inlineCode">dropna</code> to drop observations with any missing data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> feature_engine.selection <span class="hljs-keyword">as</span> fesel
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
nls97 = pd.read_csv(<span class="hljs-string">"data/nls97g.csv"</span>,low_memory=<span class="hljs-literal">False</span>)
nls97.set_index(<span class="hljs-string">"personid"</span>, inplace=<span class="hljs-literal">True</span>)
ltpoland = pd.read_csv(<span class="hljs-string">"data/ltpoland.csv"</span>)
ltpoland.set_index(<span class="hljs-string">"station"</span>, inplace=<span class="hljs-literal">True</span>)
ltpoland.dropna(inplace=<span class="hljs-literal">True</span>)
</code></pre>
      </li>
      <li class="numberedList">Next, we create training and testing DataFrames, as we did in the previous section:
        <pre class="programlisting code-one"><code class="hljs-code">feature_cols = [<span class="hljs-string">'satverbal'</span>,<span class="hljs-string">'satmath'</span>,<span class="hljs-string">'gpascience'</span>,
  <span class="hljs-string">'gpaenglish'</span>,<span class="hljs-string">'gpamath'</span>,<span class="hljs-string">'gpaoverall'</span>]
X_train, X_test, y_train, y_test =  \
  train_test_split(nls97[feature_cols],\
  nls97[[<span class="hljs-string">'wageincome20'</span>]], test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">0</span>)
</code></pre>
      </li>
      <li class="numberedList">We can use the pandas <code class="inlineCode">corr</code> method to see how these features are correlated:
        <pre class="programlisting code-one"><code class="hljs-code">X_train.corr()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">            satverbal  satmath  gpascience  \
satverbal        1.00     0.74        0.42  
satmath          0.74     1.00        0.47  
gpascience       0.42     0.47        1.00  
gpaenglish       0.44     0.44        0.67  
gpamath          0.36     0.50        0.62  
gpaoverall       0.40     0.48        0.79  
            gpaenglish  gpamath  gpaoverall 
satverbal         0.44     0.36        0.40 
satmath           0.44     0.50        0.48 
gpascience        0.67     0.62        0.79 
gpaenglish        1.00     0.61        0.84 
gpamath           0.61     1.00        0.76 
gpaoverall        0.84     0.76        1.00 
</code></pre>
      </li>
    </ol>
    <p class="normal-one"><code class="inlineCode">gpaoverall</code> is highly correlated<a id="_idIndexMarker653"/> with <code class="inlineCode">gpascience</code>, <code class="inlineCode">gpaenglish</code>, and <code class="inlineCode">gpamath</code>. The <code class="inlineCode">corr</code> method returns the Pearson coefficients by default. This is fine when we can assume a linear relationship between the features. When this assumption does not make sense, we should consider requesting Spearman coefficients instead. We can do that by passing <code class="inlineCode">spearman</code> to the method parameter of <code class="inlineCode">corr</code>.</p>
    <ol>
      <li class="numberedList" value="4">Let’s drop features that have a correlation higher than 0.75 with another feature. We pass 0.75 to the <code class="inlineCode">threshold</code> parameter of <code class="inlineCode">DropCorrelatedFeatures</code>, and we indicate that we want to use Pearson coefficients and evaluate all features by setting variables to <code class="inlineCode">None</code>. We use the <code class="inlineCode">fit</code> method on the training data and then transform both the training and testing data. The <code class="inlineCode">info</code> method shows that the resulting training DataFrame (<code class="inlineCode">X_train_tr</code>) has all of the features except <code class="inlineCode">gpaoverall</code>, which has a <code class="inlineCode">0.79</code> and <code class="inlineCode">0.84</code> correlation with <code class="inlineCode">gpascience</code> and <code class="inlineCode">gpaenglish</code>, respectively (<code class="inlineCode">DropCorrelatedFeatures</code> will evaluate from left to right, so if <code class="inlineCode">gpamath</code> and <code class="inlineCode">gpaoverall</code> are highly correlated, it will drop <code class="inlineCode">gpaoverall</code>. </li>
    </ol>
    <p class="normal-one">If <code class="inlineCode">gpaoverall</code> had been to the left of <code class="inlineCode">gpamath</code>, it would have dropped <code class="inlineCode">gpamath</code>):</p>
    <pre class="programlisting code-one"><code class="hljs-code">tr = fesel.DropCorrelatedFeatures(variables=<span class="hljs-literal">None</span>, method=<span class="hljs-string">'pearson'</span>, threshold=<span class="hljs-number">0.75</span>)
tr.fit(X_train)
X_train_tr = tr.transform(X_train)
X_test_tr = tr.transform(X_test)
X_train_tr.info()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">&lt;class 'pandas.core.frame.DataFrame'&gt;
Index: 6288 entries, 639330 to 166002
Data columns (total 5 columns):
 #   Column      Non-Null Count  Dtype 
---  ------      --------------  ----- 
 0   satverbal   1010 non-null   float64
 1   satmath     1010 non-null   float64
 2   gpascience  4022 non-null   float64
 3   gpaenglish  4086 non-null   float64
 4   gpamath     4076 non-null   float64
dtypes: float64(5)
memory usage: 294.8 KB
</code></pre>
    <p class="normal-one">We would typically evaluate<a id="_idIndexMarker654"/> a feature more carefully before deciding to drop it. However, there are times when feature selection is part of a pipeline and we need to automate the process. This can be done with <code class="inlineCode">DropCorrelatedFeatures</code>, since all <code class="inlineCode">feature_engine</code> methods can be brought into a scikit-learn pipeline.</p>
    <ol>
      <li class="numberedList" value="5">Let’s now create training and testing DataFrames from the land temperatures data for Poland. The value of <code class="inlineCode">year</code> is the same for all observations, as is the value for <code class="inlineCode">country</code>. The value for <code class="inlineCode">latabs</code> is also the same as for <code class="inlineCode">latitude</code> for each observation:
        <pre class="programlisting code-one"><code class="hljs-code">feature_cols = [<span class="hljs-string">'year'</span>,<span class="hljs-string">'month'</span>,<span class="hljs-string">'latabs'</span>,<span class="hljs-string">'latitude'</span>,<span class="hljs-string">'</span><span class="hljs-string">elevation'</span>,
  <span class="hljs-string">'longitude'</span>,<span class="hljs-string">'country'</span>]
X_train, X_test, y_train, y_test =  \
  train_test_split(ltpoland[feature_cols],\
  ltpoland[[<span class="hljs-string">'temperature'</span>]], test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">0</span>)
X_train.sample(<span class="hljs-number">5</span>, random_state=<span class="hljs-number">99</span>)
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">           year  month  latabs  latitude  elevation  longitude   country
station                                   
SIEDLCE    2023     11      52        52        152         22   Poland
OKECIE     2023      6      52        52        110         21   Poland
BALICE     2023      1      50        50        241         20   Poland
BALICE     2023      7      50        50        241         20   Poland
BIALYSTOK  2023     11      53        53        151         23   Poland
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">X_train.year.value_counts()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">year
2023    84
Name: count, dtype: int64
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">X_train.country.value_counts()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">country
Poland    84
Name: count, dtype: int64
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">(X_train.latitude!=X_train.latabs).<span class="hljs-built_in">sum</span>()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">0
</code></pre>
      </li>
      <li class="numberedList">Let’s drop features with the same<a id="_idIndexMarker655"/> value throughout the training dataset. Notice that <code class="inlineCode">year</code> and <code class="inlineCode">country</code> are removed after the transform:
        <pre class="programlisting code-one"><code class="hljs-code">tr = fesel.DropConstantFeatures()
tr.fit(X_train)
X_train_tr = tr.transform(X_train)
X_test_tr = tr.transform(X_test)
X_train_tr.head()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">           month  latabs  latitude  elevation  longitude
station                                                
OKECIE         1      52        52        110         21
LAWICA         8      52        52         94         17
LEBA          11      55        55          2         18
SIEDLCE       10      52        52        152         22
BIALYSTOK     11      53        53        151         23
</code></pre>
      </li>
      <li class="numberedList">Let’s drop features that have the same values as other features. In this case, the transform drops <code class="inlineCode">latitude</code>, which has the same values as <code class="inlineCode">latabs</code>:
        <pre class="programlisting code-one"><code class="hljs-code">tr = fesel.DropDuplicateFeatures()
tr.fit(X_train_tr)
X_train_tr = tr.transform(X_train_tr)
X_train_tr.head()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">           month  latabs  elevation  longitude
station                                      
OKECIE         1      52        110         21
LAWICA         8      52         94         17
LEBA          11      55          2         18
SIEDLCE       10      52        152         22
BIALYSTOK     11      53        151         23
</code></pre>
      </li>
    </ol>
    <h2 id="_idParaDest-289" class="heading-2">How it works...</h2>
    <p class="normal">This fixes some obvious problems<a id="_idIndexMarker656"/> with our features in the NLS data and the temperature data for Poland. We dropped <code class="inlineCode">gpaoverall</code> from a DataFrame that has the other GPA features because it is highly correlated with them. We also removed redundant data, dropping features with the same value throughout the DataFrame and features that duplicate the values of another feature.</p>
    <p class="normal">In <em class="italic">step 6</em>, we used the <code class="inlineCode">fit</code> method of the <em class="italic">feature engine</em> <code class="inlineCode">selection</code> object. This gathers the information needed to do the transformation we request after that. The transformation in this case is to drop features with constant values. We typically perform the fitting on training data only. We can combine the fit and transform on the training data by using <code class="inlineCode">fit_transform</code>, which we will do in most of this chapter.</p>
    <p class="normal">The rest of this chapter explores somewhat messier feature engineering challenges: encoding, transforming, binning, and scaling.</p>
    <h1 id="_idParaDest-290" class="heading-1">Encoding categorical features: one-hot encoding</h1>
    <p class="normal">There are several reasons why we may<a id="_idIndexMarker657"/> need to encode features<a id="_idIndexMarker658"/> before using them in most machine learning algorithms. First, these algorithms typically require numeric data. Second, when a categorical feature is represented with numbers, for example, 1 for female and 2 for male, we need to encode the values so that they are recognized as categorical. Third, the feature might actually be ordinal, with a discrete number of values that represent some meaningful ranking. Our models need to capture that ranking. Finally, a categorical<a id="_idIndexMarker659"/> feature might have a large number of values (known as high cardinality), and we might want our encoding to collapse categories.</p>
    <p class="normal">We can handle the encoding of features with a limited number of values, say 15 or fewer, with one-hot encoding. We go over one-hot encoding in this recipe and then discuss ordinal encoding in the next recipe. We will look at strategies for handling categorical features with high cardinality after that.</p>
    <p class="normal">One-hot encoding takes a feature and creates a binary vector for each value of that<a id="_idIndexMarker660"/> feature. So, if a feature, called <em class="italic">letter</em>, has three unique values, <em class="italic">A</em>, <em class="italic">B</em>, and <em class="italic">C</em>, one-hot encoding creates three binary vectors to represent those values. The first binary vector, which we can call <em class="italic">letter_A</em>, has 1 whenever <em class="italic">letter</em> has a value of <em class="italic">A</em>, and 0 when it is <em class="italic">B</em> or <em class="italic">C</em>. <em class="italic">letter_B</em> and <em class="italic">letter_C</em> would be coded similarly. The transformed features, <em class="italic">letter_A</em>, <em class="italic">letter_B</em>, and <em class="italic">letter_C</em>, are often<a id="_idIndexMarker661"/> referred to as <strong class="keyWord">dummy variables</strong>. <em class="italic">Figure 8.1</em> illustrates one-hot encoding.</p>
    <table id="table001" class="table-container">
      <tbody>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">letter</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">letter_A</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">letter_B</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">letter_C</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">A</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">B</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal">C</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">0</p>
          </td>
          <td class="table-cell">
            <p class="normal">1</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Figure 8.1: One-hot encoding of a categorical feature</p>
    <h2 id="_idParaDest-291" class="heading-2">Getting ready</h2>
    <p class="normal">We will use the <code class="inlineCode">OneHotEncoder</code> and <code class="inlineCode">OrdinalEncoder</code> modules in the next two recipes from <code class="inlineCode">feature_engine</code> and <code class="inlineCode">scikit_learn</code>, respectively. We will continue working with the NLS data.</p>
    <h2 id="_idParaDest-292" class="heading-2">How to do it...</h2>
    <p class="normal">A number of features from the NLS data are appropriate for one-hot encoding. We encode some of those features in the following code blocks:</p>
    <ol>
      <li class="numberedList" value="1">Let’s start by importing the <code class="inlineCode">OneHotEncoder</code> module from <code class="inlineCode">feature_engine</code> and loading the data. We also import the <code class="inlineCode">OrdinalEncoder</code> module from <code class="inlineCode">scikit-learn</code>, since we will use it later.
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> feature_engine.encoding <span class="hljs-keyword">import</span> OneHotEncoder
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> OrdinalEncoder
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
nls97 = pd.read_csv(<span class="hljs-string">"data/nls97g.csv"</span>, low_memory=<span class="hljs-literal">False</span>)
nls97.set_index(<span class="hljs-string">"personid"</span>, inplace=<span class="hljs-literal">True</span>)
</code></pre>
      </li>
      <li class="numberedList">Next, we create training and testing DataFrames for the NLS data.</li>
    </ol>
    <p class="normal-one">For our purposes in this recipe, we drop rows with missing data:</p>
    <pre class="programlisting code-one"><code class="hljs-code">feature_cols = [<span class="hljs-string">'gender'</span>,<span class="hljs-string">'maritalstatus'</span>,<span class="hljs-string">'colenroct99'</span>]
nls97demo = nls97[[<span class="hljs-string">'wageincome20'</span>] + feature_cols].dropna()
X_demo_train, X_demo_test, y_demo_train, y_demo_test =  \
  train_test_split(nls97demo[feature_cols],\
  nls97demo[[<span class="hljs-string">'wageincome20'</span>]], test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">0</span>)
</code></pre>
    <ol>
      <li class="numberedList" value="3">One option we have for the encoding<a id="_idIndexMarker662"/> is the pandas <code class="inlineCode">get_dummies</code> method. We can use it to indicate that we want to convert the <code class="inlineCode">gender</code> and <code class="inlineCode">maritalstatus</code> features. <code class="inlineCode">get_dummies</code> gives us a dummy variable for each value of <code class="inlineCode">gender</code> and <code class="inlineCode">maritalstatus</code>. For example, <code class="inlineCode">gender</code> has the values Female and Male. <code class="inlineCode">get_dummies</code> creates a feature, <code class="inlineCode">gender_Female</code>, which is 1 when <code class="inlineCode">gender</code> is Female and 0 when <code class="inlineCode">gender</code> is Male. When <code class="inlineCode">gender</code> is Male, <code class="inlineCode">gender_Male</code> is 1 and <code class="inlineCode">gender_Female</code> is 0. This is a tried-and-true method of doing this encoding that has served statisticians well for many years:
        <pre class="programlisting code-one"><code class="hljs-code">pd.get_dummies(X_demo_train,
  columns=[<span class="hljs-string">'gender'</span>,<span class="hljs-string">'maritalstatus'</span>], dtype=<span class="hljs-built_in">float</span>).\
  head(<span class="hljs-number">2</span>).T
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                            606986             764231
colenroct99      3. 4-year college    1. Not enrolled
gender_Female                    1                  0
gender_Male                      0                  1
maritalstatus_Divorced           0                  0
maritalstatus_Married            0                  1
maritalstatus_Never-married      1                  0
maritalstatus_Separated          0                  0
maritalstatus_Widowed            0                  0
</code></pre>
      </li>
    </ol>
    <p class="normal-one">We are not creating a new DataFrame with <code class="inlineCode">get_dummies</code> because we will be using a different technique to do the encoding later in this recipe.</p>
    <p class="normal-one">We typically create <em class="italic">k</em>-1 dummy variables for <em class="italic">k</em> unique values for a feature. So, if <code class="inlineCode">gender</code> has two values in our data, we only need to create one dummy variable. If we know the value for <code class="inlineCode">gender_Female</code>, we also know the value of <code class="inlineCode">gender_Male</code>, so the latter variable is redundant. Similarly, we know the value of <code class="inlineCode">maritalstatus_Divorced</code> if we know the values of the other <code class="inlineCode">maritalstatus</code> dummies. Creating a redundancy in this way<a id="_idIndexMarker663"/> is inelegantly referred to as the <strong class="keyWord">dummy variable trap</strong>. To prevent this problem, we drop one dummy from each group.</p>
    <div class="note-one">
      <p class="normal"><strong class="keyWord">Note</strong></p>
      <p class="normal">For some machine learning algorithms, such as linear regression, dropping one dummy variable is actually required. In estimating the parameters of a linear model, the matrix is inverted. If our model has an intercept, and all dummy variables are included, the matrix cannot be inverted.</p>
    </div>
    <ol>
      <li class="numberedList" value="4">We can set the <code class="inlineCode">get_dummies</code> <code class="inlineCode">drop_first</code> parameter to <code class="inlineCode">True</code> to drop the first dummy<a id="_idIndexMarker664"/> from each group:
        <pre class="programlisting code-one"><code class="hljs-code">pd.get_dummies(X_demo_train,
  columns=[<span class="hljs-string">'gender'</span>,<span class="hljs-string">'maritalstatus'</span>], dtype=<span class="hljs-built_in">float</span>,
  drop_first=<span class="hljs-literal">True</span>).head(<span class="hljs-number">2</span>).T
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                                 606986           764231
colenroct99           3. 4-year college  1. Not enrolled
gender_Male                           0                1
maritalstatus_Married                 0                1
maritalstatus_Never-married           1                0
maritalstatus_Separated               0                0
maritalstatus_Widowed                 0                0
</code></pre>
      </li>
    </ol>
    <p class="normal-one">An alternative to <code class="inlineCode">get_dummies</code> is the one-hot encoder in either <code class="inlineCode">sklearn</code> or <code class="inlineCode">feature_engine</code>. These one-hot encoders have the advantage that they can be easily brought into a machine learning pipeline, and they can persist information gathered from the training dataset to the testing dataset.</p>
    <ol>
      <li class="numberedList" value="5">Let’s use the <code class="inlineCode">OneHotEncoder</code> from <code class="inlineCode">feature_engine</code> to do the encoding. We set <code class="inlineCode">drop_last</code> to <code class="inlineCode">True</code> to drop one of the dummies from each group. We fit the encoding to the training data and then transform both the training and testing data.
        <pre class="programlisting code-one"><code class="hljs-code">ohe = OneHotEncoder(drop_last=<span class="hljs-literal">True</span>,
  variables=[<span class="hljs-string">'gender'</span>,<span class="hljs-string">'maritalstatus'</span>])
ohe.fit(X_demo_train)
X_demo_train_ohe = ohe.transform(X_demo_train)
X_demo_test_ohe = ohe.transform(X_demo_test)
X_demo_train_ohe.<span class="hljs-built_in">filter</span>(regex=<span class="hljs-string">'gen|mar'</span>, axis=<span class="hljs-string">"columns"</span>).head(<span class="hljs-number">2</span>).T
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                           606986   764231
gender_Female                   1        0
maritalstatus_Never-married     1        0
maritalstatus_Married           0        1
maritalstatus_Divorced          0        0
maritalstatus_Separated         0        0
</code></pre>
      </li>
    </ol>
    <p class="normal">This demonstrates that one-hot encoding is a fairly straightforward way to prepare nominal data for a machine learning algorithm. </p>
    <h2 id="_idParaDest-293" class="heading-2">How it works...</h2>
    <p class="normal">The pandas <code class="inlineCode">get_dummies</code> method<a id="_idIndexMarker665"/> is a handy way to create dummy variables or one-hot encoding. We saw this in <em class="italic">step 3</em> where we simply passed the training DataFrame, and the columns where we want dummy variables, to <code class="inlineCode">get_dummies</code>. Notice that we used <code class="inlineCode">float</code> for <code class="inlineCode">dtype</code>. Depending on your version of pandas, this is necessary to return 0 and 1 values rather than true and false values.</p>
    <p class="normal">We typically need to remove one of the values in a dummy variable group to avoid the <em class="italic">dummy variable trap</em>. We can set <code class="inlineCode">drop_first</code> to <code class="inlineCode">True</code> to drop the first dummy variable from each dummy variable group. We did that in <em class="italic">step 4</em>.</p>
    <p class="normal">We looked at another tool for one-hot encoding, <code class="inlineCode">feature_engine</code>, in <em class="italic">step 5</em>. We are able to accomplish the same task as <code class="inlineCode">get_dummies</code> using <em class="italic">feature_engine’s</em> <code class="inlineCode">OneHotEncoder</code>. The advantage of using <code class="inlineCode">feature_engine</code> is its variety of tools for working within scikit-learn data pipelines, including being able to handle categories in either the training or testing DataFrame, but not in both.</p>
    <h2 id="_idParaDest-294" class="heading-2">There’s more</h2>
    <p class="normal">I did not discuss scikit-learn’s own one-hot encoder in this recipe. It works very much like the one-hot encoder for <code class="inlineCode">feature_engine</code>. There is not much advantage of using one rather than the other, although I find it handy that <code class="inlineCode">feature_engine</code>'s <code class="inlineCode">transform</code> and <code class="inlineCode">fit_transform</code> methods return DataFrames, whereas those methods for scikit-learn return a NumPy array.</p>
    <h1 id="_idParaDest-295" class="heading-1">Encoding categorical features: ordinal encoding</h1>
    <p class="normal">Categorical features<a id="_idIndexMarker666"/> can be either nominal<a id="_idIndexMarker667"/> or ordinal. Gender and marital status are nominal. Their values do not imply order. For example, never married is not a higher value than divorced.</p>
    <p class="normal">When a categorical feature is ordinal, however, we want the encoding to capture the ranking of the values. For example, if we have a feature that has the values low, medium, and high, one-hot encoding would lose this ordering. Instead, a transformed feature with values of 1, 2, and 3 for low, medium, and high, respectively, would be better. We can accomplish this with ordinal encoding.</p>
    <p class="normal">The college enrollment feature on the NLS dataset can be considered an ordinal feature. The values range from <em class="italic">1. Not enrolled</em> to <em class="italic">3. 4-year college</em>. We should use ordinal encoding to prepare it for modeling. We do that next.</p>
    <h2 id="_idParaDest-296" class="heading-2">Getting ready</h2>
    <p class="normal">We will use the <code class="inlineCode">OrdinalEncoder</code> module<a id="_idIndexMarker668"/> in this recipe from <code class="inlineCode">scikit-learn</code>.</p>
    <h2 id="_idParaDest-297" class="heading-2">How to do it...</h2>
    <ol>
      <li class="numberedList" value="1">College enrollment for 1999 might be a good candidate for ordinal encoding. Let’s first take a look at the values of <code class="inlineCode">colenroct99</code> prior to encoding. The values are strings, but there is an implied order:
        <pre class="programlisting code-one"><code class="hljs-code">X_demo_train.colenroct99.\
  sort_values().unique()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">array(['1. Not enrolled', '2. 2-year college ', '3. 4-year college'],
      dtype=object)
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">X_demo_train.head()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">        gender  maritalstatus        colenroct99
606986  Female  Never-married  3. 4-year college
764231    Male        Married    1. Not enrolled
673419    Male  Never-married  3. 4-year college
185535    Male        Married    1. Not enrolled
903011    Male  Never-married    1. Not enrolled
</code></pre>
      </li>
    </ol>
    <p class="normal-one">We need to be careful about assumptions of linearity here. For example, if we are trying to model the impact of the college enrollment feature on some target variable, we cannot assume that movement from 1 to 2 (from not enrolled in college to enrolled for 2 years in college) has the same impact as movement from 2 to 3 (from 2-year college to 4-year college enrollment).</p>
    <ol>
      <li class="numberedList" value="2">We can tell the <code class="inlineCode">OrdinalEncoder</code> to rank the values in the implied order by passing the above array to the <code class="inlineCode">categories</code> parameter. We can then use <code class="inlineCode">fit_transform</code> to transform the college enrollment field <code class="inlineCode">colenroct99</code>. (The <code class="inlineCode">fit_transform</code> method of sklearn’s <code class="inlineCode">OrdinalEncoder</code> returns a NumPy array, so we need to use the pandas DataFrame method to create a DataFrame.) Finally, we join the encoded features with the other features from the training data:
        <pre class="programlisting code-one"><code class="hljs-code">oe = OrdinalEncoder(categories=\
  [X_demo_train.colenroct99.sort_values().\
   unique()])
colenr_enc = \
  pd.DataFrame(oe.fit_transform(X_demo_train[[<span class="hljs-string">'colenroct99'</span>]]),
    columns=[<span class="hljs-string">'colenroct99'</span>], index=X_demo_train.index)
X_demo_train_enc = \
  X_demo_train[[<span class="hljs-string">'gender'</span>,<span class="hljs-string">'maritalstatus'</span>]].\
  join(colenr_enc)
</code></pre>
      </li>
      <li class="numberedList">Let’s view a few observations<a id="_idIndexMarker669"/> from the resulting DataFrame. We should also compare the counts of the original college enrollment feature to the transformed feature:
        <pre class="programlisting code-one"><code class="hljs-code">X_demo_train_enc.head()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">        gender  maritalstatus  colenroct99
606986  Female  Never-married            2
764231    Male        Married            0
673419    Male  Never-married            2
185535    Male        Married            0
903011    Male  Never-married            0
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">X_demo_train.colenroct99.value_counts().\
  sort_index()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">               colenroct99
1. Not enrolled       2843
2. 2-year college      137
3. 4-year college      324
Name: count, dtype: int64
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">X_demo_train_enc.colenroct99.value_counts().\
  sort_index()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">        colenroct99
0              2843
1               137
2               324
Name: count, dtype: int64
</code></pre>
      </li>
    </ol>
    <p class="normal">The ordinal encoding replaces the initial values for <code class="inlineCode">colernoct99</code> with numbers from 0 to 2. It is now in a form that is consumable by many machine learning models, and we have retained the meaningful ranking information.</p>
    <h2 id="_idParaDest-298" class="heading-2">How it works...</h2>
    <p class="normal"><em class="italic">Scitkit-learn’s</em> <code class="inlineCode">OrdinalEncoder</code> is fairly straightforward to use. We passed an array of values to use for the categories that is sorted in a meaningful order. We did this at the start of <em class="italic">step 2</em> when we instantiated an <code class="inlineCode">OrdinalEncoder</code> object. We then passed training data with just the <code class="inlineCode">colenroct99</code> column to the <code class="inlineCode">fit_transform</code> method of the <code class="inlineCode">OrdinalEncoder</code>. We then converted the NumPy array returned by <code class="inlineCode">fit_transform</code> to a DataFrame, using the training data<a id="_idIndexMarker670"/> index, and we used <code class="inlineCode">join</code> to append the rest of the training data.</p>
    <h2 id="_idParaDest-299" class="heading-2">There’s more</h2>
    <p class="normal">Ordinal encoding is appropriate for non-linear models such as decision trees. It might not make sense in a linear regression model because that would assume that the distance between values was equally meaningful along the whole distribution. In this example, that would assume that the increase from 0 to 1 (from no enrollment to 2-year enrollment) is the same thing as the increase from 1 to 2 (from 2-year enrollment to 4-year enrollment).</p>
    <p class="normal">One-hot and ordinal encoding are relatively straightforward approaches to engineering categorical features. It can be more complicated to deal with categorical features when there are many more unique values. We go over a couple of techniques for handling those features in the next section.</p>
    <h1 id="_idParaDest-300" class="heading-1">Encoding categorical features with medium or high cardinality</h1>
    <p class="normal">When we are working<a id="_idIndexMarker671"/> with a categorical feature<a id="_idIndexMarker672"/> that has many unique<a id="_idIndexMarker673"/> values, say 15 or more, it can be impractical<a id="_idIndexMarker674"/> to create a dummy variable for each value. When there is high cardinality, a very large number of unique values, there may be too few observations with certain values to provide much information for our models. At the extreme, with an ID variable, there is just one observation for each value.</p>
    <p class="normal">There are a couple of ways to handle medium or high cardinality. One is to create dummies for the top k categories and group the remaining values into an <em class="italic">other</em> category. Another is to use feature<a id="_idIndexMarker675"/> hashing, also<a id="_idIndexMarker676"/> known<a id="_idIndexMarker677"/> as the hashing trick. We will explore both strategies in this recipe.</p>
    <h2 id="_idParaDest-301" class="heading-2">Getting ready</h2>
    <p class="normal">We continue to use the <code class="inlineCode">OneHotEncoder</code> from <code class="inlineCode">feature_engine</code> in this recipe. We will also use the <code class="inlineCode">HashingEncoder</code> from <code class="inlineCode">category_encoders</code>. We will be working with COVID-19 data in this recipe, which has total cases and deaths by country, as well as demographic data.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Data note</strong></p>
      <p class="normal">Our World in Data provides COVID-19 public use data at <a href="https://ourworldindata.org/covid-cases"><span class="url">https://ourworldindata.org/covid-cases</span></a>. The data used in this recipe was downloaded on March 3, 2024.</p>
    </div>
    <h2 id="_idParaDest-302" class="heading-2">How to do it...</h2>
    <ol>
      <li class="numberedList" value="1">Let’s create training and testing DataFrames from the COVID-19 data, and then import the <code class="inlineCode">feature_engine</code> and <code class="inlineCode">category_encoders</code> libraries:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> feature_engine.encoding <span class="hljs-keyword">import</span> OneHotEncoder
<span class="hljs-keyword">from</span> category_encoders.hashing <span class="hljs-keyword">import</span> HashingEncoder
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
covidtotals = pd.read_csv(<span class="hljs-string">"data/covidtotals.csv"</span>)
feature_cols = [<span class="hljs-string">'location'</span>,<span class="hljs-string">'population'</span>,
    <span class="hljs-string">'aged_65_older'</span>,<span class="hljs-string">'life_expectancy'</span>,<span class="hljs-string">'region'</span>]
covidtotals = covidtotals[[<span class="hljs-string">'total_cases'</span>] + feature_cols].dropna()
X_train, X_test, y_train, y_test =  \
  train_test_split(covidtotals[feature_cols],\
  covidtotals[[<span class="hljs-string">'total_cases'</span>]], test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">0</span>)
</code></pre>
      </li>
    </ol>
    <p class="normal-one">The feature region has 16 unique values, the first 5 of which have counts of 10 or more:</p>
    <pre class="programlisting code-one"><code class="hljs-code">X_train.region.value_counts()
</code></pre>
    <pre class="programlisting con-one"><code class="hljs-con">region
Eastern Europe     15
Western Europe     15
West Asia          12
South America      11
Central Africa     10
East Asia           9
Caribbean           9
Oceania / Aus       9
West Africa         7
Southern Africa     7
Central Asia        6
South Asia          6
East Africa         5
Central America     5
North Africa        4
North America       1
Name: count, dtype: int64
</code></pre>
    <ol>
      <li class="numberedList" value="2">We can use the <code class="inlineCode">OneHotEncoder</code> from <code class="inlineCode">feature_engine</code> again<a id="_idIndexMarker678"/> to encode<a id="_idIndexMarker679"/> the <code class="inlineCode">region</code> feature. This time, we use<a id="_idIndexMarker680"/> the <code class="inlineCode">top_categories</code> parameter <a id="_idIndexMarker681"/>to indicate that we only want to create dummies for the top 6 category values. Any values for <code class="inlineCode">region</code> that do not fall into the top 6 will have a 0 value for all of the dummies:
        <pre class="programlisting code-one"><code class="hljs-code">ohe = OneHotEncoder(top_categories=<span class="hljs-number">6</span>, variables=[<span class="hljs-string">'region'</span>])
covidtotals_ohe = ohe.fit_transform(covidtotals)
covidtotals_ohe.<span class="hljs-built_in">filter</span>(regex=<span class="hljs-string">'location|region'</span>,
  axis=<span class="hljs-string">"columns"</span>).sample(<span class="hljs-number">5</span>, random_state=<span class="hljs-number">2</span>).T
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                              31        157        2     170     78
location                Bulgaria  Palestine  Algeria  Russia  Ghana
region_Eastern Europe          1          0        0       1      0
region_Western Europe          0          0        0       0      0
region_West Africa             0          0        0       0      1
region_West Asia               0          1        0       0      0
region_East Asia               0          0        0       0      0
region_Caribbean               0          0        0       0      0
</code></pre>
      </li>
    </ol>
    <p class="normal-one">An alternative approach to one-hot encoding, when a categorical feature has many<a id="_idIndexMarker682"/> unique values, is to use <strong class="keyWord">feature hashing</strong>.</p>
    <p class="normal-one">Feature hashing maps a large number<a id="_idIndexMarker683"/> of unique feature values to a smaller number of dummy<a id="_idIndexMarker684"/> variables. We can specify the number of dummy variables to create. Each feature value<a id="_idIndexMarker685"/> maps to one and only one dummy variable<a id="_idIndexMarker686"/> combination. However, collisions are possible—that is, some feature values might map to the same dummy variable combination. The number of collisions increases as we decrease the number of requested dummy variables. </p>
    <ol>
      <li class="numberedList" value="3">We can use the <code class="inlineCode">HashingEncoder</code> from <code class="inlineCode">category_encoders</code> to do feature hashing. We use <code class="inlineCode">n_components</code> to indicate that we want 6 dummy variables (we copy the <code class="inlineCode">region</code> feature before we do the transform so that we can compare the original values to the new dummies):
        <pre class="programlisting code-one"><code class="hljs-code">X_train[<span class="hljs-string">'region2'</span>] = X_train.region
he = HashingEncoder(cols=[<span class="hljs-string">'region'</span>], n_components=<span class="hljs-number">6</span>)
X_train_enc = he.fit_transform(X_train)
X_train_enc.\
 groupby([<span class="hljs-string">'col_0'</span>,<span class="hljs-string">'col_1'</span>,<span class="hljs-string">'col_2'</span>,<span class="hljs-string">'col_3'</span>,<span class="hljs-string">'col_4'</span>,
   <span class="hljs-string">'</span><span class="hljs-string">col_5'</span>,<span class="hljs-string">'region2'</span>]).\
 size().reset_index(name=<span class="hljs-string">"count"</span>)
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">   col_0  col_1  col_2  col_3  col_4  col_5          region2  count
0      0      0      0      0      0      1        Caribbean      9
1      0      0      0      0      0      1   Central Africa     10
2      0      0      0      0      0      1      East Africa      5
3      0      0      0      0      0      1     North Africa      4
4      0      0      0      0      1      0  Central America      5
5      0      0      0      0      1      0   Eastern Europe     15
6      0      0      0      0      1      0    North America      1
7      0      0      0      0      1      0    Oceania / Aus      9
8      0      0      0      0      1      0  Southern Africa      7
9      0      0      0      0      1      0        West Asia     12
10     0      0      0      0      1      0   Western Europe     15
11     0      0      0      1      0      0     Central Asia      6
12     0      0      0      1      0      0        East Asia      9
13     0      0      0      1      0      0       South Asia      6
14     0      0      1      0      0      0      West Africa      7
15     1      0      0      0      0      0    South America     11
</code></pre>
      </li>
    </ol>
    <p class="normal">This gives us a large number of collisions, unfortunately. For example, Caribbean, Central Africa, East Africa, and North Africa all get the same dummy variable values. In this case at least, using one-hot encoding and specifying the number of categories, or increasing the number of components for the hashing encoder, would give us better results.</p>
    <h2 id="_idParaDest-303" class="heading-2">How it works...</h2>
    <p class="normal">We used the <code class="inlineCode">OneHotEncoder</code> from <code class="inlineCode">feature_engine</code> in the same way we did in the <em class="italic">Encoding categorical features: one-hot encoding</em> recipe. The difference here is that we limited the dummies to the six regions with the most number of rows (countries in this case). All countries not in one of the top six regions got zeroes for all dummies, such as Algeria in <em class="italic">step 2</em>.</p>
    <p class="normal">In <em class="italic">step 3</em>, we used the <code class="inlineCode">HashingEncoder</code> from <code class="inlineCode">category_encoders</code>. We indicated the column to use, <code class="inlineCode">region</code>, and that we wanted six dummies. We used the <code class="inlineCode">fit_transform</code> method of the <code class="inlineCode">HashingEncoder</code> to fit and transform our data, just as we did with the <code class="inlineCode">OneHotEncoder</code> of <code class="inlineCode">feature_engine</code> and the <code class="inlineCode">OrdinalEncoder</code> of scikit-learn.</p>
    <p class="normal">We have covered common encoding<a id="_idIndexMarker687"/> strategies in the last three<a id="_idIndexMarker688"/> recipes: one-hot<a id="_idIndexMarker689"/> encoding, ordinal<a id="_idIndexMarker690"/> encoding, and feature hashing. Almost all of our categorical features will require some kind of encoding before we can use them in a model. But we sometimes need to alter our features in other ways, including with transformations, binning, and scaling. We consider the reasons why we might need to alter our features in these ways, and explore tools to do that, in the next three recipes.</p>
    <h1 id="_idParaDest-304" class="heading-1">Using mathematical transformations</h1>
    <p class="normal">We sometimes want to use features<a id="_idIndexMarker691"/> that do not have a Gaussian distribution with a machine learning algorithm that assumes our features are distributed in that way. When that happens, we either need to change our minds about which algorithm to use (choose KNN or random forest rather than linear regression, for example) or transform our features so that they approximate a Gaussian distribution. We go over a couple of strategies for doing the latter in this recipe.</p>
    <h2 id="_idParaDest-305" class="heading-2">Getting ready</h2>
    <p class="normal">We will use the transformation module from feature engine in this recipe. We continue to work with the COVID-19 data, which has one row for each country with the total cases and deaths and some demographic data.</p>
    <h2 id="_idParaDest-306" class="heading-2">How to do it...</h2>
    <ol>
      <li class="numberedList" value="1">We start by importing the <code class="inlineCode">transformation</code> module from <code class="inlineCode">feature_engine</code>, <code class="inlineCode">train_test_split</code> from <code class="inlineCode">sklearn</code>, and <code class="inlineCode">stats</code> from <code class="inlineCode">scipy</code>. We also create a training and testing DataFrame with the COVID-19 data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> feature_engine <span class="hljs-keyword">import</span> transformation <span class="hljs-keyword">as</span> vt
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> stats
covidtotals = pd.read_csv(<span class="hljs-string">"data/covidtotals.csv"</span>)
feature_cols = [<span class="hljs-string">'location'</span>,<span class="hljs-string">'population'</span>,
    <span class="hljs-string">'aged_65_older'</span>,<span class="hljs-string">'life_expectancy'</span>,<span class="hljs-string">'region'</span>]
covidtotals = covidtotals[[<span class="hljs-string">'total_cases'</span>] + feature_cols].dropna()
X_train, X_test, y_train, y_test =  \
  train_test_split(covidtotals[feature_cols],\
  covidtotals[[<span class="hljs-string">'</span><span class="hljs-string">total_cases'</span>]], test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">0</span>)
</code></pre>
      </li>
      <li class="numberedList">Let’s take a look at how total cases by country are distributed. We should also calculate the skew:
        <pre class="programlisting code-one"><code class="hljs-code">y_train.total_cases.skew()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">6.092053479609332
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">plt.hist(y_train.total_cases)
plt.title(<span class="hljs-string">"Total COVID-19 Cases (in millions)"</span>)
plt.xlabel(<span class="hljs-string">'Cases'</span>)
plt.ylabel(<span class="hljs-string">"Number of Countries"</span>)￼
plt.show()
</code></pre>
      </li>
    </ol>
    <p class="normal-one">This produces the following<a id="_idIndexMarker692"/> histogram:</p>
    <figure class="mediaobject"><img src="../Images/B18596_08_01.png" alt="" role="presentation"/></figure>
    <p class="packt_figref">Figure 8.1: Histogram of total COVID-19 cases</p>
    <p class="normal-one">This illustrates the very high skew for total cases. It actually looks log-normal, which is not surprising given the large number of very low values and several very high values.</p>
    <ol>
      <li class="numberedList" value="3">Let’s try a log transformation. All we need<a id="_idIndexMarker693"/> to do to get <code class="inlineCode">feature_engine</code> to do the transformation is to call <code class="inlineCode">LogTransformer</code> and pass the feature or features we would like to transform:
        <pre class="programlisting code-one"><code class="hljs-code">tf = vt.LogTransformer(variables = [<span class="hljs-string">'total_cases'</span>])
y_train_tf = tf.fit_transform(y_train)
y_train_tf.total_cases.skew()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">0.09944093918837159
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">plt.hist(y_train_tf.total_cases)
plt.title(<span class="hljs-string">"Total COVID-19 Cases (log transformation)"</span>)
plt.xlabel(<span class="hljs-string">'Cases'</span>)
plt.ylabel(<span class="hljs-string">"Number of Countries"</span>)
plt.show()
</code></pre>
      </li>
    </ol>
    <p class="normal-one">This produces the following histogram:</p>
    <figure class="mediaobject"><img src="../Images/B18596_08_02.png" alt="" role="presentation"/></figure>
    <p class="packt_figref">Figure 8.2: Histogram of total COVID-19 cases with log transformation</p>
    <p class="normal-one">Effectively, log transformations<a id="_idIndexMarker694"/> increase variability at the lower end of the distribution and decrease variability at the upper end. This produces a more symmetrical distribution. This is because the slope of the logarithmic function is steeper for smaller values than for larger ones.</p>
    <ol>
      <li class="numberedList" value="4">This is definitely a big improvement, but let’s also try a Box-Cox transformation to see what results we get:
        <pre class="programlisting code-one"><code class="hljs-code">tf = vt.BoxCoxTransformer(variables = [<span class="hljs-string">'total_cases'</span>])
y_train_tf = tf.fit_transform(y_train)
y_train_tf.total_cases.skew()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">0.010531307863482307
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">plt.hist(y_train_tf.total_cases)
plt.title(<span class="hljs-string">"Total COVID-19 Cases (Box Cox transformation)"</span>)
plt.xlabel(<span class="hljs-string">'Cases'</span>)
plt.ylabel(<span class="hljs-string">"Number of Countries"</span>)
plt.show()
</code></pre>
      </li>
    </ol>
    <p class="normal-one">This produces the following histogram:</p>
    <figure class="mediaobject"><img src="../Images/B18596_08_03.png" alt="" role="presentation"/></figure>
    <p class="packt_figref">Figure 8.3: Histogram of total COVID-19 cases with a Box-Cox transformation</p>
    <p class="normal-one">Box-Cox transformations<a id="_idIndexMarker695"/> identify a value for lambda between -5 and 5 that generates a distribution that is closest to normal. It uses the following equation for the transformation:</p>
    <p class="center"><img src="../Images/B18596_08_001.png" alt="" role="presentation"/></p>
    <p class="center">or</p>
    <p class="center"><img src="../Images/B18596_08_002.png" alt="" role="presentation"/></p>
    <p class="normal">Where <img src="../Images/B18596_08_003.png" alt="" role="presentation"/> is our transformed feature. Just for fun, let’s see the value of lambda that was used to transform <code class="inlineCode">total_cases</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">stats.boxcox(y_train.total_cases)[<span class="hljs-number">1</span>]
</code></pre>
    <pre class="programlisting con"><code class="hljs-con">-0.020442184436288167
</code></pre>
    <p class="normal">The lambda for the Box-Cox transformation is -0.02. For comparison, the lambda for a feature with a Gaussian distribution would be 1.000, meaning that no transformation would be necessary.</p>
    <h2 id="_idParaDest-307" class="heading-2">How it works...</h2>
    <p class="normal">Many of our research or modeling projects require some transformation of features or target variables for us to produce good results. Tools like <em class="italic">feature engine</em> make it easy for us to incorporate such transformations in our data preparation process. We imported the <code class="inlineCode">transformation</code> module in <em class="italic">step 1</em>, and then we used it to do a log transformation in <em class="italic">step 3</em> and a Box-Cox transformation in <em class="italic">step 4</em>.</p>
    <p class="normal">The transformed total cases feature looked good after the log and Box-Cox transformations. This will likely be an easier target to model. It is also easy to integrate this transformation with a pipeline with other preprocessing steps. <code class="inlineCode">Feature_engine</code> has a number of other transformations<a id="_idIndexMarker696"/> that are implemented similarly to the log and Box-Cox transformations.</p>
    <h2 id="_idParaDest-308" class="heading-2">See also</h2>
    <p class="normal">You may be wondering how we make predictions or evaluate a model with a transformed target. It is actually fairly straightforward to set up our pipeline to restore values to their original values when we make predictions. I go over this in detail in my book <em class="italic">Data Cleaning and Exploration with Machine Learning</em>.</p>
    <h1 id="_idParaDest-309" class="heading-1">Feature binning: equal width and equal frequency</h1>
    <p class="normal">We sometimes want <a id="_idIndexMarker697"/>to convert a feature from continuous to categorical. The process of creating <em class="italic">k</em> equally spaced intervals from the minimum<a id="_idIndexMarker698"/> to the maximum value<a id="_idIndexMarker699"/> of a distribution is called <strong class="keyWord">binning</strong>, or the somewhat less friendly <strong class="keyWord">discretization</strong>. Binning can address several important issues with<a id="_idIndexMarker700"/> a feature: skew, excessive<a id="_idIndexMarker701"/> kurtosis, and the presence of outliers.</p>
    <h2 id="_idParaDest-310" class="heading-2">Getting ready</h2>
    <p class="normal">Binning might be a good choice with the COVID-19 total cases data. It might also be useful with other variables in the dataset, including total deaths and population, but we will only work with total cases for now. <code class="inlineCode">total_cases</code> is the target variable in the following code, so it is a column—the only column—on the <code class="inlineCode">y_train</code> DataFrame.</p>
    <p class="normal">Let’s try equal width and equal frequency binning with the COVID-19 data.</p>
    <h2 id="_idParaDest-311" class="heading-2">How to do it...</h2>
    <ol>
      <li class="numberedList" value="1">We first need to import the <code class="inlineCode">EqualFrequencyDiscretiser</code> and <code class="inlineCode">EqualWidthDiscretiser</code> from <code class="inlineCode">feature_engine</code>. We also need to create training and testing DataFrames from the COVID-19 data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> feature_engine.discretisation <span class="hljs-keyword">import</span> EqualFrequencyDiscretiser <span class="hljs-keyword">as</span> efd
<span class="hljs-keyword">from</span> feature_engine.discretisation <span class="hljs-keyword">import</span> EqualWidthDiscretiser <span class="hljs-keyword">as</span> ewd
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> KBinsDiscretizer
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
covidtotals = pd.read_csv(<span class="hljs-string">"data/covidtotals.csv"</span>)
feature_cols = [<span class="hljs-string">'location'</span>,<span class="hljs-string">'population'</span>,
    <span class="hljs-string">'aged_65_older'</span>,<span class="hljs-string">'life_expectancy'</span>,<span class="hljs-string">'region'</span>]
covidtotals = covidtotals[[<span class="hljs-string">'total_cases'</span>] + feature_cols].dropna()
X_train, X_test, y_train, y_test =  \
  train_test_split(covidtotals[feature_cols],\
  covidtotals[[<span class="hljs-string">'total_cases'</span>]], test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">0</span>)
</code></pre>
      </li>
      <li class="numberedList">We can use the pandas <code class="inlineCode">qcut</code> method, and its<a id="_idIndexMarker702"/> <code class="inlineCode">q</code> parameter, to create 10 bins<a id="_idIndexMarker703"/> of relatively equal<a id="_idIndexMarker704"/> frequency:
        <pre class="programlisting code-one"><code class="hljs-code">y_train[<span class="hljs-string">'total_cases_group'</span>] = \
  pd.qcut(y_train.total_cases, q=<span class="hljs-number">10</span>,
  labels=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>])
y_train.total_cases_group.value_counts().\
  sort_index()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">    total_cases_group
0    14
1    13
2    13
3    13
4    13
5    13
6    13
7    13
8    13
9    13
Name: count, dtype: int64
</code></pre>
      </li>
      <li class="numberedList">We can accomplish the same thing with the <code class="inlineCode">EqualFrequencyDiscretiser</code>. First, we define a function to run the transformation. The function takes a <code class="inlineCode">feature_engine</code> transformation and the training and testing DataFrames. It returns the transformed DataFrames (it is not necessary to define a function, but it makes sense here, since we will repeat these steps later in this recipe):
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">runtransform</span>(<span class="hljs-params">bt, dftrain, dftest</span>):
  bt.fit(dftrain)
  train_bins = bt.transform(dftrain)
  test_bins = bt.transform(dftest)
  <span class="hljs-keyword">return</span> train_bins, test_bins
</code></pre>
      </li>
      <li class="numberedList">Next, we create<a id="_idIndexMarker705"/> an <code class="inlineCode">EqualFrequencyDiscretiser</code> transformer <a id="_idIndexMarker706"/>and call the <code class="inlineCode">runtransform</code> function<a id="_idIndexMarker707"/> we just created:
        <pre class="programlisting code-one"><code class="hljs-code">y_train.drop([<span class="hljs-string">'total_cases_group'</span>], axis=<span class="hljs-number">1</span>, inplace=<span class="hljs-literal">True</span>)
bintransformer = efd(q=<span class="hljs-number">10</span>, variables=[<span class="hljs-string">'total_cases'</span>])
y_train_bins, y_test_bins = runtransform(bintransformer, y_train, y_test)
y_train_bins.total_cases.value_counts().sort_index()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">     total_cases
0    14
1    13
2    13
3    13
4    13
5    13
6    13
7    13
8    13
9    13
Name: count, dtype: int64
</code></pre>
      </li>
    </ol>
    <p class="normal-one">This gives us the same results as <code class="inlineCode">qcut</code>, but it has the advantage that it is easier to bring into a machine learning pipeline, since we are using <code class="inlineCode">feature_engine</code> to produce it. The equal frequency binning addresses both the skew and outlier problems.</p>
    <ol>
      <li class="numberedList" value="5">The <code class="inlineCode">EqualWidthDiscretiser</code> works similarly:
        <pre class="programlisting code-one"><code class="hljs-code">bintransformer = ewd(bins=<span class="hljs-number">10</span>, variables=[<span class="hljs-string">'total_cases'</span>])
y_train_bins, y_test_bins = runtransform(bintransformer, y_train, y_test)
y_train_bins.total_cases.value_counts().sort_index()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">     total_cases
0    122
1      2
2      3
3      2
4      1
9      1
Name: count, dtype: int64
</code></pre>
      </li>
    </ol>
    <p class="normal-one">This is a far less successful transformation. Almost all of the values are at the bottom of the distribution in the data prior to the binning, so it is not surprising that equal width binning would have the same problem. It results in only 6 bins, despite the fact that we have requested 10.</p>
    <ol>
      <li class="numberedList" value="6">Let’s examine the range of each bin. We can see here that the equal width binner is not even able to construct equal width bins because of the small number of observations at the top of the distribution:
        <pre class="programlisting code-one"><code class="hljs-code">y_train_bins = y_train_bins.\
  rename(columns={<span class="hljs-string">'total_cases'</span>:<span class="hljs-string">'total_cases_group'</span>}).\
  join(y_train)
y_train_bins.groupby(<span class="hljs-string">"total_cases_group"</span>)[<span class="hljs-string">"total_cases"</span>].\
  agg([<span class="hljs-string">'min'</span>,<span class="hljs-string">'max'</span>])
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                         min           max
total_cases_group                     
0                      5,085     8,633,769
1                 11,624,000    13,980,340
2                 23,774,451    26,699,442
3                 37,519,960    38,437,756
4                 45,026,139    45,026,139
9                 99,329,249    99,329,249
</code></pre>
      </li>
    </ol>
    <p class="normal">Although equal width binning<a id="_idIndexMarker708"/> was a bad choice<a id="_idIndexMarker709"/> in this case, there are many<a id="_idIndexMarker710"/> times when it makes sense. It can be useful when data is more uniformly distributed, or when the equal widths make sense substantively.</p>
    <h1 id="_idParaDest-312" class="heading-1">k-means binning</h1>
    <p class="normal">Another option is to use <em class="italic">k</em>-means clustering<a id="_idIndexMarker711"/> to determine the bins. The <em class="italic">k</em>-means algorithm randomly selects <em class="italic">k</em> data points as centers of clusters, and then it assigns the other data points to the closest cluster. The mean of each cluster is computed, and the data points are reassigned to the nearest new cluster. This process is repeated until the optimal centers are found.</p>
    <p class="normal">When <em class="italic">k</em>-means is used for binning, all data points<a id="_idIndexMarker712"/> in the same cluster will have the same ordinal value.</p>
    <h2 id="_idParaDest-313" class="heading-2">Getting ready</h2>
    <p class="normal">We will use scikit-learn this time for our binning. <em class="italic">Scitkit-learn</em> has a great tool for creating bins based on <em class="italic">k</em>-means, <code class="inlineCode">KBinsDiscretizer</code>.</p>
    <h2 id="_idParaDest-314" class="heading-2">How to do it...</h2>
    <ol>
      <li class="numberedList" value="1">We start by instantiating a <code class="inlineCode">KBinsDiscretizer</code> object. We will use it to create bins with the COVID-19 cases data:
        <pre class="programlisting code-one"><code class="hljs-code">kbins = KBinsDiscretizer(n_bins=<span class="hljs-number">10</span>, encode=<span class="hljs-string">'ordinal'</span>,
  strategy=<span class="hljs-string">'kmeans'</span>, subsample=<span class="hljs-literal">None</span>)
y_train_bins = \
  pd.DataFrame(kbins.fit_transform(y_train),
  columns=[<span class="hljs-string">'total_cases'</span>], index=y_train.index)
y_train_bins.total_cases.value_counts().sort_index()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">     total_cases
0    57
1    19
2    25
3    10
4    11
5     2
6     3
7     2
8     1
9     1
Name: count, dtype: int64
</code></pre>
      </li>
      <li class="numberedList">Let’s compare the skew and kurtosis of the original total cases variable to that of the binned variable. Recall that we would expect a skew of 0 and a kurtosis near 3 for a variable with a Gaussian distribution. The distribution of the binned variable is much closer to Gaussian:
        <pre class="programlisting code-one"><code class="hljs-code">y_train.total_cases.agg([<span class="hljs-string">'skew'</span>,<span class="hljs-string">'kurtosis'</span>])
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">skew        6.092
kurtosis   45.407
Name: total_cases, dtype: float64
</code></pre>
        <pre class="programlisting code-one"><code class="hljs-code">y_train_bins.total_cases.agg([<span class="hljs-string">'skew'</span>,<span class="hljs-string">'kurtosis'</span>])
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">skew       1.504
kurtosis   2.281
Name: total_cases, dtype: float64
</code></pre>
      </li>
      <li class="numberedList">Let’s take a closer look at the range<a id="_idIndexMarker713"/> of total cases values in each bin. The first bin goes up to 272,010 total cases, and the next goes up to 834,470. There is a fair bit of drop-off in terms of the number of countries after about 8.6 million total cases. We might consider reducing the number of bins to 5 or 6:
        <pre class="programlisting code-one"><code class="hljs-code">y_train_bins.rename(columns={<span class="hljs-string">'total_cases'</span>:<span class="hljs-string">'total_cases_bin'</span>}, inplace=<span class="hljs-literal">True</span>)
y_train.join(y_train_bins).\
  groupby([<span class="hljs-string">'total_cases_bin'</span>])[<span class="hljs-string">'total_cases'</span>].\
  agg([<span class="hljs-string">'min'</span>,<span class="hljs-string">'</span><span class="hljs-string">max'</span>,<span class="hljs-string">'size'</span>])
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">                       min        max  size
total_cases_bin                           
0                    5,085    272,010    57
1                  330,417    834,470    19
2                  994,037  2,229,538    25
3                2,465,545  4,536,733    10
4                5,269,967  8,633,769    11
5               11,624,000 13,980,340     2
6               23,774,451 26,699,442     3
7               37,519,960 38,437,756     2
8               45,026,139 45,026,139     1
9               99,329,249 99,329,249     1
</code></pre>
      </li>
    </ol>
    <p class="normal">These steps demonstrate how to use <em class="italic">k</em>-means for binning.</p>
    <h2 id="_idParaDest-315" class="heading-2">How it works...</h2>
    <p class="normal">All we need to run <em class="italic">k</em>-means binning is to instantiate a <code class="inlineCode">KBinsDiscretizer</code> object. We indicated the number of bins we wanted, <code class="inlineCode">10</code>, and that we wanted the bins to be <code class="inlineCode">ordinal</code>. We specified <code class="inlineCode">ordinal</code> because we want higher bin values to reflect higher total cases values. We converted the NumPy array returned from the scikit-learn <code class="inlineCode">fit_transform</code> into a DataFrame. This is often not necessary in a data pipeline, but we did it here because we will use the DataFrame in subsequent steps.</p>
    <p class="normal">Binning can help us address skew, kurtosis, and outliers in our data. It does, however, mask much of the variation in the feature and reduces its explanatory potential. Often, some form<a id="_idIndexMarker714"/> of scaling, such as min-max or z-score, is a better option. Let’s examine feature scaling in the next recipe.</p>
    <h1 id="_idParaDest-316" class="heading-1">Feature scaling</h1>
    <p class="normal">Often, the features we want<a id="_idIndexMarker715"/> to use in our model are on very different scales. Put another way, the distance between the min and max values, or the range, varies substantially across possible features. In the COVID-19 data for example, the <code class="inlineCode">total cases</code> feature goes from 5,000 to almost 100 million, while <code class="inlineCode">aged 65 or older</code> goes from 9 to 27 (the number represents the percent of population).</p>
    <p class="normal">Having features on very different scales impacts many machine learning algorithms. For example, KNN models often use Euclidean distance, and features with greater ranges will have greater influence on the model. Scaling can address this problem.</p>
    <p class="normal">We will go over two popular<a id="_idIndexMarker716"/> approaches to scaling<a id="_idIndexMarker717"/> in this section: <strong class="keyWord">min-max scaling</strong> and <strong class="keyWord">standard</strong> (or <strong class="keyWord">z-score</strong>) scaling. Min-max scaling replaces each value with its location in the range. More precisely:</p>
    <p class="center"><img src="../Images/B18596_08_004.png" alt="" role="presentation"/></p>
    <p class="normal">Here, <em class="italic">z</em><sub class="subscript-italic" style="font-style: italic;">ij</sub> is the min-max score, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">ij</sub> is the value for the <em class="italic">i</em><sup class="superscript">th</sup> observation of the <em class="italic">j</em><sup class="superscript-italic" style="font-style: italic;">th</sup> feature, and <em class="italic">min</em><sub class="subscript-italic" style="font-style: italic;">j</sub> and <em class="italic">max</em><sub class="subscript-italic" style="font-style: italic;">j</sub> are the min and max values of the <em class="italic">j</em><sup class="superscript-italic" style="font-style: italic;">th</sup> feature.</p>
    <p class="normal">Standard scaling normalizes the feature values around a mean of 0. Those who studied undergraduate statistics will recognize it as the z-score. Specifically:</p>
    <p class="center"><img src="../Images/B18596_08_005.png" alt="" role="presentation"/></p>
    <p class="normal">Here, <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">ij</sub> is the value for the <em class="italic">i</em><sup class="superscript">th</sup> observation of the <em class="italic">j</em><sup class="superscript-italic" style="font-style: italic;">th</sup> feature, <em class="italic">u</em><sub class="subscript-italic" style="font-style: italic;">j</sub> is the mean for feature <em class="italic">j</em>, and <em class="italic">s</em><sub class="subscript-italic" style="font-style: italic;">j</sub> is the standard deviation for that feature.</p>
    <h2 id="_idParaDest-317" class="heading-2">Getting ready</h2>
    <p class="normal">We will use scikit-learn’s preprocessing module for all of the transformations in this recipe. We will work with the COVID-19 data again.</p>
    <h2 id="_idParaDest-318" class="heading-2">How to do it...</h2>
    <p class="normal">We can use scikit-learn’s preprocessing module to get the min-max and standard scalers:</p>
    <ol>
      <li class="numberedList" value="1">We start by importing the <code class="inlineCode">preprocessing</code> module and creating training and testing DataFrames from the COVID-19 data:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MinMaxScaler, StandardScaler, RobustScaler
covidtotals = pd.read_csv(<span class="hljs-string">"</span><span class="hljs-string">data/covidtotals.csv"</span>)
feature_cols = [<span class="hljs-string">'population'</span>,<span class="hljs-string">'total_deaths'</span>,
    <span class="hljs-string">'aged_65_older'</span>,<span class="hljs-string">'life_expectancy'</span>]
covidtotals = covidtotals[[<span class="hljs-string">'total_cases'</span>] + feature_cols].dropna()
X_train, X_test, y_train, y_test =  \
  train_test_split(covidtotals[feature_cols],\
  covidtotals[[<span class="hljs-string">'total_cases'</span>]], test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">0</span>)
</code></pre>
      </li>
      <li class="numberedList">We can now run the min-max<a id="_idIndexMarker718"/> scaler. As we have done in previous recipes when working with the scikit-learn <code class="inlineCode">fit_transform</code>, we convert the NumPy array so that it returns to a DataFrame using the columns and index from the training DataFrame. Notice that all features now have values between 0 and 1:
        <pre class="programlisting code-one"><code class="hljs-code">scaler = MinMaxScaler()
X_train_mms = pd.DataFrame(scaler.fit_transform(X_train),
  columns=X_train.columns, index=X_train.index)
X_train_mms.describe()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">           population  total_deaths  aged_65_older  life_expectancy
count          131.00        131.00         131.00           131.00
mean             0.03          0.05           0.34             0.65
std              0.13          0.14           0.28             0.23
min              0.00          0.00           0.00             0.00
25%              0.00          0.00           0.11             0.54
50%              0.01          0.01           0.24             0.69
75%              0.02          0.03           0.60             0.81
max              1.00          1.00           1.00             1.00
</code></pre>
      </li>
      <li class="numberedList">We run the standard scaler in the same manner:
        <pre class="programlisting code-one"><code class="hljs-code">scaler = StandardScaler()
X_train_ss = pd.DataFrame(scaler.fit_transform(X_train),
  columns=X_train.columns, index=X_train.index)
X_train_ss.describe()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">          population  total_deaths  aged_65_older  life_expectancy
count         131.00        131.00         131.00           131.00
mean           -0.00         -0.00          -0.00             0.00
std             1.00          1.00           1.00             1.00
min            -0.28         -0.39          -1.24            -2.79
25%            -0.26         -0.38          -0.84            -0.48
50%            -0.22         -0.34          -0.39             0.18
75%            -0.09         -0.15           0.93             0.67
max             7.74          6.95           2.37             1.51
</code></pre>
      </li>
    </ol>
    <p class="normal-one">If we have outliers<a id="_idIndexMarker719"/> in our data, robust scaling might be a good option. Robust scaling subtracts the median from each value of a variable and divides that value by the interquartile range. So, each value is:</p>
    <p class="center"><img src="../Images/B18596_08_006.png" alt="" role="presentation"/></p>
    <p class="normal-one">Where <img src="../Images/B18596_08_007.png" alt="" role="presentation"/> is the value for the <em class="italic">j</em><sup class="superscript-italic" style="font-style: italic;">th</sup> feature, and <em class="italic">median</em><sub class="subscript-italic" style="font-style: italic;">j</sub>, 3<sup class="superscript-italic" style="font-style: italic;">rd</sup> <em class="italic">quantile</em><sub class="subscript-italic" style="font-style: italic;">j</sub>, and 1<sup class="superscript-italic" style="font-style: italic;">st</sup> <em class="italic">quantile</em><sub class="subscript-italic" style="font-style: italic;">j</sub>, are the median, third, and first quantile of the <em class="italic">j</em><sup class="superscript-italic" style="font-style: italic;">th</sup> feature, respectively. Robust scaling is less sensitive to extreme values, since it does not use the mean or variance.</p>
    <ol>
      <li class="numberedList" value="4">We can use scikit-learn’s <code class="inlineCode">RobustScaler</code> module to do robust scaling:
        <pre class="programlisting code-one"><code class="hljs-code">scaler = RobustScaler()
X_train_rs = pd.DataFrame(scaler.fit_transform(X_train),
  columns=X_train.columns, index=X_train.index)
X_train_rs.describe()
</code></pre>
        <pre class="programlisting con-one"><code class="hljs-con">          population    total_deaths    aged_65_older    life_expectancy
count         131.00          131.00           131.00             131.00
mean            1.29            1.51             0.22              -0.16
std             5.81            4.44             0.57               0.87
min            -0.30           -0.20            -0.48              -2.57
25%            -0.22           -0.16            -0.26              -0.58
50%             0.00            0.00             0.00               0.00
75%             0.78            0.84             0.74               0.42
max            46.09           32.28             1.56               1.15
</code></pre>
      </li>
    </ol>
    <p class="normal">The previous steps demonstrate three popular scaling transformations, standard scaling, min-max scaling, and robust scaling.</p>
    <h2 id="_idParaDest-319" class="heading-2">How it works...</h2>
    <p class="normal">We use feature scaling with most machine learning algorithms. Although it is not often required, it yields noticeably better results. Min-max scaling and standard scaling are popular scaling techniques, but there are times when robust scaling might be the better option.</p>
    <p class="normal"><em class="italic">Scitkit-learn’s</em> <code class="inlineCode">preprocessing</code> module makes it easy to use a variety of scaling transformations. We just need to instantiate<a id="_idIndexMarker720"/> the scaler and then run the <code class="inlineCode">fit</code>, <code class="inlineCode">transform</code>, or <code class="inlineCode">fit_transform</code> method.</p>
    <h1 id="_idParaDest-320" class="heading-1">Summary</h1>
    <p class="normal">We have covered a wide range of feature engineering techniques in this chapter. We used tools to drop redundant or highly correlated features. We explored the most common kinds of encoding—one-hot, ordinal, and hashing encoding. We then used transformations to improve the distribution of our features. Finally, we used common binning and scaling approaches to address skew, kurtosis, and outliers, and to adjust for features with widely different ranges. In the next chapter, we’ll learn how to fix messy data when aggregating.</p>
    <h1 class="heading-1">Leave a review!</h1>
    <p class="normal">Enjoying this book? Help readers like you by leaving an Amazon review. Scan the QR code below to get a free eBook of your choice.</p>
    <p class="normal"><img src="../Images/Review_copy.png" style="width:10em" alt="" role="presentation"/></p>
  </div>
</body></html>