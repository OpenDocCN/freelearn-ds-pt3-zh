- en: Chapter 9. Numerical Optimization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章 数值优化
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Finding the root of a mathematical function
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找数学函数的根
- en: Minimizing a mathematical function
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小化数学函数
- en: Fitting a function to data with nonlinear least squares
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用非线性最小二乘法拟合数据
- en: Finding the equilibrium state of a physical system by minimizing its potential
    energy
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过最小化潜在能量找到物理系统的平衡状态
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: '**Mathematical optimization** is a wide area of applied mathematics. It consists
    of finding the best solution to a given problem. Many real-world problems can
    be expressed in an optimization framework. What is the shortest path on the road
    from point A to point B? What is the best strategy to solve a puzzle? What is
    the most energy-efficient shape of a car (automotive aerodynamics)? Mathematical
    optimization is relevant in many domains including engineering, economics, finance,
    operations research, image processing, data analysis, and others.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**数学优化**是应用数学的一个广泛领域，它涉及到寻找给定问题的最佳解。许多现实世界的问题可以用优化框架来表示。比如，从A点到B点的最短路径是什么？解决一个难题的最佳策略是什么？汽车的最节能形状是什么（汽车空气动力学）？数学优化在许多领域都有应用，包括工程学、经济学、金融学、运筹学、图像处理、数据分析等。'
- en: Mathematically, an optimization problem generally consists of finding the maximum
    or minimum value of a function. We sometimes use the terms **continuous optimization**
    or **discrete optimization**, according to whether the function variable is real-valued
    or discrete.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学角度看，优化问题通常包括找到一个函数的最大值或最小值。根据函数变量是实值的还是离散的，我们有时会使用**连续优化**或**离散优化**这两个术语。
- en: In this chapter, we will focus on numerical methods for solving continuous optimization
    problems. Many optimization algorithms are implemented in the `scipy.optimize`
    module. We will come across other instances of optimization problems in several
    other chapters of this book. For example, we will see discrete optimization problems
    in [Chapter 14](ch14.html "Chapter 14. Graphs, Geometry, and Geographic Information
    Systems"), *Graphs, Geometry, and Geographic Information Systems*. In this introduction,
    we will give a few important definitions and key concepts related to mathematical
    optimization.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点讨论解决连续优化问题的数值方法。许多优化算法都在`scipy.optimize`模块中实现。我们将在本书的其他几章中遇到其他类型的优化问题。例如，我们将在[第14章](ch14.html
    "第14章 图形、几何学与地理信息系统")中看到离散优化问题，*图形、几何学与地理信息系统*。在本引言中，我们将介绍一些与数学优化相关的重要定义和关键概念。
- en: The objective function
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目标函数
- en: We will study methods to find a root or an **extremum** of a real-valued function
    *f* called the **objective function**. An extremum is either a maximum or a minimum
    of a function. This mathematical function is generally implemented in a Python
    function. It can accept one or several variables, it can be continuous or not,
    and so on. The more assumptions we have about the function, the easier it can
    be optimized.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究找到实值函数*f*的根或**极值**的方法，称为**目标函数**。极值可以是函数的最大值或最小值。这个数学函数通常在Python函数中实现。它可以接受一个或多个变量，可以是连续的或不连续的，等等。我们对函数的假设越多，优化起来就越容易。
- en: Note
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: A maximum of *f* is a minimum of *-f*, so any minimization algorithm can be
    used to maximize a function by considering the *opposite* of that function. Therefore,
    from now on, when we talk about *minimization*, we will really mean *minimization
    or maximization*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*f*的最大值即为*-f*的最小值，因此任何最小化算法都可以通过考虑该函数的*对立面*来实现函数的最大化。因此，从现在开始，当我们谈论*最小化*时，实际上指的是*最小化或最大化*。'
- en: '**Convex functions** are generally easier to optimize than non-convex functions,
    as they satisfy certain useful properties. For example, any local minimum is necessarily
    a global minimum. The field of **convex optimization** deals with algorithms that
    are specifically adapted to the optimization of convex functions on convex domains.
    Convex optimization is an advanced topic, and we can''t cover much of it here.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**凸函数**通常比非凸函数更容易优化，因为它们满足某些有用的性质。例如，任何局部最小值必然是全局最小值。**凸优化**领域处理的是专门用于优化凸函数在凸领域上算法的研究。凸优化是一个高级主题，我们在这里不能深入讨论。'
- en: '**Differentiable functions** have gradients, and these gradients can be particularly
    useful in optimization algorithms. Similarly, **continuous functions** are typically
    easier to optimize than non-continuous functions.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Also, functions with a single variable are easier to optimize than functions
    with multiple variables.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: The choice of the most adequate optimization algorithm depends on the properties
    satisfied by the objective function.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Local and global minima
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **minimum** of a function *f* is a point x[0] such that *f(x)* ![Local and
    global minima](img/4818OS_09_22.jpg) *f(x[0]**)*, for a particular set of points
    *x* in *E*. When this inequality is satisfied on the whole set *E*, we refer to
    *x[0]* as a **global minimum**. When it is only satisfied locally (around the
    point *x[0]*), we say that *x[0]* is a **local minimum**. A **maximum** is defined
    similarly.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'If *f* is differentiable, an extremum *x[0]* satisfies:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '![Local and global minima](img/4818OS_09_01.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
- en: Therefore, finding the extrema of an objective function is closely related to
    finding the roots of the derivative. However, a point x[0] satisfying this property
    is not necessarily an extremum.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: It is more difficult to find global minima than to find local minima. In general,
    when an algorithm finds a local minimum, there is no guarantee that it is also
    a global minimum. Frequently, an algorithm seeking a global minimum stays *stuck*
    in a local minimum. This problem needs to be accounted for, specifically in global
    minimization algorithms. However, things are simpler with convex functions since
    these do not have strictly local minima. Moreover, there are many cases where
    finding a local minimum is good enough (for example, when looking for a good solution
    to a problem rather than the absolute best solution). Finally, let's note that
    a global minimum or maximum does not necessarily exist (the function can go to
    infinity). In that case, it may be necessary to constrain the space search; this
    is the subject of **constrained optimization**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '![Local and global minima](img/4818OS_09_02.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
- en: Local and global extrema
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Constrained and unconstrained optimization
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Unconstrained optimization**: Finding the minimum of a function *f* on the
    full set *E* where *f* is defined'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Constrained optimization**: Finding the minimum of a function *f* on a subset
    *E''* of *E*; this set is generally described by equalities and inequalities:![Constrained
    and unconstrained optimization](img/4818OS_09_03.jpg)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, the *g[i]* and *h[j]* are arbitrary functions defining the constraints.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For example, optimizing the aerodynamic shape of a car requires constraints
    on parameters such as the volume and mass of the car, the cost of the production
    process, and others.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Constrained optimization is generally harder than unconstrained optimization.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Deterministic and stochastic algorithms
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some global optimization algorithms are **deterministic**, others are **stochastic**.
    Typically, deterministic methods are adapted to well-behaved functions, whereas
    stochastic methods may be useful with highly irregular and noisy functions.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: The reason is that deterministic algorithms may be stuck in local minima, particularly
    if there are many non-global local minima. By spending some time exploring the
    space *E*, stochastic algorithms may have a chance of finding a global minimum.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The SciPy lecture notes are an excellent reference on mathematical optimization
    with SciPy and are available at [http://scipy-lectures.github.io/advanced/mathematical_optimization/index.html](http://scipy-lectures.github.io/advanced/mathematical_optimization/index.html)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reference manual of `scipy.optimize` available at [http://docs.scipy.org/doc/scipy/reference/optimize.html](http://docs.scipy.org/doc/scipy/reference/optimize.html)
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overview of mathematical optimization on Wikipedia, available at [http://en.wikipedia.org/wiki/Mathematical_optimization](http://en.wikipedia.org/wiki/Mathematical_optimization)
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extrema, minima, and maxima on Wikipedia, available at [http://en.wikipedia.org/wiki/Maxima_and_minima](http://en.wikipedia.org/wiki/Maxima_and_minima)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convex optimization on Wikipedia, available at [http://en.wikipedia.org/wiki/Convex_optimization](http://en.wikipedia.org/wiki/Convex_optimization)
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced optimization methods for image processing by Gabriel Peyré, available
    at [http://github.com/gpeyre/numerical-tours](http://github.com/gpeyre/numerical-tours)
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the root of a mathematical function
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this short recipe, we will see how to use SciPy to find the root of a simple
    mathematical function of a single real variable.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s import NumPy, SciPy, `scipy.optimize`, and matplotlib:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We define the mathematical function *f(x)=cos(x)-x* in Python. We will try
    to find a root of this function numerically. Here, a root corresponds to a fixed
    point of the cosine function:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s plot this function on the interval *[-5, 5]* (using 1000 samples):'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![How to do it…](img/4818OS_09_04.jpg)'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'We see that this function has a unique root on this interval (this is because
    the function''s sign changes on this interval). The `scipy.optimize` module contains
    a few root-finding functions that are adapted here. For example, the `bisect()`
    function implements the **bisection method** (also called the **dichotomy method**).
    It takes as input the function and the interval to find the root in:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let''s visualize the root on the plot:'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![How to do it…](img/4818OS_09_05.jpg)'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'A faster and more powerful method is `brentq()` (**Brent''s method**). This
    algorithm also requires *f* to be continuous and *f(a)* and *f(b)* to have different
    signs:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `brentq()` method is faster than `bisect()`. If the conditions are satisfied,
    it is a good idea to try Brent''s method first:'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: How it works…
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bisection method consists of iteratively cutting an interval in half and
    selecting a subinterval that necessarily contains a root. This method is based
    on the fact that, if *f* is a continuous function of a single real variable, *f(a)>0*,
    and *f(b)<0*, then *f* has a root in *(a,b)* (**intermediate value theorem**).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 二分法通过反复将区间一分为二，选择一个必定包含根的子区间来进行。该方法基于这样一个事实：如果 *f* 是一个单一实变量的连续函数，且 *f(a)>0*
    且 *f(b)<0*，则 *f* 在 *(a,b)* 区间内必有根（**中值定理**）。
- en: '**Brent''s method** is a popular hybrid algorithm combining root bracketing,
    interval bisection, and inverse quadratic interpolation. It is a default method
    that works in many cases.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**Brent 方法** 是一种流行的混合算法，结合了根的括起来、区间二分法和反向二次插值。它是一个默认方法，在许多情况下都能工作。'
- en: Let's also mention **Newton's method**. The idea is to approximate *f(x)* by
    its tangent (found with *f'(x)*) and find the intersection with the *y=0* line.
    If *f* is regular enough, the intersection point will be closer to the actual
    root of *f*. By iterating this operation, the algorithm generally converges to
    the sought solution.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也提一下**牛顿法**。其基本思想是通过切线近似 *f(x)*（由 *f'(x)* 求得），然后找到与 *y=0* 线的交点。如果 *f* 足够规则，那么交点会更接近
    *f* 的实际根。通过反复执行此操作，算法通常会收敛到所寻求的解。
- en: There's more…
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'Here are a few references:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一些参考文献：
- en: Documentation of `scipy.optimize` available at [http://docs.scipy.org/doc/scipy/reference/optimize.html#root-finding](http://docs.scipy.org/doc/scipy/reference/optimize.html#root-finding)
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scipy.optimize` 的文档，地址为 [http://docs.scipy.org/doc/scipy/reference/optimize.html#root-finding](http://docs.scipy.org/doc/scipy/reference/optimize.html#root-finding)'
- en: A course on root finding with SciPy available at [http://quant-econ.net/scipy.html#roots-and-fixed-points](http://quant-econ.net/scipy.html#roots-and-fixed-points)
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个关于 SciPy 根查找的课程，地址为 [http://quant-econ.net/scipy.html#roots-and-fixed-points](http://quant-econ.net/scipy.html#roots-and-fixed-points)
- en: The Bisection method on Wikipedia, available at [http://en.wikipedia.org/wiki/Bisection_method](http://en.wikipedia.org/wiki/Bisection_method)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二分法的维基百科页面，地址为 [http://en.wikipedia.org/wiki/Bisection_method](http://en.wikipedia.org/wiki/Bisection_method)
- en: The intermediate value theorem on Wikipedia, available at [http://en.wikipedia.org/wiki/Intermediate_value_theorem](http://en.wikipedia.org/wiki/Intermediate_value_theorem)
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中值定理的维基百科页面，地址为 [http://en.wikipedia.org/wiki/Intermediate_value_theorem](http://en.wikipedia.org/wiki/Intermediate_value_theorem)
- en: Brent's method on Wikipedia, available at [http://en.wikipedia.org/wiki/Brent%27s_method](http://en.wikipedia.org/wiki/Brent%27s_method)
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brent 方法的维基百科页面，地址为 [http://en.wikipedia.org/wiki/Brent%27s_method](http://en.wikipedia.org/wiki/Brent%27s_method)
- en: Newton's method on Wikipedia, available at [http://en.wikipedia.org/wiki/Newton%27s_method](http://en.wikipedia.org/wiki/Newton%27s_method)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 牛顿法的维基百科页面，地址为 [http://en.wikipedia.org/wiki/Newton%27s_method](http://en.wikipedia.org/wiki/Newton%27s_method)
- en: See also
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: The *Minimizing a mathematical function* recipe
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*最小化数学函数* 的教程'
- en: Minimizing a mathematical function
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最小化数学函数
- en: Mathematical optimization deals mainly with the problem of finding a minimum
    or a maximum of a mathematical function. Frequently, a real-world numerical problem
    can be expressed as a function minimization problem. Such examples can be found
    in statistical inference, machine learning, graph theory, and other areas.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 数学优化主要涉及寻找数学函数的最小值或最大值的问题。现实世界中的许多数值问题可以表达为函数最小化问题。这类问题可以在统计推断、机器学习、图论等领域中找到。
- en: Although there are many function minimization algorithms, a generic and universal
    method does not exist. Therefore, it is important to understand the differences
    between existing classes of algorithms, their specificities, and their respective
    use cases. We should also have a good understanding of our problem and our objective
    function; is it continuous, differentiable, convex, multidimensional, regular,
    or noisy? Is our problem constrained or unconstrained? Are we seeking local or
    global minima?
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有许多函数最小化算法，但并没有一个通用且普适的方法。因此，理解现有算法类别之间的差异、它们的特点以及各自的使用场景非常重要。我们还应该对问题和目标函数有清晰的了解；它是连续的、可微的、凸的、多维的、规则的，还是有噪声的？我们的优化问题是约束的还是无约束的？我们是在寻找局部最小值还是全局最小值？
- en: In this recipe, we will demonstrate a few usage examples of the function minimization
    algorithms implemented in SciPy.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将演示在 SciPy 中实现的几种函数最小化算法的使用示例。
- en: How to do it…
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现……
- en: 'We import the libraries:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导入库：
- en: '[PRE7]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'First, let''s define a simple mathematical function (the opposite of the **cardinal
    sine**). This function has many local minima but a single global minimum ([http://en.wikipedia.org/wiki/Sinc_function](http://en.wikipedia.org/wiki/Sinc_function)):'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let''s plot this function on the interval *[-20, 20]* (with 1000 samples):'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![How to do it…](img/4818OS_09_06.jpg)'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'The `scipy.optimize` module comes with many function minimization routines.
    The `minimize()` function offers a unified interface to many algorithms. The **Broyden–Fletcher–Goldfarb–Shanno**
    (**BFGS**) algorithm (the default algorithm in `minimize()`) gives good results
    in general. The `minimize()` function requires an initial point as argument. For
    scalar univariate functions, we can also use `minimize_scalar()`:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Starting from *x[0]**=3*, the algorithm was able to find the actual global
    minimum, as shown in the following figure:'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![How to do it…](img/4818OS_09_07.jpg)'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Now, if we start from an initial point that is further away from the actual
    global minimum, the algorithm converges towards a *local* minimum only:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![How to do it…](img/4818OS_09_08.jpg)'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Like most function minimization algorithms, the BFGS algorithm is efficient
    at finding *local* minima, but not necessarily *global* minima, especially on
    complicated or noisy objective functions. A general strategy to overcome this
    problem is to combine such algorithms with an exploratory grid search on the initial
    points. Another option is to use a different class of algorithms based on heuristics
    and stochastic methods. A popular example is the **simulated annealing method**:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![How to do it…](img/4818OS_09_09.jpg)'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: This time, the algorithm was able to find the global minimum.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, let's define a new function, in two dimensions this time, called the **Lévi
    function**:![How to do it…](img/4818OS_09_10.jpg)
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This function is very irregular and may be difficult to minimize in general.
    It is one of the many **test functions for optimization** that researchers have
    developed to study and benchmark optimization algorithms ([http://en.wikipedia.org/wiki/Test_functions_for_optimization](http://en.wikipedia.org/wiki/Test_functions_for_optimization)):'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let''s display this function with `imshow()`, on the square *[-10,10]²*:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![How to do it…](img/4818OS_09_11.jpg)'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'The BFGS algorithm also works in multiple dimensions:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![How to do it…](img/4818OS_09_12.jpg)'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: How it works…
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many function minimization algorithms are based on the fundamental idea of **gradient
    descent**. If a function *f* is differentiable, then at every point, the opposite
    of its gradient points to the direction of the greatest decrease rate of the function.
    By following this direction, we can expect to find a local minimum.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: This operation is generally done iteratively, by following the direction of
    the gradient with a small step. The way this step is computed depends on the optimization
    method.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Newton's method can also be used in this context of function minimization. The
    idea is to find a root of *f'* with Newton's method, thereby making use of the
    *second* derivative *f''*. In other words, we approximate *f* with a *quadratic*
    function instead of a *linear* function. In multiple dimensions, this is done
    by computing the **Hessian** (second derivatives) of *f*. By performing this operation
    iteratively, we can expect the algorithm to converge towards a local minimum.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: When the computation of the Hessian is too costly, we can compute an *approximation*
    of the Hessian. Such methods are called **Quasi-Newton methods**. The BFGS algorithm
    belongs to this class of algorithms.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: These algorithms make use of the objective function's gradient. If we can compute
    an analytical expression of the gradient, we should provide it to the minimization
    routine. Otherwise, the algorithm will compute an approximation of the gradient
    that may not be reliable.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'The **simulated annealing** algorithm is a generic probabilistic metaheuristic
    for the global optimization problem. It is based on an analogy with thermodynamic
    systems: by increasing and decreasing the temperature, the configuration may converge
    to a state of low energy.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: There are many stochastic global optimization methods based on metaheuristics.
    They are generally less well-theoretically grounded than the deterministic optimization
    algorithms previously described, and convergence is not always guaranteed. However,
    they may be useful in situations where the objective function is very irregular
    and noisy, with many local minima. The **Covariance Matrix Adaptation Evolution
    Strategy** (**CMA-ES**) algorithm is a metaheuristic that performs well in many
    situations. It is currently not implemented in SciPy, but there's a Python implementation
    in one of the references given later.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: SciPy's `minimize()` function accepts a `method` keyword argument to specify
    the minimization algorithm to use. This function returns an object containing
    the results of the optimization. The `x` attribute is the point reaching the minimum.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are a few further references:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: The `scipy.optimize` reference documentation available at [http://docs.scipy.org/doc/scipy/reference/optimize.html](http://docs.scipy.org/doc/scipy/reference/optimize.html)
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An excellent lecture on mathematical optimization with SciPy available at [http://scipy-lectures.github.io/advanced/mathematical_optimization/](http://scipy-lectures.github.io/advanced/mathematical_optimization/)
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Definition of the gradient on Wikipedia, available at [http://en.wikipedia.org/wiki/Gradient](http://en.wikipedia.org/wiki/Gradient)
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Newton's method on Wikipedia, available at [http://en.wikipedia.org/wiki/Newton%27s_method_in_optimization](http://en.wikipedia.org/wiki/Newton%27s_method_in_optimization)
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quasi-Newton methods on Wikipedia, available at [http://en.wikipedia.org/wiki/Quasi-Newton_method](http://en.wikipedia.org/wiki/Quasi-Newton_method)
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metaheuristics for function minimization on Wikipedia, available at [http://en.wikipedia.org/wiki/Metaheuristic](http://en.wikipedia.org/wiki/Metaheuristic)
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维基百科上的函数最小化元启发式方法，链接：[http://en.wikipedia.org/wiki/Metaheuristic](http://en.wikipedia.org/wiki/Metaheuristic)
- en: Simulated annealing on Wikipedia, available at [http://en.wikipedia.org/wiki/Simulated_annealing](http://en.wikipedia.org/wiki/Simulated_annealing)
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维基百科上的模拟退火，链接：[http://en.wikipedia.org/wiki/Simulated_annealing](http://en.wikipedia.org/wiki/Simulated_annealing)
- en: The CMA-ES algorithm described at [http://en.wikipedia.org/wiki/CMA-ES](http://en.wikipedia.org/wiki/CMA-ES)
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维基百科上的 CMA-ES 算法描述，链接：[http://en.wikipedia.org/wiki/CMA-ES](http://en.wikipedia.org/wiki/CMA-ES)
- en: A Python implementation of CMA-ES available at [http://www.lri.fr/~hansen/cmaes_inmatlab.html#python](http://www.lri.fr/~hansen/cmaes_inmatlab.html#python)
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可在 [http://www.lri.fr/~hansen/cmaes_inmatlab.html#python](http://www.lri.fr/~hansen/cmaes_inmatlab.html#python)
    获取 CMA-ES 的 Python 实现
- en: See also
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见其他资料
- en: The *Finding the root of a mathematical function* recipe
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*求解数学函数的根*教程'
- en: Fitting a function to data with nonlinear least squares
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用非线性最小二乘法拟合数据函数
- en: In this recipe, we will show an application of numerical optimization to **nonlinear
    least squares curve fitting**. The goal is to fit a function, depending on several
    parameters, to data points. In contrast to the linear least squares method, this
    function does not have to be linear in those parameters.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将展示数值优化应用于**非线性最小二乘曲线拟合**的一个例子。目标是根据多个参数拟合一个函数到数据点上。与线性最小二乘法不同，这个函数在这些参数上不必是线性的。
- en: We will illustrate this method on artificial data.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用人工数据来演示这种方法。
- en: How to do it…
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: 'Let''s import the usual libraries:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入常用的库：
- en: '[PRE17]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We define a logistic function with four parameters:![How to do it…](img/4818OS_09_13.jpg)
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义了一个具有四个参数的逻辑斯蒂函数：![如何实现…](img/4818OS_09_13.jpg)
- en: '[PRE18]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s define four random parameters:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义四个随机参数：
- en: '[PRE19]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, we generate random data points by using the sigmoid function and adding
    a bit of noise:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们通过使用 sigmoid 函数并添加一点噪声来生成随机数据点：
- en: '[PRE20]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here is a plot of the data points, with the particular sigmoid used for their
    generation (in dashed black):'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里是数据点的图示，图中显示了用于生成数据的特定 sigmoid（用虚线黑色表示）：
- en: '[PRE21]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![How to do it…](img/4818OS_09_14.jpg)'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何实现…](img/4818OS_09_14.jpg)'
- en: 'We now assume that we only have access to the data points and not the underlying
    generative function. These points could have been obtained during an experiment.
    By looking at the data, the points appear to approximately follow a sigmoid, so
    we may want to try to fit such a curve to the points. That''s what **curve fitting**
    is about. SciPy''s `curve_fit()` function allows us to fit a curve defined by
    an arbitrary Python function to the data:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在假设我们只能访问数据点，而无法访问底层的生成函数。这些点可能是在实验中获得的。从数据来看，这些点似乎大致符合一个 sigmoid 曲线，因此我们可能希望尝试将这样的曲线拟合到这些点上。这就是**曲线拟合**的含义。SciPy
    的 `curve_fit()` 函数允许我们将由任意 Python 函数定义的曲线拟合到数据上：
- en: '[PRE22]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, let''s take a look at the fitted sigmoid curve:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下拟合后的 sigmoid 曲线：
- en: '[PRE23]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![How to do it…](img/4818OS_09_15.jpg)'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何实现…](img/4818OS_09_15.jpg)'
- en: The fitted sigmoid appears to be reasonably close to the original sigmoid used
    for data generation.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 拟合后的 sigmoid 曲线似乎与用于数据生成的原始 sigmoid 曲线非常接近。
- en: How it works…
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'In SciPy, nonlinear least squares curve fitting works by minimizing the following
    cost function:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在 SciPy 中，非线性最小二乘曲线拟合是通过最小化以下代价函数来实现的：
- en: '![How it works…](img/4818OS_09_16.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的…](img/4818OS_09_16.jpg)'
- en: Here, ![How it works…](img/4818OS_09_20.jpg) is the vector of parameters (in
    our example, ![How it works…](img/4818OS_09_20.jpg) *=(a,b,c,d)*).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![它是如何工作的…](img/4818OS_09_20.jpg) 是参数的向量（在我们的示例中，![它是如何工作的…](img/4818OS_09_20.jpg)
    *=(a,b,c,d)*）。
- en: Nonlinear least squares is really similar to linear least squares for linear
    regression. Whereas the function *f* is *linear* in the parameters with the linear
    least squares method, it is *not linear* here. Therefore, the minimization of
    *S(*![How it works…](img/4818OS_09_20.jpg) *)* cannot be done analytically by
    solving the derivative of *S* with respect to ![How it works…](img/4818OS_09_20.jpg).
    SciPy implements an iterative method called the **Levenberg-Marquardt algorithm**
    (an extension of the Gauss–Newton algorithm).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 非线性最小二乘法实际上与线性回归中的线性最小二乘法非常相似。在线性最小二乘法中，函数 *f* 在参数上是*线性*的，而在这里则*不是线性*的。因此，*S(*![它是如何工作的…](img/4818OS_09_20.jpg)
    *)* 的最小化不能通过解析地解出 *S* 对 ![它是如何工作的…](img/4818OS_09_20.jpg) 的导数来完成。SciPy 实现了一种称为
    **Levenberg-Marquardt 算法** 的迭代方法（高斯-牛顿算法的扩展）。
- en: There's more…
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'Here are further references:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是更多的参考资料：
- en: Reference documentation of `curvefit` available at [http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html)
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nonlinear least squares on Wikipedia, available at [http://en.wikipedia.org/wiki/Non-linear_least_squares](http://en.wikipedia.org/wiki/Non-linear_least_squares)
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Levenberg-Marquardt algorithm on Wikipedia, available at [http://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm](http://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm)
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Minimizing a mathematical function* recipe
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the equilibrium state of a physical system by minimizing its potential
    energy
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will give an application example of the function minimization
    algorithms described earlier. We will try to numerically find the equilibrium
    state of a physical system by minimizing its potential energy.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: More specifically, we'll consider a structure made of masses and springs, attached
    to a vertical wall and subject to gravity. Starting from an initial position,
    we'll search for the equilibrium configuration where the gravity and elastic forces
    compensate.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s import NumPy, SciPy, and matplotlib:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We define a few constants in the International System of Units:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We define the initial positions of the masses. They are arranged on a two-dimensional
    grid with two lines and *n/2* columns:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, let''s define the connectivity matrix between the masses. Coefficient
    *(i,j)* is 1 if masses *i* and *j* are connected by a spring, 0 otherwise:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We also specify the spring stiffness of each spring. It is *l*, except for
    *diagonal* springs where it is ![How to do it…](img/4818OS_09_21.jpg):'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We get the indices of the spring connections:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This `dist` function computes the distance matrix (distance between any pair
    of masses):'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We define a function that displays the system. The springs are colored according
    to their tension:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Here is the system in its initial configuration:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![How to do it…](img/4818OS_09_17.jpg)'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'To find the equilibrium state, we need to minimize the total potential energy
    of the system. The following function computes the energy of the system given
    the positions of the masses. This function is explained in the *How it works…*
    section:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let''s compute the potential energy of the initial configuration:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now, let''s minimize the potential energy with a function minimization method.
    We need a **constrained optimization algorithm**, because we make the assumption
    that the first two masses are fixed to the wall. Therefore, their positions cannot
    change. The **L-BFGS-B** algorithm, a variant of the BFGS algorithm, accepts bound
    constraints. Here, we force the first two points to stay at their initial positions,
    whereas there are no constraints on the other points. The `minimize()` function
    accepts a `bounds` list containing, for each dimension, a pair of `[min, max]`
    values:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let''s display the stable configuration:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![How to do it…](img/4818OS_09_18.jpg)'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: This configuration looks realistic. The tension appears to be maximal on the
    top springs near the wall.
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works…
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This example is conceptually simple. The state of the system is only described
    by the positions of the masses. If we can write a Python function that returns
    the total energy of the system, finding the equilibrium is just a matter of minimizing
    this function. This is the **principle of minimum total potential energy**, due
    to the second law of thermodynamics.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Here, we give an expression of the total energy of the system. Since we are
    only interested in the *equilibrium*, we omit any kinetic aspect and we only consider
    potential energy due to gravity (**gravitational force**) and spring forces (**elastic
    potential energy**).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: 'Letting *U* be the total potential energy of the system, *U* can be expressed
    as the sum of the gravitational potential energies of the masses and the elastic
    potential energies of the springs. Therefore:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/4818OS_09_19.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
- en: 'Here:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '*m* is the mass'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*g* is the gravity of Earth'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*k* is the stiffness of the springs'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*p[i] = (x[i], y[i])* is the position of mass *i*'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*a[ij]* is 1 if masses *i* and *j* are attached by a spring, 0 otherwise'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*l[ij]* is the relaxed length of spring *(i,j)*, or 0 if masses *i* and *j*
    are not attached'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `energy()` function implements this formula using vectorized computations
    on NumPy arrays.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following references contain details about the physics behind this formula:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Potential energy on Wikipedia, available at [http://en.wikipedia.org/wiki/Potential_energy](http://en.wikipedia.org/wiki/Potential_energy)
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elastic potential energy on Wikipedia, available at [http://en.wikipedia.org/wiki/Elastic_potential_energy](http://en.wikipedia.org/wiki/Elastic_potential_energy)
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hooke's law, which is the linear approximation of the springs' response, described
    at [http://en.wikipedia.org/wiki/Hooke%27s_law](http://en.wikipedia.org/wiki/Hooke%27s_law)
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Principle of minimum energy on Wikipedia, available at [http://en.wikipedia.org/wiki/Minimum_total_potential_energy_principle](http://en.wikipedia.org/wiki/Minimum_total_potential_energy_principle)
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is a reference about the optimization algorithm:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: L-BFGS-B algorithm on Wikipedia, available at [http://en.wikipedia.org/wiki/Limited-memory_BFGS#L-BFGS-B](http://en.wikipedia.org/wiki/Limited-memory_BFGS#L-BFGS-B)
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Minimizing a mathematical function* recipe
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
