- en: Restructuring Data into a Tidy Form
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the datasets used in the preceding chapters have not had much or any work
    done to change their structure. We immediately began processing the datasets in
    their original shape. Many datasets in the wild will need a significant amount
    of restructuring before commencing a more detailed analysis. In some cases, an
    entire project might only be concerned with formatting the data in such a way
    that it can be easily processed by someone else.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Tidying variable values as column names with `stack`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tidying variable values as column names with `melt`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stacking multiple groups of variables simultaneously
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inverting stacked data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unstacking after a `groupby` aggregation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replicating `pivot_table` with a `groupby` aggregation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Renaming axis levels for easy reshaping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tidying when multiple variables are stored as column names
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tidying when multiple variables are stored as column values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tidying when two or more values are stored in the same cell
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tidying when variables are stored in column names and values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tidying when multiple observational units are stored in the same table
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many terms that are used to describe the process of data restructuring,
    with **tidy data** being the most common to data scientists. Tidy data is a term
    coined by Hadley Wickham to describe a form of data that makes analysis easy to
    do. This chapter will cover many ideas formulated by Hadley and how to accomplish
    them with pandas. To learn a great deal more about tidy data, read Hadley's paper
    ([http://vita.had.co.nz/papers/tidy-data.pdf](http://vita.had.co.nz/papers/tidy-data.pdf)).
  prefs: []
  type: TYPE_NORMAL
- en: 'What is tidy data? Hadley puts forth three simple guiding principles that determine
    whether a dataset is tidy or not:'
  prefs: []
  type: TYPE_NORMAL
- en: Each variable forms a column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each observation forms a row
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each type of observational unit forms a table
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any dataset that does not meet these guidelines is considered messy. This definition
    will make more sense once we start restructuring our data into tidy form, but
    for now, we'll need to know what variables, observations, and observational units
    are.
  prefs: []
  type: TYPE_NORMAL
- en: To gain intuition about what a variable actually is, it is good to think about
    the distinction between a variable name and the variable value. The variable names
    are labels, such as gender, race, salary, and position. The variable values are
    those things liable to change for every observation, such as male/female for gender
    or white/black for race. A single observation is the collection of all variable
    values for a single observational unit. To help understand what an observational
    unit might be, consider a retail store, which has data for each transaction, employee,
    customer, item, and the store itself. Each of these can be considered an observational
    unit and would require its own table. Combining employee information (like the
    number of hours worked) with customer information (like amount spent) in the same
    table would break this tidy principle.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step to resolving messy data is to recognize it when it exists, and
    there are boundless possibilities. Hadley explicitly mentions five of the most
    common types of messy data:'
  prefs: []
  type: TYPE_NORMAL
- en: Column names are values, not variable names
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple variables are stored in column names
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Variables are stored in both rows and columns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple types of observational units are stored in the same table
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A single observational unit is stored in multiple tables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important to understand that tidying data does not typically involve changing
    the values of your dataset, filling in missing values, or doing any sort of analysis.
    Tidying data involves changing the shape or structure of the data to meet the
    tidy principles. Tidy data is akin to having all your tools in the toolbox instead
    of scattered randomly throughout your house. Having the tools properly in the
    toolbox allows all other tasks to be completed easily. Once the data is in the
    correct form, it becomes much easier to perform further analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have spotted messy data, you will use the pandas tools to restructure
    the data, so that it is tidy. The main tidy tools that pandas has available for
    you are the DataFrame methods `stack`, `melt`, `unstack`, and `pivot`. More complex
    tidying involves ripping apart text, which necessitates the `str` accessor. Other
    helper methods, such as `rename`, `rename_axis`, `reset_index`, and `set_index`
    will help with applying the final touches to tidy data.
  prefs: []
  type: TYPE_NORMAL
- en: Tidying variable values as column names with stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To help understand the differences between tidy and messy data, let''s take
    a look at a simple table that may or may not be in tidy form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/0c3550a4-3074-402c-8c02-ba272547bde2.png)'
  prefs: []
  type: TYPE_IMG
- en: There does not appear to be anything messy about this table, and the information
    is easily consumable. However, according to the tidy principles, it isn't actually
    tidy. Each column name is actually the value of a variable. In fact, none of the
    variable names are even present in the DataFrame. One of the first steps to transform
    a messy dataset into tidy data is to identify all of the variables. In this particular
    dataset, we have variables for **state** and **fruit**. There's also the numeric
    data that wasn't identified anywhere in the context of the problem. We can label
    this variable as **weight** or any other sensible name.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This particular messy dataset contains variable values as column names. We will
    need to transpose these column names into column values. In this recipe, we use
    the `stack` method to restructure our DataFrame into tidy form.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, take note that the state names are in the index of the DataFrame. These
    states are correctly placed vertically and do not need to be restructured. It
    is the column names that are the problem. The `stack` method takes all of the
    column names and reshapes them to be vertical as a single index level:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that we now have a Series with a MultiIndex. There are now two levels
    in the index. The original index has been pushed to the left to make room for
    the old column names. With this one command, we now essentially have tidy data.
    Each variable, state, fruit, and weight is vertical. Let''s use the `reset_index`
    method to turn the result into a DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/85efcd7a-edc3-44b9-8578-696dafb6a1bd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Our structure is now correct, but the column names are meaningless. Let''s
    replace them with proper identifiers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/9e607e7b-2dd2-4c90-94c3-4e5f7f659dc7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Instead of directly changing the columns attribute, it''s possible to use the
    lesser-known Series method `rename_axis` to set the names of the index levels
    before using `reset_index`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'From here, we can simply chain the `reset_index` method with the `name` parameter
    to reproduce the output from step 3:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `stack` method is powerful and it takes time to understand and appreciate
    fully. It takes all the column names and transposes them, so they become the new
    innermost index level. Notice how each old column name still labels its original
    value by being paired with each state. There were nine original values in a 3
    x 3 DataFrame, which got transformed into a single Series with the same number
    of values. The original first row of data became the first three values in the
    resulting Series.
  prefs: []
  type: TYPE_NORMAL
- en: After resetting the index in step 2, pandas defaults our DataFrame columns to
    `level_0`, `level_1`, and `0`. This is because the Series calling this method
    has two index levels that were formally unnamed. Pandas also refers to indexes
    by integer beginning from zero from the outside.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 shows a simple and intuitive way to rename the columns. You can simply
    set new columns for the entire DataFrame by setting the columns attribute equal
    to a list.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, it is possible to set the column names in a single step by chaining
    the `rename_axis` method that, when passing a list as the first argument, uses
    those values as the index level names. Pandas uses these index level names as
    the new column names when the index is reset. Additionally, the `reset_index`
    method has a `name` parameter corresponding to the new column name of the Series
    values.
  prefs: []
  type: TYPE_NORMAL
- en: All Series have a `name` attribute that can be set directly or with the `rename`
    method. It is this attribute that becomes the column name when using `reset_index`.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the keys to using `stack` is to place all of the columns that you do
    not wish to transform in the index. The dataset in this recipe was initially read
    with the states in the index. Let''s take a look at what would have happened if
    we did not read the states into the index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/825e195b-4117-4d76-a0a6-9c475c9f493f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As the state names are not in the index, using `stack` on this DataFrame reshapes
    all values into one long Series of values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This command reshapes all the columns, this time including the states, and
    is not at all what we need. In order to reshape this data correctly, you will
    need to put all the non-reshaped columns into the index first with the `set_index`
    method, and then use `stack`. The following code gives a similar result to step
    1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pandas official documentation on *Reshaping and Pivot Tables* ([http://bit.ly/2xbnNms](http://pandas.pydata.org/pandas-docs/stable/reshaping.html))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pandas official documentation on the `stack` method ([http://bit.ly/2vWZhH1](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.stack.html))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tidying variable values as column names with melt
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like most large Python libraries, pandas has many different ways to accomplish
    the same task--the differences usually being readability and performance. Pandas
    contains a DataFrame method named `melt` that works similarly to the `stack` method
    described in the previous recipe but gives a bit more flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: Before pandas version 0.20, `melt` was only provided as a function that had
    to be accessed with `pd.melt`. Pandas is still an evolving library and you need
    to expect changes with each new version. Pandas has been making a push to move
    all functions that only operate on DataFrames to methods, such as they did with
    `melt`. This is the preferred way to use `melt` and the way this recipe uses it.
    Check the *What's New* part of the pandas documentation to stay up to date with
    all the changes ([http://bit.ly/2xzXIhG](http://bit.ly/2xzXIhG)).
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we use the `melt` method to tidy a simple DataFrame with variable
    values as column names.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the `state_fruit2` dataset and identify which columns need to be transformed
    and which ones do not:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/a8e3bd31-0e35-437c-93e2-b78b1c43a731.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the `melt` method by passing the appropriate columns to the `id_vars` and
    `value_vars` parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/21219e55-bc00-472e-a99c-e85328927350.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This one step creates tidy data for us. By default, `melt` refers to the transformed
    former column names as *variable* and the corresponding values as *value*. Conveniently,
    `melt` has two additional parameters, `var_name` and `value_name`, that give you
    the ability to rename these two columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/8622f3dc-f2f8-4598-90f2-9a2e72e9cd64.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `melt` method is powerful and dramatically reshapes your DataFrame. It
    takes up to five parameters, with two of them being crucial to understanding how
    to reshape your data correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '`id_vars` is a list of column names that you want to preserve as columns and
    not reshape'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`value_vars` is a list of column names that you want to reshape into a single
    column'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `id_vars`, or the identification variables, remain in the same column but
    repeat for each of the columns passed to `value_vars`. One crucial aspect of `melt`
    is that it ignores values in the index, and, in fact, it silently drops your index
    and replaces it with a default `RangeIndex`. This means that if you do have values
    in your index that you would like to keep, you will need to reset the index first
    before using `melt`.
  prefs: []
  type: TYPE_NORMAL
- en: It is somewhat common terminology to refer to the transformation of horizontal
    column names into vertical column values as **melting**, **stacking**, or **unpivoting**.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All the parameters for the `melt` method are optional, and if you desire all
    your values to be in a single column and their old column labels to be in the
    other, you may call `melt` with just its defaults:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/98b9e58c-f2d0-4210-92dd-e2d5dac1e42d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'More realistically, you might have lots of variables that need melting and
    would like to specify only the identification variables. In that case, calling
    `melt` in the following manner will yield the same result as in step 2\. You actually
    don''t even need a list when melting a single column and can simply pass its string
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pandas official documentation on the `melt` method ([http://bit.ly/2vcuZNJ](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.melt.html))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pandas developers discussion of `melt` and other similar functions being converted
    to methods ([http://bit.ly/2iqIQhI](https://github.com/pandas-dev/pandas/issues/12640))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stacking multiple groups of variables simultaneously
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some datasets contain multiple groups of variables as column names that need
    to be stacked simultaneously into their own columns. An example of the `movie`
    dataset can help clarify this. Let''s begin by selecting all columns containing
    the actor names and their corresponding Facebook likes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/28f8a2eb-d81b-475d-a563-3d82da61a598.png)'
  prefs: []
  type: TYPE_IMG
- en: If we define our variables as the title of the movie, the actor name, and the
    number of Facebook likes, then we will need to stack independently two sets of
    columns, which is not possible using a single call to `stack` or `melt`.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will tidy our `actor` DataFrame by simultaneously stacking
    the actor names and their corresponding Facebook likes with the `wide_to_long`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will be using the versatile `wide_to_long` function to reshape our data
    into tidy form. To use this function, we will need to change the column names
    that we are stacking, so that they end with a digit. We first create a user-defined
    function to change the column names:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Pass this function to the `rename` method to transform all the column names:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/7ef188f2-f6c0-4325-a78d-8c0bcd1e752f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the `wide_to_long` function to stack the actor and Facebook sets of columns
    simultaneously:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/24a5560f-de6c-4b7f-a913-6a9650921b6e.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `wide_to_long` function works in a fairly specific manner. Its main parameter
    is `stubnames`, which is a list of strings. Each string represents a single column
    grouping. All columns that begin with this string will be stacked into a single
    column. In this recipe, there are two groups of columns: *actor*, and *actor_facebook_likes*.
    By default, each of these groups of columns will need to end in a digit. This
    digit will subsequently be used to label the reshaped data. Each of these column
    groups has an underscore character separating the `stubname` from the ending digit.
    To account for this, you must use the `sep` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: The original column names do not match the pattern needed for `wide_to_long`
    to work. The column names could have been changed manually by exactly specifying
    their values with a list. This could quickly become a lot of typing so instead,
    we define a function that automatically converts our columns to a format that
    works. The `change_col_name` function removes **_name** from the actor columns
    and rearranges the Facebook columns so that now they both end in digits.
  prefs: []
  type: TYPE_NORMAL
- en: To actually accomplish the column renaming, we use the `rename` method in step
    2\. It accepts many different types of arguments, one of which is a function.
    When passing it to a function, every column name gets implicitly passed to it
    one at a time.
  prefs: []
  type: TYPE_NORMAL
- en: We have now correctly created two independent groups of columns, those beginning
    with **actor** and **actor_facebook_likes** that will be stacked**.** In addition
    to this, `wide_to_long` requires a unique column, parameter `i`, to act as an
    identification variable that will not be stacked. Also required is the parameter
    `j`, which simply renames the identifying digit stripped from the end of the original
    column names. By default, the prefix parameter contains the **regular expression**,
    **\d+** that searches for one more or more digits. The **\d** is a special token
    that matches the digits 0-9\. The plus sign, **+**, makes the expression match
    for one or more of these digits.
  prefs: []
  type: TYPE_NORMAL
- en: To become a powerful user of the `str` methods, you will need to be familiar
    with regular expressions, which are a sequence of characters that match a particular
    pattern within some text. They consist of **metacharacters**, which have a special
    meaning, and **literal** characters. To make yourself useful with regular expressions
    check this short tutorial from *Regular-Expressions.info* ([http://bit.ly/2wiWPbz](http://bit.ly/2wiWPbz)).
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The function `wide_to_long` works when all groupings of variables have the
    same numeric ending as they did in this recipe. When your variables do not have
    the same ending or don''t end in a digit, you can still use `wide_to_long` to
    do simultaneous column stacking. For instance, let''s take a look at the following
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/ab29bdc4-c4a2-4f3a-a9bb-217ce9330c2d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s say we wanted columns `a1` and `b1` stacked together, as well as columns
    `d` and `e`. Additionally, we wanted to use `a1` and `b1` as labels for the rows.
    To accomplish this task, we would need to rename the columns so that they ended
    in the label we desired:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/44caf11d-1056-4f5f-99a6-c155b4979a95.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We would then need to modify the suffix parameter, which normally defaults
    to a regular expression that selects digits. Here, we simply tell it to find any
    number of characters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/dd943f25-9112-4778-8006-b0fccb810901.png)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pandas official documentation for `wide_to_long` ([http://bit.ly/2xb8NVP](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.wide_to_long.html))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inverting stacked data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DataFrames have two similar methods, `stack` and `melt`, to convert horizontal
    column names into vertical column values. DataFrames have the ability to invert
    these two operations directly with the `unstack` and `pivot` methods respectively. 
    `stack`/`unstack` are simpler methods that allow control over only the column/row
    indexes, while `melt`/`pivot` gives more flexibility to choose which columns are
    reshaped.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will `stack`/`melt` a dataset and promptly invert the operation
    with `unstack`/`pivot` back to its original form.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the `college` dataset with the institution name as the index, and with
    only the undergraduate race columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/efc80119-761f-4d14-b1a5-3f42839c8892.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the `stack` method to convert each horizontal column name into a vertical
    index level:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Invert this stacked data back to its original form with the `unstack` Series
    method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'A similar sequence of operations can be done with `melt` followed by `pivot`.
    First, read in the data without putting the institution name in the index:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/b634368b-df19-474a-97bf-39d015e36450.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the `melt` method to transpose all the race columns into a single column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/d3043e3c-0590-402f-ba89-581207ade0bc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the `pivot` method to invert this previous result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/99990148-2b85-45ac-a1d6-1a00c08d9940.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Notice that the institution names are now shuttled over into the index and
    are not in their original order. The column names are not in their original order.
    To get an exact replication of our starting DataFrame from step 4, use the `.loc`
    indexing operator to select rows and columns simultaneously and then reset the
    index:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are multiple ways to accomplish the same thing in step 1\. Here, we show
    the versatility of the `read_csv` function. The `usecols` parameter accepts either
    a list of the columns that we would like to import or a function that dynamically
    determines them. We use an anonymous function that checks whether the column name
    contains `UGDS_` or is equal to `INSTNM`. The function is passed each column name
    as a string and must return a boolean. A huge amount of memory can be saved in
    this manner.
  prefs: []
  type: TYPE_NORMAL
- en: The `stack` method in step 2 puts all column names into the innermost index
    level and returns a Series. In step 3, the `unstack` method inverts this operation
    by taking all the values in the innermost index level converting them to column
    names.
  prefs: []
  type: TYPE_NORMAL
- en: The result from step 3 isn't quite an exact replication of step 1\. There are
    entire rows of missing values, and by default, the `stack` method drops these
    during step 2\. To keep these missing values and create an exact replication,
    use `dropna=False` in the `stack` method.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 reads in the same dataset as in step 1 but does not put the institution
    name in the index because the `melt` method isn't able to access it. Step 5 uses
    the `melt` method to transpose all the **Race** columns. It does this by leaving
    the `value_vars` parameter as its default value `None`. When not specified, all
    the columns not present in the `id_vars` parameter get transposed.
  prefs: []
  type: TYPE_NORMAL
- en: Step 6 inverts the operation from step 5 with the `pivot` method, which accepts
    three parameters. Each parameter takes a single column as a string. The column
    referenced by the `index` parameter remains vertical and becomes the new index.
    The values of the column referenced by the `columns` parameter become the column
    names. The values referenced by the `values` parameter become tiled to correspond
    with the intersection of their former index and columns label.
  prefs: []
  type: TYPE_NORMAL
- en: To make an exact replication with `pivot`, we need to sort the rows and columns
    in the exact order from the original. As the institution name is in the index,
    we use the `.loc` indexing operator as a way to sort the DataFrame by its original
    index.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To help further understand `stack`/`unstack`, let's use them to **transpose**
    the `college` DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: In this context, we are using the precise mathematical definition of the transposing
    of a matrix, where the new rows are the old columns of the original data matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you take a look at the output from step 2, you''ll notice that there are
    two index levels. By default, the `unstack` method uses the innermost index level
    as the new column values. Index levels are numbered beginning from zero from the
    outside. Pandas defaults the `level` parameter of the `unstack` method to -1,
    which refers to the innermost index. We can instead `unstack` the outermost column
    using `level=0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/23f980c3-580e-470f-94c9-476146342f49.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There is actually a very simple way to transpose a DataFrame that don''t require
    `stack` or `unstack` by using the `transpose` method or the `T` attribute like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Refer to the *Selecting DataFrame rows and columns simultaneously* recipe from
    [Chapter 10](3b938362-1f65-406c-ba9d-3bf735543ca8.xhtml), *Selecting Subsets of
    Data*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pandas official documentation of the `unstack` ([http://bit.ly/2xIyFvr](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.unstack.html))
    and `pivot` ([http://bit.ly/2f3qAWP](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pivot.html))
    methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unstacking after a groupby aggregation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Grouping data by a single column and performing an aggregation on a single column
    returns a simple and straightforward result that is easy to consume. When grouping
    by more than one column, a resulting aggregation might not be structured in a
    manner that makes consumption easy. Since `groupby` operations by default put
    the unique grouping columns in the index, the `unstack` method can be extremely
    useful to rearrange the data so that it is presented in a manner that is more
    useful for interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we use the `employee` dataset to perform an aggregation, grouping
    by multiple columns. We then use the `unstack` method to reshape the result into
    a format that makes for easier comparisons of different groups.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the employee dataset and find the mean salary by race:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a very simple `groupby` operation that results in a Series that is
    easy to read and has no need to reshape. Let''s now find the average salary for
    all races by gender:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This aggregation is more complex and can be reshaped to make different comparisons
    easier. For instance, it would be easier to compare male versus female salaries
    for each race if they were side by side and not vertical as they are now. Let''s
    unstack the gender index level:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/d0f45d1b-2ade-4b1d-afdd-1a734cd20390.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, we can `unstack` the race index level:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/ecc8127d-acf5-46df-9220-f3d95d9fb67a.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Step 1 has the simplest possible aggregation with a single grouping column (`RACE`),
    a single aggregating column (`BASE_SALARY`), and a single aggregating function
    (`mean`). This result is easy to consume and doesn't require any more processing
    to evaluate. Step 2 slightly increases the complexity by grouping by both race
    and gender together. The resulting MultiIndex Series contains all the values in
    a single dimension, which makes comparisons more difficult. To make the information
    easier to consume, we use the `unstack` method to convert the values in one (or
    more) of the levels to columns.
  prefs: []
  type: TYPE_NORMAL
- en: By default, `unstack` uses the innermost index level as the new columns. You
    can specify the exact level you would like to unstack with the `level` parameter,
    which accepts either the level name as a string or the level integer location.
    It is preferable to use the level name over the integer location to avoid ambiguity.
    Steps 3 and 4 unstack each level, which results in a DataFrame with a single-level
    index. It is now much easier to compare salaries from each race by gender.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If there are multiple grouping and aggregating columns, then the immediate
    result will be a DataFrame and not a Series. For instance, let''s calculate more
    aggregations than just the mean, as was done in step 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/e38c7d48-cec8-4d77-a314-b241e25607e3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Unstacking the **Gender** column will result in MultiIndex columns. From here,
    you can keep swapping row and column levels with both the `unstack` and `stack`
    methods until you achieve the structure of data you desire:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/ba0f9ae2-4f39-4fa4-beaa-12eb750daafa.png)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Refer to the *Grouping and aggregating with multiple columns* recipe and functions
    from [Chapter 13](b50e0294-740b-45fc-9c4e-284ecfda8b7d.xhtml), *Grouping for Aggregation,
    Filtration, and Transformation*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replicating pivot_table with a groupby aggregation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At first glance, it may seem that the `pivot_table` method provides a unique
    way to analyze data. However, after a little massaging, it is possible to replicate
    its functionality exactly with a `groupby` aggregation. Knowing this equivalence
    can help shrink the universe of pandas functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we use the `flights` dataset to create a pivot table and then
    recreate it using `groupby` operations.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the flights dataset, and use the `pivot_table` method to find the total
    number of canceled flights per origin airport for each airline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/563d0c11-0a75-4dc2-962d-a70ff0a70e91.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A `groupby` aggregation cannot directly replicate this table. The trick is
    to group by all the columns in the `index` and `columns` parameters first:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `unstack` method to pivot the `ORG_AIR` index level to column names:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `pivot_table` method is very versatile and flexible but performs a rather
    similar operation to a `groupby` aggregation with step 1 showing a simple example.
    The `index` parameter takes a column (or columns) that will not be pivoted and
    whose unique values will be placed in the index. The `columns` parameter takes
    a column (or columns) that will be pivoted and whose unique values will be made
    into column names. The `values` parameter takes a column (or columns) that will
    be aggregated.
  prefs: []
  type: TYPE_NORMAL
- en: There also exists an `aggfunc` parameter that takes an aggregating function
    (or functions) that determines how the columns in the `values` parameter get aggregated.
    It defaults to the mean, and, in this example, we change it to calculate the sum.
    Additionally, some unique combinations of `AIRLINE` and `ORG_AIR` do not exist.
    These missing combinations will default to missing values in the resulting DataFrame.
    Here, we use the `fill_value` parameter to change them to zero.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 begins the replication process using all the columns in the `index` and
    `columns` parameter as the grouping columns. This is the key to making this recipe
    work. A pivot table is simply an intersection of all the unique combinations of
    the grouping columns. Step 3 finishes the replication by pivoting the innermost
    index level into column names with the `unstack` method. Just like with `pivot_table`,
    not all combinations of `AIRLINE` and `ORG_AIR` exist; we again use the `fill_value`
    parameter to force these missing intersections to zero.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is possible to replicate much more complex pivot tables with `groupby` aggregations.
    For instance, take the following result from `pivot_table`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/ee0f83c3-f7e7-4cd0-ac93-2be6b3bd0e52.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To replicate this with a `groupby` aggregation, simply follow the same pattern
    from the recipe and place all the columns from the `index` and `columns` parameters
    into the `groupby` method and then `unstack` the columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: There are a few differences. The `pivot_table` method does not accept aggregation
    functions as strings when passed as a list like the `agg` groupby method. Instead,
    you must use NumPy functions. The order of the column levels also differs, with
    `pivot_table` putting the aggregation functions at a level preceding the columns
    in the `values` parameter. This is equalized with the `swaplevel` method that,
    in this instance, switches the order of the top two levels.
  prefs: []
  type: TYPE_NORMAL
- en: As of the time of writing this book, there is a bug when unstacking more than
    one column. The `fill_value` parameter is ignored ([http://bit.ly/2jCPnWZ](https://github.com/pandas-dev/pandas/issues/13971)).
    To work around this bug, chain `.fillna(0)` to the end of the code.
  prefs: []
  type: TYPE_NORMAL
- en: Renaming axis levels for easy reshaping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reshaping with the `stack`/`unstack` methods is far easier when each axis (index/column)
    level has a name. Pandas allows users to reference each axis level by integer
    location or by name. Since integer location is implicit and not explicit, you
    should consider using level names whenever possible. This advice follows from
    *The* *Zen of Python* ([http://bit.ly/2xE83uC](http://bit.ly/2xE83uC)), a short
    list of guiding principles for Python of which the second one is *Explicit is
    better than implicit*.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When grouping or aggregating with multiple columns, the resulting pandas object
    will have multiple levels in one or both of the axes. In this recipe, we will
    name each level of each axis and then use the methods `stack`/`unstack` to dramatically
    reshape the data to the desired form.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the college dataset, and find a few basic summary statistics on the
    undergraduate population and SAT math scores by institution and religious affiliation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/6ec7dfb9-fb3b-439d-9693-dea41616d025.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Notice that both index levels have names and are the old column names. The
    column levels, on the other hand, do not have names. Use the `rename_axis` method
    to supply level names to them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/d68168ab-e11d-4f74-ac6e-e567fae7f7dd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that each axis level has a name, reshaping is a breeze. Use the `stack`
    method to move the `AGG_FUNCS` column to an index level:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/2651e1eb-49ec-4de9-a8c3-1c5ba20e8bb4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'By default, stacking places the new column level in the innermost position.
    Use the `swaplevel` method to switch the placement of the levels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/77c9ed9a-de64-4f3f-89ce-eb0ef47617a3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can continue to make use of the axis level names by sorting levels with
    the `sort_index` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/f83a1be9-1118-4ce7-9b80-e374e3d0c29e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To completely reshape your data, you might need to stack some columns while
    unstacking others. Chain the two methods together in a single command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/d3d07ca2-2a5f-4b03-a969-7dc29d04e458.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Stack all the columns at once to return a Series:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is common for the result of a `groupby` aggregation to produce a DataFrame
    or Series with multiple axis levels. The resulting DataFrame from the `groupby`
    operation in step 1 has multiple levels for each axis. The column levels are not
    named, which would require us to reference them only by their integer location.
    To greatly ease our ability to reference the column levels, we rename them with
    the `rename_axis` method.
  prefs: []
  type: TYPE_NORMAL
- en: The `rename_axis` method is a bit strange in that it can modify both the level
    names and the level values based on the type of the first argument passed to it.
    Passing it a list (or a scalar if there is only one level) changes the names of
    the levels. Passing it a dictionary or a function changes the values of the levels.
    In step 2, we pass the `rename_axis` method a list and are returned a DataFrame
    with all axis levels named.
  prefs: []
  type: TYPE_NORMAL
- en: Once all the axis levels have names, we can easily and explicitly control the
    structure of data. Step 3 stacks the `AGG_FUNCS` column into the innermost index
    level. The `swaplevel` method in step 4 accepts the name or position of the levels
    that you want to swap as the first two arguments. The `sort_index` method is called
    twice and sorts the actual values of each level. Notice that the values of the
    column level are the column names `SATMTMID` and `UGDS`.
  prefs: []
  type: TYPE_NORMAL
- en: We can get vastly different output by both stacking and unstacking, as done
    in step 6\. It is also possible to stack every single column level into the index
    to produce a Series.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you wish to dispose of the level values altogether, you may set them to
    `None`. A case for this can be made when there is a need to reduce clutter in
    the visual output of a DataFrame or when it is obvious what the column levels
    represent and no further processing will take place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/b1ad2bd3-f4b8-4c58-ad05-3372f30ef470.png)'
  prefs: []
  type: TYPE_IMG
- en: Tidying when multiple variables are stored as column names
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One particular flavor of messy data appears whenever the column names contain
    multiple different variables themselves. A common example of this scenario occurs
    when age and sex are concatenated together. To tidy datasets like this, we must
    manipulate the columns with the pandas `str` accessor, an attribute that contains
    additional methods for string processing.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will first identify all the variables of which some will
    be concatenated together as column names. We then reshape the data and parse the
    text to extract the correct variable values.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the men''s `weightlifting` dataset, and identify the variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/edd05ae0-84ad-445b-9253-a47df0bfc41c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The variables are the weight category, sex/age category, and the qualifying
    total. The age and sex variables have been concatenated together into a single
    cell. Before we can separate them, let''s use the `melt` method to transpose the
    age and sex column names into a single vertical column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/339c92ee-9050-4902-be9e-956b2a6dcc9d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select the `sex_age` column, and use the `split` method available from the
    `str` accessor to split the column into two different columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/fafd813e-d36e-43cf-8c2b-1a150aacc052.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This operation returned a completely separate DataFrame with meaningless column
    names. Let''s rename the columns so that we can explicitly access them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/4dffbd4f-2739-4cff-9b78-28b679065e88.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the indexing operator directly after the `str` accessor to select the first
    character from the `Sex` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/d243cb22-19e7-43dc-a3cc-96fb06022077.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the `pd.concat` function to concatenate this DataFrame with `wl_melt` to
    produce a tidy dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/cb920c05-8091-49c8-b933-746cafedeef4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This same result could have been created with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `weightlifting` dataset, like many datasets, has easily digestible information
    in its raw form, but technically, it is messy, as all but one of the column names
    contain information for sex and age. Once the variables are identified, we can
    begin to tidy the dataset. Whenever column names contain variables, you will need
    to use the `melt` (or `stack`) method. The `Weight Category` variable is already
    in the correct position so we keep it as an identifying variable by passing it
    to the `id_vars` parameter. Note that we don't explicitly need to name all the
    columns that we are melting with `value_vars`. By default, all the columns not
    present in `id_vars` get melted.
  prefs: []
  type: TYPE_NORMAL
- en: The `sex_age` column needs to be parsed, and split into two variables. For this,
    we turn to the extra functionality provided by the `str` accessor, only available
    to Series (a single DataFrame column). The `split` method is one of the more common
    methods in this situation, as it can separate different parts of the string into
    their own column. By default, it splits on an empty space, but you may also specify
    a string or regular expression with the `pat` parameter. When the `expand` parameter
    is set to `True`, a new column forms for each independent split character segment.
    When `False`, a single column is returned, containing a list of all the segments.
  prefs: []
  type: TYPE_NORMAL
- en: After renaming the columns in step 4, we need to use the `str` accessor again.
    Interestingly enough, the indexing operator is available to select or slice segments
    of a string. Here, we select the first character, which is the variable for sex.
    We could go further and split the ages into two separate columns for minimum and
    maximum age, but it is common to refer to the entire age group in this manner,
    so we leave it as is.
  prefs: []
  type: TYPE_NORMAL
- en: Step 6 shows one of two different methods to join all the data together. The
    `concat` function accepts a collection of DataFrames and either concatenates them
    vertically (`axis='index'`) or horizontally (`axis='columns'`). Because the two
    DataFrames are indexed identically, it is possible to assign the values of one
    DataFrame to new columns in the other as done in step 7.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another way to complete this recipe, beginning after step 2, is by directly
    assigning new columns from the `sex_age` column without using the `split` method.
    The `assign` method may be used to add these new columns dynamically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The `Sex` column is found in the exact same manner as done in step 5\. Because
    we are not using `split`, the `Age Group` column must be extracted in a different
    manner. The `extract` method uses a complex regular expression to extract very
    specific portions of the string. To use `extract` correctly, your pattern must
    contain capture groups. A capture group is formed by enclosing parentheses around
    a portion of the pattern. In this example, the entire expression is one large
    capture group. It begins with `\d{2}`, which searches for exactly two digits,
    followed by either a literal plus or minus, optionally followed by two more digits.
    Although the last part of the expression, `(?:\d{2})?`, is surrounded by parentheses,
    the `?:`  denotes that it is not actually a capture group. It is technically a
    non-capturing group used to express two digits together as optional. The `sex_age`
    column is no longer needed and is dropped. Finally, the two tidy DataFrames are
    compared against one another and are found to be equivalent.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Refer to the site *Regular-Expressions.info* for more on non-capturing groups
    ([http://bit.ly/2f60KSd](http://www.regular-expressions.info/brackets.html))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tidying when multiple variables are stored as column values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Tidy datasets must have a single column for each variable. Occasionally, multiple
    variable names are placed in a single column with their corresponding value placed
    in another. The general format for this kind of messy data is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/42ccf8cc-1772-41ed-978d-baeb3c6042db.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this example, the first and last three rows represent two distinct observations
    that should each be rows. The data needs to be pivoted such that it ends up like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8bbcb829-f145-419a-b236-d56c301bed4b.png)'
  prefs: []
  type: TYPE_IMG
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we identify the column containing the improperly structured
    variables and pivot it to create tidy data.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the restaurant `inspections` dataset, and convert the `Date` column
    data type to `datetime64`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/c0cb0612-2512-4bf6-b4c7-fe701add7627.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This dataset has two variables, `Name` and `Date`, that are each correctly
    contained in a single column. The `Info` column itself has five different variables: `Borough`,
    `Cuisine`, `Description`, `Grade`, and `Score`. Let''s attempt to use the `pivot`
    method to keep the `Name` and `Date` columns vertical, create new columns out
    of all the values in the `Info` column, and use the `Value` column as their intersection:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Unfortunately, pandas developers have not implemented this functionality for
    us. There is a good chance that in the future, this line of code is going to work.
    Thankfully, for the most part, pandas has multiple ways of accomplishing the same
    task. Let''s put `Name`, `Date`, and `Info` into the index:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/8cc902d7-4f90-45e4-9e77-c46bb9f9bad2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use the `unstack` method to pivot all the values in the `Info` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/1d9dc70a-4ba4-4c52-baaa-0885be04978e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Make the index levels into columns with the `reset_index` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/43f33846-bc71-4616-8bef-0479a9369591.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The dataset is tidy, but there is some annoying leftover pandas debris that
    needs to be removed. Let''s use the MultiIndex method `droplevel` to remove the
    top column level and then rename the index level to `None`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/03216f24-010c-4470-996c-1d5f4f3f575c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The creation of the column MultiIndex in step 4 could have been avoided by
    converting that one column DataFrame into a Series with the `squeeze` method.
    The following code produces the same result as the previous step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In step 1, we notice that there are five variables placed vertically in the
    `Info` column with their corresponding value in the `Value` column. Because we
    need to pivot each of these five variables as horizontal column names, it would
    seem that the `pivot` method would work. Unfortunately, pandas developers have
    yet to implement this special case when there is more than one non-pivoted column.
    We are forced to use a different method.
  prefs: []
  type: TYPE_NORMAL
- en: The `unstack` method also pivots vertical data, but only for data in the index.
    Step 3 begins this process by moving both the columns that will and will not be
    pivoted into the index with the `set_index` method. Once these columns are in
    the index, `unstack` can be put to work as done in step 3.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that as we are unstacking a DataFrame, pandas keeps the original column
    names (here, it is just a single column, `Value`) and creates a MultiIndex with
    the old column names as the upper level. The dataset is now essentially tidy but
    we go ahead and make our non-pivoted columns normal columns with the `reset_index`
    method. Because we have MultiIndex columns, we can choose which level the new
    column names will belong to with the `col_level` parameter. By default, the names
    are inserted into the uppermost level (level 0). We use `-1` to indicate the bottommost
    level.
  prefs: []
  type: TYPE_NORMAL
- en: After all this, we have some excess DataFrame names and indexes that need to
    be discarded. Unfortunately, there isn't a DataFrame method that can remove levels,
    so we must drop down into the index and use its `droplevel` method. Here, we overwrite
    the old MultiIndex columns with single-level columns. These columns still have
    a useless name attribute, `Info`, which is renamed to `None`.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up the MultiIndex columns could have been avoided by forcing the resulting
    DataFrame from step 3 to a Series. The `squeeze` method works only on single-column
    DataFrames and turns them into Series.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is actually possible to use the `pivot_table` method, which has no restrictions
    on how many non-pivoted columns are allowed. The `pivot_table` method differs
    from `pivot` by performing an aggregation for all the values that correspond to
    the intersection between the columns in the `index` and `columns` parameters.
    Because it is possible that there are multiple values in this intersection, `pivot_table`
    requires the user to pass it an aggregating function, in order to output a single
    value. We use the `first` aggregating function, which takes the first of the values
    of the group. In this particular example, there is exactly one value for each
    intersection, so there is nothing to be aggregated. The default aggregation function
    is the mean, which will produce an error here since some of the values are strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pandas official documentation of the `droplevel` ([http://bit.ly/2yo5BXf](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.MultiIndex.droplevel.html))
    and `squeeze` ([http://bit.ly/2yo5TgN](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.squeeze.html))
    methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tidying when two or more values are stored in the same cell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tabular data, by nature, is two-dimensional, and thus, there is a limited amount
    of information that can be presented in a single cell. As a workaround, you will
    occasionally see datasets with more than a single value stored in the same cell.
    Tidy data allows for exactly a single value for each cell. To rectify these situations,
    you will typically need to parse the string data into multiple columns with the
    methods from the `str` Series accessor.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we examine a dataset that has a column containing multiple different
    variables in each cell. We use the `str` accessor to parse these strings into
    separate columns to tidy the data.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the Texas `cities` dataset, and identify the variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/31a2b314-702f-4cca-b436-cd0d8fdc701c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `City` column looks good and contains exactly one value. The `Geolocation`
    column, on the other hand, contains four variables: `latitude`, `latitude direction`,
    `longitude`, and `longitude direction`. Let''s split the `Geolocation` column
    into four separate columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/5264d585-9f44-4741-9b3e-c87b9bd36cb9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Because the original data type for the `Geolocation` was an object, all the
    new columns are also objects. Let''s change `latitude` and `longitude` into floats:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Concatenate these new columns with the `City` column from the original:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/d64eada2-828f-45a4-bf44-27938354fa58.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After reading the data, we decide how many variables there are in the dataset.
    Here, we chose to split the `Geolocation` column into four variables, but we could
    have just chosen two for latitude and longitude and used a negative sign to differentiate
    between west/east and south/north.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few ways to parse the `Geolocation` column with the methods from
    the `str` accessor. The easiest way is to use the `split` method. We pass it a
    simple regular expression defined by any character (the period) and a space. When
    a space follows any character, a split is made, and a new column is formed. The
    first occurrence of this pattern takes place at the end of the latitude. A space
    follows the degree character, and a split is formed. The splitting characters
    are discarded and not kept in the resulting columns. The next split matches the
    comma and space following directly after the latitude direction.
  prefs: []
  type: TYPE_NORMAL
- en: A total of three splits are made, resulting in four columns. The second line
    in step 2 provides them with meaningful names. Even though the resulting `latitude`
    and `longitude` columns appear to be floats, they are not. They were originally
    parsed from an object column and therefore remain object data types. Step 3 uses
    a dictionary to map the column names to their new types.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of using a dictionary, which would require a lot of typing if you had
    many column names, you can use the function `to_numeric` to attempt to convert
    each column to either integer or float. To apply this function iteratively over
    each column, use the `apply` method with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Step 4 concatenates the city to the front of this new DataFrame to complete
    the process of making tidy data.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `split` method worked exceptionally well in this example with a simple
    regular expression. For other examples, some columns might require you to create
    splits on several different patterns. To search for multiple regular expressions,
    use the pipe character `|`. For instance, if we wanted to split only the degree
    symbol and comma, each followed by a space, we would do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: This returns the same DataFrame from step 2\. Any number of additional split
    patterns may be appended to the preceding string pattern with the pipe character.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `extract` method is another excellent method which allows you to extract
    specific groups within each cell. These capture groups must be enclosed in parentheses.
    Anything that matches outside the parentheses is not present in the result. The
    following line produces the same output as step 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: This regular expression has four capture groups. The first and third groups
    search for at least one or more consecutive digits with decimals. The second and
    fourth groups search for a single character (the direction). The first and third
    capture groups are separated by any character followed by a space. The second
    capture group is separated by a comma and then a space.
  prefs: []
  type: TYPE_NORMAL
- en: Tidying when variables are stored in column names and values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One particularly difficult form of messy data to diagnose appears whenever variables
    are stored both horizontally across the column names and vertically down column
    values. You will typically encounter this type of dataset, not in a database,
    but from a summarized report that someone else has already generated.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, variables are identified both vertically and horizontally and
    reshaped into tidy data with the `melt` and `pivot_table` methods.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the `sensors` dataset and identify the variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/282dc5ee-23e7-4efb-aaa3-f0dc2d4a047f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The only variable placed correctly in a vertical column is `Group`. The `Property`
    column appears to have three unique variables, `Pressure`, `Temperature`, and
    `Flow`. The rest of the columns `2012` to `2016` are themselves a single variable,
    which we can sensibly name `Year`. It isn''t possible to restructure this kind
    of messy data with a single DataFrame method. Let''s begin with the `melt` method
    to pivot the years into their own column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/0d2b310a-19e4-4cb7-87c8-d0c052a7e68a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This takes care of one of our issues. Let''s use the `pivot_table` method to
    pivot the `Property` column into new column names:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/10329c01-746c-4fdd-8402-a4fa284c0286.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we have identified the variables in step 1, we can begin our restructuring.
    Pandas does not have a method to pivot columns simultaneously, so we must take
    on this task one step at a time. We correct the years by keeping the `Property`
    column vertical by passing it to the `id_vars` parameter in the `melt` method.
  prefs: []
  type: TYPE_NORMAL
- en: The result is now precisely the pattern of messy data found in the preceding
    recipe, *Tidying when multiple variables are stored as column values.* As explained
    in the *There's more* section of that recipe, we must use `pivot_table` to pivot
    a DataFrame when using more than one column in the `index` parameter. After pivoting,
    the `Group` and `Year` variables are stuck in the index. We push them back out
    as columns. The `pivot_table` method preserves the column name used in the `columns`
    parameter as the name of the column index. After resetting the index, this name
    is meaningless, and we remove it with `rename_axis`.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Whenever a solution involves `melt`, `pivot_table`, or `pivot`, you can be
    sure that there is an alternative method using `stack` and `unstack`. The trick
    is first to move the columns that are not currently being pivoted into the index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: Tidying when multiple observational units are stored in the same table
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is generally easier to maintain data when each table contains information
    from a single observational unit. On the other hand, it can be easier to find
    insights when all data is in a single table, and in the case of machine learning,
    all data must be in a single table. The focus of tidy data is not on directly
    performing analysis. Rather, it is structuring the data so that analysis is easier
    further down the line, and when there are multiple observational units in one
    table, they may need to get separated into their own tables.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we use the `movie` dataset to identify the three observational
    units (movies, actors, and directors) and create separate tables for each. One
    of the keys to this recipe is understanding that the actor and director Facebook
    likes are independent of the movie. Each actor and director is mapped to a single
    value representing their number of Facebook likes. Due to this independence, we
    can separate the data for the movies, directors, and actors into their own tables.
    Database folks call this process normalization, which increases data integrity
    and reduces redundancy.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the altered `movie` dataset, and output the first five rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/b97a1df3-edb5-4e9c-8a1d-56e74387c59c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This dataset contains information on the movie itself, the director, and actors.
    These three entities can be considered observational units. Before we start, let''s
    use the `insert` method to create a column to uniquely identify each movie:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/764642b0-57b7-450a-aa3d-ec0fb80d040f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s attempt to tidy this dataset with the `wide_to_long` function to put
    all the actors in one column and their corresponding Facebook likes in another,
    and do the same for the director, even though there is only one per movie:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/db2fb0dd-88b9-4ca5-8d58-a1a47e5fcd3a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The dataset is now ready to be split into multiple smaller tables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/5ea1387e-c719-46d4-91ab-dddbda8d76b3.png)  ![](img/fc4648c2-7958-4413-8d1c-71a644b02675.png) 
    ![](img/393e3f43-5347-419b-89f6-e5b2cdebdf0c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There are still several issues with these tables. The `movie` table duplicates
    each movie three times, the director table has two missing rows for each ID, and
    a few movies have missing values for some of the actors. Let''s take care of these
    issues:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/5fff55d4-6424-4a23-a31e-9b3811062ec7.png)    ![](img/f2c340d0-bc16-4d3f-9b3e-e985172fe4d6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that we have separated the observational units into their own tables, let''s
    compare the memory of the original dataset with these three tables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'Our new tidier data actually takes up a little more memory. This is to be expected,
    as all the data in the original columns are simply spread out into the new tables.
    The new tables also each have an index, and two of them have an extra `num` column,
    which accounts for the extra memory. We can, however, take advantage of the fact
    that the count of Facebook likes is independent of the movie, meaning that each
    actor and director has exactly one count of Facebook likes for all movies. Before
    we can do this, we need to create another table mapping each movie to each actor/director.
    Let''s first create `id` columns specific to the actor and director tables, uniquely
    identifying each actor/director:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/daf3c29d-7671-482c-8238-fba2bbcbf5aa.png)   ![](img/216498c9-7f00-499c-8364-15e4062a925e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can use these tables to form our intermediate tables and unique `actor`/`director`
    tables. Let''s first do this with the `director` tables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/70bc3432-dfb3-4c38-8d3f-70bc9c0be26a.png)     ![](img/820a26f7-83b9-4d2c-b109-513beb3c607a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s do the same thing with the `actor` table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/0a2222e9-0cb6-4351-922d-21aab964aee2.png)    ![](img/e577a0e7-455c-4a7d-8abf-6863ea069432.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s find out how much memory our new tables consume:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have normalized our tables, we can build an entity-relationship
    diagram showing all the tables (entities), columns, and relationships. This diagram
    was created with the easy to use ERDPlus ([https://erdplus.com](https://erdplus.com/#/)):![](img/272f2599-5e7a-4001-94e9-90eb430ba6d7.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After importing the data and identifying the three entities, we must create
    a unique identifier for each observation so that we can link to the movies, actors
    and directors together once they have been separated into different tables. In
    step 2, we simply set the ID column as the row number beginning from zero. In
    step 3, we use the `wide_to_long` function to simultaneously `melt` the `actor`
    and `director` columns. It uses the integer suffix of the columns to align the
    data vertically and places this integer suffix in the index. The parameter `j`
    is used to control its name. The values in the columns not in the `stubnames`
    list repeat to align with the columns that were melted.
  prefs: []
  type: TYPE_NORMAL
- en: In step 4, we create our three new tables, keeping the `id` column in each.
    We also keep the `num` column to identify the exact `director`/`actor` column
    from which it was derived. Step 5 condenses each table by removing duplicates
    and missing values.
  prefs: []
  type: TYPE_NORMAL
- en: After step 5, the three observational units are in their own tables, but they
    still contain the same amount of data as the original (and a bit more), as seen
    in step 6\. To return the correct number of bytes from the `memory_usage` method
    for `object` data type columns, you must set the `deep` parameter to `True`.
  prefs: []
  type: TYPE_NORMAL
- en: Each actor/director needs only one entry in his or her respective tables. We
    can't simply make a table of just actor name and Facebook likes, as there would
    be no way to link the actors back to the original movie. The relationship between
    movies and actors is called a **many-to-many relationship**. Each movie is associated
    with multiple actors, and each actor can appear in multiple movies. To resolve
    this relationship, an intermediate or associative table is created, which contains
    the unique identifiers (**primary keys**) of both the movie and actor.
  prefs: []
  type: TYPE_NORMAL
- en: To create associative tables, we must uniquely identify each actor/director.
    One trick is to create a categorical data type out of each actor/director name
    with `pd.Categorical`. Categorical data types have an internal map from each value
    to an integer. This integer is found in the `codes` attribute, which is used as
    the unique ID. To set up the creation of the associative table, we add this unique
    ID to the `actor`/`director` tables.
  prefs: []
  type: TYPE_NORMAL
- en: Step 8 and step 9 create the associative tables by selecting both of the unique
    identifiers. Now, we can reduce the `actor` and `director` tables to just the
    unique names and Facebook likes. This new arrangement of tables uses 20% less
    memory than the original. Formal relational databases have entity-relationship
    diagrams to visualize the tables. In step 10, we use the simple ERDPlus tool to
    make the visualization, which greatly eases the understanding of the relationships
    between the tables.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is possible to recreate the original `movie` table by joining all the tables
    back together. First, join the associative tables to the `actor`/`director` tables.
    Then pivot the num column, and add the column prefixes back:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/ba4a5426-19e4-4531-b181-647f0192e0df.png)![](img/c3b43d8b-89fd-4066-8431-9f8ded3783f7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'These tables can now be joined together with `movie_table`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: More on database normalization ([http://bit.ly/2w8wahQ](https://en.wikipedia.org/wiki/Database_normalization)),
    associative tables ([http://bit.ly/2yqE4oh](https://en.wikipedia.org/wiki/Associative_entity)),
    and primary and foreign keys ([http://bit.ly/2xgIvEb](https://en.wikipedia.org/wiki/Unique_key))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the *Stacking multiple groups of variables simultaneously* recipe in
    this chapter for more information on the `wide_to_long` function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
