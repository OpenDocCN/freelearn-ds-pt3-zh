- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why Time Series Analysis?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter delves into the practical significance of analyzing time-dependent
    data. It elucidates how time series analysis enables predictive modeling, trend
    identification, and anomaly detection. By illustrating real-world applications
    across industries, the chapter emphasizes the critical role of temporal insights
    in decision-making. Grasping the importance of time series analysis is crucial
    for professionals, as it highlights the impact on forecasting accuracy, resource
    optimization, and strategic planning, fostering a comprehensive appreciation for
    the utility of time-oriented data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The need for time series analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Industry-specific use cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hands-on with selected use cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Following the first chapter, we will go one notch up with the code here. The
    objective will be to showcase the use of time series for selected use cases. The
    code for this chapter can be found in the `ch2` folder of the GitHub repository
    of this book: https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/tree/main/ch2.'
  prefs: []
  type: TYPE_NORMAL
- en: Refer to this GitHub repository for the latest revisions of the code, which
    will be commented on if updated post-publication from what is presented in the
    code sections of this book.
  prefs: []
  type: TYPE_NORMAL
- en: The hands-on section of this chapter will go into further detail.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the need for time series analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed in the previous chapter, time series are present in all avenues
    of life and across all industries. Hence, the need for analyzing time series is
    everywhere. We will explore the different use cases for different industries in
    this chapter. Before we get to that, in this section, we will look at the underlying
    approaches. These can be broadly categorized as forecasting, pattern detection
    and categorization, and anomaly detection. *Figure 2**.1* shows several key time
    series analysis concepts that will be discussed in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18568_02_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: Concepts in time series analysis'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now go into further detail on each of these.
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Forecasting time series is the prediction of future values based on previously
    observed values. This is achieved by modeling the underlying patterns in the time
    series data – such as trends, seasonality, and cycles – to make predictions about
    future data points. For example, in the case of the temperature time series we
    visualized in *Chapter 1*, we can use forecasting models to predict next month’s
    temperatures based on the pattern learned from previous months. Forecasting is
    the most common approach used for time series analysis, and we will spend the
    most time on it in this book. This can be single-step, multi-step, univariate,
    or multivariate.
  prefs: []
  type: TYPE_NORMAL
- en: Single-step forecasting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With single-step forecasting, we predict the next occurrence in the time series
    based on our analysis of the historical data points, and the model built accordingly.
    The granularity of the step is usually the same as in the dataset from which we
    are learning the historical patterns. For example, if in our historical time series,
    we have daily temperatures, then the next step will be the next day. If we have
    aggregated the data points to, for example, monthly averages, and modeled the
    pattern of monthly changes, then the next step will be the average temperature
    for the next month.
  prefs: []
  type: TYPE_NORMAL
- en: While single-step forecasting is usually the most reliable forecast we can get,
    it is, unfortunately, insufficient for many requirements because, in real life,
    we plan way more ahead than just one (time) step at a time. If we are doing daily
    forecasts, we want to forecast not just for tomorrow. We want to predict days,
    weeks, and even months into the future. A single step is just not sufficient for
    planning.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-step forecasting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With muti-step forecasting, we predict multiple next steps in the time series
    using the model built from the historical data points. We also use the forecasted
    prior steps as input. With our daily temperature example, this could mean forecasting
    day by day for the entire upcoming week.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The challenge with multi-step forecasting is that further predictions are built
    upon prior predictions, which contrasts with single-step forecasting, where predictions
    are based on actual data points. Practically, this means recursively applying
    the forecasting algorithm one step at a time, each step adding the forecast to
    the dataset, and using the historical and forecasted data points to predict the
    next step. Hence, inaccuracies in the forecast are cumulated further and further
    as we go each step into the future.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: This cumulation of forecasting errors with multi-step forecasting is the kind
    of limitation you want to be upfront about with the business or anyone you are
    building the forecast for. You want to be sure to set the expectations on longer-term
    forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: Solutions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There are a few ways to address the multi-step forecast challenge, besides
    limiting it to a very short horizon:'
  prefs: []
  type: TYPE_NORMAL
- en: First and foremost, build as accurate a model as possible so that the initial
    step forecasted is close to reality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another approach is to use a combination of models, aiming to average out the
    forecasting errors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, limit the forecasting interval or number of steps and recalculate the
    forecast when new measurements come in
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Univariate forecasting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, with the temperature time series in [*Chapter 1*](B18568_01.xhtml#_idTextAnchor016),
    we have considered only one variable (univariate) at a time, that is, the temperature
    at a specific location. Another example of a univariate time series, this time
    in the economic sector, is the rate of unemployment for a specific region or country.
    A single time series is univariate by definition, be it for temperature or unemployment
    rate. In real-world scenarios, the requirement is likely going to be to forecast
    multiple time series at the same time so that we can get a more comprehensive
    view of the future than just one time series can give us. In the case of temperature,
    this can mean taking multiple locations into account or additionally forecasting
    the level of pollutants in the air. For economic forecasting, it can be about
    forecasting the **Gross Domestic Product** (**GDP**) in addition to the level
    of unemployment. This leads us to multivariate forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: Multivariate forecasting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'While univariate is about a single time series, there are a couple of ways
    to characterize multivariate forecasting:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multiple input** dimensions are the case when we provide several variables
    (time series and non time series) as input to the forecasting model – for example,
    using past temperatures and pollutant levels to predict future temperatures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multiple output** prediction uses the forecasting model to predict multiple
    variables. With the preceding temperature example, this means forecasting both
    the temperature and the pollutant level.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we have seen with the preceding examples, there can be several scenarios
    with multiple time series. These series can be **correlated**, and if they have
    the same underlying cause (which can itself be represented by yet another time
    series), can have **co-movement**. They can have **causal dependency**, where
    one time series has a causality relationship to another. They can also be **independent**,
    and we just predict them simultaneously. We will address some of these considerations
    in [*Chapter 6*](B18568_06.xhtml#_idTextAnchor116) on exploratory data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, forecasting is rarely done in isolation, and the number of time
    series that we need to analyze at the same time can be in the hundreds or even
    thousands. This need to scale to multiple time series is a good reason to use
    a parallel execution tool such as Apache Spark, as we will see in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have discussed forecasting, let’s see another type of analysis,
    which will enable us to classify time series.
  prefs: []
  type: TYPE_NORMAL
- en: Pattern detection and categorization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pattern detection and categorization is about identifying and classifying time
    series based on certain patterns. In general, time series follow a certain pattern,
    which we can identify and label. These labels allow us to classify time series
    by matching the labeled pattern to new occurrences of time series. We can follow
    different approaches to achieve this, broadly categorized as distance-based, interval-based,
    frequency-based, dictionary-based, shapelets, ensembles, and deep learning. These
    approaches will now be detailed.
  prefs: []
  type: TYPE_NORMAL
- en: Distance-based
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Distance-based time series classification using **k-Nearest Neighbors** (**kNN**)
    and **Dynamic Time Warping** (**DTW**), which will be explained here, is a proven
    method for analyzing time-sequential data. Due to shifts and distortions in time
    series data, standard Euclidean distance is a poor metric for similarity measurement.
    DTW offers an alternative by aligning the sequences in time. It calculates the
    minimum distance between two time series, considering all possible alignments,
    which makes it compute-intensive. kNN is then used to classify the time series
    based on the similarity of their shapes.
  prefs: []
  type: TYPE_NORMAL
- en: The following chart shows the outcome of DTW to calculate the distance between
    the shares of Google (lower, black) and Amazon, and the shares of Google and Meta.
    We will execute this example in the hands-on section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18568_02_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: DTW distance (GOOG – black line)'
  prefs: []
  type: TYPE_NORMAL
- en: Interval-based
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With this approach, the time series is first partitioned into intervals, for
    which descriptive statistics are calculated. These intervals are then used as
    feature vectors together with classifiers such as random forests or support vector
    machines. The advantage of this method is that it captures the properties of time
    series over different phases, which works well for time series with non-uniform
    patterns over time. This summarization of the time series into intervals with
    statistical features is also a great way to reduce complexity and improve interpretability.
  prefs: []
  type: TYPE_NORMAL
- en: Frequency-based
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This classification method, such as **Random Interval Spectral Ensemble** (**RISE**),
    involves first transforming the time series to the frequency domain, using, for
    example, the Fourier transform. RISE is an ensemble approach based on classifiers,
    such as decision trees, built from random intervals and spectral features extracted
    for these intervals. The advantage of this method is in identifying frequency-related
    or periodic characteristics, and as an ensemble approach, it is robust while providing
    accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Dictionary-based
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Dictionary-based time series classification methods convert time series into
    symbolic representations, allowing the use of text-based techniques for classification.
    Prominent methods following this approach are these:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bag of Patterns** (**BoP**): BoP creates a “bag” of patterns by applying
    a sliding window to capture local patterns. This is then hashed into a frequency
    histogram, which is used as the feature vector for classification.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bag of SFA Symbols** (**BOSS**): BOSS is a variation that is more robust
    to noise and effective at capturing key patterns. It uses **Symbolic Fourier Approximation**
    (**SFA**) to capture the time series at different resolutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RandOm Convolutional KErnel Transform** (**ROCKET**): ROCKET offers further
    speed and efficiency for large datasets. It generates and uses random convolutional
    kernels to convert time series into feature vectors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shapelets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: These are sub-sequences within the time series, which are representative of
    class-specific patterns. By finding shapelets that match within the time series
    or another correlated time series, it is possible to classify the time series
    accordingly. This works well when the class-defining features are localized in
    time – for example, a sudden spike in transaction amount, which could correspond
    to a credit card theft. Shapelets can also help with interpretability—once it
    is well understood, a shapelet can be used to explain the time series at the points
    in time where they match.
  prefs: []
  type: TYPE_NORMAL
- en: Ensembles
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The ensemble classification methods mentioned so far group a similar type of
    classifier. Another approach, such as the **Hierarchical Vote Collective of Transformation-based
    Ensembles** (**HIVE-COTE**), is with different types of classifiers. The idea
    is to have an ensemble based on different aspects of the time series as captured
    by the different nature of classifiers used. These are trained independently,
    and the predictions are combined based on a hierarchical voting method. As with
    other ensemble methods, this can yield greater robustness and accuracy. Also,
    due to the various techniques used, HIVE-COTE is a good candidate for complex
    multi-pattern time series. This does, however, come with a high compute cost.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Methods such as **TimeNet** leverage deep neural networks to automatically extract
    features, patterns, and relationships within time series. TimeNet is pre-trained,
    which makes it quickly usable. It combines layers of **Convolutional Neural Networks**
    (**CNNs**) for local features and **Recurrent Neural Networks** (**RNNs**) for
    sequential patterns. This allows TimeNet to capture both low-level and high-level
    patterns, effectively learning the hierarchical representation. The benefit is
    adaptability to various time series classification problems while limiting the
    need for manual feature engineering. The cons, similar to other deep learning
    approaches, are the high volume of data needed for pre-training, the computing
    resources required, and the lack of interpretability. Despite these, they are
    state-of-the-art in performance in several complex cases.
  prefs: []
  type: TYPE_NORMAL
- en: While we will not spend as much time on the classification of time series in
    this book as on forecasting, this is a promising area for further research, together
    with its own set of operational challenges.
  prefs: []
  type: TYPE_NORMAL
- en: This brings us to the final type of analysis, which is about detecting anomalies
    from time series data.
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The third category of use cases for time series analysis is anomaly detection,
    which is about flagging unexpected patterns or occurrences. While this is related
    to pattern detection and forecasting, the purpose here is different: to identify
    an unexpected deviation in the behavior of the source system. Anomaly detection
    is crucial in various domains, such as finance, healthcare, and industrial systems.
    These anomalies can be indicative of critical incidents, such as system failures,
    financial fraud, or network intrusions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to being uni- or multivariate, an anomaly can be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Point**: This is the case when a single data point is identified as an anomaly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Collective**: It can be that multiple data points as a group of near measurements
    are all flagged'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Contextual**: A data point or a collective can be anomalous in the context
    of surrounding measurements, and the same point or collective may not be an issue
    in another context'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anomalies can also be distinguished as outliers and novelties, where outliers
    may indicate errors or faults, and novelties are previously unseen patterns that
    may not be problematic.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: For anomaly detection to work, the prior data preparation stage must keep the
    outliers in the dataset, which is the opposite of what is usually done during
    the data curation process.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to traditional statistical and rule-based approaches, there are
    newer machine learning techniques. The methods for anomaly detection in time series
    data can be categorized into unsupervised, supervised, and semi-supervised approaches,
    each with its own set of techniques and algorithms. An anomaly score is usually
    calculated with a threshold configured to flag anomalies.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised anomaly detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Unsupervised anomaly detection does not need labeled data. This assumes that
    anomalies are different enough from the normal that they can be detected without
    prior knowledge. Common methods include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Statistical** methods such as **z-score** and **box plot analysis** are used
    to identify outliers based on statistical properties'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clustering-based** methods such as **DBSCAN** or **k-means** cluster similar
    data points, with anomalies as points that do not fit into any cluster'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Density-based** methods such as kNN and **Local Outlier Factor** (**LOF**)
    use the density of the local neighborhood to identify anomalies'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Isolation forest** is a tree-based model that works well for high-dimensional
    data, isolating anomalies'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The chart in *Figure 2**.3* shows the outcome of an isolation forest model,
    used to detect anomalies in a household’s energy consumption.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18568_02_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: Anomaly detection on energy consumption'
  prefs: []
  type: TYPE_NORMAL
- en: The model was fitted to consumption data up to November 9 and thereafter used
    on previously unseen data in the box. The anomalies are shown in red/paler color.
    We will run this example in the hands-on section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised anomaly detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Supervised anomaly detection works with a labeled dataset having both normal
    and anomalous cases. Better at detecting anomalies, it does, however, require
    labeled data, which can be difficult to obtain. Techniques include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Classification models** such as traditional classifiers such as logistic
    regression, **Support Vector Machines** (**SVMs**), or more complex models such
    as CNNs and RNNs, trained to distinguish between normal and anomalous instances'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ensemble methods** such as random forest or gradient boosting can be used
    with improved detection accuracy as they combine multiple models'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-supervised anomaly detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Semi-supervised anomaly detection needs a smaller amount of labeled data together
    with a larger set of unlabeled data. An example is the case of industrial monitoring
    when we have limited data points from sensor readings. These measurements correspond
    mostly to normal operations of the equipment and can be labeled as such. New readings
    falling out of the normal label can then be flagged as anomalous.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also useful when labeling a large dataset is expensive, semi-supervised techniques
    include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Modifying unsupervised techniques to include the limited available labels –
    for example, modifying density-based or clustering methods for added sensitivity
    to labeled anomalies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Novelty detection** trains a model on the normal data to find its distribution,
    akin to unsupervised statistical approaches, and then deviation from this distribution
    is flagged. One-class SVMs and autoencoders are examples of techniques in this
    case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced deep learning methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Methods using deep learning techniques include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Autoencoders** are neural networks that compress and then reconstruct the
    input data. The idea is that these models will reconstruct normal data well and
    have higher reconstruction errors with anomalous data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequence types of models such as **Long Short-Term Memory** (**LSTM**), **RNNs**,
    and **Transformers** identify temporal dependencies in time series data, hence
    are useful for anomaly detection in sequences.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: From an operational point of view, an anomaly detection system is part of a
    comprehensive monitoring and alerting architecture. Note that Kalman filters are
    used in cases where low-latency or real-time detection and alerting are required.
  prefs: []
  type: TYPE_NORMAL
- en: This summarizes the various methods for anomaly detection. The choice of method
    for anomaly detection depends on the characteristics of the time series and anomalies
    that need to be detected, the availability of labeled data, the computational
    resources available, and the requirement for real-time detection. Hybrid and advanced
    methods, especially those based on deep learning, have shown promising results
    in various applications due to their ability to model complex patterns and dependencies
    in time series data.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on from an overview of the landscape of time series analysis, let’s now
    consider how they are used and their impact in various sectors.
  prefs: []
  type: TYPE_NORMAL
- en: Industry-specific use cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We looked at different types of time series analysis in the previous section.
    The question remains on their applicability across different sectors, which we
    will now dive into. But before we do that, the chart in *Figure 2**.4* gives you
    a sense of the multitude of applications across industries.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18568_02_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Application of time series analysis across industries'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the application of time series analysis in each of these sectors
    in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Financial services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Time series analysis in financial services is crucial for understanding trends,
    patterns, and future behaviors. The applications are diverse, offering valuable
    insights for decision-making, strategic planning, risk management, and regulatory
    compliance. The following is how time series analysis is used across various functions
    within financial services:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Market analysis**: The future prices of assets are forecast by analyzing
    their historical prices, including trends and seasonality. This helps traders
    and investors decide on which asset to trade and when.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Risk management**: In addition to the preceding, another important aspect
    of financial instruments’ prices is their volatility, which needs to be analyzed
    to better manage risks and design mitigation strategies. This includes **Value
    at Risk** (**VaR**) modeling, which estimates the potential loss for an investment
    over a period based on historical volatility and correlations. Another area of
    risk management is credit risk, which covers time series data on repayment histories,
    defaults, and economic conditions. This helps assess the likelihood of future
    defaults and losses. The counter to this, estimation for provisioning, ensures
    enough funds are set aside to cover potential loan losses, while liquidity management
    ensures sufficient liquidity is maintained. Finally, at the macro-economic level,
    stress testing involves analyzing historical worst-case scenarios.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Portfolio management**: The two main aspects here are optimizing asset allocation
    and related performance evaluation of the portfolio. By analyzing the historical
    returns and correlations between assets, portfolio managers can define the asset
    allocation to meet the desired risk-return profiles. Looking back at their performance
    over time, the portfolio can then be adjusted as needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Algorithmic trading**: At its core, this involves using time series data
    on a microseconds or milliseconds scale to make high-frequency trading decisions.
    The complete cycle includes developing strategies, doing backtesting, and then,
    once strategies are in active use, generating the correct signals for trading.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fraud detection**: The idea here is to analyze transactions to identify and
    flag patterns that could indicate fraudulent activities, including market manipulation
    or insider trading.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Economic forecasting**: This is used to project, for example, interest rates
    and other economic indicators with an impact on policymaking by central banks,
    governments, and financial institutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In essence, time series analysis in financial services is foundational to support
    a wide range of activities, from trading decisions to portfolio management and
    regulatory compliance. It leverages historical data to forecast future events,
    manage risks, and uncover valuable insights. Thus, time series analysis drives
    informed decision-making across the financial ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: Retail
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Time series analysis in the retail industry uses chronological data for decision-making,
    to optimize operations, and to enhance customer experiences. Retailers can gain
    insights into trends, seasonal variations, and cyclical behaviors that affect
    their business. The following are some of the key use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sales forecasting and revenue prediction**: Predicting future sales based
    on historical data, considering seasonal variations, trends, and external factors
    such as holidays and economic conditions, helps plan inventory, staffing, and
    marketing activities. This is crucial for financial planning and investment decisions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inventory management and supply chain optimization**: Retailers can optimize
    stock levels by analyzing purchasing patterns and lead times. Better demand planning
    and scheduling of replenishment minimizes stockouts and reduces excess inventory.
    Forecasting can be done at each product level, facilitating efficient inventory
    replenishment. This has also a positive impact on supply chain management. A related
    use case in retail that is growing in adoption is food waste prediction and reduction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Price optimization and marketing planning**: Optimal pricing strategies over
    time, maximizing sales and profits, can be determined by analyzing the impact
    of price changes on sales volumes. This includes insight into seasonal price sensitivities,
    impacts of promotions and marketing campaigns, and competitive pricing. This also
    optimizes marketing spend, while better aligning to seasonal patterns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Customer behavior analysis and product life cycle management**: Retailers
    can inform marketing strategies and product development by understanding changes
    in customer buying habits over time. This analysis helps identify trends, such
    as changes in purchasing channels or increasing interest in product categories.
    This, in turn, improves decisions about product introductions, discontinuation,
    or relaunches. With better customer behavior analysis, it is also possible to
    develop effective loyalty projects, resulting in improved customer retention.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Store performance analysis and workforce planning**: By comparing the sales
    trends across different locations, this analysis identifies high-performing stores
    and those needing help. This informs decisions about store expansions or closures
    and aligns staffing levels to the right store and busy times. The impact here
    is both on operational efficiency and improved customer service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The use of time series analysis in retail influences every aspect of the business,
    from inventory and pricing to marketing and workforce management. By leveraging
    historical data, retailers can make informed decisions that enhance operational
    efficiency, customer satisfaction, and profitability.
  prefs: []
  type: TYPE_NORMAL
- en: Healthcare
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Time series analysis in healthcare is an essential tool for tracking health-related
    data over chronological intervals. This method allows for the observation of patterns,
    trends, and changes in health metrics, which can be critical in improving patient
    care, operational efficiency, and clinical outcomes. Here’s an overview of applications
    in healthcare:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Patient monitoring**: In the continuous monitoring of vital signs (heart
    rate, blood pressure, etc.), time series analysis can be used for real-time assessment
    of patient health and early detection of acute medical events. Similarly, by analyzing
    data from wearable devices, one can monitor trends in physical activity, sleep
    patterns, and other health indicators over time. This can be either in a clinical
    setting or for personal health awareness.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Epidemiology and disease surveillance**: The significance of this requirement
    was highlighted by COVID-19\. The spread of infectious diseases must be tracked
    over time to understand transmission patterns, identify outbreaks, and plan public
    interventions accordingly. At the individual level, patients with a chronic disease
    may need to adjust their treatment plans based on the progression of the disease.
    Though similar, this is different from monitoring vitals in terms of the timescale
    of interventions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Management of hospital resources**: With most public hospitals stretched
    thin, it is a huge benefit to be able to predict hospital admission rates in order
    to optimize bed allocation and staffing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are numerous other applications of time series analysis in healthcare,
    such as healthcare quality monitoring, drug development, and medical research,
    and with the COVID-19 pandemic, public health monitoring, analysis, and policy-making.
  prefs: []
  type: TYPE_NORMAL
- en: By using time series analysis, the healthcare sector can enhance patient care,
    improve operational efficiencies, and contribute to medical research, ultimately
    leading to better health outcomes and more informed healthcare policies.
  prefs: []
  type: TYPE_NORMAL
- en: Manufacturing and utilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Time series analysis is important in the manufacturing and utilities sectors
    for ensuring safety, optimizing operations, and improving efficiency. Here’s an
    overview of its use cases in these industries:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Manufacturing**: First, in terms of planning, with demand forecasting, scheduling
    production, and inventory management, time series help meet market demand without
    overproduction. Then, to keep production going, machine sensors send data to predictive
    maintenance models to generate warnings of potential failures, resulting in prompt
    maintenance. This can significantly reduce downtime while saving on unnecessary
    preventive maintenance. Anomaly detection further helps with early detection and
    limitation of quality issues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Oil and gas**: As in manufacturing, predictive maintenance and anomaly detection
    ensure reduced downtime, while maximizing output. Also, with the significant upfront
    investment required in infrastructure in this sector, it is crucial to have good
    forecasting of demand and prices to guide planning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Utilities**: The primary use cases in the utilities sector are demand and
    load forecasting, which result in planning, grid management, and development.
    This further leads to optimal grid utilization, with improved customer service,
    while preventing outages. Finally, time series analysis and forecasting of new
    renewal energy sources ensures they can be optimally integrated into the overall
    energy mix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In all these sectors, time series analysis contributes to resource optimization,
    cost reduction, and strategic planning, ultimately leading to more resilient and
    efficient operations.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: A predominant and fast-growing source of time series data is **Internet of Things**
    (**IoT**) devices and sensors. This is due to the explosion in the number of connected
    devices. This data is collected, stored, and analyzed – usually in real time –
    with use cases across industries, some of which have been discussed, from machine
    sensor data used for predictive maintenance to energy meter data to forecast consumption
    to health trackers, and many more.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes the section on industry-specific use cases, on the many applications
    of time series analysis to different sectors of activity. The list is ever-expanding
    with frequent innovation on new use cases, driven by new analysis methods and
    new business requirements. Next, we will see some of the time series analysis
    methods in action with industry-specific datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Hands-on with selected use cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this hands-on section, we will go through some selected use cases with industry-specific
    datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the forecasting use case, we started with an example on temperatures in
    [*Chapter 1*](B18568_01.xhtml#_idTextAnchor016), where we loaded the dataset,
    analyzed its components, and visualized the result. The focus was on the past
    – that is, historical data. In the following steps, we will highlight the specific
    part of the code related to the future – that is, forecasting. This is based on
    the code in `ts-spark_ch1_2fp`, which we imported into Databricks Community Edition
    in [*Chapter 1*](B18568_01.xhtml#_idTextAnchor016).
  prefs: []
  type: TYPE_NORMAL
- en: 'The forecasting steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the dataset, which was covered in [*Chapter 1*](B18568_01.xhtml#_idTextAnchor016).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Using the `Prophet` library, the model is created and trained (fit) on the
    data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then use a very handy function in Prophet to generate future dates, `make_future_dataframe`.
    These will be required as input, and passed as parameters, to do the prediction
    part, which is with the `predict` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: plot_plotly(model, forecast, changepoints=True)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![](img/B18568_02_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: Forecasting temperature'
  prefs: []
  type: TYPE_NORMAL
- en: This was a brief hands-on introduction to forecasting. We will be doing more
    forecasting, including with other libraries in addition to Prophet, in the rest
    of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Pattern classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For pattern classification, we will use financial time series – more specifically,
    share prices of technology companies. We will explore the use of two different
    open source libraries for DTW, `fastdtw` and `dtw-python`. This is based on the
    code in `ts-spark_ch2_1.dbc`, which we can import from the GitHub location for
    [*Chapter 2*](B18568_02.xhtml#_idTextAnchor044) into Databricks Community Edition,
    as per the approach explained in [*Chapter 1*](B18568_01.xhtml#_idTextAnchor016).
  prefs: []
  type: TYPE_NORMAL
- en: 'The code URL is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch2/ts-spark_ch2_1.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch2/ts-spark_ch2_1.dbc)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with `fastdtw` with the following code steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: from_date = "2019-01-01"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: to_date = "2024-01-01"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: yftickers = [
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"AAPL", "AMZN", "GOOG", "META",'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"MSFT", "NVDA", "PYPL", "TSLA"]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: yfdata = {
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'yftick: yf.download('
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'yftick, start=from_date, end=to_date, multi_level_index=False)[fastdtw library
    is used to calculate the DTW distances for each pair of stocks:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then plot the distance matrix using a heatmap with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This creates the visualization in *Figure 2**.6*, where the value of the DTW
    distance between AMZN and GOOG share prices is highlighted. Of the combination
    of shares analyzed, these two are the nearest to each other compared to the other
    DTW distances.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B18568_02_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: DTW distance heatmap'
  prefs: []
  type: TYPE_NORMAL
- en: The line showing the DTW distance measurement between the two time series, AMZN
    and GOOG, is visualized in *Figure 2**.2*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The plot of the time series for all the tickers is simply done with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This creates *Figure 2**.7*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B18568_02_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.7: Selected technology share prices'
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the following code with the `dtw-python` library to generate the alignment
    plot in *Figure 2**.2*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This concludes a brief hands-on introduction to pattern classification – more
    specifically, the initial step of distance calculation for the distance-based
    method using DTW, as applied to financial time series. Following this step, you
    can then apply the kNN classification algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the final hands-on example of this chapter, we will explore an anomaly detection
    use case applied to energy consumption for a household. This is based on the code
    in `ts-spark_ch2_2.dbc`, and the dataset in `ts-spark_ch2_ds2.csv`. We import
    the code into Databricks Community Edition, as per the approach explained in [*Chapter
    1*](B18568_01.xhtml#_idTextAnchor016).
  prefs: []
  type: TYPE_NORMAL
- en: 'The code URL is as follows: [https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch2/ts-spark_ch2_2.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch2/ts-spark_ch2_2.dbc)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The code steps follow:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As discussed earlier in this chapter, isolation forest is a tree-based model
    that can be used for isolating anomalies.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Spark is used to read the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that this is a different yet equivalent syntax to `spark.load()`, which
    we used in [*Chapter 1*](B18568_01.xhtml#_idTextAnchor016).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To enable calculations on the columns’ value, we need to change the data types
    of the columns from string to double:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then choose the first part of the dataset to use for training the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The Isolation Forest model can then be created and fitted to the training dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The model can then be used to flag the anomalies in the full dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, to show the result in *Figure 2**.3*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This completes the hands-on introduction to anomaly detection using an energy
    consumption time series. As discussed in this chapter, Isolation Forest, used
    here, is just one of many methods available.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we focused on the practical significance of analyzing time
    series data for predictive modeling, trend identification, and anomaly detection.
    We viewed real-world applications across industries, highlighting the importance
    of time series analysis while getting some practice with two different sector-specific
    datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Before we can scale these and other use cases, we need an additional key component,
    Apache Spark, to which you will be introduced in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section serves as a repository of sources that can help you build on your
    understanding of the topic:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Time Series Analysis - Data, Methods, and Applications*, edited by Chun-Kit
    Ngan: [https://www.intechopen.com/books/8362](https://www.intechopen.com/books/8362)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Financial services:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Essentials of Time Series for Financial Applications* by Massimo Guidolin
    and Manuela Pedio: [https://www.sciencedirect.com/book/9780128134092/essentials-of-time-series-for-financial-applications](https://www.sciencedirect.com/book/9780128134092/essentials-of-time-series-for-financial-applications)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Time-Series Forecasting Techniques for Banking Variables* by Arindam Bandyopadhyay:
    [https://academic.oup.com/book/43110/chapter-abstract/361614151?redirectedFrom=fulltext&login=false](https://academic.oup.com/book/43110/chapter-abstract/361614151?redirectedFrom=fulltext&login=false)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Retail:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*A profit prediction model with time series analysis for retail store* by Sridevi
    U. K. and Shanthi P: [https://www.researchgate.net/publication/325882164_A_profit_prediction_model_with_time_series_analysis_for_retail_store](https://www.researchgate.net/publication/325882164_A_profit_prediction_model_with_time_series_analysis_for_retail_store)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*A Comparative Study on Forecasting of Retail Sales* (Hasan et al., 2022):
    [https://arxiv.org/pdf/2203.06848.pdf](https://arxiv.org/pdf/2203.06848.pdf)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Healthcare:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*AI in Healthcare: Time-Series Forecasting Using Statistical, Neural, and Ensemble
    Architectures* (Kaushik et al., 2020): [https://www.frontiersin.org/articles/10.3389/fdata.2020.00004/full](https://www.frontiersin.org/articles/10.3389/fdata.2020.00004/full)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Time Series Forecasting for Healthcare Diagnosis and Prognostics with the
    Focus on Cardiovascular Diseases* (Bui et al., 2018): [https://www.researchgate.net/publication/320002542_Time_Series_Forecasting_for_Healthcare_Diagnosis_and_Prognostics_with_the_Focus_on_Cardiovascular_Diseases](https://www.researchgate.net/publication/320002542_Time_Series_Forecasting_for_Healthcare_Diagnosis_and_Prognostics_with_the_Focus_on_Cardiovascular_Diseases)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manufacturing** **and utilities:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Time Series Prediction in Industry 4.0: A Comprehensive Review and Prospects
    for Future Advancements* (Kashpruk et al., 2023): [https://www.mdpi.com/2076-3417/13/22/12374](https://www.mdpi.com/2076-3417/13/22/12374)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Time-series pattern recognition in Smart Manufacturing Systems: A literature
    review and ontology* (Farahani et al., 2023): [https://www.sciencedirect.com/science/article/pii/S0278612523000997](https://www.sciencedirect.com/science/article/pii/S0278612523000997)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Measuring the energy intensity of domestic activities from smart meter data*
    (Stankovic et al., 2016): [https://www.sciencedirect.com/science/article/pii/S0306261916313897](https://www.sciencedirect.com/science/article/pii/S0306261916313897)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Libraries:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FastDTW: [http://cs.fit.edu/~pkc/papers/tdm04.pdf](http://cs.fit.edu/~pkc/papers/tdm04.pdf)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'dtw-python: [https://dynamictimewarping.github.io/python/](https://dynamictimewarping.github.io/python/)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/ds](https://packt.link/ds)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ds_(1).jpg)'
  prefs: []
  type: TYPE_IMG
