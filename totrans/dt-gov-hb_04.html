<html><head></head><body>
		<div id="_idContainer032">
			<h1 id="_idParaDest-88" class="chapter-number"><a id="_idTextAnchor087"/>4</h1>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor088"/>Baseline Your Organization</h1>
			<p>A key component of measuring success is measuring your progress. To do that effectively, you need to know where you start from. In this chapter, you will learn the importance of defining a baseline, both for the organization at large and for individual projects. Next, you will learn how to capture a baseline and who to communicate it to. Finally, we will discuss how to ensure agreement on the baseline before <span class="No-Break">beginning work.</span></p>
			<p>There are many ways to baseline the organization to be able to measure your impact, but one of the most common is through the use of a data maturity model. Throughout the course of my last ten years in leading data transformations, one thing is for certain: having a strong baseline is beneficial not just for your stakeholders but also for you. It gives you an opportunity to demonstrate how much of an impact you’ve been able to drive through your tenure as the leader and the measurable progress of <span class="No-Break">your team.</span></p>
			<p>We will discuss the need to provide discrete value for a solution or a product-by-product basis. There is also a need to be able to demonstrate the systematic evolution of data management maturity at an enterprise level. We will discuss why it is important to measure maturity, the various ways to measure maturity, how to involve stakeholders, how to regularly reassess to demonstrate progress, and the importance of strong communication. Do not make the mistake of underappreciating the importance of measuring progress at this level. It is one of the best ways to show your value and to measure progress <span class="No-Break">over time.</span></p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor089"/>What is a data management maturity model?</h1>
			<p>A <strong class="bold">data management maturity model</strong> is a measurement framework used to assess the overall maturation of an organization’s <a id="_idIndexMarker241"/>management of its data. Said another way, it measures how well the company is managing data. The assessment provides a score by category, provides the aggregate maturity level of the company, and identifies areas for improvement. The maturity assessment is subjective. There are a series of ways to minimize the degree of subjectivity, which I will outline over the next several pages. Data management maturity models are broken down into different categories, and further broken down into levels of maturity against each of the categories, which helps minimize, but does not eliminate, <span class="No-Break">the subjectivity.</span></p>
			<p>A very simple (non-data) example would be to measure how grey <span class="No-Break">something is:</span></p>
			<div>
				<div id="_idContainer029" class="IMG---Figure">
					<img src="image/B18846_04_01.jpg" alt="Figure 4.1 – Visual example of the degree of grey"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.1 – Visual example of the degree of grey</p>
			<p>In this example, none of these colors are wrong, they are simply progressively measuring the current <a id="_idIndexMarker242"/>state of the color from lightest grey to darkest grey. The current color simply tells us where we are. The delta, or variance, between the current color and the color we aim to be tells us how far apart we are, much like the data management maturity assessment measures the current state of data management. The level is not “wrong”, but it can tell us how far away from our optimal state we are. It also tells us how far we’ve come since our <span class="No-Break">last assessment.</span></p>
			<p>If this is your first data management maturity assessment, you are embarking on establishing a baseline. This is simply a snapshot of where the company is today. It’s important to frame this context for your stakeholders, who may need help to understand what a baseline means, not because they don’t understand maturity models, but because some may struggle with having a low score representing a low state of maturity. You will need to ensure they understand it’s simply a baseline and it will go up as you work together <span class="No-Break">as partners.</span></p>
			<p>This baseline will give the organization a sense of where it is today and can be used to compare against similar companies across the industry you operate in. For example, if you are a bank and your average data management maturity is 2.5, but the industry is averaging 3.5, you know you are behind your <span class="No-Break">peer group.</span></p>
			<table id="table001-2" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Hint </strong><span class="No-Break"><strong class="bold">for success</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Do not confuse a maturity model for a data strategy or a methodology. Methodologies are very useful (i.e., DAMA), but they define what a capability is, procedures to deploy it, and approaches to delivering data solutions. Maturity models aren’t plans to implement. They assess where you are on your <span class="No-Break">data journey.</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<h1 id="_idParaDest-91"><a id="_idTextAnchor090"/>Overview of process</h1>
			<p>Before we get into the details, let’s start with a preview of the data management maturity process. The process can<a id="_idIndexMarker243"/> be broken into 10 <span class="No-Break">simple steps:</span></p>
			<ol>
				<li><strong class="bold">Define the scope of the assessment</strong>: What data and processes will <span class="No-Break">be included?</span></li>
				<li><strong class="bold">Assemble a team of stakeholders</strong>: This team should include representatives from all levels of the organization, as well as from <span class="No-Break">different departments.</span></li>
				<li><strong class="bold">Select a data management maturity model</strong>: There are a number of different models available, so choose one that is appropriate for your <span class="No-Break">organization’s needs.</span></li>
				<li><strong class="bold">Execute the assessment and collect data</strong>: This data can be collected through surveys, interviews, and <span class="No-Break">document reviews.</span></li>
				<li><strong class="bold">Analyze the data</strong>: Use the data to identify strengths and weaknesses in your organization’s data <span class="No-Break">management practices.</span></li>
				<li><strong class="bold">Communicate results</strong>: Inform all relevant parties of the results of <span class="No-Break">the assessment.</span></li>
				<li><strong class="bold">Develop a plan for improvement</strong>: Based on your findings, develop a plan to improve your organization’s data <span class="No-Break">management practices.</span></li>
				<li><strong class="bold">Implement the plan</strong>: This may involve making changes to policies, procedures, <span class="No-Break">or technology.</span></li>
				<li><strong class="bold">Monitor progress</strong>: Track your progress and make adjustments to your plan <span class="No-Break">as needed.</span></li>
				<li><strong class="bold">Reassess your maturity</strong>: Periodically reassess your organization’s data management maturity to ensure<a id="_idIndexMarker244"/> that you are <span class="No-Break">making progress.</span></li>
			</ol>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/B18846_04_02.jpg" alt="Figure 4.2 – Phases of a data management maturity assessment"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.2 – Phases of a data management maturity assessment</p>
			<p>Over the course of this chapter, I will walk through each of these ten steps and explain how to navigate challenging situations for each. I’ll also share some of my lessons learned so you can avoid issues and have a great data management maturity <span class="No-Break">assessment experience.</span></p>
			<h1 id="_idParaDest-92"><a id="_idTextAnchor091"/>Why you should baseline data management maturity</h1>
			<p>While you are off <a href="B18846_02.xhtml#_idTextAnchor041"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Building a Coalition of Advocates</em>, and <a href="B18846_03.xhtml#_idTextAnchor057"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Building a High Performing Team</em>, you should also launch a data management maturity assessment (ideally, concurrently). This<a id="_idIndexMarker245"/> process will help you understand the company’s data maturity horizontally across the organization leveraging a standardized approach, which will help highlight any blind spots you or your team did not uncover and help identify any biases (unconscious or not) you may have had in assessing the company’s needs. Additionally, it will help identify areas where the stakeholders are aware of the maturity level for their areas or are unaware of the maturity level. This can help you build your relationship with your <a id="_idIndexMarker246"/>stakeholders by helping them understand the state of <span class="No-Break">the union.</span></p>
			<h2 id="_idParaDest-93"><a id="_idTextAnchor092"/>Foundational reasons to baseline</h2>
			<p>You will need to start by understanding and communicating the purpose of this assessment. Your communications will need to<a id="_idIndexMarker247"/> anchor on one basic question: Why are we doing it? There are five core reasons to execute a data maturity assessment to get <span class="No-Break">you started:</span></p>
			<ul>
				<li><strong class="bold">To establish understanding</strong>: As mentioned, the most well-understood reason to complete a maturity assessment is to measure the state of data practices at the company. The first assessment establishes the baseline you need to gain a comprehensive and fair understanding of the state of the company. Every subsequent time you execute the assessment will measure progress (more on <span class="No-Break">that later).</span></li>
				<li><strong class="bold">To inform data strategy</strong>: The outcome of the initial baseline will, in part, inform your data strategy. By taking inventory of where the company is with regard to data maturity, you will better understand what areas need improvement across the overall state of data governance. Note that just because an area is immature, does not mean you should put all your resources into improving it. See <em class="italic">#8 </em><em class="italic">Implement the Plan</em> on how to consider <span class="No-Break">these results.</span></li>
				<li><strong class="bold">To assess information risk</strong>: One of the key outcomes of the assessment is to grasp how significant the risk of the current state of data management/governance poses to the organization. If limited controls are in place, it’s worth investigating with the CISO to understand what protections exist for the data, if adequate data governance controls are not in place. You may have a serious problem on your hands if data governance is immature <em class="italic">and</em> information security is immature. The outcome of your assessment and the discussions with the CISO will be a key topic for your readout with <span class="No-Break">senior management.</span></li>
				<li><strong class="bold">To prioritize your solutions</strong>: As you gather an understanding of the state of data management at your organization, you will begin to see where opportunities to improve exist. In my experience, there are often outliers of opportunity, meaning areas of inherent weakness in the data management of the company. For example, if <a id="_idIndexMarker248"/>metadata management is low, it may be clear that you need to seek out prioritizing a metadata management <span class="No-Break">improvement program.</span></li>
				<li><strong class="bold">To up-level the company’s understanding of the value of data</strong>: One of the best benefits of the assessment is not necessarily the assessment itself but the conversation about data that comes alongside the assessment. You will find questions emerge from individuals you may not have had an engagement with previously because of this work. Embrace it. Even an adversarial colleague, when met with an open mind and a curious disposition, can prove to be fruitful. Encourage their questions and welcome the opportunity to educate, even in micro-moments throughout the assessment. Additionally, individuals may not realize how much they are gaining from their existing work. The entire process will drive a better understanding of how data is or is not <span class="No-Break">used today.</span></li>
			</ul>
			<p>Be confident in why you are launching a baseline of your organization’s data maturity. It may feel unnatural to you, and perhaps to some of your stakeholders, to go through this process. To some, it may feel like an audit or a compliance exercise. You will have the maximum support and success in your baseline if you are clear about the <span class="No-Break"><em class="italic">why</em></span><span class="No-Break"> upfront.</span></p>
			<p>Communicate with your stakeholders that this effort may feel uncomfortable or even hard to discuss the reality of where the company is and/or its function. Be clear about the results and what they will do for the company. What do you intend to do with them? Share openly that the outcome may feel uncomfortable and encourage the collective stakeholder group to embrace it. This is a stepping stone to <span class="No-Break">driving change.</span></p>
			<h1 id="_idParaDest-94"><a id="_idTextAnchor093"/>Executing a data management maturity assessment</h1>
			<p>Executing the assessment can<a id="_idIndexMarker249"/> be a bit of a nerve-wracking process. You are likely to encounter some great supporters and some less supportive stakeholders. It’s critical that you have a great value proposition and are able to explain why this benefits the stakeholder as an individual (what they will personally get out of the process), why it benefits their team, and why it benefits the company <span class="No-Break">at large.</span></p>
			<p>It may go without saying, but communication is the most important part of this process. Your primary responsibility is to<a id="_idIndexMarker250"/> remain unbiased, share information, translate to ensure understanding across the enterprise at the highest and lowest levels, and drive the assessment results to inform your strategy and ultimately the value of data at <span class="No-Break">your organization.</span></p>
			<h2 id="_idParaDest-95"><a id="_idTextAnchor094"/>[#1] Defining the scope</h2>
			<p>Before you prepare to launch<a id="_idIndexMarker251"/> your assessment, you will need to define the scope of the assessment. Often, it can be tempting to say “all” and move on. However, there are options when it comes to defining the scope of your data management maturity assessment. There are three primary options to choose from, and <a id="_idIndexMarker252"/>you should consider what the best option is for your organization. It is a time commitment to conduct, both for you and your team and for <span class="No-Break">your stakeholders.</span></p>
			<h3>Enterprise-wide</h3>
			<p>Most companies choose to do an enterprise-wide assessment. This is my recommendation, with very few exceptions (that I will outline). If your objective is to assess the state of data management for the <a id="_idIndexMarker253"/>company, you need to assess the entirety of the company to achieve this objective. This is also the best way to determine if you have areas of strengths or weaknesses that you need to take into account as you set up your program, deliver on transformation, and/or build capabilities for the organization <span class="No-Break">at large.</span></p>
			<p>When following the enterprise-wide approach, you should leverage the data domains that you defined in <a href="B18846_02.xhtml#_idTextAnchor041"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>. This will give you a better understanding of which groups are stronger or have matured beyond others. Whether you report on this domain model is a separate consideration (see <em class="italic">Section 6</em>, <span class="No-Break"><em class="italic">Communicating Results</em></span><span class="No-Break">).</span></p>
			<table id="table002-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Hint </strong><span class="No-Break"><strong class="bold">for success</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>If you don’t assess the enterprise as a whole, you should not claim the outcome to be an “enterprise assessment”. I have seen this in a company; only about half of the company was included in the assessment, but the claim was made that it was an “enterprise” score. Unfortunately, once we baselined the entire company, the score was, in fact, much lower than previously reported. The groups who did not wish to participate previously had lower data maturity, thus, when they were baselined, the average <span class="No-Break">score dropped.</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<h3>Pilot and data office</h3>
			<p>If you are struggling to gain support for this effort, you could select a single data domain to pilot the process with. As you<a id="_idIndexMarker254"/> work with this data domain, you will be able to work individually with this pilot data domain and build a deeper relationship with them. However, it is easier to become biased when assessing a <span class="No-Break">single group.</span></p>
			<p>While you assess the pilot data domain, you should also assess your own data office. This can be a somewhat humbling experience, as you might find that the pilot data domain has a stronger maturity level than your own data office does (been there!). This should not be a concern or something to shy away from. Remember this is simply a baseline by which to justify future investment. Embrace the baseline and use it to your advantage. Do not be afraid of a low score for your team or the pilot <span class="No-Break">data domain.</span></p>
			<p>Oftentimes, these early assessments shine a light on the weaknesses of the company’s data maturity and specifically highlight capabilities that need investment to drive adoption enterprise-wide (e.g., metadata management, reference data, lineage, etc.). The low score in the data office will highlight where the central data team needs to invest in the service of the data domains, such that consistent capabilities are built and then leveraged across the company. Embrace the opportunity to show how far you have <span class="No-Break">to go.</span></p>
			<h3>Rolling assessment</h3>
			<p>A rolling assessment can be used if <a id="_idIndexMarker255"/>you are able to achieve buy-in for an enterprise-wide assessment but do not have the resourcing to drive an enterprise assessment concurrently. It’s a great option for high interest in the process but low resourcing to conduct such an assessment. It becomes very important to maintain strong consistency as you roll the assessment across the company. You and your team will become more efficient, and perhaps effective, at executing the assessment as you progress through the data domains; however, you must take extra care to ensure that the first team assessed and the last team<a id="_idIndexMarker256"/> assessed are given an equal experience and an <span class="No-Break">equivalent assessment.</span></p>
			<p>The following chart can be leveraged to show the scope of your assessment. Enter the data domains on the left side, including one row for the central data office. In the second column, enter whether that data domain is in scope for the assessment or not (only use this column if not all groups are included). In the third column, enter the baseline score. In the last column, enter the current score. You should consider the full chart to be internal to the data office unless you intend to publish the disaggregated results (see Section 6 <span class="No-Break">Communicating Results).</span></p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/B18846_04_03.jpg" alt="Figure 4.3 – Example scoping model"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.3 – Example scoping model</p>
			<h2 id="_idParaDest-96"><a id="_idTextAnchor095"/>[#2] Identifying stakeholders</h2>
			<p>The next step in the data management maturity assessment is to identify who will be responsible, who will be accountable, who <a id="_idIndexMarker257"/>will be consulted, and who will be informed in the process. First, start by identifying the roles and groups before you assign names to the roles. This will help you create an evergreen<a id="_idIndexMarker258"/> approach you can maintain as people come and go from <span class="No-Break">the company.</span></p>
			<p>Here are some additional tips for identifying the roles needed to participate in a data management <span class="No-Break">maturity assessment:</span></p>
			<ul>
				<li>Consider the different departments and functions within the organization that are involved in <span class="No-Break">data management.</span></li>
				<li>Identify the people who have a vested interest in the success of the data <span class="No-Break">management program.</span></li>
				<li>Look for people who have a deep understanding of the company’s data assets and how they are used to support <span class="No-Break">business decisions.</span></li>
				<li>Involve a mix of technical and non-technical people in the assessment. This will help to ensure<a id="_idIndexMarker259"/> that the assessment is comprehensive and that it gets the input of all <span class="No-Break">the stakeholders.</span></li>
			</ul>
			<h3>Responsible</h3>
			<p>The role responsible for <a id="_idIndexMarker260"/>executing the data management maturity assessment, from defining the methodology, execution, and reporting, is your head of data governance. This individual usually reports to the chief data and analytics officer and has responsibility for <span class="No-Break">the assessment.</span></p>
			<h3>Accountable</h3>
			<p>The <strong class="bold">chief data and analytics officer</strong> (<strong class="bold">CDAO</strong>) is ultimately accountable for the company’s data management maturity <a id="_idIndexMarker261"/>assessment because they have the overall responsibility for data management within the organization. Since the CDAO is also responsible for driving data-driven decision-making throughout the organization, the data management maturity assessment is a critical tool for the CDAO to understand the current state of data management within the organization and identify areas <span class="No-Break">for improvement.</span></p>
			<p>The assessment will help the CDAO to do <span class="No-Break">the following:</span></p>
			<ul>
				<li>Identify gaps in data management processes <span class="No-Break">and procedures</span></li>
				<li>Assess the maturity of data governance policies <span class="No-Break">and practices</span></li>
				<li>Evaluate the quality of <span class="No-Break">data assets</span></li>
				<li>Identify opportunities to improve <span class="No-Break">data-driven decision-making</span></li>
			</ul>
			<p>The CDAO can then use the results of the assessment to develop a plan for improving data management within the organization. This plan should be aligned with the company’s overall business strategy and should be communicated to <span class="No-Break">all stakeholders.</span></p>
			<p>By taking accountability for the company’s data management maturity assessment, the CDAO can ensure that data is managed effectively and that the organization is able to derive maximum value from its <span class="No-Break">data assets.</span></p>
			<p>In addition to the reasons mentioned, the CDAO is also accountable for the company’s data management maturity assessment because they have the authority to make changes to data management processes and procedures. This is important because the assessment may identify areas where data management needs to be improved. The CDAO can then use its authority to implement changes that will help the organization achieve a higher level of <span class="No-Break">data maturity.</span></p>
			<p>Finally, the CDAO is accountable for the company’s data management maturity assessment because they are the public face of data management within the organization. They are responsible for communicating the importance of data management to the rest of the organization and for ensuring that data management is a priority. The data management maturity assessment is a valuable tool for the CDAO to use to communicate the importance of data management and to demonstrate the value that data can bring to <span class="No-Break">the organization.</span></p>
			<h3>Consulted</h3>
			<p>The following groups of individuals should be consulted during the data management maturity assessment, both for broad context and for <span class="No-Break">scoring purposes:</span></p>
			<ul>
				<li><strong class="bold">Data domain executives</strong>: The data domain executives are responsible for data management within their data domains, so they should be consulted to get their perspective on the<a id="_idIndexMarker262"/> current state of data management and to identify areas <span class="No-Break">for improvement.</span></li>
				<li><strong class="bold">Business data stewards</strong>: Data stewards are responsible for ensuring the quality and accuracy of data, so they should be consulted to get their input on the data quality and <span class="No-Break">governance processes.</span><ul><li><strong class="bold">Data analysts</strong>: Data analysts use data to make business decisions, so they should be consulted to get their perspective on the usability of data and the effectiveness of <span class="No-Break">data-driven decision-making.</span></li><li><strong class="bold">Business users</strong>: Business users are the ones who ultimately need to use data, so they should be consulted to get their input on the data that is available to them and the challenges they face in <span class="No-Break">using data.</span></li></ul></li>
				<li><strong class="bold">Technical data stewards</strong>: IT staff are responsible for the infrastructure that supports data management, so they should be consulted to get their input on the data management systems <span class="No-Break">and processes.</span></li>
			</ul>
			<p>In addition to these key stakeholders, it is also important to consult with a variety of other people to gather context and examples of both successes and failures of data management, such as <span class="No-Break">the following:</span></p>
			<ul>
				<li>Subject matter experts who have deep knowledge of the company’s <span class="No-Break">data assets</span></li>
				<li>People who have experience with data management <span class="No-Break">best practices</span></li>
				<li>People who have been involved in previous data <span class="No-Break">management initiatives</span></li>
			</ul>
			<p>By consulting with a variety of people, you can get a comprehensive view of the company’s data management maturity and identify areas <span class="No-Break">for improvement.</span></p>
			<h3>Informed</h3>
			<p>As a part of the data management maturity assessment, you should inform several groups along the way. Ahead of the assessment, you should inform your data domain executives and the enterprise <a id="_idIndexMarker263"/>data committee. You need their support and buy-in for the assessment, so they can set the expectation with participants to prioritize <span class="No-Break">the effort.</span></p>
			<p>Upon completion of the assessment, you will want to go back to the data domain executives and enterprise data committee to inform them regarding the results and what will come next. Additionally, you should inform the C-Suite and the board of directors of the results so that they understand the needs of the company and can assist with funding and prioritizing any follow-up transformational work required in the data <span class="No-Break">management space.</span></p>
			<h2 id="_idParaDest-97"><a id="_idTextAnchor096"/>[#3] Selecting a data management maturity model</h2>
			<p>Before you get started, you will need to select the data management maturity model that is appropriate for your <a id="_idIndexMarker264"/>organization. There are several different models that exist with pros and cons that you can choose from, or you can choose to create your own. If your company has never done a data management maturity assessment before, I strongly recommend you select a<a id="_idIndexMarker265"/> widely used model, as it will help you to defend the criteria and the process overall. If your company is no stranger to data management maturity and has found that a more customized model may suit your needs better, then (and only then) you could create your <span class="No-Break">maturity model.</span></p>
			<h3>Common industry models</h3>
			<p>Data management maturity models are frameworks that organizations can use to assess their current data management <a id="_idIndexMarker266"/>practices and identify areas for improvement. These models typically define a set of stages or levels of maturity, with each stage representing a successively higher level of sophistication in data <span class="No-Break">management practices.</span></p>
			<p>Some of the most common data<a id="_idIndexMarker267"/> management maturity models include <span class="No-Break">the following:</span></p>
			<ul>
				<li>The <strong class="bold">Data Management Maturity Model</strong> (<strong class="bold">DMMM</strong>) by the <strong class="bold">Data Management Association</strong> (<strong class="bold">DAMA</strong>) (retired <span class="No-Break">in </span><span class="No-Break"><a id="_idIndexMarker268"/></span><span class="No-Break">2021)</span></li>
				<li>The <strong class="bold">Data Governance Maturity Model</strong> (<strong class="bold">DGMM</strong>) by the IBM Data <span class="No-Break">Governance </span><span class="No-Break"><a id="_idIndexMarker269"/></span><span class="No-Break">Council</span></li>
				<li>The <strong class="bold">Data Management Capability Model</strong> (<strong class="bold">DCAM</strong>) by the EDM Council, is a non-profit organization that <a id="_idIndexMarker270"/>promotes the use of data management <span class="No-Break">best practices</span></li>
				<li>The Gartner IT Score for Data <span class="No-Break">and Analytics</span></li>
				<li>The Stanford Data Governance <span class="No-Break">Maturity Model</span></li>
				<li>The TDWI Data Management Maturity Model <span class="No-Break">and Assessment</span></li>
			</ul>
			<p>Additionally, most consulting firms have their own proprietary models. The risk in using a consulting firm’s proprietary <a id="_idIndexMarker271"/>model is that they are proprietary. Often, the company will require an engagement (i.e., funding) to continue to use the model over time. If you intend to execute your assessment over a series of years, this may not be the most cost-effective option for you and <span class="No-Break">your company.</span></p>
			<p>The model I’ve used the most is the DMMM model from DAMA, but it was retired in 2021. DMMM was replaced by DCAM. DCAM is more comprehensive than DMMM, and based on conversations I have had with other CDAOs, DCAM seems to be the choice of data maturity model for companies who had previously been using DMMM. My recommendation is to select a model that resonates closest with your company’s needs and stick with it so that you can establish a consistent comparison of maturity <span class="No-Break">over time.</span></p>
			<h3>Building your own model</h3>
			<p>Although less common, one approach could be to create your own model or blend models from various programs to fit your needs. It’s critical to ensure you have a strong methodology heading into this <a id="_idIndexMarker272"/>approach, as you will need to be able to explain why your model is designed the way it is, especially in instances where someone or some team is scored low. I have seen situations where the team that scores low attacks the homegrown model versus looking at the results, and you need to be prepared <span class="No-Break">for that.</span></p>
			<p>Here’s how to build your <span class="No-Break">own model:</span></p>
			<ol>
				<li><strong class="bold">Define the scope of your model</strong>: Consider which aspects or areas of data management you will want <span class="No-Break">to assess.</span></li>
				<li><strong class="bold">Identify the thresholds for each level of maturity</strong>: Consider what specific criteria are required for each level to be achieved. The stages in a data management maturity model may vary, but common <span class="No-Break">stages include:</span><ol><li class="Alphabets"><strong class="bold">Ad hoc</strong>: Data is managed in <a id="_idIndexMarker273"/>a reactive and ad hoc manner. There is no formal data management strategy <span class="No-Break">or plan.</span></li><li class="Alphabets"><strong class="bold">Basic</strong>: Data is managed in a more structured manner, but there is still no formal data management strategy <span class="No-Break">or plan.</span></li><li class="Alphabets"><strong class="bold">Repeatable</strong>: Data management processes are documented and repeatable. There is still no formal data management strategy or plan, but there is a commitment to improving data <span class="No-Break">management capabilities.</span></li><li class="Alphabets"><strong class="bold">Defined</strong>: Data management processes are well-defined and documented. There is a formal data management strategy and plan <span class="No-Break">in place.</span></li><li class="Alphabets"><strong class="bold">Managed</strong>: Data management processes are actively managed and monitored. There is a strong commitment to improving data <span class="No-Break">management capabilities.</span></li><li class="Alphabets"><strong class="bold">Optimized</strong>: Data management processes are optimized for efficiency and effectiveness. There is a continuous improvement process in place for <span class="No-Break">data management.</span></li></ol></li>
				<li><strong class="bold">Develop an assessment tool</strong>: Consider how you might capture this information. The tool could be a checklist, an interview guide/questionnaire, or something more sophisticated. It should collect the data needed to produce the results of <span class="No-Break">the assessment.</span></li>
			</ol>
			<h2 id="_idParaDest-98"><a id="_idTextAnchor097"/>[#4] Execute the assessment and collect data</h2>
			<p>Now that we’ve gone through what a data management maturity model is, you’ve selected the participants, and <a id="_idIndexMarker274"/>you’ve selected (or designed) your data management maturity model, it’s time to put the assessment to work. Let’s execute <span class="No-Break">the</span><span class="No-Break"><a id="_idIndexMarker275"/></span><span class="No-Break"> assessment!</span></p>
			<p class="callout-heading">Use case - gaming the system</p>
			<p class="callout">Be mindful of <em class="italic">who</em> is executing <span class="No-Break">the assessment.</span></p>
			<p class="callout">At one of my previous companies, we executed an enterprise data management maturity assessment. At the time, the company had federated data offices established in each major division, plus a central data office. To conduct the assessment, each data officer (both federated and central) was given an assessment to score themselves. Seemingly efficient <span class="No-Break">process, right?</span></p>
			<p class="callout"><span class="No-Break"><em class="italic">Wrong</em></span><span class="No-Break">.</span></p>
			<p class="callout">Heading into the assessment, we knew which data offices had been established longer, had more resources and funding, and were more mature. But the results did not match the <span class="No-Break">reality. Why?</span></p>
			<p class="callout">Because funding was decentralized, some data officers used the assessment to game the results. This means they purposefully scored their maturity lower so they could use the results to advocate for additional funding for their data programs, despite being more mature than their peer <a id="_idIndexMarker276"/>data offices. What that looked like in aggregate was that the company overall was less mature than it really was, and the data offices with higher maturity scored lower than those with lower maturity. Further, some data officers over-scored their programs to demonstrate impact and progress. This is equally as bad, as it suggests the data office was more mature and had less work to do to build reliable, trustworthy <span class="No-Break">data assets.</span></p>
			<p class="callout">This invalidated the results, confused management, and ultimately undermined the credibility of the data management maturity assessment, along with the data <span class="No-Break">officers individually.</span></p>
			<p class="callout">Ultimately, we had to redo the assessment and hire a third party to conduct the assessment independently. This allowed the company to have an objective assessment, with results it could trust. Because of the way the first assessment played out, we had to conduct many interviews and collect evidence to support the assessment. We also added a layer of credible challenges by asking each data officer about what they knew from their peers to help validate the results and highlight any gaps in <span class="No-Break">the interviews.</span></p>
			<h3>Preparing to launch</h3>
			<p>As you prepare to launch your assessment, I recommend you communicate a few different ways to ensure<a id="_idIndexMarker277"/> your stakeholders know what to expect. In your enterprise data committee and enterprise data council meetings, be sure to present on this topic well in advance of the annual exercise. In your enterprise data committee, I recommend a pitch deck that includes the <span class="No-Break">following information:</span></p>
			<ul>
				<li>What is a data management <span class="No-Break">maturity model?</span></li>
				<li>Why is it important to assess maturity? What are the benefits to the company, data office, and <span class="No-Break">data domains?</span></li>
				<li>What will be done with <span class="No-Break">the information?</span></li>
				<li>How will they <span class="No-Break">be engaged?</span></li>
				<li>What do they need from the <span class="No-Break">data team?</span></li>
				<li>What is the timeline of the assessment? How will we validate <span class="No-Break">the results?</span></li>
				<li>When will we report the results? <span class="No-Break">To whom?</span></li>
				<li>What is the time commitment you expect for each type of persona in <span class="No-Break">the RACI?</span></li>
			</ul>
			<h3>Communicating expectations</h3>
			<p>Before you launch, you will need to set expectations about what this is, why you need to do the assessment, what you will do with the results, and why this process will benefit the stakeholders involved. You<a id="_idIndexMarker278"/> should also communicate the expectations to the individuals who are participating in the assessment. They need to understand what to expect during the assessment, what they should plan for from a time commitment perspective, what will be done with results, and why this process matters to them (as well as the company). Individuals involved will need to know what is coming and what will be required of them. Communication will become one of the most important parts of the <span class="No-Break">assessment process.</span></p>
			<p>Here’s an example email you can send to your stakeholders kicking off <span class="No-Break">the assessment:</span></p>
			<p class="callout-heading">Sample maturity assessment announcement email</p>
			<p class="callout">To: All business data stewards; technical <a id="_idIndexMarker279"/><span class="No-Break">data stewards</span></p>
			<p class="callout">CC: Data domain executives, enterprise data committee members, chief data and analytics officer, and individuals conducting <span class="No-Break">the assessment</span></p>
			<p class="callout">Subject: Announcing the enterprise data management <span class="No-Break">maturity assessment</span></p>
			<p class="callout"><span class="No-Break">Dear stakeholders,</span></p>
			<p class="callout">In the coming weeks, we will be launching an enterprise-wide data management maturity assessment. We have selected an assessment model to measure our company’s progress against stated maturity levels across a series of data management dimensions. We have selected the<a id="_idIndexMarker280"/> industry-leading assessment model: DCAM. You can read more about the model <span class="No-Break">here: </span><a href="https://edmcouncil.org/frameworks/dcam/"><span class="No-Break">https://edmcouncil.org/frameworks/dcam/</span></a><span class="No-Break">.</span></p>
			<p class="callout">To support this effort, we are asking for two hours of your time over the next eight weeks. The first hour will be used to interview you and your teammates about the current state of data management in your area of the company. There are no wrong answers. We are simply taking a pulse of where we stand. There may be a request for supporting materials from that initial conversation, which we will send in writing following the <span class="No-Break">first meeting.</span></p>
			<p class="callout">The second meeting will include a read-out of the results of your first meeting against our maturity model and will give you the opportunity to ask questions, challenge any of our assumptions, and edit to ensure we have the most appropriate score going into the aggregation <span class="No-Break">process company-wide.</span></p>
			<p class="callout">Lastly, we will share the results with the enterprise data committee, the executive team, and, in aggregate, the board of directors. Your division’s individual scores will not be shared—only at the company level. We will share the materials with you in advance, so you can see transparently <a id="_idIndexMarker281"/>what is being communicated. The results of the assessment will help with future funding, prioritization, and identifying where we can improve our data capabilities enterprise-wide in order to serve <span class="No-Break">you better.</span></p>
			<p class="callout">Thank you in advance for your support of this important annual event. We are happy to answer any questions you might have. Meetings will be coming from our chief data and analytics officer’s calendar in the <span class="No-Break">coming days.</span></p>
			<p class="callout"><span class="No-Break">Sincerely,</span></p>
			<p class="callout">Head of <span class="No-Break">data governance</span></p>
			<p class="callout"><span class="No-Break">CDAO Office</span></p>
			<h3>How to launch the data management maturity assessment</h3>
			<p>This is a great opportunity to both assess the current state and educate the stakeholders you engage with about the goals and objectives of a data management program. You can use this process to educate them <a id="_idIndexMarker282"/>on the core components while you also assess the state of maturity. Pay extra attention to the language you use. For example, not everyone will know what technical metadata is, but if you educate them on the term, they may understand it and be able to better share their understanding of the state of maturity for metadata management within <span class="No-Break">their division.</span></p>
			<p>By using these assessment sessions as dual purpose, you may be able to engage the stakeholders more fully in the conversation and use it to build your rapport with them. The more you can do in person, the better. You can use a workshop-style setting to bring common groups together. I have found this approach to be particularly helpful because it gives teams the opportunity to come together when they <span class="No-Break">otherwise wouldn’t.</span></p>
			<h4>Who you need to include</h4>
			<p>As mentioned, your assessment should target those closest to the data; business data stewards and technical data stewards. You may want to include a wide variety of individuals from across <a id="_idIndexMarker283"/>the organization, especially if the roles of business data stewards and technical data stewards are not yet formalized. At the very minimum, you should have a representative from every department with some additional focus from groups such as information technology and finance where there is heavier involvement <span class="No-Break">in data.</span></p>
			<h4>Who you don’t need to include</h4>
			<p>You may run into instances where you have individuals seemingly crawling out of the woodwork to join your workshops. It is OK to share and state clearly who was selected and why. You do not want to run into a situation where every data person in the company is included or you will struggle to complete your workshop in the time allocated. Stick to having a business data steward and a technical data steward from each data domain included in your assessment. If others want their voice heard, encourage them to speak to their data domain’s representative ahead of <span class="No-Break">the workshop.</span></p>
			<h4>Workshop versus one-on-one sessions</h4>
			<p>Depending on your stakeholders, you may want to consider whether it is best to schedule workshops or one-on-one sessions with them (or a combination). Ideally, you should conduct workshops as the default. They create the most inclusive environment and limit bias in the process. However, there are some specific instances where you may want to conduct a one-on-one session. See the following table for the rationale <span class="No-Break">for both:</span></p>
			<table id="table003-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Workshop</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">One-on-one sessions</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Should be <span class="No-Break">the default</span></p>
							<p>Can help others hear ideas from <span class="No-Break">each other</span></p>
							<p>Helps <span class="No-Break">remove bias</span></p>
							<p><span class="No-Break">Drives consistency</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Best for <span class="No-Break">adversarial individuals</span></p>
							<p>Can be used ahead of the workshop to help gain support of less <span class="No-Break">supportive individuals</span></p>
							<p>Can be used for extremely supportive individuals to help them understand the importance of their role in helping to guide a <span class="No-Break">positive workshop</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<h3>Execute one-on-ones</h3>
			<p>If you are conducting one-on-one workshops with those you need to bring on board with the process, you should<a id="_idIndexMarker284"/> do that ahead of the workshops. You may want to take time to explain the why and listen to what their concerns are. Common concerns include <span class="No-Break">the following:</span></p>
			<ol>
				<li>Wanting their individual results and not <span class="No-Break">supporting aggregation</span></li>
				<li>Fear of a <span class="No-Break">low score</span></li>
				<li>Fear of management’s perception of <span class="No-Break">their maturity</span></li>
				<li>Not <span class="No-Break">being included</span></li>
				<li>Not being elevated to a data <span class="No-Break">domain executive</span></li>
				<li>Not being <span class="No-Break">represented fairly</span></li>
			</ol>
			<p>Be sure to hear them out and do your best to calm any nerves, explain why, and always use transparency. Facts matter in <span class="No-Break">these situations.</span></p>
			<h3>Executing the workshop(s)</h3>
			<p>Your workshop needs to be executed very well. You should not cut corners in preparing the workshop and should facilitate<a id="_idIndexMarker285"/> your attendees. Remember to reiterate that a maturity model is simply a tool that you use to assess how well your company has done in using data to drive business outcomes. Most models break down into areas of focus or capabilities and provide a scoring approach to determine how mature the company or division is within that area of focus <span class="No-Break">or capability.</span></p>
			<p class="callout-heading">Sample agenda</p>
			<p class="callout">Welcome and introductions <em class="italic">[welcome the attendees and take time to do introductions for </em><span class="No-Break"><em class="italic">all participants]</em></span></p>
			<p class="callout">Aligning purpose: why are we here? <em class="italic">[Explain the purpose of the assessment and what the attendees can expect from </em><span class="No-Break"><em class="italic">the session]</em></span></p>
			<p class="callout">What the <span class="No-Break">assessment is</span></p>
			<p class="callout">Why we are conducting <span class="No-Break">the assessment</span></p>
			<p class="callout">Allow time for <span class="No-Break">brief questions</span></p>
			<p class="callout">Explain why this is beneficial <span class="No-Break">for attendees</span></p>
			<p class="callout">Explain why this is beneficial for <span class="No-Break">the company</span></p>
			<p class="callout">Goals and outcomes: what will we <span class="No-Break">achieve together?</span></p>
			<p class="callout">Topical discussion <a id="_idIndexMarker286"/>and <span class="No-Break">assessment exercise</span></p>
			<p class="callout"><span class="No-Break">Scoring</span></p>
			<p class="callout">Data office’s <span class="No-Break">next steps</span></p>
			<p class="callout">Gathering example documents (avoid saying “evidence”, as this can feel like an audit and may change the tone of <span class="No-Break">the conversation)</span></p>
			<p class="callout"><span class="No-Break">Aggregating scores</span></p>
			<p class="callout">Attendee next steps: explain what will come next, when, and how they will be engaged <span class="No-Break">going forward</span></p>
			<p class="callout">Thanks <span class="No-Break">and adjourn</span></p>
			<h4>Bonus outcomes</h4>
			<p>As a result of conducting the maturity <a id="_idIndexMarker287"/>assessments in a workshop style, you will be able to gather additional outcomes that, while not the intention of the maturity assessment, will aid in your overall business case development and inform your strategy and initiatives going forward. Some bonus outcomes include <span class="No-Break">the following:</span></p>
			<ol>
				<li>Ideas <span class="No-Break">for opportunity</span></li>
				<li>Ideas <span class="No-Break">for initiatives</span></li>
				<li>Identifying <span class="No-Break">common themes</span></li>
				<li>Identifying <span class="No-Break">troubled areas</span></li>
				<li><span class="No-Break">Community building</span></li>
			</ol>
			<h2 id="_idParaDest-99"><a id="_idTextAnchor098"/>[#5] Analyzing the data</h2>
			<p>Now that you’ve completed the workshop, the<a id="_idIndexMarker288"/> next step in the process is to analyze the data and prepare to communicate the results. As a part of this step, you have both quantitative and qualitative data to <a id="_idIndexMarker289"/>analyze. Both are valuable in <span class="No-Break">this exercise.</span></p>
			<h3>The numbers – quantitative data</h3>
			<p>Arguably the easiest part of analyzing the data is looking at the scores themselves in isolation. Having collected the scores during <a id="_idIndexMarker290"/>the workshops, you need to add these scores into a common template and conduct a simple average to measure the company’s aggregated data management maturity score. The average score is what you will use to report your results to the enterprise data committee, the executive team (C-suite), and the board of directors. The business data stewards and technical data stewards should also receive this information in advance of the <a id="_idIndexMarker291"/>executive <span class="No-Break">communication plan.</span></p>
			<h3>The context – qualitative data</h3>
			<p>This analysis is more subjective and needs to be treated with care to ensure bias does not creep into the analysis. As you assess, please<a id="_idIndexMarker292"/> keep in mind <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Be objective</strong>: Avoid making any assumptions or jumping to conclusions with your analysis. Imagine defending these results to stakeholders. Will your conclusions hold up? Use this thought process to help credibly challenge your assessment or that of <span class="No-Break">your team.</span></li>
				<li><strong class="bold">Be realistic</strong>: Don’t expect to nail the assessment of the qualitative data overnight. This will be iterative and require back and forth with your participants to ensure you’ve captured their insights properly. Expect this in <span class="No-Break">your timeline.</span></li>
				<li><strong class="bold">Be collaborative</strong>: You will need to involve your stakeholders in this part of the analysis. You will ensure that your qualitative data is represented fairly and that no one is surprised when it comes time for the communication process. Try phrases such as “I think I heard you say ____, can you confirm that for me?” It will help build trust in <span class="No-Break">the results.</span></li>
				<li><strong class="bold">Be iterative</strong>: As you work on consolidating the findings and reporting on the results, you should expect to come back to the results again as you plan for improvement initiatives. Expect to iterate now and when you conduct next year’s assessment. Keep the documents accessible <span class="No-Break">for reference.</span></li>
			</ul>
			<p>To analyze the data coming out of the <a id="_idIndexMarker293"/>assessment, take the following steps <span class="No-Break">in sequence:</span></p>
			<ol>
				<li><strong class="bold">Identify key findings</strong>: Start by listing out all the key findings you heard during the <span class="No-Break">assessment process.</span></li>
				<li><strong class="bold">Group findings into themes</strong>: Are you seeing a pattern of issues related to customer identifier data being low quality across groups? Lack of tooling? Group these types of findings into common buckets/themes to identify where you have consistency across <span class="No-Break">data domains.</span></li>
				<li><strong class="bold">Compare findings to the maturity model</strong>: Look at these qualitative findings against the<a id="_idIndexMarker294"/> model. Align them into each topical area so you can see where you have specific areas that need improvement that may influence <span class="No-Break">your scores.</span></li>
				<li><strong class="bold">Compare findings across data domains</strong>: Now assess these same themes across data domains. Are particular domains lower? These qualitative results are helpful during improvement conversations. It may be that a domain hasn’t had any investment, or perhaps they were not aware of the central capabilities available to them. These qualitative data points are great for debriefing conversations and ongoing <span class="No-Break">maturity planning.</span></li>
				<li><strong class="bold">Look for root causes</strong>: Is there a common reason why the qualitative results are what they are? Causation can be helpful when reporting results. Executives will likely want to know why the results are what they are. This is a good area to focus energy on, <span class="No-Break">if possible.</span></li>
				<li><strong class="bold">Prioritize findings</strong>: Not every finding or comment is created equal. Focus on the findings that are the most impactful for your company’s success in achieving its broader strategy to maximize impact and align <span class="No-Break">on outcomes.</span></li>
				<li><strong class="bold">Develop your plan for improvement</strong>: You should gather at least a top-five list of what you believe the company needs to focus on going forward as a result of <span class="No-Break">the assessment.</span></li>
			</ol>
			<h1 id="_idParaDest-100"><a id="_idTextAnchor099"/>Alignment and agreement</h1>
			<p>The following steps speak to the <a id="_idIndexMarker295"/>alignment and agreement portion of the data management maturity assessment. The execution <a id="_idIndexMarker296"/>of the assessment itself is a challenge at times, but the hard work comes in alignment. It’s critical that you gain the support of your stakeholders to ensure that they will buy into the results, support the implementation plan, and partner with you on your <span class="No-Break">data strategy.</span></p>
			<h2 id="_idParaDest-101"><a id="_idTextAnchor100"/>[#6] Communicate the results</h2>
			<p>Once you have the results of your data maturity assessment, you will need to decide how you want to communicate<a id="_idIndexMarker297"/> your results. You have options, and there are pros and cons to how you execute this step. You can make the decision on how to communicate these results yourself, as CDAO, or you could employ your enterprise data committee to make this decision collectively. Either can work in your favor equally (I have seen both work well in <span class="No-Break">different companies/industries).</span></p>
			<h2 id="_idParaDest-102"><a id="_idTextAnchor101"/>Communicating disaggregated results</h2>
			<p>Your first option is to<a id="_idIndexMarker298"/> communicate results by division. Communicating by division means giving the marketing division the marketing score, the sales division the sales score, engineering the engineering score, etc. Your stakeholders will most likely advocate for their own results because they feel more connected to their own scores versus their scores rolled up with the rest of the company. However, this is not my recommendation. In my experience across multiple companies, this disaggregation reporting approach generally leads to the separation of the data community, data funding, and capabilities. This leads to duplication of capabilities, disconnected results, and increased costs. There are only a couple of very limited reasons why I would recommend <span class="No-Break">disaggregated results:</span></p>
			<ul>
				<li><strong class="bold">You have no central team</strong>: This can be a good option when you do not have much of a team in place to help guide the company individually and you need to allow them to move the ball forward in the interim while you establish your team and <span class="No-Break">hire leaders.</span></li>
				<li><strong class="bold">You have no data strategy</strong>: When the company is in its infancy regarding developing a data strategy, reporting disaggregated results can show how disparate the results are across the organization. However, use caution. Sometimes this backfires and can result in individual groups (especially strong/mature ones) advocating for the company to work together on <span class="No-Break">enterprise efforts.</span></li>
			</ul>
			<h3>Pros</h3>
			<p>The pros for disaggregated results are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Stakeholder preference</strong>: Stakeholders most likely will want their own score so they can feel ownership of the<a id="_idIndexMarker299"/> result and action it independent <span class="No-Break">of others</span></li>
				<li><strong class="bold">Accountability</strong>: Stakeholders feel more accountable and thus may accept <span class="No-Break">the results</span></li>
				<li><strong class="bold">Bias to action</strong>: Teams may decide to take action right away, and they can because they know exactly what their teams’ weaknesses are and what they can do to move <span class="No-Break">it forward</span></li>
			</ul>
			<h3>Cons</h3>
			<p>The cons for disaggregated results are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Stakeholder disbelief</strong>: The stakeholders may not believe the result without seeing the details, especially if it’s a<a id="_idIndexMarker300"/> mismatch with <span class="No-Break">their expectations.</span></li>
				<li><strong class="bold">Gaming the system</strong>: When disaggregated results are shared, individual teams may be incentivized to overstate their maturity when they are looking to show off their maturity or understate their maturity if they are <span class="No-Break">seeking funding.</span></li>
				<li><strong class="bold">Lack of collaboration</strong>: Teams are not incentivized to work together to improve the scores when they have access to their own individual scores. They are now incentivized to improve their own area and not work together across the company. This can result in teams investing in their own capabilities instead of investing together toward company-wide capabilities, which are usually more cost-effective <span class="No-Break">and efficient.</span></li>
			</ul>
			<h2 id="_idParaDest-103"><a id="_idTextAnchor102"/>Communicating aggregated results</h2>
			<p>Your second option is to<a id="_idIndexMarker301"/> communicate a company aggregated score. Communicating at the company level only means that individual divisions will <em class="italic">not</em> receive individual scores and only the aggregated company score is disclosed. Be aware: some teams may agree to this and like the rationale only to attempt to disclose their score off the record after the fact. This approach only works if you maintain the aggregated score and do not disclose the individual team’s scores. You can and should disclose what the individual teams need to work on where there are outliers (i.e., specific areas of weakness); however, the company score is just that. It’s the score for the company as <span class="No-Break">a whole.</span></p>
			<h3>Pros</h3>
			<ul>
				<li><strong class="bold">Company view</strong>: Providing exclusively aggregated results drives the organization to accept that this <a id="_idIndexMarker302"/>score is a reflection of how well the company is doing in managing data and thus can unify the company to take <span class="No-Break">action collectively.</span></li>
				<li><strong class="bold">Partnership</strong>: Aggregated results can drive divisions to work together to raise the bar vs. working <span class="No-Break">in silos.</span></li>
				<li><strong class="bold">Learning</strong>: Teams are motivated to share and learn from one another so that best practices can be driven across <span class="No-Break">the company.</span></li>
			</ul>
			<h3>Cons</h3>
			<ul>
				<li><strong class="bold">Individual team accountability</strong>: Teams may <a id="_idIndexMarker303"/>not feel like they need to take action and they can rely on the greater organization to lift <span class="No-Break">the scores.</span></li>
				<li><strong class="bold">Existing capabilities could atrophy</strong>: By leaning more on the central team, if you do not carefully communicate the importance of existing capabilities, decentralized teams may not carry forward their existing capabilities, which can lead to a dip in short-term data <span class="No-Break">management maturity.</span></li>
			</ul>
			<h2 id="_idParaDest-104"><a id="_idTextAnchor103"/>Program baseline</h2>
			<p>Similar to the enterprise data management<a id="_idIndexMarker304"/> maturity assessment, you can perform an isolated maturity assessment for a specific program. This can be a great starting point for companies who are not ready to assess an overall company-wide assessment or in situations where they want to evaluate the lift provided by the data investment in a large <span class="No-Break">transformational program.</span></p>
			<p>You would execute the same steps, only against the program scope instead of across the entire data domain construct. You may desire to supplement this assessment by baselining data quality as well to measure the trustworthiness of the data ahead of program implementation and again at the end of the deployment to show the measured improvement for specific systems, data sets, <span class="No-Break">or processes.</span></p>
			<h2 id="_idParaDest-105"><a id="_idTextAnchor104"/>[#7] Develop a plan</h2>
			<p>As you finalize your <a id="_idIndexMarker305"/>communication plan, you should concurrently begin to work internally on your data office team, as well as with your stakeholders to develop a plan for improvement. This plan should focus on the high-priority findings you identified and come with assigned owners, timelines, and <span class="No-Break">funding needs.</span></p>
			<p>Bring your stakeholders along with you as you craft this plan. This is a super topic for a data community of practice or a data steward working group to develop together. I recommend prioritizing the common themes that came up during the assessment that benefit the whole of the data community, along with any glaring issues that impact customers, are a violation of law or contractual obligations, or have major ethical implications. Address any legal or contractual obligations in partnership with your in-house legal team and chief <span class="No-Break">privacy officer.</span></p>
			<p>Aside from major issues, focusing on building capabilities that will support the masses inside your organization is a great place to start. For example, if you have several concerns about low visibility into where data is coming from or going and the quality of the data, you may want to start with deploying a metadata management program alongside a data quality initiative. As you read <em class="italic">Part 2</em> of this book, we will dive into the specifics of these capabilities <span class="No-Break">in detail.</span></p>
			<p>While you are developing the plan, consider what capabilities will have the biggest impact and focus on why they will have the impact. For example, if your stakeholders mentioned concerns about low-quality and low-trust data, define what good-quality data would allow them to do. Why will high-quality, trustworthy data matter? This seems like a potentially obvious question, but try getting really specific. What will the stakeholders be able to<a id="_idIndexMarker306"/> do once they have this high-quality data that they can’t today? Will it impact revenue? How? Can you measure it? How can you measure it? These answers will help you define exactly what you need to deliver and how to message it for buy-in at the top levels of <span class="No-Break">the organization.</span></p>
			<p>Once you have identified what you will do, who will drive it, when you will deliver it, and how you will measure success, build this into a program plan. This plan can be, and should be, part of your communication to your enterprise data committee, C-suite, and potentially board (depending on how much interest they have in your data program). You will use this for <em class="italic">steps 8</em>, <em class="italic">9</em>, <span class="No-Break">and </span><span class="No-Break"><em class="italic">10</em></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-106"><a id="_idTextAnchor105"/>[#8] Implement the plan</h2>
			<p>Assuming you are successful in securing buy-in and funding for the plan you developed in <em class="italic">step 7</em>, you will execute the plan. Bring your stakeholders along on the journey by using your data steward working<a id="_idIndexMarker307"/> groups and enterprise data committee to report on iterative progress, results during delivery (i.e., quick wins), issues, risks, and how you are progressing against <span class="No-Break">measured results.</span></p>
			<p>As you deliver, do not be shy about claiming results. If you are seeing business impacts, don’t just mark the milestone as complete and move on; ask the business user (not your data steward, the end user) to share a story about how they are experiencing the results of your deployment in their day-to-day business. Did they have lower customer attrition as a result of your data management deployment? Measure it and <span class="No-Break">report it!</span></p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor106"/>[#9] Monitor progress</h2>
			<p>As you implement the plan you developed in <em class="italic">step 8</em>, you should build in metrics to measure progress. For example, if one of the solutions you and your team are delivering is to catalog 500 data assets in your enterprise data catalog, you should create a scorecard to track that metric <a id="_idIndexMarker308"/>over the course of your program. As you deliver, the number of assets cataloged divided by 500 should give you a percentage of completion that you can then report to your stakeholders and <span class="No-Break">executive team.</span></p>
			<p>Reporting and monitoring progress is also a good way to keep everyone aligned on what you defined as success at the onset of the program. Scope creep is a very real risk to data programs because data is everywhere. There is also a risk of how data “feels” to stakeholders, and thus measuring and monitoring data initiatives is an important way to ground the improvement in facts <span class="No-Break">vs. feelings.</span></p>
			<p>The result of monitoring progress can also help build confidence in the team’s delivery, which can be used for future funding, even ahead of final delivery. You can show that the investment to date is driving progress as agreed, and use that story to secure additional funding for the <span class="No-Break">next initiative.</span></p>
			<p>Report on a regular basis in a transparent fashion. You should bake measured results into all data-related projects and programs to show the impact of investing in data maturity for the company. As you reassess your maturity (see step #10), you can correlate the impact of these program investments to the uplift of your data management maturity scores over <span class="No-Break">time. Win-win!</span></p>
			<h2 id="_idParaDest-108"><a id="_idTextAnchor107"/>[#10] Reassess your maturity</h2>
			<h3>Frequency of reassessment</h3>
			<p>You should develop a plan for reassessment. I find it most useful to decide on a pattern of reassessment and stick to it. It drives <a id="_idIndexMarker309"/>more credibility and consistency in the results, which translates into better <span class="No-Break">buy-in enterprise-wide.</span></p>
			<p>I’m a big fan of an annual assessment as the default timeline. There may be situations where you would vary from <span class="No-Break">this frequency:</span></p>
			<ul>
				<li><strong class="bold">New acquisition</strong>: If your company is acquiring new organizations, you may want to require a light version of the assessment within 90 days of the transaction being completed and then ramp the acquisition into the standard process from there. This will highlight areas of weakness that may need rapid focus as the acquisition adjusts to <span class="No-Break">the organization.</span></li>
				<li><strong class="bold">Spin out</strong>: If your company is going through a divestiture, you may need to execute a special purpose assessment as a part of <span class="No-Break">due diligence.</span></li>
				<li><strong class="bold">Significant change</strong>: If a division has made a significant investment in data, completed a major program, or<a id="_idIndexMarker310"/> has gone through a major restructuring, it may want a special purpose assessment to show the uplift as a measure <span class="No-Break">of success.</span></li>
			</ul>
			<h1 id="_idParaDest-109"><a id="_idTextAnchor108"/>Measuring success</h1>
			<p>As you reflect upon the data management maturity assessment, you should consider how you measure the success<a id="_idIndexMarker311"/> of your assessment. Some considerations include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Did all of your <span class="No-Break">stakeholders participate?</span></li>
				<li>Did you achieve buy-in of <span class="No-Break">the results?</span></li>
				<li>How many questions did you receive from the <span class="No-Break">executive team?</span></li>
				<li>Was the board interested in <span class="No-Break">your progress?</span></li>
				<li>Have scores improved over time? By <span class="No-Break">how much?</span></li>
			</ul>
			<p>You may also consider the amount of time it takes to conduct the assessment year over year to determine if your team is becoming more efficient at conducting the assessment and/or if the stakeholders are more engaged in the process (be careful in how you set up duration metrics to account for <span class="No-Break">these two).</span></p>
			<p>At the end of the assessment, what matters is how your company uses the information. If the assessment is conducted and then lands on the preverbal shelf until next time, it’s likely a paper exercise and not one of value. Consider basing your value on how the assessment is used to feed additional investment, the dialog about data that ensues, and how your data community is engaging with one another. It’s a great process to drive conversation, build <a id="_idIndexMarker312"/>community, and drive awareness of what trustworthy data can do to improve the value of <span class="No-Break">your company.</span></p>
			<h1 id="_idParaDest-110"><a id="_idTextAnchor109"/>Conclusion</h1>
			<p>It is important to ensure when you conduct this baseline, you do it well. Your credibility will be, in part, established by how transparent your baselining process is conducted. Ensuring that you communicate the methodology and the plans for sharing the results and to whom up front will help your stakeholders buy into the process. Be candid about the maturity of your team also. By being pragmatic about this process, you can gain credibility to help you design the program you need to lead for your company. Conducting this baseline of your organization is a great launching point by which to establish a credible and critical seat at the proverbial executive table. Take the time to do this well <span class="No-Break">and thoroughly.</span></p>
		</div>
	</body></html>