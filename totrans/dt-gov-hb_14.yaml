- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data Automation for Impact and More Powerful Results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Traditional data governance processes can feel like a program that is separate
    from the business. With the pace of today’s modern business models, governance
    must be embedded into the process, and that requires a new way of thinking about
    data governance. In modern data governance teams, there is a shift away from too
    much committee work, with more emphasis placed on embedding data governance into
    processes by design. I refer to this newer model of governance as **data governance**
    **by design**.
  prefs: []
  type: TYPE_NORMAL
- en: This newer way of thinking requires data governance professionals to think and
    act differently when it comes to governance activities. Data governance by design
    requires professionals to think about how to embed data governance capabilities
    into a business process from the start, not alongside it after it has been built.
    The longer I have spent in the business of data, the more I see the demands of
    data increasing at a pace that does not have the patience to wait for governance
    to “happen.” We must evolve now as a profession.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting actionable insights from vast corporate data ecosystems at the speed
    of business needs also requires a powerful set of tools or data automation capabilities.
    This chapter dives deep into this transformative set of capabilities, equipping
    you with the knowledge and understanding to harness the potential of automated
    data processes. This is a key design component and set of capabilities that support
    and enable data governance by design.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a world where data flows seamlessly, users trust the information they
    receive, and insights emerge effortlessly. Automation is a lever that can be pulled
    to expedite data governance deliveries. By automating repetitive, manual tasks,
    we free our teams from the mundane task of data movement and manual manipulation,
    unlocking time and resources to focus on higher-level analysis and strategic decision-making.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is automation?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is Data automation?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types of data automation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benefits of data automation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to determine which type of automation to use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Third-party enrichment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data solution examples powered by data automation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before we get into the specifics, let’s ground ourselves in key basic definitions.
  prefs: []
  type: TYPE_NORMAL
- en: What is automation?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Automation broadly refers to the use of technology to perform tasks with minimal
    human intervention. It encompasses a wide range of techniques and technologies
    applied in various ways. The key aspects of automation include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reduced human involvement**: The goal is to minimize the need for team members
    to manually perform tasks, leading to increased efficiency and productivity. A
    secondary benefit is team member satisfaction, which we will discuss later in
    this chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use of technology**: Automation relies on various technologies, from simple
    tools and scripts to complex artificial intelligence (AI) algorithms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pre-defined instructions or processes**: Automated tasks are typically guided
    by pre-programmed rules, instructions, or decision-making criteria. This could
    include primary data management algorithms, as defined in [*Chapter 10*](B18846_10.xhtml#_idTextAnchor206).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are a number of types of automation beyond those covered in this chapter.
    For the purposes of this book, we will be focusing on data automation capabilities.
    The capabilities outlined here are specifically selected to enable your data governance
    capabilities and data governance program, so let’s start to dive deeper by digging
    into the basics of data automation and how data automation applies to data governance.
  prefs: []
  type: TYPE_NORMAL
- en: What is data automation?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we go deep into this topic, we will ground ourselves in a few basics
    about what data automation is. **Data automation** is a broad term encompassing
    various methods for automatically handling data tasks. Data automation is a specific
    subset of automation techniques that apply technology to perform data governance
    with minimal human interaction. This can include a wide range of techniques, from
    data entry and data cleaning to more complex techniques such as analytics and
    reporting. We will go into the specific types of data automation in a few pages,
    but for now, let’s focus on the value and benefits data automation brings to data
    governance.
  prefs: []
  type: TYPE_NORMAL
- en: Types of data automation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The data automation techniques included in this section should be applied comprehensively
    across all capabilities outlined in *Part 2* of this book. Data automation transforms
    the way you work with information and is a complimentary suite of solutions that
    unlocks additional value in your data capabilities. Consider the contents of this
    chapter to be additive to what you have learned to this point.
  prefs: []
  type: TYPE_NORMAL
- en: By applying data automation to data governance capabilities, you add exponential
    benefits and speed to the results and, in essence, you are creating embedded data
    governance by design into your data governance program, enterprise-wide. We’ll
    delve into the diverse types of data automation in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Data integration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Data integration** is the ability to move data between systems without human
    intervention (or a significant reduction in human intervention), which breaks
    down data silos and enables a more seamless analysis experience for users. Data
    integration combines data from multiple sources into a unified view. There are
    typically a series of steps that are involved in integrating data well (known
    as ETL):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Extracting data**: Gathering data from one or more sources (e.g., websites,
    databases, and spreadsheets).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Transforming data**: This may include cleaning, formatting, or standardizing
    the data in some way to ensure it is consistent and/or comparable across the various
    sources that the data was extracted from. You may need to address issues such
    as formatting, inconsistencies, and null values, and you will need to build processes
    to resolve conflicting data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Loading data**: This involves putting the transformed data into a target
    source (e.g., a data lake, data warehouse, or other type of source, such as a
    report).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The purpose of data integration is to bring datasets that were previously isolated
    or trapped in other systems together, sometimes in different formats. These existing
    data silos make it difficult to analyze the data maintained in various locations
    (this is sometimes referred to as **data fragmentation**). By integrating data
    into common formats and locations together, this allows companies to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Improve data quality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See and leverage deeper insights from larger and more comprehensive datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improve decision making
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase operational efficiency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples of this include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Providing a centralized data source for business intelligence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enabling machine learning models by improving accuracy and performance by using
    a unified dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Obtaining a unified view of a customer in a **customer relationship management**
    tool (**CRM**) by integrating multiple customer data sources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data integration example
  prefs: []
  type: TYPE_NORMAL
- en: Instead of manually copying and pasting data from one system to another or spending
    hours crunching numbers in spreadsheets, data automation empowers you to set up
    **ETL processes** that do the heavy lifting for you. These ETL processes follow
    pre-defined instructions, ensuring that data flows seamlessly, tasks execute automatically,
    and insights emerge effortlessly.
  prefs: []
  type: TYPE_NORMAL
- en: In some CRM environments, you may find up to 80–100 integrations that have been
    built to enrich the unified view of a customer. When acquisitions occur and customer
    data is stored in multiple CRMs, integrations can be used to bring customer data
    together prior to system integration as a temporary solution that enables the
    business to see all customer information ahead of the hard work of system integration
    and the decommissioning of legacy systems.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, data integration is an essential process for organizations that rely
    on data to make informed decisions, improve operational efficiency, and gain a
    competitive edge. In today’s economy, it is difficult to find a company that does
    not rely on data in this way, but in my experience, there are a plethora of opportunities
    to integrate data better for improved time to insight and improved operations.
  prefs: []
  type: TYPE_NORMAL
- en: Data transformation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Data transformation** is the process of cleaning, formating, and manipulating
    data to prepare it for analysis by using a (more) standardized format for accuracy
    and usability. Data transformation converts data from one format or structure
    into another, which makes it more usable. Data transformation is a key step in
    data pipeline management and is often a part of data integration work. Data transformation
    (and integration) work is typically performed by data engineers in service of
    operations or analytics.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The purpose of data transformation is to convert data or enrich data to make
    it more useful for a specific purpose or set of purposes. There are many ways
    to transform data based on the specific need you are working to solve. Examples
    of this include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Cleaning**: Removing errors, inconsistencies, and duplicates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standardization**: Driving consistency in data (e.g., dates 1/1/2011 to January
    1, 2011).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Creating new fields**: Creating derived data by adding or converging data
    into new fields (e.g., totaling).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Aggregation**: Summarizing data by grouping it (e.g., average sales per month;
    total sales per month).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Filtering**: Extracting subsets of data based on a range of filters (e.g.,
    current year sales).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Transformation Example
  prefs: []
  type: TYPE_NORMAL
- en: One of the most common types of data transformation is the use of **primary
    data management** (**PDM**) techniques. PDM, as we covered in [*Chapter 10*](B18846_10.xhtml#_idTextAnchor206),
    is a capability that I have implemented in three different companies. Typically,
    by bringing together multiple sources of customer data, I have seen dramatic improvements
    in data quality, which has a cascading impact on the way in which companies are
    able to rely on and use customer information to improve revenue, reduce costs,
    and improve insights. In all cases, the analytics improved as well; however, the
    main beneficiary was the business. Don’t forget to focus on the impact made outside
    of your team. In the case of data transformation, the business often benefits
    the most from the speed and quality of improved data transformation.
  prefs: []
  type: TYPE_NORMAL
- en: Data analysis and insights
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Data analysis and insights**: They represent the ability to automate repetitive
    analysis tasks, such as generating reports and identifying patterns (e.g., trends),
    to drive decision-making. Automating these tasks extracts knowledge and insights
    from data and saves time and resources in terms of data analysts and data scientists.
    There are various components to data analysis and insights that can be automated,
    including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data acquisition and preparation**: This process leverages tooling to automatically
    extract data from a variety of sources (systems, APIs, and spreadsheets), reducing
    the manual effort traditionally followed, and this enables error-prone processes
    to be completed consistently and at scale. This process may also include transformation
    to automate data cleaning (e.g., correcting the inconsistencies and formatting)
    to improve the data for further analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data exploration and analysis**: Tools can identify the patterns and trends
    in data and any outliers that are normally identified through manual analytics
    work. This can also benefit data analysts by finding insights that are commonly
    overlooked or buried deep in the data. The scale of a large organization’s datasets
    makes it difficult for a human to find trends without using long time frames and
    expensive tooling. Data automation can enable these processes, where scale is
    a historical challenge.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Insight generation and communication**: Data automation tools can generate
    automated reporting and create visualizations (e.g., Tableau dashboards), which
    present insights in a format that is far easier for end users to explore and review.'
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of data analysis and insight data automation is to expedite and
    drive efficiencies that were once traditionally carried out by high value resources.
    This process enables data analysis to be completed on higher value work and frees
    up your data analysts and scientists to perform more high-value tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples of this include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Automating reporting and insights so that analysts can focus on interpreting
    the results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing human errors in data handling so analysts have higher confidence in
    the reliability of the results, thus improving trust in the data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enabling the democratization of data insights so that a wider range of individuals
    can access and use insights at the speed of business
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data monitoring and alerting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Data monitoring and alerting** is the process of using technology to continuously
    observe and analyze data sources, as well as automating the triggering of alerts
    when specific conditions are met. This capability enables organizations to identify
    problems when they occur before they become major problems. **Monitoring** includes
    collecting information from sources (e.g., databases, APIs, and network devices)
    and using tools to track very specific metrics (e.g., error rates, performance
    indicators, such as time to process, or specific data quality thresholds, such
    as percentage completed), as well as analyzing the data in real-time or on a regular
    candace (i.e., nightly). Another term for this type of process is **data observability**.
    Alerting occurs when a pre-defined threshold is met through monitoring; then,
    an alert is delivered through an email, SMS, or internal notification (e.g., Slack).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples of this include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Server failures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security threats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Errors in processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A sudden drop in orders
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suspicious activities (i.e., fraud)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data cleansing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data cleansing, the process of identifying and correcting errors and inconsistencies
    in data, is a crucial step in ensuring reliable and trustworthy information for
    analysis. Fortunately, this tedious task can be significantly automated, freeing
    up your valuable time and resources.
  prefs: []
  type: TYPE_NORMAL
- en: Types of data cleansing automation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There are several types of data cleansing automation that represent common
    techniques to improve the quality of data. There are a few common types that I
    will provide an overview of here, but please note that each of these types requires
    its own chapter to get into the technical implementation details. At a high level,
    the following are the various types of automation when it comes to data cleaning:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Rule-based automation**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Define rules**: Establish clear rules to identify and address common errors
    based on data formats, values, and relationships'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data profiling tools**: Analyze data to identify patterns and define any
    rules based on these patterns'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Examples of this**: Standardizing date formats, removing outliers, and flagging
    missing values'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fuzzy matching**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Identify similar records**: Match records that have slight variations, such
    as typos or abbreviations'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data deduplication**: Eliminate duplicate records based on fuzzy matching
    algorithms'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Examples of this**: Merging duplicate customer records and identifying inconsistent
    product names (e.g., PDM capabilities)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some of the benefits of automating cleansing include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Increased efficiency**: Saving time and resources by automating repetitive
    cleaning tasks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved accuracy**: Reducing human error and ensuring consistent data quality'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability**: Easily handling large datasets and complex cleaning requirements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Better insights**: Building more reliable and trustworthy models based on
    clean data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Considerations for the automation of data cleansing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Before selecting a type of automated data cleansing for your use case, you
    should consider the following as you evaluate your options:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data complexity**: Complex data with diverse errors may require manual intervention
    or advanced algorithms'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rule development**: Defining effective rules requires understanding your
    data and common errors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data security**: Ensure the chosen solutions comply with data security and
    privacy regulations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Begin with automating simple cleaning tasks and gradually expand as you gain
    confidence. By carefully selecting and implementing data cleansing automation,
    you can unlock the true potential of your data for informed decision-making.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced data automation capabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several additional advanced capabilities that can be explored beyond
    the more common data automation capabilities above. Beyond these core types, the
    advanced capabilities include the following: data cleansing, machine learning
    and AI automation, and **robotic process automation** (**RPA**). These advanced
    capabilities are very helpful for capabilities that are standardized and repeatable.
    At a high level, there are two capabilities that are especially useful for data
    automation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Machine learning and AI automation**: Leverages AI algorithms for deeper
    analysis, predictions, and data-driven recommendations. Some examples include
    the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training algorithms**: Train models on labeled data to identify and correct
    errors with greater accuracy and adaptability'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Supervised learning**: Training models on labeled data with correct and incorrect
    examples'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unsupervised learning**: Use algorithms to identify anomalies and patterns
    to suggest potential errors'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Examples of this**: Identifying and correcting spelling errors and predicting
    missing values based on other data points'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Robotic Process Automation** (**RPA**): Automating tasks that interact directly
    with user interfaces, such as data entry in web applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These advanced data automation capabilities are much more robust and involved
    and could warrant an entire book of their own. For now, be aware that these additional
    types exist; it is often beneficial to evaluate if they are fit for use in your
    organization once you have tackled the implementation of the data automation capabilities
    covered in this chapter. Next, we will dig into the benefits of data automation
    and how to measure the benefits.
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of data automation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When it comes to automation, the benefits extend beyond efficiency. Efficiency
    is a great first principle, but data automation empowers us to do so much more.
    These benefits can and should be quantified as you build your business case, and
    as you realize the value, you should report on them to show the return on investment
    (ROI) for your data automation investments. The common benefits are wide-ranging,
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ensure accuracy and consistency**: Data automation eliminates human error
    in data handling, leading to reliable and trustworthy information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Example**: Automating the enrichment of data for marketing leads to reduced
    errors and produces comparable, consistent results daily.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gain deeper insights**: Analyzing vast datasets at scale, uncovering hidden
    patterns and trends that are invisible to the human eye.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Example**: Automatically identifying the hidden patterns between product
    purchases and customer demographics, such as a situation whereby customers who
    buy raincoats are also likely to buy umbrellas when weather predicts rain within
    48 hours in their location. Thus, the company would benefit from placing umbrellas
    at the front of the store to encourage a higher purchase rate.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improve decision-making**: Driving data-driven choices by automating data
    analysis and reporting, providing real-time insights to inform actions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Example**: Data observability built into a data lake to alert when data volumes
    drop below expectations (e.g., by 5% or greater).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduce costs**: Streamlining workflows and optimizing resource allocation,
    leading to significant cost savings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Example**: Automating the data cleansing of customer records to expedite
    them leads to account matching in a CRM system.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Boost agility**: Respond faster to changing market conditions by automating
    data collection, analysis, and reporting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Example**: The automation of daily sales reports allows for the additional
    capacity of data analysts to be focused on anomalies.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improve team member experience**: By automating data processes and basic
    reporting, team members are able to focus on more interesting and high-value activities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Example**: After automating daily sales reports, data analysts are able to
    focus on anomaly detection, and they are able to dig into anomalies and uncover
    additional sales opportunities for specific customer segments, increasing revenue
    opportunities.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Beyond identifying the benefits of data automation, it is critical to measure
    the impact of the benefits so that you can measure the return on the investment
    of implementing data automation techniques within your data governance program.
    As you work to build out this capability within your data program, ensure you
    leverage what was learned in [*Chapter 5*](B18846_05.xhtml#_idTextAnchor110).
    We will build on what was learned in the following section, with a specific tilt
    towards data automation.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring the benefits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a few types of measurement to consider, including both quantitative
    and qualitative measures. Remember, quantitative measures are based on numbers
    and are more directly measured, whereas qualitative measures are based on experiences
    and are harder to measure directly. Both types of measures are important for your
    audience to understand, as they benefit your stakeholders in a variety of ways,
    including their experience of working for your organization.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of quantitative measures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Some examples of quantitative measures include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Improvement in customer conversion rate**: After implementing data-driven
    product recommendations based on next-best-action modeling, track the percentage
    of customers who make a purchase before and after the implementation of the automation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increase in revenue**: Measure sales before and after implementing a data
    automation capability. Be sure to take into account external factors such as market
    trends (adjust as needed). Examples of this include personalized marketing campaigns,
    optimized product placement, or dynamic pricing (e.g., airline ticket pricing).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduction in cost**: Measure the savings of person-hours achieved by automating
    tasks such as moving data and cleaning data by measuring the number of hours saved
    multiplied by a base all-in salary rate, including benefits and bonuses. Measure
    this of a time horizon, such as a week, a month, or a year, less the cost of automation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples of qualitative measures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Some examples of qualitative measures include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Customer satisfaction surveys**: By conducting customer satisfaction surveys,
    you can identify how effectively data automation capabilities are used to improve
    the customer experience. An increase in customer satisfaction after the implementation
    of data automation can indicate improved customer experience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Employee surveys**: By conducting employee satisfaction surveys for those
    who benefited from data automation (analysts, business users, and so on) before
    and after, this can help identify and assess the impact of data automation on
    their employee experience. You should expect an increase in job satisfaction when
    mundane tasks are automated well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Brand reputation analysis**: By monitoring online reviews and social media,
    you can determine how brand image is impacted among customer sentiment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Aggregate – Qualitative and quantitative measures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When joined together, both qualitative and quantitative measures should enable
    you to calculate the ROI in data automation activities:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Net Benefits /** **Total Costs**'
  prefs: []
  type: TYPE_NORMAL
- en: Here, net benefits (increased revenue, cost savings, and employee satisfaction
    improvement) are divided by total costs (investment, time, and so on). This assigns
    a financial metric to assess the overall benefit of the implementation of data
    automation capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Define the measures in advance of completing the work. This will result in a
    more objective calculation of the success of the project (in retrospect) than
    when the calculation of success is determined in hindsight.
  prefs: []
  type: TYPE_NORMAL
- en: By combining quantitative and qualitative data, businesses can gain a comprehensive
    understanding of the value generated through data automation in this specific
    example. This multifaceted approach allows for a more holistic evaluation of the
    impact on both business metrics and customer experience.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, I will walk you through how to evaluate the data automation
    types previously explained and define a process that you can use to select the
    appropriate data automation capability for your needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we explore this determination process together, you will be equipped with
    the knowledge to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Identify your automation needs**: Assess your current data challenges and
    determine the most suitable automation solutions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Select the right tools**: Navigate the diverse landscape of data automation
    tools and choose the ones that best fit your requirements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implement effectively**: Understand the key considerations for successful
    implementation, ensuring smooth adoption and maximized impact'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we walk through this next section, it may be helpful to have a use case in
    mind so that you can evaluate this process against it.
  prefs: []
  type: TYPE_NORMAL
- en: How to determine which type of automation to use
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is a fairly straightforward process to identify your needs, select the
    right tools and techniques, and implement them effectively. We will walk through
    exactly how to determine which type to use and how to execute the process for
    your company.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – Identify your goals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Start by exploring the problem. A few key questions to ask include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: What are you trying to achieve?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is working well and needs to be retained?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the current challenges?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What outcomes would indicate a successful solution?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These exploratory questions can help you determine if you need to increase efficiency,
    improve data quality, or if you are looking for a deeper result, such as finding
    deeper insights or meeting regulatory expectations. Perhaps you uncover that you
    are spending far too much of your team members time on low-value work, such as
    manual data cleaning, or you are struggling to identify problems proactively.
    This step will help you identify these goals.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – Identify the existing process and pain points
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, begin to explore the current state. Ask the following questions of your
    team and your stakeholders:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the current process?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have we reviewed the data flow, and are there obvious inefficiencies?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the current systems and datasets? (e.g., structured, unstructured,
    databases, or APIs)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where in the process are there manual steps?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you have the answers to the current state, you can begin to formulate specific
    steps to address the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – Agree on the problem statement(s)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you frame the situation in Steps 1 and 2 above, you are ultimately working
    towards an agreed problem statement (or statements) that define the current state.
    It’s important to ensure that you have agreement on what the problem is prior
    to defining any paths forward for the options in Step 4\. Without firmly aligning
    all parties on the problem, you are much more likely to run into issues when it
    comes to later steps in the process, especially when affirming the solution when
    working as it was designed.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – Align on the approach and ROI calculation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After (or concurrently) aligning on the problem statement, you should put together
    at least one (ideally, two or three) option(s) for how you can approach the solution.
    This alignment may include a combination of data automation techniques and may
    also vary in complexity and the extent of the solution. In the following example,
    the problem statement comes into play because if the general consensus is that
    reporting isn’t the issue, it’s unlikely to be supported and receive money to
    automate it:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Approach A** | **Approach B** | **Approach C** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Automate data pipelines and implement data monitoring and alerting capabilities.
    | Automate data pipelines and implement data monitoring and alerting capabilities.
    | Automate data pipelines and implement data monitoring and alerting capabilities.
    |'
  prefs: []
  type: TYPE_TB
- en: '| No change to analytics. | Automate basic analytics work. | Automate basic
    analytics work. |'
  prefs: []
  type: TYPE_TB
- en: '| No change to reporting. | No change to reporting. | Automate daily reporting
    processes. |'
  prefs: []
  type: TYPE_TB
- en: Table 14.1 – Example of an approach proposal
  prefs: []
  type: TYPE_NORMAL
- en: Example menu of data automation capabilities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following list represents a “menu” of data automation capabilities to choose
    from:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data integration**: Use this if you need to move data between different systems
    regularly, regardless of the format or source'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data transformation**: Choose this if your data requires cleaning, formatting,
    or manipulation before being further used'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data loading**: Implement this if you need to automate the final step of
    depositing transformed data into your target system'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data analysis and insights**: Consider this if you want to automate repetitive
    analysis tasks and generate insights without manual intervention'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data monitoring and alerting**: Choose this if you need proactive notifications
    based on specific data conditions to identify and address issues quickly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Machine learning and AI automation**: Explore this if you want to go beyond
    simple rules and leverage AI for deeper analysis, predictions, and data-driven
    recommendations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Return on investment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you can explain the ROI of the proposals, this adds another layer to the
    decision-making process. Providing a proposed ROI for each solution at this stage
    directly exposes the value of the possible solutions, and this tends to result
    in a very different outcome than if ROI is strictly calculated upon the completion
    of the project. In this example, you may want to add an ROI calculation to each
    row:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Approach A | Approach B | Approach C |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Current resourcing hours * personnel cost of manual supportLess new cost:
    Resourcing hours * personnel cost of maintaining the automated pipelines going
    forward (post-implementation)= Cost savings of automationConsideration: Resourcing
    hours * personnel cost to automate (one-time costs) | Current resourcing hours
    * personnel cost of manual supportLess new cost: Resourcing hours * personnel
    cost of maintaining the automated pipelines going forward (post-implementation)=
    Cost savings of automationConsideration: Resourcing hours * personnel cost to
    automate (one-time costs) | Current resourcing hours * personnel cost of manual
    supportLess new cost: Resourcing hours * personnel cost of maintaining the automated
    pipelines going forward (post-implementation)= Cost savings of automationConsideration:
    Resourcing hours * personnel cost to automate (one-time costs) |'
  prefs: []
  type: TYPE_TB
- en: '| No change to analytics. | Current resourcing hours * personnel cost of manual
    supportLess new cost: Resourcing hours * personnel cost of maintaining the automated
    pipelines going forward (post-implementation)= Cost savings of automationConsideration:
    Resourcing hours * personnel cost to automate (one-time costs) | Current resourcing
    hours * personnel cost of manual supportLess new cost: Resourcing hours * personnel
    cost of maintaining the automated pipelines going forward (post-implementation)=
    Cost savings of automationConsideration: Resourcing hours * personnel cost to
    automate (one-time costs) |'
  prefs: []
  type: TYPE_TB
- en: '| No change to reporting. | No change to reporting. | Current resourcing hours
    * personnel cost of manual supportLess new cost: Resourcing hours * personnel
    cost of maintaining the automated pipelines going forward (post-implementation)=
    Cost savings of automationConsideration: Resourcing hours * personnel cost to
    automate (one-time costs) |'
  prefs: []
  type: TYPE_TB
- en: '| Add together each row for Total Cost of Savings for Approach A | Add together
    each row for Total Cost of Savings for Approach B | Add together each row for
    Total Cost of Savings for Approach C |'
  prefs: []
  type: TYPE_TB
- en: '| Add the sum of the cost of the automation project (row 1) | Add the sum of
    the cost of the automation project (row 1 + 2) | Add the sum of the cost of the
    automation project (row 1 + 2 + 3) |'
  prefs: []
  type: TYPE_TB
- en: Table 14.2 – Process for calculating the value of an automation project
  prefs: []
  type: TYPE_NORMAL
- en: This process becomes the expected ROI for the project. You should go into the
    project with this as a “working assumption.” Upon the completion of Step 6, you
    will measure the actual results to determine the ROI for the project. Do not let
    this prevent you from sharing the assumptions with the stakeholders as you enter
    into the project. Even if you end up materially different than your expectations,
    this process will build transparency and trust. Your stakeholders may provide
    valuable input into your ROI modeling by sharing the model with them upfront.
  prefs: []
  type: TYPE_NORMAL
- en: Additional factors to consider
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are a number of factors you could consider, but the following are typically
    the most important to evaluate for your particular project or solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Available budget**: What financial resources can you afford to spend on this
    project?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resourcing**: Do you have the time and personnel to complete this project?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Technical expertise**: Do the resources that you have (onboard) also have
    the technical expertise to complete the work, or do you need to supplement this
    with outside resources?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security or compliance**: Are there specific requirements you need to consider
    to remain compliant with laws, regulations, or customer contractual obligations?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability**: If your company is growing or your data volumes are expected
    to grow, can the solution handle future projected volumes? Or will you need a
    new solution down the line?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this ROI example, keep in mind that it is typical to combine multiple types
    of data automation together to optimize the results. If you are considering an
    example such as the one outlined in the previous part for Step 4, the maximum
    result will be realized by adopting Approach C.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – Execute
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While this step in the process often takes the longest amount of time, it is
    pretty straightforward. In this step, you execute the option you selected. If
    you find that you need to adjust your plan as you progress through the project,
    make adjustments. My advice is to be transparent when you do, with this forming
    a part of your ongoing messaging and reporting about the project to your stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: Step 6 – Measure and report
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Upon completion, calculate your results based on the model you produced in Step
    4\. Any deviations (from the expectations) that require you to reassess or redesign
    your model are OK; just be clear about why this is and what the impact on your
    measurement is. The last thing you want is to complete this work only to erode
    trust by failing to measure and report transparently. Now that you have completed
    this six-step process, I will explain some additional options for automation that
    you can buy and incorporate into your environment versus building them.
  prefs: []
  type: TYPE_NORMAL
- en: Third-party enrichment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One very common type of data enrichment is the use of third-party data enrichment
    services. Third-party refers to the use of external data. This type of data is
    typically purchased from an outside data vendor and added to the data your company
    creates (referred to as first-party) to create a more enriched and higher-quality
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you are considering using a third-party data source, consider the following
    factors. Not all data enrichment is high quality, and using a third-party source
    that does not meet the expectations of your business can reduce the quality of
    your data versus improve the quality of your data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data quality and accuracy**: Ensure the data is reliable and consistently
    updated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data coverage and relevance**: Verify the data aligns with your specific
    needs and target audience'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data privacy and compliance**: Check for compliance with relevant data privacy
    regulations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pricing and cost models**: Understand the pricing structure and choose a
    solution that fits your budget'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security and integration**: Ensure secure data access and compatibility with
    your existing systems'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember, it’s often beneficial to evaluate different sources and compare their
    offerings before committing to one. By carefully evaluating your needs and the
    available options, you can choose the best third-party data sources to enrich
    your data for your business needs.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: This is not an endorsement of any of the third parties listed (or not) in the
    following section; this is simply an example list of the types of third-party
    enrichment services available that you may have heard of. As with any technology
    selection process, you should assess the needs of your business and your cost/budget,
    making a selection based on your company’s process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The best sources will depend heavily on the needs of your company and the type
    of data you are working to enhance. I have provided examples of several types
    of data to help you understand what types of third-party data enrichment are available,
    and I provide some examples of each:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Contact and** **company data**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**LeadGenius/ZoomInfo**: Provides comprehensive B2B contact and company information
    with high accuracy and real-time updates'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Clearbit**: Offers enrichment for email addresses, domains, and companies,
    including firmographics, technographics, and social media insights'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Dun & Bradstreet**: Features extensive business data with global reach, including
    financial information, credit reports, and business relationships'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Demographic and** **lifestyle data**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Experian**: Delivers consumer credit, marketing, and risk analysis data to
    understand individual demographics and purchasing behaviors'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Equifax**: Offers consumer credit reports, risk assessment tools, and marketing
    data for individual-level enrichment'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mosaic (Nielsen)**: Uses segmentation techniques to categorize individuals
    based on demographics, lifestyles, and purchase behaviors'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Claritas (Claritas)**: Provides consumer segmentation data based on demographics,
    spending habits, and media consumption patterns'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Location and** **geospatial data**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mapbox**: Delivers mapping, geolocation, and geospatial data services to
    enrich data with geographical context'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Google Cloud Location Intelligence**: Utilizes Google Maps data to offer
    insights on demographics, travel patterns, and spatial relationships'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**HERE Technologies**: Provides location-based data APIs and services for mapping,
    routing, and geospatial analysis'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Foursquare**: Features insights on points of interest (POIs), foot traffic
    patterns, and competitor analysis based on location data'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Social media and** **web data**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Brandwatch**: Tracks and analyzes social media conversations and online discussions
    relevant to your brand or industry'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Sprout Social**: Offers social media listening and analytics tools to understand
    audience sentiment and brand mentions'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Similarweb**: Provides competitive intelligence on website traffic, audience
    demographics, and online marketing strategies'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Buzzsumo**: Helps identify trending content and influential figures in your
    domain to inform content marketing efforts.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Custom and** **specialized data**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Numerous specialized data providers exist in various industries, such as healthcare,
    finance, and technology
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Conduct research specific to your industry and data needs to discover niche
    providers focused on enriching your particular dataset
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Remember, there are hundreds of options when it comes to third-party enrichment
    services. You need to evaluate and select these based on the needs of your organization.
    This list is intended to offer examples and to get you started and is not an endorsement
    of any particular third-party data solution.
  prefs: []
  type: TYPE_NORMAL
- en: Data solution examples powered by data automation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have gone through the types of data automation, the benefits of
    data automation, how to calculate the return on your data automation investment,
    and what to do to implement it, the hardest remaining part is identifying where
    to get started. I recommend you select an area of the business that is exceptionally
    manual and begin. Yes, just begin. By focusing your efforts on one area, you can
    show dramatic results. If you spread your data automation efforts across divisions,
    it may become hard to feel the dramatic improvement that can be realized through
    data automation capabilities. By focusing your efforts, stakeholders in other
    divisions will take notice, and you can, over time, move into new parts of the
    organization.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are 10 strategic areas to consider starting with when it comes to designing
    your data automation capability in your organization:'
  prefs: []
  type: TYPE_NORMAL
- en: Customer domain
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, in the customer domain (every company has customers, so this likely
    applies to your organization), there are several options for accelerating your
    data solutions with automation. Consider the following five common opportunities:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Enhance marketing campaigns**: Automate personalized email marketing, A/B
    testing, and lead scoring, driving higher engagement and ROI'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Streamline customer onboarding**: Automate data collection, account creation,
    and initial communication, making the process faster and smoother for new customers'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Personalize customer service**: Utilize chatbots and AI-powered assistants
    to answer common questions, resolve issues, and enhance the customer experience'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Automate reporting and analytics**: Generate routine reports and dashboards
    automatically, empowering data-driven decisions across departments'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Accelerate product development**: Automate market research analysis, customer
    feedback integration, and competitor monitoring, informing efficient product development
    cycles'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Operations domain
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Like customers, every organization has operations to manage their business.
    Consider optimizing operations with the following data automation use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Optimize order processing**: Automate order intake, inventory checks, and
    shipment management, minimizing errors and improving delivery speed'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Optimize supply chain management**: Automate inventory tracking, supplier
    communication, and logistics planning, which leads to cost-efficiency and improved
    responsiveness'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Improve financial management**: Automate invoice processing, expense tracking,
    and budget monitoring, ensuring accuracy and timely insights'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Boost HR efficiency**: Automate payroll processing, benefit administration,
    and employee onboarding, freeing up HR resources for higher-level tasks'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Enhance risk management**: Implement automated data security scans, threat
    detection, and compliance reporting, ensuring a proactive approach to security'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While these are only a few examples, they are great places to get started in
    building out your data automation capabilities. As with other capabilities, be
    sure to build in feedback loops and effective communication patterns for your
    stakeholders to understand what you are delivering and how to build virtuous cycles
    of improvement as a standard in your program overall.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data automation is a specific technique that is additive to the capabilities
    that are already deployed in your organization. There are several types of data
    automation that are available to you, and we have covered these. Typically, this
    capability is a great place for your data engineers and data analytics professionals
    to drive additional value to your organization. If traditional data governance
    capabilities are effective at getting from place A to B on a bike, adding data
    automation capabilities to existing data governance capabilities is like using
    a car to get from A to B. It will move you faster and with velocity. However,
    be careful. Moving faster isn’t always the best answer. You must be sure you are
    automating a strong process; otherwise, you are simply moving problems through
    your organization faster. As we covered previously, there are several options
    at your disposal, including using third-party enrichment, implementing additional
    tooling, such as RPA, and improving data cleansing with services. Consider where
    automation is beneficial to the business.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you embark on your data automation journey, remember to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Identify the types of automation that would best support data transformation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify where to apply automation in terms of data products and solutions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn how to obtain support for automation solutions, what types of skills are
    needed, and how to communicate the results to leadership/sponsors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Above all else, partner closely with your stakeholders. Focus on aligning expectations
    and what “good” looks like so that you are tightly aligned on the results that
    drive tremendous impact and trust in data. Not every single step of every process
    is a great candidate for automation. As we covered previously, it’s important
    to evaluate the options and deliberately apply automation where it will drive
    the most significant ROI.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, I will pivot to the topic of driving the adoption of your
    solutions. In this chapter, we will carry forward the learnings we have obtained
    thus far, and we will discuss how to make the solutions “sticky” or more highly
    adopted within your company. This helps further your ROI by increasing the use
    of your solutions.
  prefs: []
  type: TYPE_NORMAL
