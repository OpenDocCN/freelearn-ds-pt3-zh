["```py\n    In [4]: import matplotlib.pyplot as plt\n               %matplotlib inline  \n    In [5]: plt.hist([7,0,1,2,3,7,1,2,3,4,2,7,6,5,2,1,6,8,9,7])\n               plt.xlabel('x')\n               plt.ylabel('Count')\n               plt.title('Bimodal distribution')\n               plt.show()\n```", "```py\n    In [18]: grades = [10, 10, 14, 18, 18, 5, 10, 8, 1, 12, 14, 12, 13, 1, 18]  \n```", "```py\n    In [29]: %precision 3  # Set output precision to 3 decimal places\n    Out[29]:u'%.3f'\n\n    In [30]: import numpy as np\n             np.mean(grades)\n    Out[30]: 10.933\n\n    In [35]: %precision\n             np.median(grades)\n    Out[35]: 12.0\n\n    In [24]: from scipy import stats\n             stats.mode(grades)\n    Out[24]: (array([ 10.]), array([ 3.]))\n    In [39]: import matplotlib.pyplot as plt\n    In [40]: plt.hist(grades)\n             plt.title('Histogram of grades')\n             plt.xlabel('Grade')\n             plt.ylabel('Frequency')\n             plt.show()  \n```", "```py\n    In [45]: %precision 2\n             salaries = [17, 23, 14, 16, 19, 22, 15, 18, 18, 93, 95]\n\n    In [46]: np.mean(salaries)\n    Out[46]: 31.82\n```", "```py\n    In [59]: fig = plt.figure()\n             ax = fig.add_subplot(111)\n             ind = np.arange(len(salaries))\n             width = 0.2\n             plt.hist(salaries, bins=xrange(min(salaries),\n             max(salaries)).__len__())\n             ax.set_xlabel('Salary')\n             ax.set_ylabel('# of employees')\n             ax.set_title('Bar chart of salaries')\n             plt.show()  \n```", "```py\n    In [47]: np.median(salaries)\n    Out[47]: 18.00\n```", "```py\n    In [56]: plt.hist(salaries, bins=len(salaries))\n             plt.title('Histogram of salaries')\n             plt.xlabel('Salary')\n             plt.ylabel('Frequency')\n             plt.show()\n```", "```py\n    In [27]: import random\n             random.seed(100)\n             testScores = [random.randint(0,100) for p in \n                           xrange(0,20)]\n             testScores\n    Out[27]: [14, 45, 77, 71, 73, 43, 80, 53, 8, 46, 4, 94, 95, 33, 31, 77, 20, 18, 19, 35]\n\n    In [28]: #data needs to be sorted for quartiles\n          sortedScores = np.sort(testScores) \n    In [30]: rankedScores = {i+1: sortedScores[i] for i in \n                             xrange(len(sortedScores))}\n\n    In [31]: rankedScores\n    Out[31]:\n    {1: 4,\n     2: 8,\n     3: 14,\n     4: 18,\n     5: 19,\n     6: 20,\n     7: 31,\n    8: 33,\n     9: 35,\n     10: 43,\n     11: 45,\n     12: 46,\n     13: 53,\n     14: 71,\n     15: 73,\n     16: 77,\n     17: 77,\n     18: 80,\n     19: 94,\n     20: 95}\n\n```", "```py\nQ1 = (19+20)/2 = 19.5\nQ2 = (43 + 45)/2 = 44\nQ3 = (73 + 77)/2 = 75  \n```", "```py\n    In [38]: from scipy.stats.mstats import mquantiles\n             mquantiles(sortedScores)\n    Out[38]: array([ 19.45,  44\\.  ,  75.2 ])\n\n    In [40]: [np.percentile(sortedScores, perc) for perc in [25,50,75]]\n    Out[40]: [19.75, 44.0, 74.0]\n\n```", "```py\nIn [104]: 1 - stats.norm.cdf(3.75)\nOut[104]: 8.841728520081471e-05  \n```", "```py\nIn [53]: import pandas as pd  \nimport numpy as np  \nfeRawData = pd.read_csv('2014_FEGuide.csv') \n\nIn [54]: feRawData.columns[:20]\nOut[54]: Index([u'Model Year', u'Mfr Name', u'Division', u'Carline', u'Verify Mfr Cd', u'Index (Model Type Index)', u'Eng Displ', u'# Cyl', u'Trans as listed in FE Guide (derived from col AA thru AF)', u'City FE (Guide) - Conventional Fuel', u'Hwy FE (Guide) - Conventional Fuel', u'Comb FE (Guide) - Conventional Fuel', u'City Unadj FE - Conventional Fuel', u'Hwy Unadj FE - Conventional Fuel', u'Comb Unadj FE - Conventional Fuel', u'City Unrd Adj FE - Conventional Fuel', u'Hwy Unrd Adj FE - Conventional Fuel', u'Comb Unrd Adj FE - Conventional Fuel', u'Guzzler? ', u'Air Aspir Method'], dtype='object')\n\nIn [51]: feRawData = feRawData.rename(columns={'Trans as listed in FE Guide (derived from col AA thru AF)' :'TransmissionType', 'Comb FE (Guide) - Conventional Fuel' : 'CombinedFuelEcon'})\n\n    In [57]: transType=feRawData['TransmissionType']\n             transType.head()\n    Out[57]: 0      Auto(AM7)\n             1     Manual(M6)\n             2      Auto(AM7)\n             3     Manual(M6)\n             4    Auto(AM-S7)\n             Name: TransmissionType, dtype: object\n\n```", "```py\n    In [58]: transTypeSeries = transType.str.split('(').str.get(0)\n             transTypeSeries.head()\n    Out[58]: 0      Auto\n             1    Manual\n             2      Auto\n             3    Manual\n             4      Auto\n             Name: TransmissionType, dtype: object\n\n```", "```py\n    In [61]: feData=pd.DataFrame([transTypeSeries,feRawData['CombinedFuelEcon']]).T\n             feData.head()\n    Out[61]:    TransmissionType    CombinedFuelEcon\n             0  Auto                16\n             1  Manual              15\n             2  Auto                16\n             3  Manual              15\n             4  Auto                17\n             5 rows × 2 columns\n\n```", "```py\n    In [62]: feData_auto=feData[feData['TransmissionType']=='Auto']\n             feData_manual=feData[feData['TransmissionType']=='Manual']\n    In [63]: feData_auto.head()\n    Out[63]:   TransmissionType     CombinedFuelEcon\n            0  Auto                 16\n            2  Auto                 16\n            4  Auto                 17\n            6  Auto                 16\n            8  Auto                 17\n            5 rows × 2 columns\n```", "```py\n    In [64]: len(feData_auto)\n    Out[64]: 987\n\n    In [65]: len(feData_manual)\n    Out[65]: 211\n\n    In [87]: np.mean(feData_auto['CombinedFuelEcon'])\n    Out[87]: 22.173252279635257\n\n    In [88]: np.mean(feData_manual['CombinedFuelEcon'])\n    Out[88]: 25.061611374407583\n\n    In [84]: import scipy.stats as stats\n             stats.ttest_ind(feData_auto['CombinedFuelEcon'].tolist(), \n                             feData_manual['CombinedFuelEcon'].tolist())\n    Out[84]: (array(-6.5520663209014325), 8.4124843426100211e-11)\n\n    In [86]: stats.ttest_ind(feData_auto['CombinedFuelEcon'].tolist(), \n                             feData_manual['CombinedFuelEcon'].tolist(), \n                             equal_var=False)\n    Out[86]: (array(-6.949372262516113), 1.9954143680382091e-11)\n\n```", "```py\n #Function to calculate the chi-square statistic \ndef chi_sq_stat(data_ob):              \n    col_tot=data_ob.sum(axis=0) \n    row_tot=data_ob.sum(axis=1) \n    tot=col_tot.sum(axis=0) \n    row_tot.shape=(2,1) \n    data_ex=(col_tot/tot)*row_tot \n    num,den=(data_ob-data_ex)**2,data_ex \n    chi=num/den \n    return chi.sum() \n\n#Function to calculate the degrees of freedom \ndef degree_of_freedom(data_ob): \n    dof=(data_ob.shape[0]-1)*(data_ex.shape[1]-1) \n    return dof \n\n# Calculting these for the observed data \ndata_ob=np.array([(20,6,30,44),(180,34,50,36)]) \nchi_sq_stat(data_ob) \ndegree_of_freedom(data_ob) \n```", "```py\n    import pandas as pd\n    data=pd.read_csv('ANOVA.csv')\n    data.head()\n```", "```py\n# Calculating SSAG\ngroup_mean=data.groupby('Lot').mean()\ngroup_mean=np.array(group_mean['OD'])\ntot_mean=np.array(data['OD'].mean())\ngroup_count=data.groupby('Lot').count()\ngroup_count=np.array(group_count['OD'])\nfac1=(group_mean-tot_mean)**2\nfac2=fac1*group_count\nDF1=(data['Lot'].unique()).size-1\nSSAG=(fac2.sum())/DF1\nSSAG\n\n#Calculating SSWG\ngroup_var=[]\nfor i in range((data['Lot'].unique()).size):\n    lot_data=np.array(data[data['Lot']==i+1]['OD'])\n    lot_data_mean=lot_data.mean()\n    group_var_int=((lot_data-lot_data_mean)**2).sum()\n    group_var.append(group_var_int)\ngroup_var_sum=(np.array(group_var)).sum()\nDF2=data.shape[0]-(data['Lot'].unique()).size-1\nSSAW=group_var_sum/DF2\nSSAW\n\nF=SSAG/SSAW\nF\n```", "```py\n    In [46]: import statsmodels.api as sma\n             faithful=sma.datasets.get_rdataset(\"faithful\")\n             faithful\n    Out[46]: <class 'statsmodels.datasets.utils.Dataset'>\n\n    In [48]: faithfulDf=faithful.data\n             faithfulDf.head()\n    Out[48]:    eruptions   waiting\n            0   3.600       79\n            1   1.800       54\n            2   3.333       74\n            3   2.283       62\n            4  4.533        85\n    5 rows × 2 columns\n\n    In [50]: len(faithfulDf)\n    Out[50]: 272\n```", "```py\n    In [80]: mean,std=(np.mean(faithfulDf['waiting']),\n                       np.std(faithfulDf['waiting']))  \n```", "```py\n    In [81]: from scipy import stats\n          N=len(faithfulDf['waiting'])\n            ci=stats.norm.interval(0.95,loc=mean,scale=std/np.sqrt(N))\n    In [82]: ci\n    Out[82]: (69.28440107709261, 72.509716569966201)\n```", "```py\n    In [38]: import pandas as pd\n             import numpy as np\n             chirpDf= pd.read_csv('cricket_chirp_temperature.csv')\n    In [39]: chirpDf\n    Out[39]:chirpFrequency  temperature\n    0       20.000000       88.599998\n    1       16.000000       71.599998\n    2       19.799999       93.300003\n    3       18.400000       84.300003\n    4       17.100000       80.599998\n    5       15.500000       75.199997\n    6       14.700000       69.699997\n    7       17.100000       82.000000\n    8       15.400000       69.400002\n    9       16.200001       83.300003\n    10      15.000000       79.599998\n    11      17.200001       82.599998\n    12      16.000000       80.599998\n    13      17.000000       83.500000\n    14      14.400000       76.300003\n    15 rows × 2 columns\n\n```", "```py\n    In [29]: plt.scatter(chirpDf.temperature,chirpDf.chirpFrequency,\n                marker='o',edgecolor='b',facecolor='none',alpha=0.5)\n               plt.xlabel('Temperature')\n               plt.ylabel('Chirp Frequency')\n               slope, intercept = np.polyfit(chirpDf.temperature,chirpDf.chirpFrequency,1)\n               plt.plot(chirpDf.temperature,chirpDf.temperature*slope + intercept,'r')\n               plt.show()\n\n```", "```py\n    [37]: chirpDf= pd.read_csv('cricket_chirp_temperature.csv')\n          chirpDf=np.round(chirpDf,2)\n          result=sm.ols('temperature ~ chirpFrequency',chirpDf).fit()\n          result.summary()\n\n    Out[37]: OLS Regression Results\n       Dep. Variable: temperature     R-squared:      0.697\n       Model: OLS     Adj. R-squared: 0.674\n       Method:        Least Squares   F-statistic:    29.97\n       Date:  Wed, 27 Aug 2014     Prob (F-statistic):     0.000107\n       Time:  23:28:14        Log-Likelihood: -40.348\n       No. Observations:      15      AIC:    84.70\n       Df Residuals:  13      BIC:    86.11\n       Df Model:      1               \n                       coef     std err t     P>|t| [95.0% Conf. Int.]\n       Intercept     25.2323 10.060  2.508 0.026 3.499 46.966\n       chirpFrequency 3.2911  0.601  5.475 0.000 1.992 4.590\n\n       Omnibus:        1.003   Durbin-Watson:  1.818\n       Prob(Omnibus):  0.606   Jarque-Bera (JB):       0.874\n       Skew:   -0.391  Prob(JB):       0.646\n       Kurtosis:       2.114   Cond. No.       171.\n```", "```py\nIn [38]: R=np.sqrt(result.rsquared)\n         R\nOut[38]: 0.83514378678237422 \n```"]