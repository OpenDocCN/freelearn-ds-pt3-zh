<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">pandas Compared with Other Tools</h1>
                </header>
            
            <article>
                
<p>This chapter focuses on comparing pandas with R, the statistical package on which much of the pandas functionality is modeled, and other tools such as SQL and SAS, with which it has a significant degree of overlap. It is intended as a guide for R, SQL, and SAS users who wish to use pandas, and for users who wish to replicate functionality that they have seen in their code in pandas. It focuses on a number of key features available to R, SQL, and SAS users, and demonstrates how to achieve similar functionality in pandas by using some illustrative examples. This chapter assumes that you have the R statistical package installed. If not, it can be downloaded and installed from here: <a href="http://www.r-project.org/"><span class="URLPACKT">http://www.r-project.org/</span></a>.</p>
<p>By the end of the chapter, data analysis users should have a good grasp of the data analysis capabilities of these tools as compared to pandas, enabling them to transition to, or use, pandas should they need to. The various factors where the tools have been compared include the following:</p>
<ul>
<li>Data types and the pandas equivalents</li>
<li>Slicing and selection</li>
<li>Arithmetic operations on data type columns</li>
<li>Aggregation and GroupBy</li>
<li>Matching</li>
<li>Split-apply-combine</li>
<li>Melting and reshaping</li>
<li>Factors and categorical data</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Comparison with R</h1>
                </header>
            
            <article>
                
<p>R is the tool on which pandas is loosely designed. Many of the functionalities are very similar in terms of syntax, usage, and output. Differences occur mainly in some of the data types, which can be the matrix in R versus arrays in pandas, an aggregation framework, such as the <kbd>aggregate</kbd> function in R and the <kbd>GroupBy</kbd> operation in pandas, and subtle differences in the syntaxes of similarly named functions, such as <kbd>melt</kbd> and <kbd>cut</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data types in R</h1>
                </header>
            
            <article>
                
<p>R has five primitive or atomic types:</p>
<ul>
<li>Character</li>
<li>Numeric</li>
<li>Integer</li>
<li>Complex</li>
<li>Logical/Boolean</li>
</ul>
<p>It also has the following more complex container types:</p>
<ul>
<li><strong>Vector</strong>: This is similar to <kbd>numpy.array</kbd>. It can only contain objects of the same type.</li>
<li><strong>List</strong>: This is a heterogeneous container. Its equivalent in pandas would be a series.</li>
<li><strong>DataFrame</strong>: This is a heterogeneous two-dimensional container, equivalent to a pandas DataFrame.</li>
<li><strong>Matrix</strong>: This is a homogeneous two-dimensional version of a vector. It is similar to a <kbd>numpy.<span>array</span></kbd>.</li>
</ul>
<p>For this chapter, we will focus on list and DataFrame, which have the following equivalents in <span>pandas: </span>series and DataFrame.</p>
<div class="packt_infobox">For more information on R data types, refer to the following document at <a href="http://www.statmethods.net/input/datatypes.html"><span class="URLPACKT">http://www.statmethods.net/input/datatypes.html</span></a>.<br/>
For NumPy data types, refer to the following documents at <a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html"><span class="URLPACKT">http://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html</span></a> and <a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.html"><span class="URLPACKT">http://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.html</span></a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">R lists</h1>
                </header>
            
            <article>
                
<p>R lists can be created explicitly as a list declaration, shown as follows:</p>
<pre>&gt;h_lst&lt;- list(23,'donkey',5.6,1+4i,TRUE) 
&gt;h_lst 
[[1]] 
[1] 23 
 
[[2]] 
[1] "donkey" 
 
[[3]] 
[1] 5.6 
 
[[4]] 
[1] 1+4i 
 
[[5]] 
[1] TRUE 
 
&gt;typeof(h_lst) 
[1] "list" </pre>
<p>The following code block includes its series equivalent in pandas, with the creation of a list followed by the creation of a series therefrom:</p>
<pre>In [8]: h_list=[23, 'donkey', 5.6,1+4j, True] 
In [9]: import pandas as pd 
        h_ser=pd.Series(h_list) 
In [10]: h_ser 
Out[10]: 0        23 
         1    donkey 
         2       5.6 
         3    (1+4j) 
         4      True 
dtype: object </pre>
<p>Array indexing starts at 0 in pandas, unlike R, where it starts at 1. The following is an example:</p>
<pre>    <strong>In [11]: type(h_ser)</strong>
    <strong>Out[11]: pandas.core.series.Series</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">R DataFrames</h1>
                </header>
            
            <article>
                
<p>We can construct an R DataFrame as follows by calling the <kbd>data.frame()</kbd> constructor and then displaying it as follows:</p>
<pre>&gt;stocks_table&lt;- data.frame(Symbol=c('GOOG','AMZN','FB','AAPL', 
                                      'TWTR','NFLX','LINKD'),  
                            Price=c(518.7,307.82,74.9,109.7,37.1, 
                                           334.48,219.9), 
MarketCap=c(352.8,142.29,216.98,643.55,23.54,20.15,27.31)) 
 
&gt;stocks_table 
Symbol  PriceMarketCap 
1   GOOG 518.70    352.80 
2   AMZN 307.82    142.29 
3     FB  74.90    216.98 
4   AAPL 109.70    643.55 
5   TWTR  37.10     23.54 
6   NFLX 334.48     20.15 
7  LINKD 219.90     27.31 </pre>
<p>In the following code block, we construct a pandas DataFrame and then display it:</p>
<pre>In [29]: stocks_df=pd.DataFrame({'Symbol':['GOOG','AMZN','FB','AAPL',  
                                           'TWTR','NFLX','LNKD'], 
                                 'Price':[518.7,307.82,74.9,109.7,37.1, 
         334.48,219.9], 
'MarketCap($B)' : [352.8,142.29,216.98,643.55, 
                                                    23.54,20.15,27.31] 
                                 }) 
stocks_df=stocks_df.reindex_axis(sorted(stocks_df.columns,reverse=True),axis=1) 
stocks_df 
Out[29]: 
Symbol  PriceMarketCap($B) 
0       GOOG    518.70  352.80 
1       AMZN    307.82  142.29 
2       FB      74.90   216.98 
3       AAPL    109.70  643.55 
4       TWTR    37.10   23.54 
5       NFLX    334.48  20.15 
6       LNKD219.90  27.31 </pre>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Slicing and selection</h1>
                </header>
            
            <article>
                
<p>In R, we slice objects in the following three ways:</p>
<ul>
<li><kbd>[</kbd>: This always returns an object of the same type as the original and can be used to select more than one element.</li>
<li><kbd>[[</kbd>: This is used to extract elements of a list or DataFrame, and can only be used to extract a single element. The nature of the returned element will not necessarily be a list or DataFrame.</li>
<li><kbd>$</kbd>: This is used to extract elements of a list or DataFrame by name and is similar to <kbd>[[</kbd>.</li>
</ul>
<p>Here are some slicing examples in R and their equivalents in pandas:</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Comparing R-matrix and NumPy array</h1>
                </header>
            
            <article>
                
<p>Let's look at creation and selection in R:</p>
<pre>&gt;r_mat&lt;- matrix(2:13,4,3) 
&gt;r_mat 
     [,1] [,2] [,3] 
[1,]    2    6   10 
[2,]    3    7   11 
[3,]    4    8   12 
[4,]    5    9   13 </pre>
<p>To select the first row, we write the following:</p>
<pre>&gt;r_mat[1,] 
[1]  2  6 10 </pre>
<p>To select the second column, we use the following command:</p>
<pre>&gt;r_mat[,2] 
[1] 6 7 8 9 </pre>
<p>Let's now look at NumPy array creation and selection:</p>
<pre>In [60]: a=np.array(range(2,6)) 
         b=np.array(range(6,10)) 
         c=np.array(range(10,14)) 
In [66]: np_ar=np.column_stack([a,b,c]) 
np_ar 
Out[66]: array([[ 2,  6, 10], 
[ 3,  7, 11], 
[ 4,  8, 12], 
[ 5,  9, 13]]) </pre>
<p>To select the first row, we use the following command:</p>
<pre>    <strong>In [79]: np_ar[0,]</strong>
    <strong>Out[79]: array([ 2,  6, 10])</strong>
  </pre>
<div class="packt_infobox">Indexing is different in R and pandas/NumPy.<br/>
In R, indexing starts at 1, while in pandas/NumPy, it starts at 0. Hence, we have to subtract 1 from all indexes when making the translation from R to pandas/NumPy.</div>
<p>To select the second column, we use the following command:</p>
<pre>    <strong>In [81]: np_ar[:,1]</strong>
    <strong>Out[81]: array([6, 7, 8, 9])</strong></pre>
<p>Another option is to transpose the array first and then select the column, as follows:</p>
<pre>    <strong>In [80]: np_ar.T[1,]</strong>
    <strong>Out[80]: array([6, 7, 8, 9])</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Comparing R lists and pandas series</h1>
                </header>
            
            <article>
                
<p>List creation and selection in R is as follows:</p>
<pre>&gt;cal_lst&lt;- list(weekdays=1:8, mth='jan') 
&gt;cal_lst 
$weekdays 
[1] 1 2 3 4 5 6 7 8 
 
$mth 
[1] "jan" 
 
&gt;cal_lst[1] 
$weekdays 
[1] 1 2 3 4 5 6 7 8 
 
&gt;cal_lst[[1]] 
[1] 1 2 3 4 5 6 7 8 
 
&gt;cal_lst[2] 
$mth 
[1] "jan" </pre>
<p class="mce-root"/>
<p>Series creation and selection in pandas is effected as follows:</p>
<pre>In [92]: cal_df= pd.Series({'weekdays':range(1,8), 'mth':'jan'}) 
In [93]: cal_df 
Out[93]: mthjan 
weekdays    [1, 2, 3, 4, 5, 6, 7] 
dtype: object 
 
In [97]: cal_df[0] 
Out[97]: 'jan' 
 
In [95]: cal_df[1] 
Out[95]: [1, 2, 3, 4, 5, 6, 7] 
 
In [96]: cal_df[[1]] 
Out[96]: weekdays    [1, 2, 3, 4, 5, 6, 7] 
dtype: object </pre>
<p>Here, we see a difference between an R-list and a pandas series from the perspective of the <kbd>[]</kbd> and <kbd>[[]]</kbd> operators. We can see the difference by considering the second item, which is a character string.</p>
<p>In the case of R, the <kbd>[]</kbd> operator produces a container type, that is, a list containing the string, while the <kbd>[[]]</kbd> operator produces an atomic type, in this case, a character, as follows:</p>
<pre>&gt;typeof(cal_lst[2]) 
[1] "list" 
&gt;typeof(cal_lst[[2]]) 
[1] "character" </pre>
<p>In the case of pandas, the opposite is true: <kbd>[]</kbd> produces the atomic type, while <kbd>[[]]</kbd> results in a complex type, that is, a series, as follows:</p>
<pre>In [99]: type(cal_df[0]) 
Out[99]: str 
 
In [101]: type(cal_df[[0]]) 
Out[101]: pandas.core.series.Series </pre>
<p>In both R and pandas, the column name can be specified in order to an element.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Specifying a column name in R</h1>
                </header>
            
            <article>
                
<p>In R, this can be done with the column name preceded by the <kbd>$</kbd> operator as follows:</p>
<pre>    <strong>&gt;cal_lst$mth</strong>
    <strong>[1] "jan"</strong>
    <strong>&gt; cal_lst$'mth'</strong>
    <strong>[1] "jan"</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Specifying a column name in pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, we subset elements in the usual way with the column name in square brackets:</p>
<pre>    <strong>In [111]: cal_df['mth']</strong>
    <strong>Out[111]: 'jan'</strong></pre>
<p>One area where R and pandas differ is in the subsetting of nested elements. For example, to obtain day 4 from weekdays, we have to use the <kbd>[[]]</kbd> operator in R:</p>
<pre>    <strong>&gt;cal_lst[[1]][[4]]</strong>
    <strong>[1] 4</strong>
    
    <strong>&gt;cal_lst[[c(1,4)]]</strong>
    <strong>[1] 4 </strong></pre>
<p>However, in the case of pandas, we can just use a double <kbd>[]</kbd>:</p>
<pre>    <strong>In [132]: cal_df[1][3]</strong>
    <strong>Out[132]: 4</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">R DataFrames versus pandas DataFrames</h1>
                </header>
            
            <article>
                
<p>Selecting data in R DataFrames and pandas DataFrames follows a similar script. The following section explains how we perform multi-column selects from both.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Multi-column selection in R</h1>
                </header>
            
            <article>
                
<p>In R, we specify the multiple columns to select by stating them in a vector within square brackets:</p>
<pre>    <strong>&gt;stocks_table[c('Symbol','Price')]</strong>
    <strong>Symbol  Price</strong>
    <strong>1   GOOG 518.70</strong>
    <strong>2   AMZN 307.82</strong>
    <strong>3     FB  74.90</strong>
    <strong>4   AAPL 109.70</strong>
    <strong>5   TWTR  37.10</strong>
    <strong>6   NFLX 334.48</strong>
    <strong>7  LINKD 219.90</strong>
    
    <strong>&gt;stocks_table[,c('Symbol','Price')]</strong>
    <strong>Symbol  Price</strong>
    <strong>1   GOOG 518.70</strong>
    <strong>2   AMZN 307.82</strong>
    <strong>3     FB  74.90</strong>
    <strong>4   AAPL 109.70</strong>
    <strong>5   TWTR  37.10</strong>
    <strong>6   NFLX 334.48</strong>
    <strong>7  LINKD 219.90</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Multi-column selection in pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, we subset elements in the usual way with the column names in square brackets:</p>
<pre>    <strong>In [140]: stocks_df[['Symbol','Price']]</strong>
    <strong>Out[140]:Symbol Price</strong>
    <strong>0        GOOG   518.70</strong>
    <strong>1        AMZN   307.82</strong>
    <strong>2        FB     74.90</strong>
    <strong>3        AAPL   109.70</strong>
    <strong>4        TWTR   37.10</strong>
    <strong>5        NFLX   334.48</strong>
    <strong>6        LNKD   219.90</strong>
    
    <strong>In [145]: stocks_df.loc[:,['Symbol','Price']]</strong>
    <strong>Out[145]: Symbol  Price</strong>
    <strong>0         GOOG    518.70</strong>
    <strong>1         AMZN    307.82</strong>
    <strong>2         FB      74.90</strong>
    <strong>3         AAPL    109.70</strong>
    <strong>4         TWTR    37.10</strong>
    <strong>5         NFLX    334.48</strong>
    <strong>6         LNKD    219.90</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Arithmetic operations on columns</h1>
                </header>
            
            <article>
                
<p>In R and pandas, we can apply arithmetic operations in data columns in a similar manner. Hence, we can perform arithmetic operations such as addition or subtraction on elements in corresponding positions in two or more DataFrames.</p>
<p class="mce-root"/>
<p>Here, we construct a DataFrame in R with columns labeled x and y, and subtract column y from column x:</p>
<pre>    <strong>&gt;norm_df&lt;- data.frame(x=rnorm(7,0,1), y=rnorm(7,0,1))</strong>
    <strong>&gt;norm_df$x - norm_df$y</strong>
    <strong>[1] -1.3870730  2.4681458 -4.6991395  0.2978311 -0.8492245  1.5851009 -1.4620324</strong></pre>
<p>The <kbd>with</kbd> operator in R also has the same effect as arithmetic operations:</p>
<pre>    <strong>&gt;with(norm_df,x-y)</strong>
    <strong>[1] -1.3870730  2.4681458 -4.6991395  0.2978311 -0.8492245  1.5851009 -1.4620324</strong></pre>
<p>In pandas, the same arithmetic operations can be performed on columns and the equivalent operator is <kbd>eval</kbd>:</p>
<pre>    <strong>In [10]: import pandas as pd</strong>
    <strong>         import numpy as np</strong>
    <strong>df = pd.DataFrame({'x': np.random.normal(0,1,size=7), 'y': np.random.normal(0,1,size=7)})</strong>
    
    <strong>In [11]: df.x-df.y</strong>
    <strong>Out[11]: 0   -0.107313</strong>
    <strong>         1    0.617513</strong>
    <strong>         2   -1.517827</strong>
    <strong>         3    0.565804</strong>
    <strong>         4   -1.630534</strong>
    <strong>         5    0.101900</strong>
    <strong>         6    0.775186</strong>
    <strong>dtype: float64</strong>
    
    <strong>In [12]: df.eval('x-y')</strong>
    <strong>Out[12]: 0   -0.107313</strong>
    <strong>         1    0.617513</strong>
    <strong>         2   -1.517827</strong>
    <strong>         3    0.565804</strong>
    <strong>         4   -1.630534</strong>
    <strong>         5    0.101900</strong>
    <strong>         6    0.775186</strong>
    <strong>dtype: float64</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Aggregation and GroupBy</h1>
                </header>
            
            <article>
                
<p>Sometimes, we wish to split data into subsets and apply a function such as the mean, max, or min to each subset. In R, we can do this through the <kbd>aggregate</kbd> or <kbd>tapply</kbd> functions.</p>
<p>Here, we have a dataset of statistics on the top five strikers of the four clubs that made it to the semi-final of the European Champions League Football tournament in 2014. We will use it to illustrate aggregation in R and its equivalent GroupBy functionality in pandas.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Aggregation in R</h1>
                </header>
            
            <article>
                
<p>In R, aggregation is effected using the following command:</p>
<pre>    <strong>&gt; goal_stats=read.csv('champ_league_stats_semifinalists.csv')</strong>
    <strong>&gt;goal_stats</strong>
    <strong>              Club                 Player Goals GamesPlayed</strong>
    <strong>1  Atletico Madrid            Diego Costa     8           9</strong>
    <strong>2  Atletico Madrid             ArdaTuran     4           9</strong>
    <strong>3  Atletico Madrid            RaúlGarcía     4          12</strong>
    <strong>4  Atletico Madrid           AdriánLópez     2           9</strong>
    <strong>5  Atletico Madrid            Diego Godín     2          10</strong>
    <strong>6      Real Madrid      Cristiano Ronaldo    17          11</strong>
    <strong>7      Real Madrid            Gareth Bale     6          12</strong>
    <strong>8      Real Madrid          Karim Benzema     5          11</strong>
    <strong>9      Real Madrid                   Isco     3          12</strong>
    <strong>10     Real Madrid         Ángel Di María     3          11</strong>
    <strong>11   Bayern Munich          Thomas Müller     5          12</strong>
    <strong>12   Bayern Munich           ArjenRobben     4          10</strong>
    <strong>13   Bayern Munich            Mario Götze     3          11</strong>
    <strong>14   Bayern Munich Bastian Schweinsteiger     3           8</strong>
    <strong>15   Bayern Munich        Mario Mandzukić     3          10</strong>
    <strong>16         Chelsea        Fernando Torres     4           9</strong>
    <strong>17         Chelsea               Demba Ba     3           6</strong>
    <strong>18         Chelsea           Samuel Eto'o     3           9</strong>
    <strong>19         Chelsea            Eden Hazard     2           9</strong>
    <strong>20         Chelsea                Ramires     2          10</strong></pre>
<p>We now compute the goals-per-game ratio for each striker, so as to measure their deadliness in front of goal:</p>
<pre>    <strong>&gt;goal_stats$GoalsPerGame&lt;- goal_stats$Goals/goal_stats$GamesPlayed</strong>
    <strong>&gt;goal_stats</strong>
    <strong>              Club   Player         Goals GamesPlayedGoalsPerGame</strong>
    <strong>1  Atletico Madrid  Diego Costa     8           9    0.8888889</strong>
    <strong>2  Atletico Madrid  ArdaTuran      4           9    0.4444444</strong>
    <strong>3  Atletico Madrid  RaúlGarcía     4          12    0.3333333</strong>
    <strong>4  Atletico Madrid  AdriánLópez    2           9    0.2222222</strong>
    <strong>5  Atletico Madrid  Diego Godín     2          10    0.2000000</strong>
    <strong>6  Real Madrid  Cristiano Ronaldo  17          11    1.5454545</strong>
    <strong>7  Real Madrid  Gareth Bale         6          12    0.5000000</strong>
    <strong>8  Real Madrid    Karim Benzema     5          11    0.4545455</strong>
    <strong>9  Real Madrid       Isco           3          12    0.2500000</strong>
    <strong>10 Real Madrid  Ángel Di María     3          11    0.2727273</strong>
    <strong>11 Bayern Munich Thomas Müller     5          12    0.4166667</strong>
    <strong>12 Bayern Munich  ArjenRobben     4          10    0.4000000</strong>
    <strong>13 Bayern Munich  MarioGötze      3          11    0.2727273</strong>
    <strong>14 Bayern Munich Bastian Schweinsteiger 3      8    0.3750000</strong>
    <strong>15 Bayern Munich  MarioMandzukić  3          10    0.3000000</strong>
    <strong>16 Chelsea       Fernando Torres   4           9    0.4444444</strong>
    <strong>17 Chelsea           Demba Ba      3           6    0.5000000</strong>
    <strong>18 Chelsea           Samuel Eto'o  3           9    0.3333333</strong>
    <strong>19 Chelsea            Eden Hazard  2           9    0.2222222</strong>
    <strong>20 Chelsea                Ramires  2          10    0.2000000</strong>
  </pre>
<p>Suppose that we wanted to know the highest goals-per-game ratio for each team. We would calculate this as follows:</p>
<pre>    <strong>&gt;aggregate(x=goal_stats[,c('GoalsPerGame')], by=list(goal_stats$Club),FUN=max)</strong>
    <strong>          Group.1         x</strong>
    <strong>1 Atletico Madrid 0.8888889</strong>
    <strong>2   Bayern Munich 0.4166667</strong>
    <strong>3         Chelsea 0.5000000</strong>
    <strong>4     Real Madrid 1.5454545</strong>
  </pre>
<p>The <kbd>tapply</kbd> function is used to apply a function to a subset of an array or vector that is defined by one or more columns. The <kbd>tapply</kbd> function can also be used as follows:</p>
<pre>    <strong>&gt;tapply(goal_stats$GoalsPerGame,goal_stats$Club,max)</strong>
    <strong>Atletico Madrid   Bayern Munich         Chelsea     Real Madrid </strong>
    <strong>      0.8888889       0.4166667       0.5000000       1.5454545</strong>
  </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The pandas GroupBy operator</h1>
                </header>
            
            <article>
                
<p>In pandas, we can achieve the same result by using the <kbd>GroupBy</kbd> function:</p>
<pre>    <strong>In [6]: import pandas as pd</strong>
    <strong>importnumpy as np</strong>
    <strong>In [7]: goal_stats_df=pd.read_csv('champ_league_stats_semifinalists.csv')</strong>
    
    <strong>In [27]: goal_stats_df['GoalsPerGame']=     goal_stats_df['Goals']/goal_stats_df['GamesPlayed']</strong>
    
    <strong>In [27]: goal_stats_df['GoalsPerGame']= goal_stats_df['Goals']/goal_stats_df['GamesPlayed']</strong>
    
    <strong>In [28]: goal_stats_df</strong>
    <strong>Out[28]: Club           Player      Goals GamesPlayedGoalsPerGame</strong>
    <strong>0       Atletico Madrid Diego Costa   8       9        0.888889</strong>
    <strong>1       Atletico Madrid ArdaTuran    4       9         0.444444</strong>
    <strong>2       Atletico Madrid RaúlGarcía   4       12        0.333333</strong>
    <strong>3       Atletico Madrid AdriánLópez  2       9         0.222222</strong>
    <strong>4       Atletico Madrid Diego Godín   2       10        0.200000</strong>
    <strong>5       Real Madrid  Cristiano Ronaldo 17      11        1.545455</strong>
    <strong>6       Real Madrid     Gareth Bale   6       12        0.500000</strong>
    <strong>7       Real Madrid     Karim Benzema 5       11        0.454545</strong>
    <strong>8       Real Madrid     Isco          3       12        0.250000</strong>
    <strong>9       Real Madrid     Ángel Di María 3      11        0.272727</strong>
    <strong>10      Bayern Munich   Thomas Müller  5       12        0.416667</strong>
    <strong>11      Bayern Munich   ArjenRobben   4       10        0.400000</strong>
    <strong>12      Bayern Munich   Mario Götze    3       11        0.272727</strong>
    <strong>13      Bayern Munich  BastianSchweinsteiger 3   8     0.375000</strong>
    <strong>14      Bayern Munich  MarioMandzukić  3       10        0.300000</strong>
    <strong>15      Chelsea        Fernando Torres  4       9         0.444444</strong>
    <strong>16      Chelsea        Demba Ba         3       6         0.500000</strong>
    <strong>17      Chelsea        Samuel Eto'o     3       9         0.333333</strong>
    <strong>18      Chelsea        Eden Hazard      2       9         0.222222</strong>
    <strong>19      Chelsea        Ramires          2       10        0.200000</strong>
    
    <strong>In [30]: grouped = goal_stats_df.groupby('Club')</strong>
    
    <strong>In [17]: grouped['GoalsPerGame'].aggregate(np.max)</strong>
    <strong>Out[17]: Club</strong>
    <strong>         Atletico Madrid    0.888889</strong>
    <strong>         Bayern Munich      0.416667</strong>
    <strong>         Chelsea            0.500000</strong>
    <strong>         Real Madrid        1.545455</strong>
    <strong>         Name: GoalsPerGame, dtype: float64</strong>
    
    <strong>In [22]: grouped['GoalsPerGame'].apply(np.max)</strong>
    
    <strong>Out[22]: Club</strong>
    <strong>         Atletico Madrid    0.888889</strong>
    <strong>         Bayern Munich      0.416667</strong>
    <strong>         Chelsea            0.500000</strong>
    <strong>         Real Madrid        1.545455</strong>
    <strong>         Name: GoalsPerGame, dtype: float64</strong>
  </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Comparing matching operators in R and pandas</h1>
                </header>
            
            <article>
                
<p>Here, we demonstrate the equivalence of matching operators between R (<kbd>%in%</kbd>) and pandas (<kbd>isin()</kbd>). In both cases, a logical vector or series (pandas) is produced, which indicates the position at which a match was found.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">R %in% operator</h1>
                </header>
            
            <article>
                
<p>Here, we demonstrate the use of the <kbd>%in%</kbd> operator in R:</p>
<pre>    <strong>&gt;stock_symbols=stocks_table$Symbol</strong>
    <strong>&gt;stock_symbols</strong>
    <strong>[1] GOOG  AMZN  FB  AAPL  TWTR  NFLX  LINKD</strong>
    <strong>Levels: AAPL AMZN FB GOOG LINKD NFLX TWTR</strong>
    
    <strong>&gt;stock_symbols %in% c('GOOG','NFLX')</strong>
    <strong>[1]  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE</strong>
  </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Pandas isin() function</h1>
                </header>
            
            <article>
                
<p>Here is an example of using the pandas <kbd>isin()</kbd> function:</p>
<pre>    <strong>In [11]: stock_symbols=stocks_df.Symbol</strong>
    <strong>stock_symbols</strong>
    <strong>Out[11]: 0    GOOG</strong>
    <strong>         1    AMZN</strong>
    <strong>         2      FB</strong>
    <strong>         3    AAPL</strong>
    <strong>         4    TWTR</strong>
    <strong>         5    NFLX</strong>
    <strong>         6    LNKD</strong>
    <strong>         Name: Symbol, dtype: object</strong>
    <strong>In [10]: stock_symbols.isin(['GOOG','NFLX'])</strong>
    <strong>Out[10]: 0     True</strong>
    <strong>         1    False</strong>
    <strong>         2    False</strong>
    <strong>         3    False</strong>
    <strong>         4    False</strong>
    <strong>         5     True</strong>
    <strong>         6    False</strong>
    <strong>         Name: Symbol, dtype: bool</strong>
  </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logical subsetting</h1>
                </header>
            
            <article>
                
<p>In R, as well as in pandas, there is more than one way to perform logical subsetting. Suppose that we wished to display all players with the average goals-per-game ratio of greater than or equal to 0.5; that is, on average, they score at least one goal every two games.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logical subsetting in R</h1>
                </header>
            
            <article>
                
<p>Here's how we can do this in R:</p>
<ul>
<li>Using a logical slice:</li>
</ul>
<pre>    <strong>&gt;goal_stats[goal_stats$GoalsPerGame&gt;=0.5,]</strong>
    <strong>   Club            Player        Goals GamesPlayedGoalsPerGame</strong>
    <strong>1  Atletico Madrid Diego Costa     8           9    0.8888889</strong>
    <strong>6  Real Madrid Cristiano Ronaldo  17          11    1.5454545</strong>
    <strong>7  Real Madrid       Gareth Bale   6          12    0.5000000</strong>
    <strong>17 Chelsea          Demba Ba     3           6    0.5000000</strong>
  </pre>
<ul>
<li>Using the <kbd>subset()</kbd> function:</li>
</ul>
<pre>    <strong>&gt;subset(goal_stats,GoalsPerGame&gt;=0.5)</strong>
    <strong>   Club            Player      Goals GamesPlayedGoalsPerGame</strong>
    <strong>1  Atletico Madrid Diego Costa    8           9    0.8888889</strong>
    <strong>6  Real Madrid Cristiano Ronaldo 17          11    1.5454545</strong>
    <strong>7  Real Madrid     Gareth Bale    6          12    0.5000000</strong>
    <strong>17 Chelsea          Demba Ba     3           6    0.5000000</strong>
  </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logical subsetting in pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, we do similar:</p>
<ul>
<li>Logical slicing:</li>
</ul>
<pre>    <strong>In [33]: goal_stats_df[goal_stats_df['GoalsPerGame']&gt;=0.5]</strong>
    <strong>Out[33]:     Club        Player            Goals GamesPlayedGoalsPerGame</strong>
    <strong>0    Atletico Madrid Diego Costa     8     9          0.888889</strong>
    <strong>5    Real Madrid   Cristiano Ronaldo 17    11         1.545455</strong>
    <strong>6    Real Madrid     Gareth Bale     6     12         0.500000</strong>
    <strong>16   Chelsea         Demba Ba        3     6           0.500000</strong>
  </pre>
<ul>
<li><kbd>DataFrame.query()</kbd> operator:</li>
</ul>
<pre>    <strong>In [36]:  goal_stats_df.query('GoalsPerGame&gt;= 0.5')</strong>
    <strong>Out[36]:</strong>
    <strong>Club              Player   Goals GamesPlayedGoalsPerGame</strong>
    <strong>0    Atletico Madrid Diego Costa   8     9            0.888889</strong>
    <strong>5    Real Madrid  Cristiano Ronaldo 17    11           1.545455</strong>
    <strong>6    Real Madrid     Gareth Bale    6     12           0.500000</strong>
    <strong>16   Chelsea         Demba Ba       3     6            0.500000</strong>
  </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Split-apply-combine</h1>
                </header>
            
            <article>
                
<p>R has a library called <kbd>plyr</kbd> for a split-apply-combine data analysis. The <kbd>plyr</kbd> library has a function called <kbd>ddply</kbd>, which can be used to apply a function to a subset of a DataFrame, and then combine the results into another DataFrame.</p>
<div class="packt_infobox">For more information on <kbd>ddply</kbd>, you can refer to the following link: <a href="http://www.inside-r.org/packages/cran/plyr/docs/ddply"><span class="URLPACKT">http://www.inside-r.org/packages/cran/plyr/docs/ddply</span></a>.</div>
<p>To illustrate, let's consider a subset of a recently created dataset in R, which contains data on flights departing NYC in 2013: <a href="http://cran.r-project.org/web/packages/nycflights13/index.html"><span class="URLPACKT">http://cran.r-project.org/web/packages/nycflights13/index.html</span></a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation in R</h1>
                </header>
            
            <article>
                
<p>Here, we install the package in R and instantiate the library:</p>
<pre>    <strong>&gt;install.packages('nycflights13')</strong>
    <strong>...</strong>
    
    <strong>&gt;library('nycflights13')</strong>
    <strong>&gt;dim(flights)</strong>
    <strong>[1] 336776     16</strong>
    
    <strong>&gt;head(flights,3)</strong>
    <strong>year month day dep_timedep_delayarr_timearr_delay carrier tailnum flight</strong>
    <strong>1 2013     1   1      517         2      830        11      UA  N14228   1545</strong>
    <strong>2 2013     1   1      533         4      850        20      UA  N24211   1714</strong>
    <strong>3 2013     1   1      542         2      923        33      AA  N619AA   1141</strong>
    <strong>origindestair_time distance hour minute</strong>
    <strong>1    EWR  IAH      227     1400    5     17</strong>
    <strong>2    LGA  IAH      227     1416    5     33</strong>
    <strong>3    JFK  MIA      160     1089    5     42</strong>
    
    <strong>&gt; flights.data=na.omit(flights[,c('year','month','dep_delay','arr_delay','distance')])</strong>
    <strong>&gt;flights.sample&lt;- flights.data[sample(1:nrow(flights.data),100,replace=FALSE),]</strong>
    
    <strong>&gt;head(flights.sample,5)</strong>
    <strong>year month dep_delayarr_delay distance</strong>
    <strong>155501 2013     3         2         5      184</strong>
    <strong>2410   2013     1         0         4      762</strong>
    <strong>64158  2013    11        -7       -27      509</strong>
    <strong>221447 2013     5        -5       -12      184</strong>
    <strong>281887 2013     8        -1       -10      937</strong>
  </pre>
<p>The <kbd>ddply</kbd> function enables us to summarize the departure delays (mean and  standard deviation) by year and month:</p>
<pre>    <strong>&gt;ddply(flights.sample,.(year,month),summarize, mean_dep_delay=round(mean(dep_delay),2), s_dep_delay=round(sd(dep_delay),2))</strong>
    <strong>year month mean_dep_delaysd_dep_delay</strong>
    <strong>1  2013     1          -0.20         2.28</strong>
    <strong>2  2013     2          23.85        61.63</strong>
    <strong>3  2013     3          10.00        34.72</strong>
    <strong>4  2013     4           0.88        12.56</strong>
    <strong>5  2013     5           8.56        32.42</strong>
    <strong>6  2013     6          58.14       145.78</strong>
    <strong>7  2013     7          25.29        58.88</strong>
    <strong>8  2013     8          25.86        59.38</strong>
    <strong>9  2013     9          -0.38        10.25</strong>
    <strong>10 2013    10           9.31        15.27</strong>
    <strong>11 2013    11          -1.09         7.73</strong>
    <strong>12 2013    12           0.00         8.58</strong>
  </pre>
<p>Let's save the <kbd>flights.sample</kbd> dataset to a CSV file so that we can use the data to show us how to do the same thing in pandas:</p>
<pre>    <strong>&gt;write.csv(flights.sample,file='nycflights13_sample.csv', quote=FALSE,row.names=FALSE)</strong>
  </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation in pandas</h1>
                </header>
            
            <article>
                
<p>In order to do the same thing in pandas, we read the CSV file saved in the preceding section:</p>
<pre>    <strong>In [40]: flights_sample=pd.read_csv('nycflights13_sample.csv')</strong>
    
    <strong>In [41]: flights_sample.head()</strong>
    <strong>Out[41]: year   month   dep_delayarr_delay       distance</strong>
    <strong>0        2013   3       2       5       184</strong>
    <strong>1        2013   1       0       4       762</strong>
    <strong>2        2013   11      -7      -27     509</strong>
    <strong>3        2013   5       -5      -12     184</strong>
    <strong>4        2013   8       -1      -10     937</strong>
  </pre>
<p>We achieve the same effect as <kbd>ddply</kbd> by making use of the <kbd>GroupBy()</kbd> operator, as shown in the following code and output:</p>
<pre>    <strong>In [44]: pd.set_option('precision',3)</strong>
    <strong>In [45]: grouped = flights_sample_df.groupby(['year','month'])</strong>
    
    <strong>In [48]: grouped['dep_delay'].agg([np.mean, np.std])</strong>
    
    <strong>Out[48]:        mean    std</strong>
    <strong>year    month           </strong>
    <strong>2013    1       -0.20   2.28</strong>
    <strong>        2       23.85   61.63</strong>
    <strong>        3       10.00   34.72</strong>
    <strong>        4       0.88    12.56</strong>
    <strong>        5       8.56    32.42</strong>
    <strong>        6       58.14   145.78</strong>
    <strong>        7       25.29   58.88</strong>
    <strong>        8       25.86   59.38</strong>
    <strong>        9       -0.38   10.25</strong>
    <strong>        10      9.31    15.27</strong>
    <strong>        11      -1.09   7.73</strong>
    <strong>        12      0.00    8.58</strong>
  </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reshaping using melt</h1>
                </header>
            
            <article>
                
<p>The <kbd>melt</kbd> function converts data in a wide format to a single column consisting of unique ID-variable combinations.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">R melt function</h1>
                </header>
            
            <article>
                
<p>Here, we demonstrate the use of the <kbd>melt()</kbd> function in R. It produces long-format data in which the rows are unique variable-value combinations:</p>
<pre>    <strong>&gt;sample4=head(flights.sample,4)[c('year','month','dep_delay','arr_delay')]</strong>
    <strong>&gt; sample4</strong>
    <strong>year month dep_delayarr_delay</strong>
    <strong>155501 2013     3         2         5</strong>
    <strong>2410   2013     1         0         4</strong>
    <strong>64158  2013    11        -7       -27</strong>
    <strong>221447 2013     5        -5       -12</strong>
    
    <strong>&gt;melt(sample4,id=c('year','month'))</strong>
    <strong>year month  variable value</strong>
    <strong>1 2013     3 dep_delay     2</strong>
    <strong>2 2013     1 dep_delay     0</strong>
    <strong>3 2013    11 dep_delay    -7</strong>
    <strong>4 2013     5 dep_delay    -5</strong>
    <strong>5 2013     3 arr_delay     5</strong>
    <strong>6 2013     1 arr_delay     4</strong>
    <strong>7 2013    11 arr_delay   -27</strong>
    <strong>8 2013     5 arr_delay   -12</strong>
    <strong>&gt;</strong>  </pre>
<div class="packt_infobox">For more information, you can refer to the following link: <a href="http://www.statmethods.net/management/reshape.html"><span class="URLPACKT">http://www.statmethods.net/management/reshape.html</span></a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The pandas melt function</h1>
                </header>
            
            <article>
                
<p>In pandas, the <kbd>melt</kbd> function is similar:</p>
<pre>    <strong>In [55]: sample_4_df=flights_sample_df[['year','month','dep_delay', \</strong>
    <strong>'arr_delay']].head(4)</strong>
    <strong>In [56]: sample_4_df</strong>
    <strong>Out[56]: year   month dep_delayarr_delay</strong>
    <strong>0        2013   3       2       5</strong>
    <strong>1        2013   1       0       4</strong>
    <strong>2        2013   11      -7      -27</strong>
    <strong>3        2013   5       -5      -12</strong>
    
    <strong>In [59]: pd.melt(sample_4_df,id_vars=['year','month'])</strong>
    <strong>Out[59]: year   month   variable        value</strong>
    <strong>0        2013   3       dep_delay       2</strong>
    <strong>1        2013   1       dep_delay       0</strong>
    <strong>2        2013   11      dep_delay       -7</strong>
    <strong>3        2013   5       dep_delay       -5</strong>
    <strong>4        2013   3       arr_delay       5</strong>
    <strong>5        2013   1       arr_delay       4</strong>
    <strong>6        2013   11      arr_delay       -27</strong>
    <strong>7        2013   5       arr_delay       -12</strong>  </pre>
<div class="packt_infobox">The reference source for this information is as follows: <a href="http://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-by-melt"><span class="URLPACKT">http://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-by-melt</span></a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Categorical data</h1>
                </header>
            
            <article>
                
<p>R refers to categorical variables as factors, and the <kbd>cut()</kbd> function enables us to break a continuous numerical variable into ranges and treat the ranges as factors or categorical variables, or to classify a categorical variable into a larger bin.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">R example using cut()</h1>
                </header>
            
            <article>
                
<p>The following code block shows an example in R:</p>
<pre>    <strong>clinical.trial&lt;- data.frame(patient = 1:1000,</strong>
    <strong>age = rnorm(1000, mean = 50, sd = 5),</strong>
    <strong>year.enroll = sample(paste("19", 80:99, sep = ""),</strong>
    <strong>                             1000, replace = TRUE))</strong>
    
    <strong>&gt;clinical.trial&lt;- data.frame(patient = 1:1000,</strong>
    <strong>+                              age = rnorm(1000, mean = 50, sd = 5),</strong>
    <strong>+                              year.enroll = sample(paste("19", 80:99, sep = ""),</strong>
    <strong>+                              1000, replace = TRUE))</strong>
    <strong>&gt;summary(clinical.trial)</strong>
    <strong>patient            age         year.enroll</strong>
    <strong> Min.   :   1.0   Min.   :31.14   1995   : 61  </strong>
    <strong> 1st Qu.: 250.8   1st Qu.:46.77   1989   : 60  </strong>
    <strong>Median : 500.5   Median :50.14   1985   : 57  </strong>
    <strong> Mean   : 500.5   Mean   :50.14   1988   : 57  </strong>
    <strong> 3rd Qu.: 750.2   3rd Qu.:53.50   1990   : 56  </strong>
    <strong> Max.   :1000.0   Max.   :70.15   1991   : 55  </strong>
    <strong>                                  (Other):654  </strong>
    <strong>&gt;ctcut&lt;- cut(clinical.trial$age, breaks = 5)&gt; table(ctcut)</strong>
    <strong>ctcut</strong>
    <strong>(31.1,38.9] (38.9,46.7] (46.7,54.6] (54.6,62.4] (62.4,70.2]</strong>
    <strong>         15         232         558         186           9</strong>
  </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The pandas solution</h1>
                </header>
            
            <article>
                
<p>The following code block contains the equivalent of the earlier explained <kbd>cut()</kbd> function in pandas (only applies to version 0.15+):</p>
<pre>    <strong>In [79]: pd.set_option('precision',4)</strong>
    <strong>clinical_trial=pd.DataFrame({'patient':range(1,1001), </strong>
    <strong>                                      'age' : np.random.normal(50,5,size=1000),</strong>
    <strong>                 'year_enroll': [str(x) for x in np.random.choice(range(1980,2000),size=1000,replace=True)]})</strong>
    
    <strong>In [80]: clinical_trial.describe()</strong>
    <strong>Out[80]:        age       patient</strong>
    <strong>count   1000.000  1000.000</strong>
    <strong>mean    50.089    500.500</strong>
    <strong>std     4.909     288.819</strong>
    <strong>min     29.944    1.000</strong>
    <strong>        25%     46.572    250.750</strong>
    <strong>        50%     50.314    500.500</strong>
    <strong>        75%     53.320    750.250</strong>
    <strong>max     63.458    1000.000</strong>
    
    
    <strong>In [81]: clinical_trial.describe(include=['O'])</strong>
    <strong>Out[81]:        year_enroll</strong>
    <strong>count   1000</strong>
    <strong>unique  20</strong>
    <strong>top     1992</strong>
    <strong>freq    62</strong>
    
    
    <strong>In [82]: clinical_trial.year_enroll.value_counts()[:6]</strong>
    <strong>Out[82]: 1992    62</strong>
    <strong>         1985    61</strong>
    <strong>         1986    59</strong>
    <strong>         1994    59</strong>
    <strong>         1983    58</strong>
    <strong>         1991    58</strong>
    <strong>dtype: int64</strong>
    <strong>In [83]: ctcut=pd.cut(clinical_trial['age'], 5)</strong>
    <strong>In [84]: ctcut.head()</strong>
    <strong>Out[84]: 0    (43.349, 50.052]</strong>
    <strong>         1    (50.052, 56.755]</strong>
    <strong>         2    (50.052, 56.755]</strong>
    <strong>         3    (43.349, 50.052]</strong>
    <strong>         4    (50.052, 56.755]</strong>
    <strong>         Name: age, dtype: category</strong>
    <strong>         Categories (5, object): [(29.91, 36.646] &lt; (36.646, 43.349] &lt; (43.349, 50.052] &lt; (50.052, 56.755] &lt; (56.755, 63.458]]</strong>
    
    <strong>In [85]: ctcut.value_counts().sort_index()</strong>
    <strong>Out[85]: (29.91, 36.646]       3</strong>
    <strong>              (36.646, 43.349]     82</strong>
    <strong>       (43.349, 50.052]    396</strong>
    <strong>       (50.052, 56.755]    434</strong>
    <strong>      (56.755, 63.458]     85</strong>
    <strong>dtype: int64</strong>
    </pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>The comparison in the previous sections can be summarized by the following table:</p>
<p class="CDPAlignCenter CDPAlign"><strong><img src="assets/6c1339fc-8067-47da-be93-3ffa622739d3.png"/></strong></p>
<div class="mce-root packt_figref CDPAlignCenter CDPAlign">Comparison of data structures and operations in R and pandas</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Comparison with SQL</h1>
                </header>
            
            <article>
                
<p>Pandas is similar to SQL in many ways in the sense that it is used for data selection, data filtering, data aggregation, data generation, and data modification. SQL does to the database tables what pandas does to the DataFrames. In this section, we will compare the features in SQL with their equivalents in pandas.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SELECT</h1>
                </header>
            
            <article>
                
<p>SELECT is used to select or subset data in certain columns of the tables. Suppose you have a table/DataFrame called <kbd>DallasData</kbd>. This data would be attached in your book packet or could be accessed from the cloud drive of the book. To select five rows from the three given columns, you write the following</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SQL</h1>
                </header>
            
            <article>
                
<p>In SQL, you can use the following command: </p>
<pre><strong>select state_name,active_status,services_due from DallasData LIMIT 5;</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, you can use the following command: </p>
<pre><strong>DallasData[['state_name','active_status','services_due']].head(5)</strong></pre>
<p>The following is the output to the preceding commands: </p>
<p class="CDPAlignCenter CDPAlign"><strong><img src="assets/a78b25e9-6c2a-43e4-be1d-ed5309ab1ea7.png" style="width:19.75em;height:11.00em;"/></strong></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Output of select on DallasData</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Where</h1>
                </header>
            
            <article>
                
<p>The <kbd>Where</kbd> statement is used in SQL to apply filter conditions to filter rows based on certain criteria. The equivalent in pandas is condition-based logical subsetting.</p>
<p>Suppose we want to find out the rows where <kbd>active_status ==1</kbd>. This can be done in the two tools in the following manner.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SQL</h1>
                </header>
            
            <article>
                
<p>In SQL, you can use the following command: </p>
<pre>    <strong>select * from DallasData where active_status ==1 LIMIT 5;</strong>
    </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, you can use the following command: </p>
<pre>    <strong>DallasData[DallasData['active_status']==1].head(5);</strong></pre>
<p>The following is the output to the preceding commands: </p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-910 image-border" src="assets/542ae54e-ff9b-4f7c-86dc-7ce50c95b1cf.png" style="width:108.50em;height:19.00em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">DallasData after filtering only active customers</div>
<p>Suppose we want to find out the rows where the customers are active (<kbd>active_status ==1</kbd>) and have completed fewer than nine services (<kbd>services_completed&lt;9</kbd>). This can be done in the two tools in the following manner.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SQL</h1>
                </header>
            
            <article>
                
<p>In SQL, you can use the following command: </p>
<pre>select * from DallasData where active_status ==1 AND services_completed &lt;9 LIMIT 5;</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, you can use the following command: </p>
<pre>DallasData[(DallasData['active_status']==1) &amp; (DallasData['services_completed'] &lt;9)].head(5)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The following is the output to the preceding commands: </p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-909 image-border" src="assets/4d4d6fb8-55a3-451e-8a32-dd93ba678a47.png" style="width:109.42em;height:18.17em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">DallasData after filtering customers who are active and have completed more than nine services</div>
<p>Suppose we want to find out the rows where the customers are active (active_status ==1), but only find the customer ID, zip code, and seller ID for those rows. This can be done in the two tools in the following manner.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SQL</h1>
                </header>
            
            <article>
                
<p>In SQL, you can use the following command: </p>
<pre>select customerID,zip,soldBy from DallasData where active_status ==1 LIMIT 5;</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, you can use the following command: </p>
<pre><strong>DallasData[DallasData['active_status']==1][['customerID','zip','soldBy']].head(5)</strong></pre>
<p>The following is the output to the preceding commands: </p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-908 image-border" src="assets/2cd9dfaa-6c71-4afd-b621-b044d2e5f2e7.png" style="width:14.33em;height:10.75em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">DallasData after filtering only active customers and selecting only particular columns</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">group by</h1>
                </header>
            
            <article>
                
<p>The <kbd>group by</kbd> statement is used to aggregate data and find the aggregated values of numerical columns. The keyword for performing this operation is the same, but the syntax is a little different. Let's look at a few examples.</p>
<p>Suppose we are looking to find the numbers of active and inactive customers in the dataset. This can be done as follows in the two tools.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SQL</h1>
                </header>
            
            <article>
                
<p>In SQL, you can use the following command: </p>
<pre>select active_status, count(*) as number from DallasData group by active_status;</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, you can use the following command: </p>
<pre>DallasData.groupby('active_status').size();</pre>
<p>The following is the output to the preceding commands: </p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-907 image-border" src="assets/7a65325d-d03d-456b-9ef9-7ea443aae685.png" style="width:8.67em;height:4.83em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Count of active and inactive customers using groupby in Python</div>
<p>Different aggregation operations can be applied to two different columns simultaneously while aggregating. The following example shows how to do that.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SQL</h1>
                </header>
            
            <article>
                
<p>In SQL, you can use the following command: </p>
<pre>select active_status, sum(services_complted), mean(age_median) from DallasData group by active_status;</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, you can use the following command: </p>
<pre>DallasData.groupby('active_status').agg({'services_completed':np.sum,'age_median':np.mean})</pre>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-906 image-border" src="assets/657bd3dd-26ae-46d7-b579-165425a92689.png" style="width:22.92em;height:8.75em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Sum of services completed and the mean customer age grouped by active and inactive customers using groupby in Python</div>
<p>Aggregating by more than one column or multi-index aggregation is also possible. Suppose we want zip code-wise details of active and inactive customers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SQL</h1>
                </header>
            
            <article>
                
<p>In SQL, you can use the following command: </p>
<pre>select active_status, sum(services_complted), mean(days_old) from DallasData group by active_status,zip;</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, you can use the following command: </p>
<pre> <strong>DallasData.groupby(['active_status','zip']).agg({'services_completed':np.sum,'days_old':np.mean}).head(5)</strong></pre>
<p>The following is the output to the preceding commands:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1697 image-border" src="assets/4ce95321-6005-4939-9f4c-4460ada318e6.png" style="width:19.92em;height:11.08em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Multi-indexed grouping by customer active status and zip code using groupby in Python</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">update</h1>
                </header>
            
            <article>
                
<p>The <kbd>update</kbd> statements in SQL are used to filter data rows based on certain conditions and to update or modify certain values in those rows. In pandas, there is no particular keyword or function for doing this; instead, it is done by means of a direct assignment. Let's look at a few examples.</p>
<p>Suppose it was established that the data administrator had made a mistake in data collection. Due to this error, the data points where the age was actually 45 were randomly assigned a value greater than 35. To rectify this, we will update all such rows (<strong>age&gt;35</strong>) to 45.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SQL</h1>
                </header>
            
            <article>
                
<p>In SQL, you can use the following command: </p>
<pre>update DallasData set age_median=45 where age_median&gt;35</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, you can use the following command: </p>
<pre>    <strong>DallasData[DallasData['age_median']&gt;35]=45<br/></strong></pre>
<p class="mce-root"/>
<p>The following two screenshots show the data before and after performing the update:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1770 image-border" src="assets/51c65a70-65a7-4672-b64b-894ed68ba9b4.png" style="width:110.50em;height:39.25em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Before and after updating all ages greater than 35 to 45</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">delete</h1>
                </header>
            
            <article>
                
<p>The <kbd>delete</kbd> statements in SQL are used to delete data rows based on certain conditions from the database tables. In pandas, we don't delete rows; we just deselect them. Let's look at a few examples.</p>
<p>Suppose we want to look at those customers who are in the system for at least 500 days (<kbd>days_old&gt;500</kbd>).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SQL</h1>
                </header>
            
            <article>
                
<p>In SQL, you can use the following command: </p>
<pre>delete DallasData where days_old&lt;500</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, you can use the following command: </p>
<pre>    <strong>DallasData1 = DallasData[DallasData['days_old']&gt;500]</strong></pre>
<p>Run the following command to check whether it did the intended operation.</p>
<pre>    <strong>DallasData1[DallasData1['days_old']&lt;400]</strong></pre>
<p>This should return 0 rows if the delete action was performed correctly.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">JOIN</h1>
                </header>
            
            <article>
                
<p>The <kbd>join</kbd> statements are used to merge different tables in a database and extract important information spread across a variety of tables. In pandas, the merge operator does the same job. The only difference is that the syntax is a little different.</p>
<p>Let's create two datasets for illustrating different joins and their syntaxes in SQL and pandas:</p>
<pre><strong>df1 = pd.DataFrame({'key': ['IN', 'SA', 'SL', 'NZ'],'Result':['W','L','L','W']})</strong>
    
<strong>df2 = pd.DataFrame({'key': ['IN', 'SA', 'SA', 'WI'],'Score':[200,325,178,391]})</strong></pre>
<p>The following is the output to the preceding command:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1771 image-border" src="assets/0ef207ef-3c2b-4d03-81b7-2471a4f7f5c9.png" style="width:8.58em;height:20.83em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Two dummy datasets</div>
<p>Suppose we want to do an inner join between the two. This can be done in the two tools as shown preceding.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SQL</h1>
                </header>
            
            <article>
                
<p>In SQL, you can use the following command: </p>
<pre>SELECT * FROM df1 INNER JOIN df2 ON df1.key = df2.key;</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, you can use the following command: </p>
<pre>    <strong>pd.merge(df1,df2,on='key')<br/></strong></pre>
<p>The following is the output to the preceding commands: </p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-900 image-border" src="assets/4ff132e8-2b5c-4634-830c-c3f368f3057a.png" style="width:8.83em;height:5.50em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Output of the inner join of the two DataFrames</div>
<p>As expected of an inner join, only the key values present in both the tables appear in the merged dataset.</p>
<p>Suppose we want to implement a left join between the two. This can be done in the two tools as shown here:</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SQL</h1>
                </header>
            
            <article>
                
<p>In SQL, you can use the following command: </p>
<pre>SELECT * FROM df1 LEFT JOIN df2 ON df1.key = df2.key;</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, you can use the following command: </p>
<pre>    <strong>pd.merge(df1,df2,on='key',how='left')<br/></strong></pre>
<p>The following is the output to the preceding commands:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-899 image-border" src="assets/efa176a9-d7a8-451e-9d8a-72731f0f1961.png" style="width:8.67em;height:8.58em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Output of the left join between the two tables</div>
<p>As expected of a left join, it retrieves all the unique values of the key present in the left-hand table (<kbd>df1</kbd>, in this case), as well as the corresponding values in the right-hand table. For the key values in the left-hand table for which it doesn't find a match in the right-hand table, it returns NaN.</p>
<p>Suppose we want to implement a right join between the two. This can be done in the two tools as shown here:</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SQL</h1>
                </header>
            
            <article>
                
<p>In SQL, you can use the following command: </p>
<pre>SELECT * FROM df1 RIGHT JOIN df2 ON df1.key = df2.key;</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">pandas</h1>
                </header>
            
            <article>
                
<p>In pandas, you can use the following command: </p>
<pre>    <strong>pd.merge(df1,df2,on='key',how='right')</strong></pre>
<p>The following is the output to the preceding commands: </p>
<p class="CDPAlignCenter CDPAlign"><br/>
<img class="alignnone size-full wp-image-898 image-border" src="assets/b02be011-5eb5-40fc-953e-66477c2f2c8a.png" style="width:9.25em;height:7.42em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Output of the right join between the two tables</div>
<p>As expected of a right join, it retrieves all the unique values of the key present in the right-hand table (<kbd>df2</kbd>, in this case), as well as the corresponding values in the left-hand table. For the key values in the right-hand table for which it doesn't find a match in the left-hand table, it returns NaN.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Comparison with SAS</h1>
                </header>
            
            <article>
                
<p>SAS is the analytics sledgehammer of yesteryear. It was the market leader in analytics solutions before R and Python, the poster boys of the open source movement, dethroned it from its <em>numero uno</em> position. Nevertheless, many enterprises still trust it with all their analytics requirements, despite the unreasonably high costs.</p>
<p><span>In this section, we will keep all the comparisons to a tabular format. The SAS and pandas equivalents are summarized in the following table: </span></p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td>
<p>Pandas</p>
</td>
<td>
<p>SAS</p>
</td>
</tr>
<tr>
<td>
<p>DataFrame</p>
</td>
<td>
<p>dataset</p>
</td>
</tr>
<tr>
<td>
<p>column</p>
</td>
<td>
<p>variable</p>
</td>
</tr>
<tr>
<td>
<p>row</p>
</td>
<td>
<p>observation</p>
</td>
</tr>
<tr>
<td>
<p>groupby</p>
</td>
<td>
<p>BY-group</p>
</td>
</tr>
<tr>
<td>
<p>NaN</p>
</td>
<td>
<p>.</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Now, let's see how we can perform the basic data operations in pandas and SAS: </p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td>
<p>Task</p>
</td>
<td>
<p>Pandas</p>
</td>
<td>
<p>SAS</p>
</td>
</tr>
<tr>
<td>
<p> </p>
<p> </p>
<p>Creating a dataset</p>
</td>
<td>
<p> </p>
<p> </p>
<p><kbd>pd.DataFrame({'odds': [1, 3, 5, 7, 9], 'evens': [2, 4, 6, 8, 10]})</kbd></p>
</td>
<td>
<p><kbd>data df;</kbd></p>
<p><kbd>    input x y;</kbd></p>
<p><kbd>    datalines;</kbd></p>
<p><kbd>    1 2</kbd></p>
<p><kbd>    3 4</kbd></p>
<p><kbd>    5 6</kbd></p>
<p><kbd>    7 8</kbd></p>
<p><kbd>    9 10;</kbd></p>
<p><kbd>run;</kbd></p>
</td>
</tr>
<tr>
<td>
<p> </p>
<p>Reading a dataset</p>
</td>
<td>
<p> </p>
<p> </p>
<p><kbd>pd.read_csv(‘DallasData.csv’)</kbd></p>
</td>
<td>
<p><kbd>proc import datafile='DallasData.csv' dbms=csv out=tips replace;</kbd></p>
<p><kbd>    getnames=yes;</kbd></p>
<p><kbd>run;</kbd></p>
</td>
</tr>
<tr>
<td>
<p>Exporting a dataset</p>
</td>
<td>
<p> </p>
<p><kbd>DallasData.to_csv(‘dallas.csv’)</kbd></p>
</td>
<td>
<p><kbd>proc export data=DallasData outfile='dallas.csv' dbms=csv;</kbd></p>
<p><kbd>run;</kbd></p>
</td>
</tr>
<tr>
<td>
<p> </p>
<p>Column operations</p>
</td>
<td>
<p> </p>
<p><kbd>DallasData['days_old_year'] = DallasData['days_old']/365</kbd></p>
</td>
<td>
<p><kbd>data DallasData;</kbd></p>
<p><kbd>    set DallasData;</kbd></p>
<p><kbd>    days_old_year = days_old / 365;</kbd></p>
<p><kbd>run;</kbd></p>
</td>
</tr>
<tr>
<td>
<p> </p>
<p>Filtering</p>
</td>
<td>
<p> </p>
<p><kbd>DallasData[DallasData['days_old']&gt;800].head()</kbd></p>
</td>
<td>
<p><kbd>data tips;</kbd></p>
<p><kbd>    set DallasData;</kbd></p>
<p><kbd>    if days_old &gt; 800;</kbd></p>
<p><kbd>run;</kbd></p>
</td>
</tr>
<tr>
<td>
<p> </p>
<p> </p>
<p> </p>
<p>If-else</p>
</td>
<td>
<p> </p>
<p> </p>
<p><kbd>DallasData['income_class'] = np.where(DallasData['income_average'] &lt; 40000, 'low', 'high')</kbd></p>
</td>
<td>
<p><kbd>data DallasData;</kbd></p>
<p><kbd>    set dallas;</kbd></p>
<p><kbd>    format income_average $5.;</kbd></p>
<p> </p>
<p><kbd>    if days_old &lt; 40000 then bucket = 'low';</kbd></p>
<p><kbd>    else bucket = 'high';</kbd></p>
<p><kbd>run;</kbd></p>
</td>
</tr>
<tr>
<td>
<p> </p>
<p> </p>
<p>Column selection</p>
</td>
<td>
<p> </p>
<p> </p>
<p><kbd>DallasData[['zip','customerID','days_old','services_due']].head()</kbd></p>
</td>
<td>
<p><kbd>data dallas;</kbd></p>
<p><kbd>    set DallasData;</kbd></p>
<p><kbd>    keep zip CustomerID days_old services_due;</kbd></p>
<p><kbd>run;</kbd></p>
</td>
</tr>
<tr>
<td>
<p> </p>
<p> </p>
<p>Sort</p>
</td>
<td>
<p> </p>
<p><kbd>dallas = DallasData.sort_values(['days_old','services_completed'])</kbd></p>
</td>
<td>
<p> </p>
<p><kbd>proc sort data=DallasData;</kbd></p>
<p><kbd>    by days_old services_completed;</kbd></p>
<p><kbd>run;</kbd></p>
</td>
</tr>
<tr>
<td>
<p> </p>
<p>String length</p>
</td>
<td>
<p> </p>
<p><kbd>DallasData['state_name'].str.len().head()</kbd></p>
</td>
<td>
<p><kbd>data _null_;</kbd></p>
<p><kbd>set DallasData;</kbd></p>
<p><kbd>put(LENGTHN(state_name));</kbd></p>
<p><kbd>put(LENGTHC(state_name));</kbd></p>
<p><kbd>run;</kbd></p>
</td>
</tr>
<tr>
<td>
<p> </p>
<p>Groupby aggregation</p>
</td>
<td>
<p> </p>
<p><kbd>dallas_grouped = DallasData.groupby(['zip', 'customerID'])['days_old', 'services_completed'].sum()</kbd></p>
</td>
<td>
<p><kbd>proc summary data=DallasData nway;</kbd></p>
<p><kbd>    class zip customerID;</kbd></p>
<p><kbd>    var days_old services_completed;</kbd></p>
<p><kbd>    output out=dallas_summed sum=;</kbd></p>
<p><kbd>run;</kbd></p>
</td>
</tr>
<tr>
<td>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p>Join</p>
</td>
<td>
<p> </p>
<p><kbd>df1 = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'value': np.random.randn(4)})</kbd></p>
<p> </p>
<p><kbd>df2 = pd.DataFrame({'key': ['B', 'D', 'D', 'E'],'value': np.random.randn(4)})</kbd></p>
<p> </p>
<p><kbd>inner_join = df1.merge(df2, on=['key'], how='inner')</kbd></p>
<p> </p>
<p><kbd>left_join = df1.merge(df2, on=['key'], how='left')</kbd></p>
<p> </p>
<p><kbd>right_join = df1.merge(df2, on=['key'], how='right')</kbd></p>
</td>
<td>
<p><kbd>proc sort data=df1;</kbd></p>
<p><kbd>    by key;</kbd></p>
<p><kbd>run;</kbd></p>
<p> </p>
<p><kbd>proc sort data=df2;</kbd></p>
<p><kbd>    by key;</kbd></p>
<p><kbd>run;</kbd></p>
<p> </p>
<p><kbd>data left_join inner_join right_join outer_join;</kbd></p>
<p><kbd>    merge df1(in=a) df2(in=b);</kbd></p>
<p> </p>
<p><kbd>    if a and b then output inner_join;</kbd></p>
<p><kbd>    if a then output left_join;</kbd></p>
<p><kbd>    if b then output right_join;</kbd></p>
<p><kbd>    if a or b then output outer_join;</kbd></p>
<p><kbd>run;</kbd></p>
</td>
</tr>
</tbody>
</table>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we  attempted to compare key features in R and SQL with their pandas equivalents in order to achieve the following objectives:</p>
<ul>
<li>To assist R, SQL, and SAS users who may wish to replicate the same functionality in pandas</li>
<li>To assist any users who on reading some R, SQL, and SAS code, may wish to rewrite the code in pandas</li>
</ul>
<p>In the next chapter, we will conclude the book by providing a brief introduction to the <kbd>scikit-learn</kbd> library for performing machine learning, and we will demonstrate how pandas fits in that framework. Reference documentation for this chapter can be found here: <a href="http://pandas.pydata.org/pandas-docs/stable/comparison_with_r.html"><span class="URLPACKT">http://pandas.pydata.org/pandas-docs/stable/comparison_with_r.html</span></a>.</p>


            </article>

            
        </section>
    </body></html>