- en: Combining Pandas Objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A wide variety of options are available to combine two or more DataFrames or
    Series together. The `append` method is the least flexible and only allows for
    new rows to be appended to a DataFrame. The `concat` method is very versatile
    and can combine any number of DataFrames or Series on either axis. The `join`
    method provides fast lookups by aligning a column of one DataFrame to the index
    of others. The `merge` method provides SQL-like capabilities to join two DataFrames
    together.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Appending new rows to DataFrames
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concatenating multiple DataFrames together
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comparing President Trump's and Obama's approval ratings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the differences between `concat`, `join`, and `merge`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connecting to SQL databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appending new rows to DataFrames
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When performing a data analysis, it is far more common to create new columns
    than new rows. This is because a new row of data usually represents a new observation
    and, as an analyst, it is typically not your job to continually capture new data.
    Data capture is usually left to other platforms like relational database management
    systems. Nevertheless, it is a necessary feature to know as it will crop up from
    time to time.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will begin by appending rows to a small dataset with the
    `.loc` indexer and then transition to using the `append` method.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the names dataset, and output it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/4954144c-e882-4317-8aea-1ed33e15dc93.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s create a list that contains some new data and use the `.loc` indexer
    to set a single row label equal to this new data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/1da729da-b2ad-4cb5-abc6-aa45ba1f1c00.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `.loc` indexer uses labels to refer to the rows. In this case, the row
    labels exactly match the integer location. It is possible to append more rows
    with non-integer labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/2a083be8-7f33-46f1-a95f-316aaa26f946.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To be more explicit in associating variables to values, you may use a dictionary.
    Also, in this step, we can dynamically choose the new index label to be the length
    of the DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/8ede39cb-b883-4529-9504-08a6509b4762.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A Series can hold the new data as well and works exactly the same as a dictionary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/7a5690e9-355e-44db-936a-2513551b28ec.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding operations all use the `.loc` indexing operator to make changes
    to the `names` DataFrame in-place. There is no separate copy of the DataFrame
    that is returned. In the next few steps, we will look at the `append` method,
    which does not modify the calling DataFrame. Instead, it returns a new copy of
    the DataFrame with the appended row(s). Let''s begin with the original `names`
    DataFrame and attempt to append a row. The first argument to `append` must be
    either another DataFrame, Series, dictionary, or a list of these, but not a list
    like the one in step 2\. Let''s see what happens when we attempt to use a dictionary
    with `append`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This error message appears to be slightly incorrect. We are passing a DataFrame
    and not a Series but nevertheless, it gives us instructions on how to correct
    it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/d1209a67-6e9c-400b-878f-3b4c6454fa05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This works but `ignore_index` is a sneaky parameter. When set to `True`, the
    old index will be removed completely and replaced with a `RangeIndex` from 0 to
    n-1\. For instance, let''s specify an index for the `names` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/5ce47674-b461-431f-ac0e-0deb1442f0f1.png)'
  prefs: []
  type: TYPE_IMG
- en: Rerun the code from step 7 and you will get the same result. The original index
    is completely ignored.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s continue with this `names` dataset with these country strings in the
    index and use a Series that has a `name` attribute with the `append` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/c54f0095-e1c3-4527-b793-a90c3efa3aa3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `append` method is more flexible than the `.loc` indexer. It supports appending
    multiple rows at the same time. One way to accomplish this is with a list of Series:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/49370d22-759a-4752-8eff-b1253447829e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Small DataFrames with only two columns are simple enough to manually write
    out all the column names and values. When they get larger, this process will be
    quite painful. For instance, let''s take a look at the 2016 baseball dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/5c669c06-e152-40f1-a4ce-af3f4f91803a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This dataset contains 22 columns and it would be easy to mistype a column name
    or forget one altogether if you were manually entering new rows of data. To help
    protect against these mistakes, let''s select a single row as a Series and chain
    the `to_dict` method to it to get an example row as a dictionary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Clear the old values with a dictionary comprehension assigning any previous
    string value as an empty string and all others, missing values. This dictionary
    can now serve as a template for any new data you would like to enter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `.loc` indexing operator is used to select and assign data based on the
    row and column labels. The first value passed to it represents the row label.
    In step 2, `names.loc[4]` refers to the row with a label equal to the integer
    4\. This label does not currently exist in the DataFrame. The assignment statement
    creates a new row with data provided by the list. As was mentioned in the recipe,
    this operation modifies the `names` DataFrame itself. If there was a previously
    existing row with a label equal to the integer 4, this command would have written
    over it. This modification in-place makes this indexing operator riskier to use
    than the `append` method, which never modifies the original calling DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Any valid label may be used with the `.loc` indexing operator, as seen in step
    3\. Regardless of what the new label value actually is, the new row will always
    be appended at the end. Even though assigning with a list works, for clarity it's
    best to use a dictionary so that we know exactly which columns are associated
    with each value, as done in step 4.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 shows a little trick to dynamically set the new label to be the current
    number of rows in the DataFrame. Data stored in a Series will also get assigned
    correctly as long as the index labels match the column names.
  prefs: []
  type: TYPE_NORMAL
- en: The rest of the steps use the `append` method, which is a simple method that
    only appends new rows to DataFrames. Most DataFrame methods allow both row and
    column manipulation through an `axis` parameter. One exception is with `append`,
    which can only append rows to DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: Using a dictionary of column names mapped to values isn't enough information
    for append to work, as seen by the error message in step 6\. To correctly append
    a dictionary without a row name, you will have to set the `ignore_index` parameter
    to `True`. Step 10 shows you how to keep the old index by simply converting your
    dictionary to a Series. Make sure to use the `name` parameter, which is then used
    as the new index label. Any number of rows may be added with append in this manner
    by passing a list of Series as the first argument.
  prefs: []
  type: TYPE_NORMAL
- en: When wanting to append rows in this manner with a much larger DataFrame, you
    can avoid lots of typing and mistakes by converting a single row to a dictionary
    with the `to_dict` method and then using a dictionary comprehension to clear out
    all the old values replacing them with some defaults.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Appending a single row to a DataFrame is a fairly expensive operation and if
    you find yourself writing a loop to append single rows of data to a DataFrame,
    then you are doing it wrong. Let''s first create 1,000 rows of new data as a list
    of Series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s time how long it takes to loop through each item making one append at
    a time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'That took nearly five seconds for only 1,000 rows. If we instead pass in the
    entire list of Series, we get an enormous speed increase:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: By passing in the list of Series, the time has been reduced to under one-tenth
    of a second. Internally, pandas converts the list of Series to a single DataFrame
    and then makes the append.
  prefs: []
  type: TYPE_NORMAL
- en: Concatenating multiple DataFrames together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The versatile `concat` function enables concatenating two or more DataFrames
    (or Series) together, both vertically and horizontally. As per usual, when dealing
    with multiple pandas objects simultaneously, concatenation doesn't happen haphazardly
    but aligns each object by their index.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we combine DataFrames both horizontally and vertically with
    the `concat` function and then change the parameter values to yield different
    results.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read in the 2016 and 2017 stock datasets, and make their ticker symbol the
    index:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/78a928de-3aa5-444b-b6c3-8f74e590a2ca.png)    ![](img/82f29089-c05d-4bf1-8208-be3212c8b259.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Place all the `stock` datasets into a single list, and then call the `concat`
    function to concatenate them together:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/d273561a-b8ee-4400-84c6-6fe99b2870ec.png)'
  prefs: []
  type: TYPE_IMG
- en: 'By default, the `concat` function concatenates DataFrames vertically, one on
    top of the other. One issue with the preceding DataFrame is that there is no way
    to identify the year of each row. The `concat` function allows each piece of the
    resulting DataFrame to be labeled with the `keys` parameter. This label will appear
    in the outermost index level of the concatenated frame and force the creation
    of a MultiIndex. Also, the `names` parameter has the ability to rename each index
    level for clarity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/010d420f-feba-4c21-9d7c-3f60a806cf2e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It is also possible to concatenate horizontally by changing the `axis` parameter
    to *columns* or *1*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/6d248ec3-bfb5-496c-96ae-2b5d267e5c77.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Notice that missing values appear whenever a stock symbol is present in one
    year but not the other. The `concat` function, by default, uses an outer join,
    keeping all rows from each DataFrame in the list.  However, it gives us options
    to only keep rows that have the same index values in both DataFrames. This is
    referred to as an inner join. We set the `join` parameter to *inner* to change
    the behavior:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/4740c498-d459-403c-bd63-17d7554797d5.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first argument is the only argument required for the `concat` function and
    it must be a sequence of pandas objects, typically a list or dictionary of DataFrames
    or Series. By default, all these objects will be stacked vertically one on top
    of the other. In this recipe, only two DataFrames are concatenated, but any number
    of pandas objects work. When we were concatenating vertically, the DataFrames
    align by their column names.
  prefs: []
  type: TYPE_NORMAL
- en: In this dataset, all the column names were the same so each column in the 2017
    data lined up precisely under the same column name in the 2016 data. However,
    when they were concatenated horizontally, as in step 4, only two of the index
    labels matched from both years--*AAPL* and *TSLA*. Therefore, these ticker symbols
    had no missing values for either year. There are two types of alignment possible
    using `concat`, *outer* (the default) and *inner* referred to by the `join` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `append` method is a heavily watered down version of `concat` that can
    only append new rows to a DataFrame. Internally, `append` just calls the `concat`
    function. For instance, step 2 from this recipe may be duplicated with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Comparing President Trump's and Obama's approval ratings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Public support of the current President of the United States is a topic that
    frequently makes it into news headlines and is formally measured through opinion
    polls. In recent years, there has been a rapid increase in the frequency of these
    polls and lots of new data rolls in each week. There are many different pollsters
    that each have their own questions and methodology to capture their data, and
    thus there exists quite a bit of variability among the data. The American Presidency
    Project from the University of California, Santa Barbara, provides an aggregate
    approval rating down to a single data point each day.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike most of the recipes in this book, the data is not readily available in
    a CSV file. Often, as a data analyst, you will need to find data on the web, and
    use a tool that can scrape it into a format that you can then parse through your
    local workstation.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will use the `read_html` function, which comes heavily equipped
    to scrape data from tables online and turn them into DataFrames. You will also
    learn how to inspect web pages to find the underlying HTML for certain elements.
    I used Google Chrome as my browser and suggest you use it, or Firefox, for the
    web-based steps.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Navigate to *The American Presidency Project* approval page for President Donald
    Trump ([http://www.presidency.ucsb.edu/data/popularity.php?pres=45](http://www.presidency.ucsb.edu/data/popularity.php?pres=45)).
    You should get a page that contains a time series plot with the data in a table
    directly following it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/aa1d10d8-b146-408e-a53e-c0949b87086e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `read_html` function is able to scrape tables off web pages and place their
    data into DataFrames. It works best with simple HTML tables and provides some
    useful parameters to select the exact table you desire in case there happen to
    be multiple tables on the same page. Let''s go ahead and use `read_html` with
    its default values, which will return all the tables as DataFrames in a list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The function has returned 14 tables, which seems preposterous at first, as
    the web page appears to show only a single element that most people would recognize
    as a table. The `read_html` function formally searches for HTML table elements
    that begin with *<table*. Let''s inspect the HTML page by right-clicking on the
    approval data table and selecting inspect or inspect element:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e0ac10b2-f06d-41b7-8812-e98ff764ef59.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This opens up the console, which is a very powerful tool for web development.
    For this recipe, we will only need it for a few tasks. All consoles allow you
    to search the HTML for a specific word. Let''s search for the word `table`. My
    browser found 15 different HTML tables, very close to the number returned by `read_html`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/fa149f24-7f39-49b5-9ea0-17bb8a32f54c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s begin inspecting the DataFrames in `df_list`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/f2c5a7e0-0994-47a1-89a9-dc3872414d23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Looking back at the web page, there is a row in the approval table for nearly
    each day beginning January 22, 2017, until the day the data was scraped--September
    25, 2017\. This is a little more than eight months or 250 rows of data, which
    is somewhat close to the 308 lines in that first table. Scanning through the rest
    of the tables, you can see that lots of empty meaningless tables were discovered,
    as well as tables for different parts of the web page that don''t actually resemble
    tables. Let''s use some of the parameters of the `read_html` function to help
    us select the table we desire. We can use the `match` parameter to search for
    a specific string in the table. Let''s search for a table with the word *Start
    Date* in it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'By searching for a specific string in the table, we have reduced the number
    of tables down to just three. Another useful parameter is `attrs`, which accepts
    a dictionary of HTML attributes paired with their value. We would like to find
    some unique attributes for our particular table. To do this, let''s right-click
    again in our data table. This time, make sure to click at the very top in one
    of the table headers. For example, right click on *President,* and select inspect
    or inspect element again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8453c5fd-4db1-4cb7-9373-7c92d335c3ce.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The element that you selected should be highlighted. This is actually not the
    element we are interested in. Keep looking until you come across an HTML tag beginning
    with *<table*. All the words to the left of the equal signs are the attributes
    or `attrs` and to the right are the values. Let''s use the *align* attribute with
    its value *center* in our search:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/42221dad-03c0-4e9b-9bf7-2e6aec18e4d6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We only matched with one table and the number of rows is very close to the
    total days between the first and last dates. Looking at the data, it appears that
    we have indeed found the table we are looking for. The six column names appear
    to be on line 4\. We can go even further and precisely select the rows we want
    to skip and which row we would like to use for the column names with the `skiprows`
    and `header` parameters. We can also make sure that the start and end dates are
    coerced correctly to the right data type with the `parse_dates` parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/99e47525-f4c0-44cf-84be-62eceaa334de.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is almost exactly what we want, except for the columns with missing values.
    Let''s use the `dropna` method to drop columns with all values missing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/907ada91-650c-4666-8dac-f7347b19b9fe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s fill the missing values in the `President` column in a forward direction
    with the `ffill` method. Let''s first check whether there are any missing values
    in the other columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/da9fc9fb-8b2e-4221-893d-105d8bca02d1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, it is important to check the data types to ensure they are correct:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s build a function with all the steps combined into one to automate the
    process of retrieving approval data for any President:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The only parameter, `pres_num`, denotes the order number of each president.
    Barack Obama was the 44th President of the United States; pass 44 to the `get_pres_appr`
    function to retrieve his approval numbers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/6247a2a4-700b-48c1-97ee-065dee3a30d6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There is Presidential approval rating data dating back to 1941 during President
    Franklin Roosevelt''s third term. With our custom function along with the `concat`
    function, it is possible to grab all the presidential approval rating data from
    this site. For now, let''s just grab the approval rating data for the last five
    presidents and output the first three rows for each President:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/b5510c6f-12c7-4faa-8711-6c8ece33933d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Before continuing, let''s determine if there are any dates with multiple approval
    ratings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Only a few of the days have duplicate values. To help simplify our analysis,
    let''s keep only the first row where the duplicate date exists:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s get a few summary statistics on the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/118778a4-f5d5-4d65-a816-2a35a1024802.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s plot each President''s approval rating on the same chart. To do this,
    we will group by each President, iterate through each group, and individually
    plot the approval rating for each date:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/8b6bbb45-0f79-4cbd-95f5-e47498c98c9e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This chart places all the Presidents sequentially one after the other. We can
    compare them on a simpler scale by plotting their approval rating against the
    number of days in office. Let''s create a new variable to represent the number
    of days in office:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/b63c31b6-e297-40e4-b17a-49bddb24e807.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We have successfully given each row a relative number of days since the start
    of the presidency. It''s interesting that the new column, `Days in Office`, has
    a string representation of its value. Let''s check its data type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Days in Office` column is a `timedelta64` object with nanosecond precision.
    This is far more precision than is needed. Let''s change the data type to integer
    by getting just the days:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We could plot this data in a similar fashion to what we did in step 19, but
    there is a completely different method that doesn''t involve any looping. By default,
    when calling the `plot` method on a DataFrame, pandas attempts to plot each column
    of data as a line plot and uses the index as the x-axis. Knowing this, let''s
    pivot our data so that each President has his own column for approval rating:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/16d28567-1ef0-412b-9a27-918e22994808.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that each President has his own column of approval ratings, we can plot
    each column directly without grouping. To reduce the clutter in the plot, we will
    only plot Barack Obama and Donald J. Trump:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/82e84686-c9f1-4e28-bdfc-393437ce7825.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is typical to call `read_html` multiple times before arriving at the table
    (or tables) that you desire. There are two primary parameters at your disposal
    to specify a table, `match` and `attrs`. The string provided to `match` is used
    to find an exact match for the actual text in the table. This is text that will
    show up on the web page itself. The `attrs` parameter, on the other hand, searches
    for HTML table attributes found directly after the start of the table tag, `<table`.
    To see more of the table attributes, visit this page from W3 Schools ([http://bit.ly/2hzUzdD](https://www.w3schools.com/TagS/tag_table.asp)).
  prefs: []
  type: TYPE_NORMAL
- en: Once we find our table in step 8, we can still take advantage of some other
    parameters to simplify things. HTML tables don't typically translate directly
    to nice DataFrames. There are often missing column names, extra rows, and misaligned
    data. In this recipe, `skiprows` is passed a list of row numbers to skip over
    when reading the file. They correspond to the rows of missing values in the DataFrame
    output from step 8\. The `header` parameter is also used to specify the location
    of the column names. Notice that `header` is equal to zero, which may seem wrong
    at first. Whenever the header parameter is used in conjunction with `skiprows`,
    the rows are skipped first resulting in a new integer label for each row. The
    correct column names are in row 4 but as we skipped rows 0 through 3, the new
    integer label for it is 0.
  prefs: []
  type: TYPE_NORMAL
- en: In step 11, the `ffill` method fills any missing values vertically, going down
    with the last non-missing value. This method is just a shortcut for `fillna(method='ffill')`.
  prefs: []
  type: TYPE_NORMAL
- en: Step 13 builds a function composed of all the previous steps to automatically
    get approval ratings from any President, provided you have the order number. There
    are a few differences in the function. Instead of applying the `ffill` method
    to the entire DataFrame, we only apply it to the `President` column. In Trump's
    DataFrame, the other columns had no missing data but this does not guarantee that
    all the scraped tables will have no missing data in their other columns. The last
    line of the function sorts the dates in a more natural way for data analysis from
    the oldest to newest. This changes the order of the index too, so we discard it
    with `reset_index` to have it begin from zero again.
  prefs: []
  type: TYPE_NORMAL
- en: Step 16 shows a common pandas idiom for collecting multiple, similarly indexed
    DataFrames into a list before combining them together with the `concat` function.
    After concatenation into a single DataFrame, we should visually inspect it to
    ensure its accuracy. One way to do this is to take a glance at the first few rows
    from each President's section by grouping the data and then using the `head` method
    on each group.
  prefs: []
  type: TYPE_NORMAL
- en: The summary statistics in step 18 are interesting as each successive President
    has had lower median approval than the last. Extrapolating the data would lead
    to naively predicting a negative approval rating within the next several Presidents.
  prefs: []
  type: TYPE_NORMAL
- en: The plotting code in step 19 is fairly complex. You might be wondering why we
    need to iterate through a `groupby` object, to begin with. In the DataFrame's
    current structure, it has no ability to plot different groups based on values
    in a single column. However, step 23 shows you how to set up your DataFrame so
    that pandas can directly plot each President's data without a loop like this.
  prefs: []
  type: TYPE_NORMAL
- en: To understand the plotting code in step 19, you must first be aware that a `groupby`
    object is iterable and, when iterating through, yields a tuple containing the
    current group (here it's just the name of the President) and the sub-DataFrame
    for just that group. This `groupby` object is zipped together with values controlling
    the color and linestyle of the plot. We import the colormap module, `cm`, from
    matplotlib which contains dozens of different colormaps. Passing a float between
    0 and 1 chooses a specific color from that colormap and we use it in our `plot`
    method with the `color` parameter. It is also important to note that we had to
    create the figure, `fig`, along with a plotting surface, `ax`, to ensure that
    each approval line was placed on the same plot. At each iteration in the loop,
    we use the same plotting surface with the identically named parameter, `ax`.
  prefs: []
  type: TYPE_NORMAL
- en: To make a better comparison between Presidents, we create a new column equal
    to the number of days in office. We subtract the first date from the rest of the
    dates per President group. When two `datetime64` columns are subtracted, the result
    is a `timedelta64` object, which represents some length of time, days in this
    case. If we leave the column with nanosecond precision, the x-axis will similarly
    display too much precision by using the special `dt` accessor to return the number
    of days.
  prefs: []
  type: TYPE_NORMAL
- en: A crucial step comes in step 23\. We structure the data such that each President
    has a unique column for their approval rating. Pandas makes a separate line for
    each column. Finally, in step 24, we use the `.loc` indexer to simultaneously
    select the first 250 days (rows) along with only the columns for just Trump and
    Obama. The `ffill` method is used in the rare instances that one of the Presidents
    has a missing value for a particular day. In Python, it is possible to pass dictionaries
    that contain the parameter names and their values to functions by preceding them
    with `**` in a process called **dictionary unpacking**.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The plot from step 19 shows quite a lot of noise and the data might be easier
    to interpret if it were smoothed. One common smoothing method is called the **rolling
    average**. Pandas offers the `rolling` method for DataFrames and `groupby` objects.
    It works analogously to the `groupby` method by returning an object waiting for
    an additional action to be performed on it. When creating it, you must pass the
    size of the window as the first argument, which can either be an integer or a
    date offset string.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we take a 90-day moving average with the date offset string
    *90D*. The `on` parameter specifies the column from which the rolling window is
    calculated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'From here, we can restructure the data so that it looks similar to the output
    from step 23 with the `unstack` method, and then make our plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/d120b3da-ec23-4575-b869-80eb4a9d486c.png)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Colormap references for matplotlib ([http://bit.ly/2yJZOvt](https://matplotlib.org/examples/color/colormaps_reference.html))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A list of all the date offsets and their aliases ([http://bit.ly/2xO5Yg0](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the differences between concat, join, and merge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `merge` and `join` DataFrame (and not Series) methods and the `concat`
    function all provide very similar functionality to combine multiple pandas objects
    together. As they are so similar and they can replicate each other in certain
    situations, it can get very confusing when and how to use them correctly. To help
    clarify their differences, take a look at the following outline:'
  prefs: []
  type: TYPE_NORMAL
- en: '`concat`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pandas function
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Combines two or more pandas objects vertically or horizontally
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Aligns only on the index
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Errors whenever a duplicate appears in the index
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Defaults to outer join with option for inner
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`join`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DataFrame method
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Combines two or more pandas objects horizontally
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Aligns the calling DataFrame's column(s) or index with the other objects' index
    (and not the columns)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Handles duplicate values on the joining columns/index by performing a cartesian
    product
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Defaults to left join with options for inner, outer, and right
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`merge`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DataFrame method
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Combines exactly two DataFrames horizontally
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Aligns the calling DataFrame's column(s)/index with the other DataFrame's column(s)/index
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Handles duplicate values on the joining columns/index by performing a cartesian
    product
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Defaults to inner join with options for left, outer, and right
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The first parameter to the join method is `other` which can either be a single
    DataFrame/Series or a list of any number of DataFrames/Series.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will do what is required to combine DataFrames. The first
    situation is simpler with `concat` while the second is simpler with `merge`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s read in stock data for 2016, 2017, and 2018 into a list of DataFrames
    using a loop instead of three different calls to the `read_csv` function. Jupyter
    notebooks currently only allow a single DataFrame to be displayed on one line.
    However, there is a way to customize the HTML output with help from the `IPython`
    library. The user-defined `display_frames` function accepts a list of DataFrames
    and outputs them all in a single row:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/334685b5-02c5-4a06-a159-caccb833fc01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `concat` function is the only one able to combine DataFrames vertically.
    Let''s do this by passing it the list `stock_tables`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/0c817ede-3963-45a8-961e-4ba60ab03d7c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It can also combine DataFrames horizontally by changing the `axis` parameter
    to `columns`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/761c169f-57ab-4ac7-aae1-e5e83bda06a3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that we have started combining DataFrames horizontally, we can use the
    `join` and `merge` methods to replicate this functionality of `concat`. Here,
    we use the `join` method to combine the `stock_2016` and `stock_2017` DataFrames.
    By default, the DataFrames align on their index. If any of the columns have the
    same names, then you must supply a value to the `lsuffix` or `rsuffix` parameters
    to distinguish them in the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/7003e693-6693-46b5-9880-13e184c2612d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To exactly replicate the output of the `concat` function from step 3, we can
    pass a list of DataFrames to the `join` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/146587e7-f778-4917-8eac-06e4f8208f7a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s check whether they actually are exactly equal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s turn to `merge` that, unlike `concat` and `join`, can combine exactly
    two DataFrames together. By default, `merge` attempts to align the values in the
    columns that have the same name for each of the DataFrames. However, you can choose
    to have it align on the index by setting the boolean parameters `left_index` and
    `right_index` to `True`. Let''s merge the 2016 and 2017 stock data together:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/075849a5-3ab9-4b9c-a914-be9e715ea643.png)'
  prefs: []
  type: TYPE_IMG
- en: 'By default, merge uses an inner join and automatically supplies suffixes for
    identically named columns. Let''s change to an outer join and then perform another
    outer join of the 2018 data to exactly replicate `concat`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s turn our comparison to datasets where we are interested in aligning
    together the values of columns and not the index or column labels themselves.
    The `merge` method is built exactly for this situation. Let''s take a look at
    two new small datasets, `food_prices` and `food_transactions`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/f98e02af-0bc9-4214-bff8-783bdda27391.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If we wanted to find the total amount of each transaction, we would need to
    join these tables on the `item` and `store` columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/32a7e87a-018f-40bb-bb3e-123be98fdf88.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The price is now aligned correctly with its corresponding item and store, but
    there is a problem. Customer 2 has a total of four `steak` items. As the `steak`
    item appears twice in each table for store `B`, a Cartesian product takes place
    between them, resulting in four rows. Also, notice that the item, `coconut`, is
    missing because there was no corresponding price for it. Let''s fix both of these
    issues:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/cbeec36e-7160-4664-a8a2-983ad7e70c41.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can replicate this with the `join` method but we must first put the joining
    columns of the `food_prices` DataFrame into the index:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/a6e73c76-1791-4dd5-b906-a5f9b0f386b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `join` method only aligns with the index of the passed DataFrame but can
    use the index or the columns of the calling DataFrame. To use columns for alignment
    on the calling DataFrame, you will need to pass them to the `on` parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The output matches the result from step 11 exactly. To replicate this with
    the `concat` method, you would need to put the item and store columns into the
    index of both DataFrames. However, in this particular case, an error would be
    produced as a duplicate index value occurs in at least one of the DataFrames (with
    item `steak` and store `B`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It can get tedious to repeatedly write the `read_csv` function when importing
    many DataFrames at the same time. One way to automate this process is to put all
    the file names in a list and iterate through them with a for loop. This was done
    in step 1 with a list comprehension.
  prefs: []
  type: TYPE_NORMAL
- en: The rest of this step builds a function to display multiple DataFrames on the
    same line of output in a Jupyter notebook. All DataFrames have a `to_html` method,
    which returns a raw HTML string representation of the table. The CSS (cascading
    style sheet) of each table is changed by altering the `display` attribute to *inline*
    so that elements get displayed horizontally next to one another rather than vertically.
    To properly render the table in the notebook, you must use the helper function
    `read_html` provided by the IPython library.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of step 1, we unpack the list of DataFrames into their own appropriately
    named variables so that each individual table may be easily and clearly referenced.
    The nice thing about having a list of DataFrames is that, it is the exact requirement
    for the `concat` function, as seen in step 2\. Notice how step 2 uses the `keys`
    parameter to name each chunk of data. This can be also be accomplished by passing
    a dictionary to `concat`, as done in step 3.
  prefs: []
  type: TYPE_NORMAL
- en: In step 4, we must change the type of `join` to `outer` to include all of the
    rows in the passed DataFrame that do not have an index present in the calling
    DataFrame. In step 5, the passed list of DataFrames cannot have any columns in
    common. Although there is an `rsuffix` parameter, it only works when passing a
    single DataFrame and not a list of them. To work around this limitation, we change
    the names of the columns beforehand with the `add_suffix` method, and then call
    the `join` method.
  prefs: []
  type: TYPE_NORMAL
- en: In step 7, we use `merge`, which defaults to aligning on all column names that
    are the same in both DataFrames. To change this default behavior, and align on
    the index of either one or both, set the `left_index` or `right_index` parameters
    to `True`. Step 8 finishes the replication with two calls to merge. As you can
    see, when you are aligning multiple DataFrames on their index, `concat` is usually
    going to be a far better choice than merge.
  prefs: []
  type: TYPE_NORMAL
- en: In step 9, we switch gears to focus on a situation where `merge` has the advantage.
    The `merge` method is the only one capable of aligning both the calling and passed
    DataFrame by column values. Step 10 shows you how easy it is to merge two DataFrames.
    The `on` parameter is not necessary but provided for clarity.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, it is very easy to duplicate or drop data when combining DataFrames,
    as shown in step 10\. It is vital to take some time to do some sanity checks after
    combining data. In this instance, the `food_prices` dataset had a duplicate price
    for `steak` in store `B` so we eliminated this row by querying for only the current
    year in step 11\. We also change to a left join to ensure that each transaction
    is kept regardless if a price is present or not.
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to use join in these instances but all the columns in the passed
    DataFrame must be moved into the index first. Finally, `concat` is going to be
    a poor choice whenever you intend to align data by values in their columns.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is possible to read all files from a particular directory into DataFrames
    without knowing their names. Python provides a few ways to iterate through directories,
    with the `glob` module being a popular choice. The gas prices directory contains
    five different CSV files, each having weekly prices of a particular grade of gas
    beginning from 2007\. Each file has just two columns--the date for the week and
    the price. This is a perfect situation to iterate through all the files, read
    them into DataFrames, and combine them all together with the `concat` function.
    The `glob` module has the `glob` function, which takes a single parameter--the
    location of the directory you would like to iterate through as a string. To get
    all the files in the directory, use the string ***. In this example, **.csv* returns
    only files that end in *.csv*. The result from the `glob` function is a list of
    string filenames, which can be directly passed to the `read_csv` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/8a01d07f-d580-4dce-9d3c-f47cf9a4c0ea.png)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: IPython official documentation of the `read_html` function ([http://bit.ly/2fzFRzd](http://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.display_html))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to the *Exploding indexes* recipe from [Chapter 12](a5777e1a-6de5-44f6-b291-429cbceb505f.xhtml),
    *Index Alignment*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connecting to SQL databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To become a serious data analyst, you will almost certainly have to learn some
    amount of SQL. Much of the world's data is stored in databases that accept SQL
    statements. There are many dozens of relational database management systems, with
    SQLite being one of the most popular and easy to use.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will be exploring the Chinook sample database provided by SQLite that contains
    11 tables of data for a music store. One of the best things to do when first diving
    into a proper relational database is to study a database diagram (sometimes called
    an entity relationship diagram) to better understand how tables are related. The
    following diagram will be immensely helpful when navigating through this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bfb39fe0-ea36-4d28-a0d2-245d6385b744.png)'
  prefs: []
  type: TYPE_IMG
- en: In order for this recipe to work, you will need to have the `sqlalchemy` Python
    package installed. If you installed the Anaconda distribution, then it should
    already be available to you. SQLAlchemy is the preferred pandas tool when making
    connections to databases. In this recipe, you will learn how to connect to a SQLite
    database. You will then ask two different queries, and answer them by joining
    together tables with the `merge` method.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we can begin reading tables from the `chinook` database, we need to
    set up our SQLAlchemy engine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now step back into the world of pandas and remain there for the rest
    of the recipe. Let''s complete a simple command and read in the `tracks` table
    with the `read_sql_table` function. The name of the table is the first argument
    and the SQLAlchemy engine is the second:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/e34917a4-21a5-4bba-b011-70d354bc6d96.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For the rest of the recipe, we will answer a couple of different specific queries
    with help from the database diagram. To begin, let''s find the average length
    of song per genre:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/41707069-07b1-4426-a5c2-ffa53f5c92de.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we can easily find the average length of each song per genre. To help ease
    interpretation, we convert the `Milliseconds` column to the `timedelta` data type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s find the total amount spent per customer. We will need the `customers`,
    `invoices`, and `invoice_items` tables all connected to each other:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/6e860d89-e3e3-4d5e-8ed2-c768bf668f23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can now multiply the quantity by the unit price and then find the total
    amount spent per customer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `create_engine` function requires a connection string in order to work
    properly. The connection string for SQLite is very simple, and is just the location
    of the database, which is located in the data directory. Other relational database
    management systems have more complex connection strings. You will need to provide
    a username, password, hostname, port, and optionally, a database. You will also
    need to supply the SQL dialect and the driver. The general form for the connection
    string is as follows: `dialect+driver://username:password@host:port/database`.
    The driver for your particular relational database might need to be installed
    separately.'
  prefs: []
  type: TYPE_NORMAL
- en: Once we have created the engine, selecting entire tables into DataFrames is
    very easy with the `read_sql_table` function in step 2\. Each of the tables in
    the database has a primary key uniquely identifying each row. It is identified
    graphically with a key symbol in the diagram. In step 3, we link genres to tracks
    through `GenreId`. As we only care about the track length, we trim the tracks
    DataFrame down to just the columns we need before performing the merge. Once the
    tables have merged, we can answer the query with a basic `groupby` operation.
  prefs: []
  type: TYPE_NORMAL
- en: We go one step further and convert the integer milliseconds into a Timedelta
    object that is far easier to read. The key is passing in the correct unit of measurement
    as a string. Now that we have a Timedelta Series, we can use the `dt` attribute
    to access the `floor` method, which rounds the time down to the nearest second.
  prefs: []
  type: TYPE_NORMAL
- en: 'The query required to answer step 5 involves three tables. We can trim the
    tables down significantly to only the columns we need by passing them to the `columns`
    parameter. When using `merge`, the joining columns are not kept when they have
    the same name. In step 6, we could have assigned a column for the price times
    quantity with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: There is nothing wrong with assigning columns in this manner. We chose to dynamically
    create a new column with the assign method to allow a continuous chain of methods.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you are adept with SQL, you can write a SQL query as a string and pass it
    to the `read_sql_query` function. For example, the following will reproduce the
    output from step 4:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/ccb4217b-d635-47d8-bfd3-c5952e29082b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To reproduce the answer from step 6, use the following SQL query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/307645d3-c9aa-4981-8e8c-eb934a124bf9.png)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All engine configurations for *SQLAlchemy* ([http://bit.ly/2kb07vV](http://docs.sqlalchemy.org/en/latest/core/engines.html))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pandas official documentation on *SQL Queries* ([http://bit.ly/2fFsOQ8](http://pandas.pydata.org/pandas-docs/stable/io.html#sql-queries)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
