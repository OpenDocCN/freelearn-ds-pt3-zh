["```py\n>>> %matplotlib inline\n>>> import matplotlib.pyplot as plt\n>>> import numpy as np\n>>> import pandas as pd\n>>> import seaborn as sns\n```", "```py\n>>> import sqlite3\n>>> with sqlite3.connect('logs/logs.db') as conn:\n...     logs_2018 = pd.read_sql(\n...         \"\"\"\n...         SELECT * \n...         FROM logs \n...         WHERE\n...             datetime BETWEEN \"2018-01-01\" AND \"2019-01-01\";\n...\"\"\", \n...         conn, parse_dates=['datetime'],\n...         index_col='datetime'\n...     )\n```", "```py\n>>> logs_2018.dtypes\nsource_ip         object\nusername          object\nsuccess            int64\nfailure_reason    object\ndtype: object\n```", "```py\n>>> logs_2018.info()\n<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 38700 entries, \n2018-01-01 00:05:32.988414 to 2018-12-31 23:29:42.482166\nData columns (total 4 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   source_ip       38700 non-null  object\n 1   username        38700 non-null  object\n 2   success         38700 non-null  int64 \n 3   failure_reason  11368 non-null  object\ndtypes: int64(1), object(3)\nmemory usage: 1.5+ MB\n```", "```py\n>>> logs_2018.describe(include='all')\n           source_ip username      success       failure_reason\ncount          38700    38700 38700.000000                11368\nunique          4956     1797          NaN                    3\ntop   168.123.156.81   wlopez          NaN error_wrong_password\nfreq             314      387          NaN                 6646\nmean             NaN      NaN     0.706253                  NaN\nstd              NaN      NaN     0.455483                  NaN\nmin              NaN      NaN     0.000000                  NaN\n25%              NaN      NaN     0.000000                  NaN\n50%              NaN      NaN     1.000000                  NaN\n75%              NaN      NaN     1.000000                  NaN\nmax              NaN      NaN     1.000000                  NaN\n```", "```py\n>>> logs_2018.groupby('source_ip')\\\n...     .agg(dict(username='nunique'))\\\n...     .username.describe()\ncount    4956.000000\nmean        1.146287\nstd         1.916782\nmin         1.000000\n25%         1.000000\n50%         1.000000\n75%         1.000000\nmax       129.000000\nName: username, dtype: float64\n```", "```py\n>>> pivot = logs_2018.pivot_table(\n...     values='success', index='source_ip', \n...     columns=logs_2018.failure_reason.fillna('success'), \n...     aggfunc='count', fill_value=0\n... )\n>>> pivot.insert(0, 'attempts', pivot.sum(axis=1))\n>>> pivot = pivot\\\n...     .sort_values('attempts', ascending=False)\\\n...     .assign(\n...         success_rate=lambda x: x.success / x.attempts,\n...         error_rate=lambda x: 1 - x.success_rate\n...     )\n>>> pivot.head()\n```", "```py\n>>> pivot.plot(\n...     kind='scatter', x='attempts', y='success', \n...     title='successes vs. attempts by IP address',\n...     alpha=0.25\n... )\n```", "```py\n>>> pivot[['attempts', 'success']].plot(\n...     kind='box', subplots=True, figsize=(10, 3), \n...     title='stats per IP address'\n... )\n```", "```py\n>>> from matplotlib.ticker import MultipleLocator\n>>> ax = logs_2018.loc['2018-01'].assign(\n...     failures=lambda x: 1 - x.success\n... ).groupby('source_ip').resample('1min').agg({\n...     'username': 'nunique', \n...     'success': 'sum', \n...     'failures': 'sum'\n... }).assign(\n...     attempts=lambda x: x.success + x.failures\n... ).dropna().query('attempts > 0').reset_index().plot(\n...     y=['attempts', 'username', 'failures'], kind='hist',\n...     subplots=True, layout=(1, 3), figsize=(20, 3),\n...     title='January 2018 distributions of minutely stats'\n...           'by IP address'\n... )\n>>> for axes in ax.flatten():\n...     axes.xaxis.set_major_locator(MultipleLocator(1))\n```", "```py\n>>> logs_2018.loc['2018'].assign(\n...     failures=lambda x: 1 - x.success\n... ).query('failures > 0').resample('1min').agg(\n...     {'username': 'nunique', 'failures': 'sum'}\n... ).dropna().rename(\n...     columns={'username': 'usernames_with_failures'}\n... ).usernames_with_failures.plot(\n...     title='usernames with failures per minute in 2018', \n...     figsize=(15, 3)\n... ).set_ylabel('usernames with failures')\n```", "```py\n>>> def get_X(log, day):\n...     \"\"\"\n...     Get data we can use for the X\n...\n...     Parameters:\n...         - log: The logs dataframe\n...         - day: A day or single value we can use as a\n...                datetime index slice\n...\n...     Returns: \n...         A `pandas.DataFrame` object\n...     \"\"\"\n...     return pd.get_dummies(\n...         log.loc[day].assign(\n...             failures=lambda x: 1 - x.success\n...         ).query('failures > 0').resample('1min').agg(\n...             {'username': 'nunique', 'failures': 'sum'}\n...         ).dropna().rename(\n...             columns={'username': 'usernames_with_failures'}\n...         ).assign(\n...             day_of_week=lambda x: x.index.dayofweek, \n...             hour=lambda x: x.index.hour\n...         ).drop(columns=['failures']),\n...         columns=['day_of_week', 'hour']\n...     )\n```", "```py\n>>> X = get_X(logs_2018, '2018-01')\n>>> X.columns\nIndex(['usernames_with_failures', 'day_of_week_0',\n       'day_of_week_1', 'day_of_week_2', 'day_of_week_3',\n       'day_of_week_4', 'day_of_week_5', 'day_of_week_6',\n       'hour_0', 'hour_1', ..., 'hour_22', 'hour_23'],\n      dtype='object')\n```", "```py\n>>> from sklearn.ensemble import IsolationForest\n>>> from sklearn.pipeline import Pipeline\n>>> from sklearn.preprocessing import StandardScaler\n>>> iso_forest_pipeline = Pipeline([\n...     ('scale', StandardScaler()),\n...     ('iforest', IsolationForest(\n...         random_state=0, contamination=0.05\n...     ))\n... ]).fit(X)\n```", "```py\n>>> isolation_forest_preds = iso_forest_pipeline.predict(X)\n>>> pd.Series(np.where(\n...     isolation_forest_preds == -1, 'outlier', 'inlier'\n... )).value_counts()\ninlier     42556\noutlier     2001\ndtype: int64\n```", "```py\n>>> from sklearn.neighbors import LocalOutlierFactor\n>>> from sklearn.pipeline import Pipeline\n>>> from sklearn.preprocessing import StandardScaler\n>>> lof_pipeline = Pipeline([\n...     ('scale', StandardScaler()),\n...     ('lof', LocalOutlierFactor())\n... ]).fit(X)\n```", "```py\n>>> lof_preds = lof_pipeline.named_steps['lof']\\\n...     .negative_outlier_factor_ \n>>> lof_preds\narray([-1.33898756e+10, -1.00000000e+00, -1.00000000e+00, ...,\n       -1.00000000e+00, -1.00000000e+00, -1.11582297e+10])\n```", "```py\n>>> pd.Series(np.where(\n...     lof_preds < lof_pipeline.named_steps['lof'].offset_, \n...     'outlier', 'inlier'\n... )).value_counts()\ninlier     44248\noutlier      309\ndtype: int64\n```", "```py\n>>> from sklearn.metrics import cohen_kappa_score\n>>> is_lof_outlier = np.where(\n...     lof_preds < lof_pipeline.named_steps['lof'].offset_, \n...     'outlier', 'inlier'\n... )\n>>> is_iso_outlier = np.where(\n...     isolation_forest_preds == -1, 'outlier', 'inlier'\n... )\n>>> cohen_kappa_score(is_lof_outlier, is_iso_outlier)\n0.25862517997335677\n```", "```py\n>>> with sqlite3.connect('logs/logs.db') as conn:\n...     hackers_jan_2018 = pd.read_sql(\n...         \"\"\"\n...         SELECT * \n...         FROM attacks \n...         WHERE start BETWEEN \"2018-01-01\" AND \"2018-02-01\";\n...         \"\"\", conn, parse_dates=['start', 'end']\n...     ).assign(\n...         duration=lambda x: x.end - x.start,\n...         start_floor=lambda x: x.start.dt.floor('min'),\n...         end_ceil=lambda x: x.end.dt.ceil('min')\n...     )\n>>> hackers_jan_2018.shape\n(7, 6)\n```", "```py\n>>> def get_y(datetimes, hackers, resolution='1min'):\n...     \"\"\"\n...     Get data we can use for the y (whether or not a\n...     hacker attempted a log in during that time).\n...\n...     Parameters:\n...         - datetimes: The datetimes to check for hackers\n...         - hackers: The dataframe indicating when the \n...                    attacks started and stopped\n...         - resolution: The granularity of the datetime. \n...                       Default is 1 minute.\n...\n...     Returns: `pandas.Series` of Booleans.\n...     \"\"\"\n...     date_ranges = hackers.apply(\n...         lambda x: pd.date_range(\n...             x.start_floor, x.end_ceil, freq=resolution\n...         ), \n...         axis=1\n...     )\n...     dates = pd.Series(dtype='object')\n...     for date_range in date_ranges:\n...         dates = pd.concat([dates, date_range.to_series()])\n...     return datetimes.isin(dates)\n```", "```py\n>>> is_hacker = \\\n...     get_y(X.reset_index().datetime, hackers_jan_2018)\n```", "```py\n>>> from functools import partial\n>>> from sklearn.metrics import classification_report\n>>> from ml_utils.classification import confusion_matrix_visual\n>>> report = partial(classification_report, is_hacker)\n>>> conf_matrix = partial(\n...     confusion_matrix_visual, is_hacker, \n...     class_labels=[False, True]\n... )\n```", "```py\n>>> iso_forest_predicts_hacker = isolation_forest_preds == - 1\n>>> print(report(iso_forest_predicts_hacker)) # iso. forest\n              precision    recall  f1-score   support\n       False       1.00      0.96      0.98     44519\n        True       0.02      0.82      0.03        38\n    accuracy                           0.96     44557\n   macro avg       0.51      0.89      0.50     44557\nweighted avg       1.00      0.96      0.98     44557\n>>> lof_predicts_hacker = \\\n...     lof_preds < lof_pipeline.named_steps['lof'].offset_ \n>>> print(report(lof_predicts_hacker)) # LOF\n              precision    recall  f1-score   support\n       False       1.00      0.99      1.00     44519\n        True       0.03      0.26      0.06        38\n    accuracy                           0.99     44557\n   macro avg       0.52      0.63      0.53     44557\nweighted avg       1.00      0.99      1.00     44557\n```", "```py\n>>> fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n>>> conf_matrix(\n...     iso_forest_predicts_hacker, \n...     ax=axes[0], title='Isolation Forest'\n... )\n>>> conf_matrix(\n...     lof_predicts_hacker, \n...     ax=axes[1], title='Local Outlier Factor'\n... )\n```", "```py\n>>> with sqlite3.connect('logs/logs.db') as conn:\n...     hackers_2018 = pd.read_sql(\n...         \"\"\"\n...         SELECT * \n...         FROM attacks \n...         WHERE start BETWEEN \"2018-01-01\" AND \"2019-01-01\";\n...         \"\"\", conn, parse_dates=['start', 'end']\n...     ).assign(\n...         duration=lambda x: x.end - x.start,\n...         start_floor=lambda x: x.start.dt.floor('min'),\n...         end_ceil=lambda x: x.end.dt.ceil('min')\n...     )\n```", "```py\n>>> def get_X_y(log, day, hackers):\n...     \"\"\"\n...     Get the X, y data to build a model with.\n...\n...     Parameters:\n...         - log: The logs dataframe\n...         - day: A day or single value we can use as a \n...                datetime index slice\n...         - hackers: The dataframe indicating when the \n...                    attacks started and stopped\n...\n...     Returns:\n...         X, y tuple where X is a `pandas.DataFrame` object\n...         and y is a `pandas.Series` object\n...     \"\"\"\n...     X = get_X(log, day)\n...     y = get_y(X.reset_index().datetime, hackers)\n...     return X, y\n```", "```py\n>>> X_train, y_train = \\\n...     get_X_y(logs_2018, '2018-01', hackers_2018)\n>>> X_test, y_test = \\\n...     get_X_y(logs_2018, '2018-02', hackers_2018)\n```", "```py\n>>> from sklearn.dummy import DummyClassifier\n>>> dummy_model = DummyClassifier(\n...     strategy='stratified', random_state=0\n... ).fit(X_train, y_train)\n>>> dummy_preds = dummy_model.predict(X_test)\n```", "```py\n>>> from functools import partial\n>>> from sklearn.metrics import classification_report\n>>> from ml_utils.classification import (\n...     confusion_matrix_visual, plot_pr_curve, plot_roc\n... )\n>>> report = partial(classification_report, y_test)\n>>> roc = partial(plot_roc, y_test)\n>>> pr_curve = partial(plot_pr_curve, y_test)\n>>> conf_matrix = partial(\n...     confusion_matrix_visual, y_test, \n...     class_labels=[False, True]\n... )\n```", "```py\n>>> fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n>>> roc(dummy_model.predict_proba(X_test)[:,1], ax=axes[0])\n>>> conf_matrix(dummy_preds, ax=axes[1])\n>>> pr_curve(\n...     dummy_model.predict_proba(X_test)[:,1], ax=axes[2]\n... )\n>>> plt.suptitle('Dummy Classifier with Stratified Strategy')\n```", "```py\n>>> print(report(dummy_preds))\n              precision    recall  f1-score   support\n       False       1.00      1.00      1.00     39958\n        True       0.00      0.00      0.00         5\n    accuracy                           1.00     39963\n   macro avg       0.50      0.50      0.50     39963\nweighted avg       1.00      1.00      1.00     39963\n```", "```py\n>>> from sklearn.naive_bayes import GaussianNB\n>>> from sklearn.pipeline import Pipeline\n>>> from sklearn.preprocessing import StandardScaler\n>>> nb_pipeline = Pipeline([\n...     ('scale', StandardScaler()),\n...     ('nb', GaussianNB())\n... ]).fit(X_train, y_train)\n>>> nb_preds = nb_pipeline.predict(X_test)\n```", "```py\n>>> nb_pipeline.named_steps['nb'].class_prior_\narray([9.99147160e-01, 8.52840182e-04])\n```", "```py\n>>> fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n>>> roc(nb_pipeline.predict_proba(X_test)[:,1], ax=axes[0])\n>>> conf_matrix(nb_preds, ax=axes[1])\n>>> pr_curve(\n...     nb_pipeline.predict_proba(X_test)[:,1], ax=axes[2]\n... )\n>>> plt.suptitle('Naive Bayes Classifier')\n```", "```py\n>>> print(report(nb_preds))\n              precision    recall  f1-score   support\n       False       1.00      0.79      0.89     39958\n        True       0.00      1.00      0.00         5\n    accuracy                           0.79     39963\n   macro avg       0.50      0.90      0.44     39963\nweighted avg       1.00      0.79      0.89     39963\n```", "```py\n>>> %%capture\n>>> from sklearn.linear_model import LogisticRegression\n>>> from sklearn.model_selection import GridSearchCV\n>>> from sklearn.pipeline import Pipeline\n>>> from sklearn.preprocessing import StandardScaler\n>>> lr_pipeline = Pipeline([\n...     ('scale', StandardScaler()),\n...     ('lr', LogisticRegression(random_state=0))\n... ])\n>>> search_space = {'lr__C': [0.1, 0.5, 1, 2]}\n>>> lr_grid = GridSearchCV(\n...     lr_pipeline, search_space, scoring='recall_macro', cv=5\n... ).fit(X_train, y_train)\n>>> lr_preds = lr_grid.predict(X_test) \n```", "```py\n>>> fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n>>> roc(lr_grid.predict_proba(X_test)[:,1], ax=axes[0])\n>>> conf_matrix(lr_preds, ax=axes[1])\n>>> pr_curve(lr_grid.predict_proba(X_test)[:,1], ax=axes[2])\n>>> plt.suptitle('Logistic Regression Classifier')\n```", "```py\n>>> print(report(lr_preds))\n              precision    recall  f1-score   support\n       False       1.00      1.00      1.00     39958\n        True       1.00      0.80      0.89         5\n    accuracy                           1.00     39963\n   macro avg       1.00      0.90      0.94     39963\nweighted avg       1.00      1.00      1.00     39963\n```", "```py\nfrom sklearn.pipeline import Pipeline\nclass PartialFitPipeline(Pipeline):\n    \"\"\"\n    Subclass of sklearn.pipeline.Pipeline that supports the \n    `partial_fit()` method.\n    \"\"\"\n    def partial_fit(self, X, y):\n        \"\"\"\n        Run `partial_fit()` for online learning estimators \n        when used in a pipeline.\n        \"\"\"\n        # for all but last step\n        for _, step in self.steps[:-1]: # (name, object) tuples\n            X = step.fit_transform(X)\n        # grab object from tuple position 1 for partial_fit()\n        self.steps[-1][1].partial_fit(X, y)\n        return self\n```", "```py\n>>> X_2018, y_2018 = get_X_y(logs_2018, '2018', hackers_2018)\n```", "```py\n>>> from sklearn.linear_model import SGDClassifier\n>>> from sklearn.preprocessing import StandardScaler\n>>> from ml_utils.partial_fit_pipeline import \\\n...     PartialFitPipeline\n>>> model = PartialFitPipeline([\n...     ('scale', StandardScaler()), \n...     ('sgd', SGDClassifier(\n...random_state=10, max_iter=1000, \n...         tol=1e-3, loss='log', average=1000,\n...         learning_rate='adaptive', eta0=0.01\n...     ))\n... ]).fit(X_2018, y_2018)\n```", "```py\n>>> [(col, coef) for col, coef in \n...  zip(X_2018.columns, model.named_steps['sgd'].coef_[0])]\n[('usernames_with_failures', 0.9415581997027198),\n ('day_of_week_0', 0.05040751530926895),\n ...,\n ('hour_23', -0.02176726532333003)]\n```", "```py\n>>> with sqlite3.connect('logs/logs.db') as conn:\n...     logs_2019 = pd.read_sql(\n...         \"\"\"\n...         SELECT * \n...         FROM logs \n...         WHERE\n...             datetime BETWEEN \"2019-01-01\" AND \"2020-01-01\";\n...         \"\"\", \n...         conn, parse_dates=['datetime'],\n...         index_col='datetime'\n...     )\n...     hackers_2019 = pd.read_sql(\n...         \"\"\"\n...         SELECT * \n...         FROM attacks \n...         WHERE start BETWEEN \"2019-01-01\" AND \"2020-01-01\";\n...         \"\"\", \n...         conn, parse_dates=['start', 'end']\n...     ).assign(\n...         start_floor=lambda x: x.start.dt.floor('min'),\n...         end_ceil=lambda x: x.end.dt.ceil('min')\n...     )\n```", "```py\n>>> X_jan, y_jan = get_X_y(logs_2019, '2019-01', hackers_2019)\n```", "```py\n>>> from sklearn.metrics import classification_report\n>>> print(classification_report(y_jan, model.predict(X_jan)))\n              precision    recall  f1-score   support\n       False       1.00      1.00      1.00     44559\n        True       1.00      0.64      0.78        44\n    accuracy                           1.00     44603\n   macro avg       1.00      0.82      0.89     44603\nweighted avg       1.00      1.00      1.00     44603\n```", "```py\n>>> from ml_utils.classification import (\n...     confusion_matrix_visual, plot_pr_curve, plot_roc\n... )\n>>> def plot_performance(model, X, y, threshold=None, \n...                      title=None, show_target=True):\n...     \"\"\"\n...     Plot ROC, confusion matrix, and precision-recall curve.\n...     \n...     Parameters:\n...         - model: The model object to use for prediction.\n...         - X: The features to pass in for prediction.\n...         - y: The actuals to evaluate the prediction.\n...         - threshold: Value to use as when predicting \n...                      probabilities.\n...         - title: A title for the subplots.\n...         - show_target: Whether to show the target regions.\n...         \n...     Returns: \n...         Matplotlib `Axes` object.\n...     \"\"\"\n...     fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n...     # plot each visualization\n...     plot_roc(y, model.predict_proba(X)[:,1], ax=axes[0])\n...     confusion_matrix_visual(\n...         y, \n...         model.predict_proba(X)[:,1] >= (threshold or 0.5), \n...         class_labels=[False, True], ax=axes[1]\n...     )\n...     plot_pr_curve(\n...         y, model.predict_proba(X)[:,1], ax=axes[2]\n...     )\n...\n...     # show the target regions if desired\n...     if show_target:\n...         axes[0]\\\n...             .axvspan(0, 0.1, color='lightgreen', alpha=0.5)\n...         axes[0]\\\n...             .axhspan(0.7, 1, color='lightgreen', alpha=0.5)\n...         axes[0].annotate(\n...             'region with acceptable\\nFPR and TPR', \n...             xy=(0.1, 0.7), xytext=(0.17, 0.65), \n...             arrowprops=dict(arrowstyle='->')\n...         )\n...\n...         axes[2]\\\n...             .axvspan(0.7, 1, color='lightgreen', alpha=0.5)\n...         axes[2].axhspan(\n...             0.85, 1, color='lightgreen', alpha=0.5\n...         )\n...         axes[2].annotate(\n...             'region with acceptable\\nprecision and recall', \n...             xy=(0.7, 0.85), xytext=(0.3, 0.6), \n...             arrowprops=dict(arrowstyle='->')\n...         )\n...\n...         # mark the current performance\n...         tn, fn, fp, tp = \\\n...             [int(x.get_text()) for x in axes[1].texts]\n...         precision, recall = tp / (tp + fp), tp / (tp + fn)\n...         fpr = fp / (fp + tn)\n...\n...         prefix = 'current performance' if not threshold \\\n...                  else f'chosen threshold: {threshold:.2%}'\n...         axes[0].annotate(\n...             f'{prefix}\\n- FPR={fpr:.2%}'\n...             f'\\n- TPR={recall:.2%}',\n...             xy=(fpr, recall), xytext=(0.05, 0.45), \n...             arrowprops=dict(arrowstyle='->')\n...         )\n...         axes[2].annotate(\n...             f'{prefix}\\n- precision={precision:.2%}'\n...             f'\\n- recall={recall:.2%}', \n...             xy=(recall, precision), xytext=(0.2, 0.85), \n...             arrowprops=dict(arrowstyle='->')\n...         )\n...\n...     if title: # show the title if specified\n...         plt.suptitle(title)\n... \n...     return axes\n```", "```py\n>>> axes = plot_performance(\n...     model, X_jan, y_jan, \n...     title='Stochastic Gradient Descent Classifier '\n...           '(Tested on January 2019 Data)'\n... )\n```", "```py\nfrom sklearn.metrics import precision_recall_curve\ndef find_threshold_pr(y_test, y_preds, *, min_precision,  \n                      min_recall):\n    \"\"\"\n    Find the threshold to use with `predict_proba()` for \n    classification based on the minimum acceptable precision \n    and the minimum acceptable recall.\n    Parameters:\n        - y_test: The actual labels.\n        - y_preds: The predicted labels.\n        - min_precision: The minimum acceptable precision.\n        - min_recall: The minimum acceptable recall.\n    Returns: The thresholds that meet the criteria.\n    \"\"\"\n    precision, recall, thresholds = \\\n        precision_recall_curve(y_test, y_preds)\n    # precision and recall have one extra value at the end \n    # for plotting -- needs to be removed to make a mask \n    return thresholds[\n        (precision[:-1] >= min_precision) & \n        (recall[:-1] >= min_recall)\n    ]\n```", "```py\n>>> from ml_utils.classification import find_threshold_pr\n>>> threshold = find_threshold_pr(\n...     y_jan, model.predict_proba(X_jan)[:,1], \n...     min_precision=0.85, min_recall=0.7\n... ).max()\n>>> threshold\n0.0051533333839830974\n```", "```py\n>>> axes = plot_performance(\n...     model, X_jan, y_jan, threshold=threshold, \n...     title='Stochastic Gradient Descent Classifier '\n...           '(Tested on January 2019 Data)'\n... )\n```", "```py\n>>> model.partial_fit(X_jan, y_jan)\n```", "```py\n>>> X_feb, y_feb = get_X_y(logs_2019, '2019-02', hackers_2019)\n```", "```py\n>>> print(classification_report(\n...     y_feb, model.predict_proba(X_feb)[:,1] >= threshold\n... ))\n              precision    recall  f1-score   support\n       False       1.00      1.00      1.00     40248\n        True       1.00      0.80      0.89        10\n    accuracy                           1.00     40258\n   macro avg       1.00      0.90      0.94     40258\nweighted avg       1.00      1.00      1.00     40258\n```", "```py\n>>> axes = plot_performance(\n...     model, X_feb, y_feb, threshold=threshold,\n...     title='Stochastic Gradient Descent Classifier '\n...           '(Tested on February 2019 Data)'\n... )\n```", "```py\n>>> model.partial_fit(X_feb, y_feb)\n```", "```py\n>>> X_march, y_march = \\\n...     get_X_y(logs_2019, '2019-03', hackers_2019)\n>>> march_2019_preds = \\\n...     model.predict_proba(X_march)[:,1] >= threshold\n```", "```py\n>>> from sklearn.metrics import classification_report\n>>> print(classification_report(y_march, march_2019_preds))\n              precision    recall  f1-score   support\n       False       1.00      1.00      1.00     44154\n        True       0.88      0.76      0.81        29\n    accuracy                           1.00     44183\n   macro avg       0.94      0.88      0.91     44183\nweighted avg       1.00      1.00      1.00     44183\n```", "```py\n>>> axes = plot_performance(\n...     model, X_march, y_march, threshold=threshold,\n...     title='Stochastic Gradient Descent Classifier '\n...           '(Tested on March 2019 Data)'\n... )\n```"]