<html><head></head><body>
  <div id="sbo-rt-content"><div class="chapter" title="Chapter 13. Stochastic Dynamical Systems"><div class="titlepage"><div><div><h1 class="title"><a id="ch13"/>Chapter 13. Stochastic Dynamical Systems</h1></div></div></div><p>In this chapter, we will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Simulating a discrete-time Markov chain</li><li class="listitem" style="list-style-type: disc">Simulating a Poisson process</li><li class="listitem" style="list-style-type: disc">Simulating a Brownian motion</li><li class="listitem" style="list-style-type: disc">Simulating a stochastic differential equation</li></ul></div><div class="section" title="Introduction"><div class="titlepage"><div><div><h1 class="title"><a id="ch13lvl1sec105"/>Introduction</h1></div></div></div><p>
<span class="strong"><strong>Stochastic dynamical systems</strong></span><a id="id1849" class="indexterm"/> are dynamical systems subjected to the effect of noise. The randomness brought by the noise takes into account the variability observed in real-world phenomena. For example, the evolution of a share price typically exhibits long-term behaviors along with faster, smaller-amplitude oscillations, reflecting day-to-day or hour-to-hour variations.</p><p>Applications of stochastic systems to data science include methods for statistical inference (such as Markov chain Monte Carlo) and stochastic modeling for time series or geospatial data.</p><p>Stochastic discrete-time systems include discrete-time<a id="id1850" class="indexterm"/> <span class="strong"><strong>Markov chains</strong></span>. The <span class="strong"><strong>Markov property</strong></span><a id="id1851" class="indexterm"/> means that the state of a system at time <span class="emphasis"><em>n+1</em></span> only depends on its state at time <span class="emphasis"><em>n</em></span>. <span class="strong"><strong>Stochastic cellular automata</strong></span>, which<a id="id1852" class="indexterm"/> are stochastic extensions of cellular automata, are particular Markov chains.</p><p>As far as continuous-time systems are concerned, Ordinary Differential Equations with noise yield <a id="id1853" class="indexterm"/><span class="strong"><strong>Stochastic Differential Equations</strong></span> (<span class="strong"><strong>SDEs</strong></span>). Partial Differential <a id="id1854" class="indexterm"/>Equations with noise yield <span class="strong"><strong>Stochastic Partial Differential Equations</strong></span> (<span class="strong"><strong>SPDEs</strong></span>).</p><p>
<span class="strong"><strong>Point processes</strong></span><a id="id1855" class="indexterm"/> are another type of stochastic process. These processes model the random occurrence of instantaneous events over time (arrival of customers in a queue or action potentials in the nervous system) or space (locations of trees in a forest, cities in a territory, or stars in the sky).</p><p>Mathematically, the theory of stochastic dynamical systems is based on probability theory and measure theory. The study of continuous-time stochastic systems builds upon stochastic calculus, an extension of infinitesimal calculus (including derivatives and integrals) to stochastic processes.</p><p>In this chapter, we will see how to simulate different kinds of stochastic systems with Python.</p><div class="section" title="References"><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec398"/>References</h2></div></div></div><p>Here are a few references on the subject:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">An overview of <a id="id1856" class="indexterm"/>stochastic dynamical systems, available at <a class="ulink" href="http://www.scholarpedia.org/article/Stochastic_dynamical_systems">www.scholarpedia.org/article/Stochastic_dynamical_systems</a></li><li class="listitem" style="list-style-type: disc">The Markov property<a id="id1857" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="https://en.wikipedia.org/wiki/Markov_property">https://en.wikipedia.org/wiki/Markov_property</a></li></ul></div></div></div></div></div>


  <div id="sbo-rt-content"><div class="section" title="Simulating a discrete-time Markov chain"><div class="titlepage"><div><div><h1 class="title"><a id="ch13lvl1sec106"/>Simulating a discrete-time Markov chain</h1></div></div></div><p>Discrete-time Markov chains<a id="id1858" class="indexterm"/> are stochastic processes that undergo transitions from one state to another in a state space. Transitions occur at every time step. Markov chains are characterized by their lack of memory in that the probability to undergo a transition from the current state to the next depends only on the current state, not the previous ones. These models are widely used in scientific and engineering applications.</p><p>Continuous-time Markov processes also exist and we will cover particular instances later in this chapter.</p><p>Markov chains are relatively easy to study mathematically and to simulate numerically. In this recipe, we will simulate a simple Markov chain modeling the evolution of a population.</p><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec399"/>How to do it...</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Let's import<a id="id1859" class="indexterm"/> NumPy and matplotlib:<div class="informalexample"><pre class="programlisting">In [1]: import numpy as np
        import matplotlib.pyplot as plt
        %matplotlib inline</pre></div></li><li class="listitem">We consider a population that cannot comprise more than <span class="emphasis"><em>N=100</em></span> individuals, and define the birth and death rates:<div class="informalexample"><pre class="programlisting">In [2]: N = 100  # maximum population size
        a = 0.5/N  # birth rate
        b = 0.5/N  # death rate</pre></div></li><li class="listitem">We simulate a Markov chain on the finite space <span class="emphasis"><em>{0, 1, ..., N}</em></span>. Each state represents a population size. The <code class="literal">x</code> vector will contain the population size at each time step. We set the initial state to <span class="emphasis"><em>x<sub>0</sub>=25</em></span> (that is, there are 25 individuals in the population at initialization time):<div class="informalexample"><pre class="programlisting">In [3]: nsteps = 1000
        x = np.zeros(nsteps)
        x[0] = 25</pre></div></li><li class="listitem">Now we <a id="id1860" class="indexterm"/>simulate our chain. At each time step <span class="emphasis"><em>t</em></span>, there is a new birth with probability <span class="emphasis"><em>ax<sub>t</sub></em></span>, and independently, there is a new death with probability <span class="emphasis"><em>bx<sub>t</sub></em></span>. These probabilities are proportional to the size of the population at that time. If the population size reaches <span class="emphasis"><em>0</em></span> or <span class="emphasis"><em>N</em></span>, the evolution stops:<div class="informalexample"><pre class="programlisting">In [4]: for t in range(nsteps - 1):
            if 0 &lt; x[t] &lt; N-1:
                # Is there a birth?
                birth = np.random.rand() &lt;= a*x[t]
                # Is there a death?
                death = np.random.rand() &lt;= b*x[t]
                # We update the population size.
                x[t+1] = x[t] + 1*birth - 1*death
            # The evolution stops if we reach 0 or N.
            else:
                x[t+1] = x[t]</pre></div></li><li class="listitem">Let's look at the evolution of the population size:<div class="informalexample"><pre class="programlisting">In [5]: plt.plot(x)</pre></div><div class="mediaobject"><img src="images/4818OS_13_01.jpg" alt="How to do it..."/></div><p>We see that, at every time step, the population size can stay stable, increase, or decrease by 1.</p></li><li class="listitem">Now, we will <a id="id1861" class="indexterm"/>simulate many independent trials of this Markov chain. We could run the previous simulation with a loop, but it would be very slow (two nested <code class="literal">for</code> loops). Instead, we <span class="emphasis"><em>vectorize</em></span> the simulation by considering all independent trials at once. There is a single loop over time. At every time step, we update all trials simultaneously with vectorized operations on vectors. The <code class="literal">x</code> vector now contains the population size of all trials, at a particular time. At initialization time, the population sizes are set to random numbers between <span class="emphasis"><em>0</em></span> and <span class="emphasis"><em>N</em></span>:<div class="informalexample"><pre class="programlisting">In [6]: ntrials = 100
        x = np.random.randint(size=ntrials,
                              low=0, high=N)</pre></div></li><li class="listitem">We define a function that performs the simulation. At every time step, we find the trials that undergo births and deaths by generating random vectors, and we update the population sizes with vector operations:<div class="informalexample"><pre class="programlisting">In [7]: def simulate(x, nsteps):
            """Run the simulation."""
            for _ in range(nsteps - 1):
                # Which trials to update?
                upd = (0 &lt; x) &amp; (x &lt; N-1)
                # In which trials do births occur?
                birth = 1*(np.random.rand(ntrials) &lt;= a*x)
                # In which trials do deaths occur?
                death = 1*(np.random.rand(ntrials) &lt;= b*x)
                # We update the population size for all
                # trials.
                x[upd] += birth[upd] - death[upd]</pre></div></li><li class="listitem">Now, let's look at the histograms of the population size at different times. These histograms represent the probability distribution of the Markov chain, estimated with independent trials (the Monte Carlo method):<div class="informalexample"><pre class="programlisting">In [8]: bins = np.linspace(0, N, 25)
In [9]: nsteps_list = [10, 1000, 10000]
        for i, nsteps in enumerate(nsteps_list):
            plt.subplot(1, len(nsteps_list), i + 1)
            simulate(x, nsteps)
            plt.hist(x, bins=bins)
            plt.xlabel("Population size")
            if i == 0:
                plt.ylabel("Histogram")
            plt.title("{0:d} time steps".format(nsteps))</pre></div><div class="mediaobject"><img src="images/4818OS_13_02.jpg" alt="How to do it..."/></div><p>Whereas, initially, the <a id="id1862" class="indexterm"/>population sizes look uniformly distributed between <span class="emphasis"><em>0</em></span> and <span class="emphasis"><em>N</em></span>, they appear to converge to <span class="emphasis"><em>0</em></span> or <span class="emphasis"><em>N</em></span> after a sufficiently long time. This is because the states <span class="emphasis"><em>0</em></span> and <span class="emphasis"><em>N</em></span> are<a id="id1863" class="indexterm"/> <span class="strong"><strong>absorbing</strong></span>; once reached, the chain cannot leave these states. Furthermore, these states can be reached from any other state.</p></li></ol></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec400"/>How it works...</h2></div></div></div><p>Mathematically, a discrete-time Markov chain on a space <span class="emphasis"><em>E</em></span> is a sequence of random variables <span class="emphasis"><em>X<sub>1</sub>, X<sub>2</sub>, ...</em></span> that satisfy the Markov property:</p><div class="mediaobject"><img src="images/4818_13_03.jpg" alt="How it works..."/></div><p>A (stationary) Markov chain is characterized by the probability of transitions <span class="emphasis"><em>P(X<sub>j</sub> | X<sub>i</sub>)</em></span>. These values form a matrix called the <a id="id1864" class="indexterm"/><span class="strong"><strong>transition matrix</strong></span>. This matrix is the adjacency matrix of a directed graph called the<a id="id1865" class="indexterm"/> <span class="strong"><strong>state diagram</strong></span>. Every node is a state, and the node <span class="emphasis"><em>i</em></span> is connected to the node <span class="emphasis"><em>j</em></span> if the chain has a non-zero probability of transition between these nodes.</p></div><div class="section" title="There's more..."><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec401"/>There's more...</h2></div></div></div><p>Simulating a single Markov chain in Python is not particularly efficient because we need a <code class="literal">for</code> loop. However, simulating many independent chains following the same process can be made efficient with vectorization and parallelization (all tasks are independent, thus the problem is<a id="id1866" class="indexterm"/> <span class="strong"><strong>embarrassingly parallel</strong></span>). This is useful when we are interested in statistical properties of the chain (example of the <a id="id1867" class="indexterm"/>Monte Carlo method).</p><p>There is a vast literature on Markov chains. Many theoretical results can be established with linear algebra and probability theory. You can find references and textbooks on Wikipedia.</p><p>Many generalizations of discrete-time Markov chains exist. Markov chains can be defined on infinite state spaces, or with a continuous time. Also, the Markov property is important in a broad class of stochastic processes.</p><p>Here are a few references:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Markov chains on <a id="id1868" class="indexterm"/>Wikipedia, available at<a class="ulink" href="https://en.wikipedia.org/wiki/Markov_chain"> https://en.wikipedia.org/wiki/Markov_chain</a></li><li class="listitem" style="list-style-type: disc">Absorbing Markov chains on Wikipedia, available at <a class="ulink" href="https://en.wikipedia.org/wiki/Absorbing_Markov_chain">https://en.wikipedia.org/wiki/Absorbing_Markov_chain</a></li><li class="listitem" style="list-style-type: disc">Monte-Carlo methods on <a id="id1869" class="indexterm"/>Wikipedia, available at <a class="ulink" href="https://en.wikipedia.org/wiki/Monte_Carlo_method">https://en.wikipedia.org/wiki/Monte_Carlo_method</a></li></ul></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec402"/>See also</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <span class="emphasis"><em>Simulating a Brownian motion</em></span> recipe</li></ul></div></div></div></div>


  <div id="sbo-rt-content"><div class="section" title="Simulating a Poisson process"><div class="titlepage"><div><div><h1 class="title"><a id="ch13lvl1sec107"/>Simulating a Poisson process</h1></div></div></div><p>A <span class="strong"><strong>Poisson process</strong></span> <a id="id1870" class="indexterm"/>is a particular type of <a id="id1871" class="indexterm"/><span class="strong"><strong>point process</strong></span>, a stochastic model that represents random occurrences of instantaneous events. Roughly speaking, the Poisson process is the least structured, or the most random, point process.</p><p>The Poisson process is a particular continuous-time Markov process.</p><p>Point processes, and notably Poisson processes, can model random instantaneous events such as the arrival of clients in a queue or on a server, telephone calls, radioactive disintegrations, action potentials of nerve cells, and many other phenomena.</p><p>In this recipe, we will show different methods to simulate a homogeneous stationary Poisson process.</p><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec403"/>How to do it...</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Let's<a id="id1872" class="indexterm"/> import NumPy and matplotlib:<div class="informalexample"><pre class="programlisting">In [1]: import numpy as np
        import matplotlib.pyplot as plt
        %matplotlib inline</pre></div></li><li class="listitem">Let's specify the <code class="literal">rate</code> value, that is, the average number of events per second:<div class="informalexample"><pre class="programlisting">In [2]: rate = 20.  # average number of events per second</pre></div></li><li class="listitem">First, we will simulate the process using small time bins of 1 millisecond:<div class="informalexample"><pre class="programlisting">In [3]: dt = .001  # time step
        n = int(1./dt)  # number of time steps</pre></div></li><li class="listitem">On every time bin, the probability that an event occurs is about <span class="emphasis"><em>rate * dt</em></span> if <span class="emphasis"><em>dt</em></span> is small enough. Besides, as the Poisson process has no memory, the occurrence of an event is independent from one bin to another. Therefore, we can sample Bernoulli random variables (either 1 or 0, respectively representing an experiment's success or failure) in a vectorized way in order to simulate our process:<div class="informalexample"><pre class="programlisting">In [4]: x = np.zeros(n)
        x[np.random.rand(n) &lt;= rate*dt] = 1</pre></div><p>The <code class="literal">x</code> vector contains zeros and ones on all time bins, <code class="literal">1</code> corresponding to the occurrence of an event:</p><div class="informalexample"><pre class="programlisting">In [5]: x[:5]
Out[5]: array([ 0.,  1.,  0.,  0.,  0. ])</pre></div></li><li class="listitem">Let's display the simulated process. We draw a vertical line for each event:<div class="informalexample"><pre class="programlisting">In [6]: plt.vlines(np.nonzero(x)[0], 0, 1)
        plt.xticks([]); plt.yticks([])</pre></div><div class="mediaobject"><img src="images/4818OS_13_04.jpg" alt="How to do it..."/></div></li><li class="listitem">Another way of <a id="id1873" class="indexterm"/>representing that same object is by considering the associated <a id="id1874" class="indexterm"/><span class="strong"><strong>counting process</strong></span> <span class="emphasis"><em>N(t)</em></span>,which is the number of events that have occurred until time <span class="emphasis"><em>t</em></span>. Here, we can display this process using the <code class="literal">cumsum()</code> function:<div class="informalexample"><pre class="programlisting">In [7]: plt.plot(np.linspace(0., 1., n), np.cumsum(x))
        plt.xlabel("Time")
        plt.ylabel("Counting process")</pre></div><div class="mediaobject"><img src="images/4818OS_13_05.jpg" alt="How to do it..."/></div></li><li class="listitem">The other (and more efficient) way of simulating the homogeneous Poisson process is to use the property that the time intervals between two successive events follow an exponential distribution. Furthermore, these intervals are independent. Thus, we can sample them in a vectorized way. Finally, we get our process by cumulatively summing all of these intervals:<div class="informalexample"><pre class="programlisting">In [8]: y = np.cumsum(np.random.exponential(
                             1./rate, size=int(rate)))</pre></div><p>The <code class="literal">y</code> vector contains another realization of our Poisson process, but the data structure is different. Every component of the vector is an event time:</p><div class="informalexample"><pre class="programlisting">In [9]: y[:5]
Out[9]: array([ 0.006,  0.111,  0.244,  0.367,  0.365])</pre></div></li><li class="listitem">Finally, let's display the simulated process:<div class="informalexample"><pre class="programlisting">In [10]: plt.vlines(y, 0, 1)
         plt.xticks([]); plt.yticks([])</pre></div><div class="mediaobject"><img src="images/4818OS_13_06.jpg" alt="How to do it..."/></div></li></ol></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec404"/>How it works...</h2></div></div></div><p>For a Poisson <a id="id1875" class="indexterm"/>process with rate <span class="inlinemediaobject"><img src="images/4818OS_13_25.jpg" alt="How it works..."/></span>, the number of events in a time window of length <span class="inlinemediaobject"><img src="images/4818_13_15.jpg" alt="How it works..."/></span> follows a Poisson distribution:</p><div class="mediaobject"><img src="images/4818_13_07.jpg" alt="How it works..."/></div><p>When <span class="inlinemediaobject"><img src="images/4818_13_16.jpg" alt="How it works..."/></span> is small, we can show that, at first order, this probability is about <span class="inlinemediaobject"><img src="images/4818_13_17.jpg" alt="How it works..."/></span>.</p><p>Also, the <span class="strong"><strong>holding times</strong></span><a id="id1876" class="indexterm"/> (delays between two consecutive events) are independent and follow an exponential distribution. The Poisson process satisfies other useful properties, such as the independent and stationary increments. This property justifies the first simulation method used in this recipe.</p></div><div class="section" title="There's more..."><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec405"/>There's more...</h2></div></div></div><p>In this recipe, we only considered homogeneous time-dependent Poisson processes. Other types of Poisson processes include inhomogeneous (or non-homogeneous) processes that are characterized by a time-varying rate, and multidimensional spatial Poisson processes.</p><p>Here are further references:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The Poisson process<a id="id1877" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Poisson_process">http://en.wikipedia.org/wiki/Poisson_process</a></li><li class="listitem" style="list-style-type: disc">Point processes on <a id="id1878" class="indexterm"/>Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Point_process">http://en.wikipedia.org/wiki/Point_process</a></li><li class="listitem" style="list-style-type: disc">Continuous-time processes<a id="id1879" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Continuous-time_process">http://en.wikipedia.org/wiki/Continuous-time_process</a></li><li class="listitem" style="list-style-type: disc">Renewal theory<a id="id1880" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Renewal_theory">http://en.wikipedia.org/wiki/Renewal_theory</a></li><li class="listitem" style="list-style-type: disc">Spatial Poisson processes <a id="id1881" class="indexterm"/>on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/">http://en.wikipedia.org/wiki/</a> <a class="ulink" href="http://Spatial_Poisson_process">Spatial_Poisson_process</a></li></ul></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec406"/>See also</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <span class="emphasis"><em>Simulating a discrete-time Markov chain</em></span> recipe</li></ul></div></div></div></div>


  <div id="sbo-rt-content"><div class="section" title="Simulating a Brownian motion"><div class="titlepage"><div><div><h1 class="title"><a id="ch13lvl1sec108"/>Simulating a Brownian motion</h1></div></div></div><p>The <span class="strong"><strong>Brownian motion</strong></span><a id="id1882" class="indexterm"/> (or <span class="strong"><strong>Wiener process</strong></span>) is a fundamental object in mathematics, physics, and many other scientific and engineering disciplines. This model describes the movement of a particle suspended in a fluid resulting from random collisions with the quick molecules in the fluid (diffusion). More generally, the Brownian motion models a continuous-time<a id="id1883" class="indexterm"/> <span class="strong"><strong>random walk</strong></span>, where a particle evolves in space by making independent random steps in all directions.</p><p>Mathematically, the Brownian motion is a particular Markov continuous stochastic process. The Brownian motion is at the core of mathematical domains such as stochastic calculus and the theory of stochastic processes, but it is also central in applied fields such as quantitative finance, ecology, and neuroscience.</p><p>In this recipe, we will show how to<a id="id1884" class="indexterm"/> simulate and plot a Brownian motion in two dimensions.</p><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec407"/>How to do it...</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Let's import NumPy and matplotlib:<div class="informalexample"><pre class="programlisting">In [1]: import numpy as np
        import matplotlib.pyplot as plt
        %matplotlib inline</pre></div></li><li class="listitem">We simulate Brownian motions with 5000 time steps:<div class="informalexample"><pre class="programlisting">In [2]: n = 5000</pre></div></li><li class="listitem">We simulate two independent one-dimensional Brownian processes to form a single two-dimensional Brownian process. The (discrete) Brownian motion makes independent Gaussian jumps at each time step. Therefore, we merely have to compute the cumulative sum of independent normal random variables (one for each time step):<div class="informalexample"><pre class="programlisting">In [3]: x = np.cumsum(np.random.randn(n))
        y = np.cumsum(np.random.randn(n))</pre></div></li><li class="listitem">Now, to display the <a id="id1885" class="indexterm"/>Brownian motion, we could just use <code class="literal">plot(x, y)</code>. However, the result would be monochromatic and a bit boring. We would like to use a gradient of color to illustrate the progression of the motion in time (the hue is a function of time). matplotlib forces us to use a small hack based on <code class="literal">scatter()</code>. This function allows us<a id="id1886" class="indexterm"/> to assign a different color to each point at the expense of dropping out line segments between points. To work around this issue, we linearly interpolate the process to give the illusion of a continuous line:<div class="informalexample"><pre class="programlisting">In [4]: k = 10  # We add 10 intermediary points between two 
                # successive points.
        # We interpolate x and y.
        x2 = np.interp(np.arange(n*k), np.arange(n)*k, x)
        y2 = np.interp(np.arange(n*k), np.arange(n)*k, y)
In [5]: # Now, we draw our points with a gradient of 
        # colors.
        plt.scatter(x2, y2, c=range(n*k), linewidths=0,
                    marker='o', s=3, cmap=plt.cm.jet)
        plt.axis('equal')
        plt.xticks([]); plt.yticks([])</pre></div><div class="mediaobject"><img src="images/4818OS_13_08.jpg" alt="How to do it..."/></div></li></ol></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec408"/>How it works...</h2></div></div></div><p>The Brownian motion <span class="emphasis"><em>W(t)</em></span> has <a id="id1887" class="indexterm"/>several important properties. First, it gives rise (almost surely) to continuous trajectories. Second, its increments <span class="inlinemediaobject"><img src="images/4818_13_18.jpg" alt="How it works..."/></span> are independent on non-overlapping intervals. Third, these increments are Gaussian random variables. More precisely:</p><div class="mediaobject"><img src="images/4818_13_09.jpg" alt="How it works..."/></div><p>In particular, the density of <span class="emphasis"><em>W(t)</em></span> is a normal distribution with variance <span class="emphasis"><em>t</em></span>.</p><p>Additionally, the Brownian motion, and stochastic processes in general, have deep connections with partial differential equations. Here, the density of <span class="emphasis"><em>W(t)</em></span> is a solution of the<a id="id1888" class="indexterm"/> <span class="strong"><strong>heat equation</strong></span>, a particular diffusion equation. More generally, the <span class="strong"><strong>Fokker-Planck equation</strong></span><a id="id1889" class="indexterm"/> is a partial differential equation satisfied by the density of solutions of a stochastic differential equation.</p></div><div class="section" title="There's more..."><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec409"/>There's more...</h2></div></div></div><p>The Brownian motion is a limit of a random walk with an infinitesimal step size. We used this property here to simulate the process.</p><p>Here are a few references:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The Brownian motion<a id="id1890" class="indexterm"/> (physical phenomenon) described at <a class="ulink" href="http://en.wikipedia.org/wiki/Brownian_motion">http://en.wikipedia.org/wiki/Brownian_motion</a></li><li class="listitem" style="list-style-type: disc">The Wiener process<a id="id1891" class="indexterm"/> (mathematical object) explained at <a class="ulink" href="http://en.wikipedia.org/wiki/Wiener_process">http://en.wikipedia.org/wiki/Wiener_process</a></li><li class="listitem" style="list-style-type: disc">The Brownian motion is a particular type of the Lévy process; refer to <a class="ulink" href="http://en.wikipedia.org/wiki/L%C3%A9vy_process">http://en.wikipedia.org/wiki/L%C3%A9vy_process</a></li><li class="listitem" style="list-style-type: disc">The Fokker-Planck equation<a id="id1892" class="indexterm"/> links stochastic processes to partial differential equations; refer to <a class="ulink" href="http://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation">http://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation</a></li></ul></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec410"/>See also</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <span class="emphasis"><em>Simulating a stochastic differential equation</em></span> recipe</li></ul></div></div></div></div>


  <div id="sbo-rt-content"><div class="section" title="Simulating a stochastic differential equation"><div class="titlepage"><div><div><h1 class="title"><a id="ch13lvl1sec109"/>Simulating a stochastic differential equation</h1></div></div></div><p>
<span class="strong"><strong>Stochastic differential equations</strong></span> (<span class="strong"><strong>SDEs</strong></span>)<a id="id1893" class="indexterm"/> model dynamical systems that are subject to noise. They are widely used in physics, biology, finance, and other disciplines.</p><p>In this recipe, we simulate an <a id="id1894" class="indexterm"/><span class="strong"><strong>Ornstein-Uhlenbeck process</strong></span>, which is a solution of the <a id="id1895" class="indexterm"/><span class="strong"><strong>Langevin equation</strong></span>. This model describes the stochastic evolution of a particle in a fluid under the influence of friction. The particle's movement is due to collisions with the molecules of the fluid (diffusion). The difference with the Brownian motion is the presence of friction.</p><p>The Ornstein-Uhlenbeck process is stationary, Gaussian, and Markov, which makes it a good candidate to represent stationary random noise.</p><p>We will simulate this process with a numerical method called the <a id="id1896" class="indexterm"/><span class="strong"><strong>Euler-Maruyama method</strong></span>. It is a simple generalization to SDEs of the Euler method for ODEs.</p><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec411"/>How to do it...</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Let's import <a id="id1897" class="indexterm"/>NumPy and matplotlib:<div class="informalexample"><pre class="programlisting">In [1]: import numpy as np
        import matplotlib.pyplot as plt
        %matplotlib inline</pre></div></li><li class="listitem">We define a few parameters for our model:<div class="informalexample"><pre class="programlisting">In [2]: sigma = 1.  # Standard deviation.
        mu = 10.0  # Mean.
        tau = 0.05  # Time constant.</pre></div></li><li class="listitem">Let's define a few simulation parameters:<div class="informalexample"><pre class="programlisting">In [3]: dt = 0.001  # Time step.
        T = 1.0  # Total time.
        n = int(T/dt)  # Number of time steps.
        t = np.linspace(0., T, n)  # Vector of times.</pre></div></li><li class="listitem">We also define renormalized variables (to avoid recomputing these constants at every time step):<div class="informalexample"><pre class="programlisting">In [4]: sigma_bis = sigma * np.sqrt(2. / tau)
        sqrtdt = np.sqrt(dt)</pre></div></li><li class="listitem">We create a vector that will contain all successive values of our process during the simulation:<div class="informalexample"><pre class="programlisting">In [5]: x = np.zeros(n)</pre></div></li><li class="listitem">Now, let's simulate the process with the Euler-Maruyama method. It is really like the standard Euler method for ODEs, but with an extra stochastic term (which is just a scaled normal random variable). We will give the equation of the process along with the details of this method in the <span class="emphasis"><em>How it works...</em></span> section:<div class="informalexample"><pre class="programlisting">In [6]: for i in range(n-1):
            x[i+1] = x[i] + dt*(-(x[i]-mu)/tau) + \
                     sigma_bis * sqrtdt * np.random.randn()</pre></div></li><li class="listitem">Let's display the evolution of the process:<div class="informalexample"><pre class="programlisting">In [7]: plt.plot(t, x)</pre></div><div class="mediaobject"><img src="images/4818OS_13_10.jpg" alt="How to do it..."/></div></li><li class="listitem">Now, we are <a id="id1898" class="indexterm"/>going to take a look at the time evolution of the distribution of the process. To do this, we will simulate many independent realizations of the same process in a vectorized way. We define a vector <code class="literal">X</code> that will contain all realizations of the process at a given time (that is, we do not keep all realizations at all times in memory). This vector will be overwritten at every time step. We will show the estimated distribution (histograms) at several points in time:<div class="informalexample"><pre class="programlisting">In [8]: ntrials = 10000
        X = np.zeros(ntrials)
In [9]: # We create bins for the histograms.
        bins = np.linspace(-2., 14., 50);
        for i in range(n):
            # We update the process independently for all
            # trials.
            X += dt*(-(X-mu)/tau) + \
                 sigma_bis*sqrtdt*np.random.randn(ntrials)
            # We display the histogram for a few points in
            # time.
            if i in (5, 50, 900):
                hist, _ = np.histogram(X, bins=bins)
                plt.plot((bins[1:]+bins[:-1])/2,  hist,
                         label="t={0:.2f}".format(i*dt))
            plt.legend()</pre></div><div class="mediaobject"><img src="images/4818OS_13_11.jpg" alt="How to do it..."/></div><p>The <a id="id1899" class="indexterm"/>distribution of the process tends to a Gaussian distribution with mean <span class="inlinemediaobject"><img src="images/4818_13_19.jpg" alt="How to do it..."/></span> and standard deviation <span class="inlinemediaobject"><img src="images/4818_13_20.jpg" alt="How to do it..."/></span>. The process would be stationary if the initial distribution was also a Gaussian with the adequate parameters.</p></li></ol></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec412"/>How it works...</h2></div></div></div><p>The Langevin equation that we use in this recipe is the following stochastic differential equation:</p><div class="mediaobject"><img src="images/4818_13_12.jpg" alt="How it works..."/></div><p>Here, <span class="emphasis"><em>x(t)</em></span> is our stochastic process, <span class="emphasis"><em>dx</em></span> is the infinitesimal increment, <span class="inlinemediaobject"><img src="images/4818_13_21.jpg" alt="How it works..."/></span> is the mean, <span class="inlinemediaobject"><img src="images/4818_13_22.jpg" alt="How it works..."/></span> is the standard deviation, and <span class="inlinemediaobject"><img src="images/4818_13_15.jpg" alt="How it works..."/></span> is the time constant. Also, <span class="emphasis"><em>W</em></span> is a Brownian motion (or the Wiener process) that underlies our SDE.</p><p>The first term on the right-hand side is the deterministic term (in <span class="emphasis"><em>dt</em></span>), while the second term is the stochastic term. Without that last term, the equation would be a regular deterministic ODE.</p><p>The infinitesimal step of a Brownian motion is a Gaussian random variable. Specifically, the derivative (in a certain sense) of a Brownian motion is a <a id="id1900" class="indexterm"/><span class="strong"><strong>white noise</strong></span>, a sequence of independent Gaussian random variables.</p><p>The Euler-Maruyama method<a id="id1901" class="indexterm"/> involves discretizing time and adding infinitesimal steps to the process at every time step. This method involves a deterministic term (like in the standard Euler method for ODEs) and a stochastic term (random Gaussian variable). Specifically, for an equation:</p><div class="mediaobject"><img src="images/4818_13_13.jpg" alt="How it works..."/></div><p>The numerical scheme is (with <span class="emphasis"><em>t=n * dt</em></span>):</p><div class="mediaobject"><img src="images/4818_13_14.jpg" alt="How it works..."/></div><p>Here, <span class="inlinemediaobject"><img src="images/4818_13_23.jpg" alt="How it works..."/></span> is a random Gaussian variable with variance <span class="emphasis"><em>1</em></span> (independent at each time step). The normalization factor <span class="inlinemediaobject"><img src="images/4818_13_24.jpg" alt="How it works..."/></span> comes from the fact that the infinitesimal step for a Brownian motion has the standard deviation <span class="inlinemediaobject"><img src="images/4818_13_24.jpg" alt="How it works..."/></span>.</p></div><div class="section" title="There's more..."><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec413"/>There's more...</h2></div></div></div><p>The mathematics of SDEs comprises the theory of stochastic calculus, Itō calculus, martingales, and other topics. Although these theories are quite involved, simulating stochastic processes numerically can be relatively straightforward, as we have seen in this recipe.</p><p>The error of the Euler-Maruyama method is of order <span class="inlinemediaobject"><img src="images/4818_13_24.jpg" alt="There's more..."/></span>. The Milstein method is a more precise numerical scheme, of order <span class="emphasis"><em>dt</em></span>.</p><p>Here are a few references on these topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Stochastic differential equations<a id="id1902" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Stochastic_differential_equation">http://en.wikipedia.org/wiki/Stochastic_differential_equation</a></li><li class="listitem" style="list-style-type: disc"><a id="id1903" class="indexterm"/>White noise, described at <a class="ulink" href="http://en.wikipedia.org/wiki/White_noise">http://en.wikipedia.org/wiki/White_noise</a></li><li class="listitem" style="list-style-type: disc">The Langevin equation<a id="id1904" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Langevin_equation">http://en.wikipedia.org/wiki/Langevin_equation</a></li><li class="listitem" style="list-style-type: disc">The Ornstein-Uhlenbeck process<a id="id1905" class="indexterm"/> described at <a class="ulink" href="http://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process">http://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process</a></li><li class="listitem" style="list-style-type: disc">Diffusion processes<a id="id1906" class="indexterm"/> described at <a class="ulink" href="http://en.wikipedia.org/wiki/Diffusion_process">http://en.wikipedia.org/wiki/Diffusion_process</a></li><li class="listitem" style="list-style-type: disc">Itō calculus, <a id="id1907" class="indexterm"/>described at <a class="ulink" href="http://en.wikipedia.org/wiki/It%C5%8D_calculus">http://en.wikipedia.org/wiki/It%C5%8D_calculus</a></li><li class="listitem" style="list-style-type: disc">The Euler-Maruyama method,<a id="id1908" class="indexterm"/> explained at <a class="ulink" href="http://en.wikipedia.org/wiki/Euler%E2%80%93Maruyama_method">http://en.wikipedia.org/wiki/Euler%E2%80%93Maruyama_method</a></li><li class="listitem" style="list-style-type: disc">The Milstein method<a id="id1909" class="indexterm"/> on Wikipedia, available at <a class="ulink" href="http://en.wikipedia.org/wiki/Milstein_method">http://en.wikipedia.org/wiki/Milstein_method</a></li></ul></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch13lvl2sec414"/>See also</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <span class="emphasis"><em>Simulating a Brownian motion</em></span> recipe</li></ul></div></div></div></div>
</body></html>