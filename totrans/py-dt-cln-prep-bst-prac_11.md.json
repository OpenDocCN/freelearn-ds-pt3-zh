["```py\npip install pandas\npip install numpy\npip install matplotlib\npip install statsmodels\n```", "```py\n    date_rng = pd.date_range(start='2010-01-01', end='2020-12-31', freq='M')\n    sales_data = pd.Series(range(1, len(date_rng) + 1), index=date_rng)\n    ```", "```py\n    plt.figure(figsize=(10, 5))\n    plt.plot(sales_data, label='Sales Data')\n    plt.title('Time Series Data with Trend')\n    plt.xlabel('Time')\n    plt.ylabel('Sales')\n    plt.legend()\n    plt.show()\n    ```", "```py\n    date_rng = pd.date_range(start='2010-01-01', end='2020-12-31', freq='M')\n    seasonal_data = pd.Series([10, 12, 15, 22, 30, 35, 40, 38, 30, 22, 15, 12] * 11, index=date_rng)\n    ```", "```py\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    ```", "```py\n    date_rng = pd.date_range(start='2010-01-01', end='2020-12-31', freq='M')\n    ```", "```py\n    np.random.seed(42)\n    noise_data = pd.Series(np.random.normal(0, 2, len(date_rng)), index=date_rng)\n    ```", "```py\n    date_rng = pd.date_range(start='2010-01-01', end='2020-12-31', freq='M')\n    ```", "```py\n    temperature_data = pd.Series(np.random.normal(20, 5, len(date_rng)), index=date_rng)\n    ```", "```py\n    plt.figure(figsize=(10, 5))\n    plt.plot(temperature_data, label='Temperature Data')\n    plt.title('Univariate Time Series Data')\n    plt.xlabel('Time')\n    plt.ylabel('Temperature (°C)')\n    plt.legend()\n    plt.show()\n    ```", "```py\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    import numpy as np\n    ```", "```py\n    date_rng = pd.date_range(start='2010-01-01', end='2020-12-31', freq='M')\n    temperature_data = pd.Series(np.random.normal(20, 5, len(date_rng)), index=date_rng)\n    rainfall_data = pd.Series(np.random.normal(50, 20, len(date_rng)), index=date_rng)\n    ```", "```py\n    multivariate_data = pd.DataFrame({'Temperature': temperature_data, 'Rainfall': rainfall_data})\n    print(multivariate_data.head())\n    ```", "```py\n                Temperature   Rainfall\n    2010-01-31    19.132623  56.621393\n    2010-02-28    18.551274  51.249927\n    2010-03-31    24.502358  65.679049\n    2010-04-30    27.069077  73.044307\n    2010-05-31    21.176376  41.317497\n    ```", "```py\n    date_range = pd.date_range(start='2020-01-01', end='2023-12-31', freq='B')  # Business days\n    ```", "```py\n    n = len(date_range)\n    data = {\n        'open': np.random.uniform(100, 200, n),\n        'high': np.random.uniform(200, 300, n),\n        'low': np.random.uniform(50, 100, n),\n        'close': np.random.uniform(100, 200, n)\n    }\n    ```", "```py\n    df = pd.DataFrame(data, index=date_range)\n    ```", "```py\n    nan_indices = np.random.choice(n, size=100, replace=False)\n    df.iloc[nan_indices] = np.nan\n    ```", "```py\n    missing_dates = np.random.choice(date_range, size=50, replace=False)\n    ```", "```py\n                      open        high        low       close\n    2020-01-01  137.454012  262.589138  55.273685  183.849183\n    2020-01-02  195.071431  288.597775  82.839005  180.509032\n    2020-01-03  173.199394  261.586319  91.105158  182.298381\n    2020-01-06  159.865848  223.295947  69.021000  193.271051\n    2020-01-07         NaN         NaN        NaN         NaN\n    ```", "```py\n    complete_index = pd.date_range(start=df.index.min(), end=df.index.max(), freq='B')\n    ```", "```py\n    df_reindexed = df.reindex(complete_index)\n    ```", "```py\n    missing_timestamps = df_reindexed[df_reindexed.isnull().any(axis=1)]\n    ```", "```py\nprint(f\"\\nPercentage of Missing Timestamps: {missing_timestamps_percentage:.2f}%\")\nPercentage of Missing Timestamps: 14.09%\n```", "```py\n    plt.figure(figsize=(14, 7))\n    plt.plot(df.index, df['close'], linestyle='-', label='Closing Price', color='blue')\n    ```", "```py\n    for date in missing_dates:\n        plt.axvline(x=date, color='red', linestyle='--', linewidth=1)\n    plt.title('Daily Closing Prices with Missing Timestamps and NaN Values Highlighted')\n    plt.xlabel('Date')\n    plt.ylabel('Closing Price')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n    ```", "```py\n    nan_indices_close = np.random.choice(df.index, size=50, replace=False)\n    nan_indices_open = np.random.choice(df.index, size=50, replace=False)\n    ```", "```py\n    df.loc[nan_indices_close, 'close'] = np.nan\n    df.loc[nan_indices_open, 'open'] = np.nan\n    ```", "```py\n    missing_values = df.isnull().sum()\n    Percentage of Missing Values in Each Column:\n    open     4.793864\n    high     0.000000\n    low      0.000000\n    close    4.793864\n    ```", "```py\n    print(f\"\\nNumber of rows before dropping NaN values: {len(df)}\")\n    Number of rows before dropping NaN values: 1043\n    ```", "```py\n    df_cleaned = df.dropna()\n    print(f\"\\nNumber of rows after dropping NaN values: {len(df_cleaned)}\")\n    ----\n    Number of rows after dropping NaN values: 945\n    ```", "```py\n    nan_indices_close = np.random.choice(df.index, size=50, replace=False)\n    nan_indices_open = np.random.choice(df.index, size=50, replace=False)\n    ```", "```py\n    df.loc[nan_indices_close, 'close'] = np.nan\n    df.loc[nan_indices_open, 'open'] = np.nan\n    ```", "```py\n    df['close_ffill'] = df['close'].ffill() # Forward Fill\n    df['close_bfill'] = df['close'].bfill() # Backward Fill\n    ```", "```py\n    print(df[['open', 'close', 'close_ffill', 'close_bfill']].head(20)) # Show first 20 rows\n    ```", "```py\n                      open       close  close_ffill  close_bfill\n    2020-01-01  137.454012  183.849183   183.849183   183.849183\n    2020-01-02  195.071431  180.509032   180.509032   180.509032\n    2020-01-03  173.199394  182.298381   182.298381   182.298381\n    2020-01-06  159.865848  193.271051   193.271051   193.271051\n    2020-01-07  115.601864         NaN   193.271051   120.028202\n    2020-01-08  115.599452  120.028202   120.028202   120.028202\n    2020-01-09  105.808361  161.678361   161.678361   161.678361\n    2020-01-10  186.617615  174.288149   174.288149   174.288149\n    2020-01-13  160.111501  173.791739   173.791739   173.791739\n    2020-01-14  170.807258  152.144902   152.144902   152.144902\n    2020-01-15  102.058449         NaN   152.144902   137.111294\n    2020-01-16  196.990985  137.111294   137.111294   137.111294\n    ```", "```py\n    nan_indices_close = np.random.choice(df.index, size=50, replace=False)\n    nan_indices_open = np.random.choice(df.index, size=50, replace=False)\n    df.loc[nan_indices_close, 'close'] = np.nan\n    df.loc[nan_indices_open, 'open'] = np.nan\n    ```", "```py\n    df['close_linear'] = df['close'].interpolate(method='linear')\n    ```", "```py\n    df['close_poly'] = df['close'].interpolate(method='polynomial', order=3)\n    ```", "```py\n    df['close_spline'] = df['close'].interpolate(method='spline', order=3)\n    ```", "```py\n    plot_acf(df['close'].dropna(), lags=40, ax=plt.gca())\n    ```", "```py\n    plot_pacf(df['close'].dropna(), lags=40, ax=plt.gca())\n    ```", "```py\nresult = seasonal_decompose(df['close'], model='additive', period=252)\n```", "```py\ndf['resid_z'] = zscore(df['residual'].dropna())\n```", "```py\n    model = ARIMA(df['close_filled'], order=(2,1,1))\n    results = model.fit()\n    ```", "```py\n    df['residuals'] = results.resid\n    df['residuals_z'] = zscore(df['residuals'].dropna())\n    ```", "```py\n    outliers_arima = df[np.abs(df['residuals_z']) > 3]\n    ```", "```py\n    df['arima_smooth'] = results.fittedvalues\n    ```", "```py\n    results.plot_diagnostics(figsize=(14,8))\n    ```", "```py\n    window_size = 20\n    span = 20\n    ```", "```py\n    df['SMA'] = df['close'].rolling(window=window_size, min_periods=1).mean()\n    ```", "```py\n    df['EMA'] = df['close'].ewm(span=span, adjust=False).mean()\n    ```", "```py\n    df['SMA_residuals'] = df['close'] - df['SMA'] df['EMA_residuals'] = df['close'] - df['EMA'] sma_window = 12\n    data['SMA'] = data['Passengers'].rolling(window=sma_window).mean()\n    ```", "```py\n    outlier_indices = np.random.choice(df.index, size=10, replace=False)\n    df.loc[outlier_indices[:5], 'close'] = df['close'] * 1.5 # Increase by 50%\n    df.loc[outlier_indices[5:], 'close'] = df['close'] * 0.5 # Decrease by 50%\n    ```", "```py\n    def create_lagged_features(df, column, lags):\n        for lag in lags:\n            df[f'{column}_lag_{lag}'] =df[column].shift(lag)\n        return df # Define the lags to create lags = [1, 5, 10, 20]\n    ```", "```py\n    df = create_lagged_features(df, 'close', lags)\n    ```", "```py\n    seasonal_component = 50 * np.sin(2 * np.pi * np.arange(n) / 5) # 5-day seasonality\n    ```", "```py\n    data = {\n    'open': np.random.uniform(100, 200, n) + seasonal_component,\n    'high': np.random.uniform(200, 300, n) + seasonal_component,\n    'low': np.random.uniform(50, 100, n) + seasonal_component,\n    'close': np.random.uniform(100, 200, n) + seasonal_component\n    }\n    df = pd.DataFrame(data, index=date_range)\n    ```", "```py\n    df['First Difference'] = df['close'].diff()\n    ```", "```py\n    df['Second Difference'] = df['First Difference'].diff()\n    ```", "```py\n    df['Seasonal Difference'] = df['close'].diff(5)\n    ```", "```py\ndef adf_test(series, title=''):\n    result = adfuller(series.dropna(), autolag='AIC')\n    print(f'Augmented Dickey-Fuller Test: {title}')\n    print(f'ADF Statistic: {result[0]}')\n    print(f'p-value: {result[1]}')\n    for key, value in result[4].items():\n        print(f' {key}: {value}')\n    print('\\n')\n```", "```py\nAugmented Dickey-Fuller Test: Original Series\nADF Statistic: -3.5898552445987595\np-value: 0.005957961883734467\n   1%: -3.4367333690404767\n   5%: -2.8643583648001925\n   10%: -2.568270618452702\n```", "```py\nAugmented Dickey-Fuller Test: First Difference\nADF Statistic: -11.786384523171499\np-value: 1.0064914317100746e-21\n   1%: -3.4367709764382024\n   5%: -2.8643749513463637\n   10%: -2.568279452717228\n```", "```py\nAugmented Dickey-Fuller Test: Second Difference\nADF Statistic: -14.95687341689794\np-value: 1.2562905072914351e-27\n   1%: -3.4367899468008916\n   5%: -2.8643833180472744\n   10%: -2.5682839089705536\n```", "```py\nAugmented Dickey-Fuller Test: Seasonal Differencing\nADF Statistic: -11.48334880444129\np-value: 4.933051350797084e-21\n   1%: -3.4367899468008916\n   5%: -2.8643833180472744\n   10%: -2.5682839089705536\n```"]