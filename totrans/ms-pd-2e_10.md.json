["```py\n### Importing required libraries\nimport datetime\nimport pandas as pd\nfrom random import randint\n\n### Creating date sequence of 300 (periods=300) consecutive days (freq='D') starting from 2016-01-15\nD1=pd.date_range('2016-01-15',periods=300,freq='D')\n\n### Creating a date sequence with of 300 days with day (b/w 1-30), month (b/w 1-12) and year (b/w 2010-2025) chosen at random\ndate_str=[]\nfor i in range(300):\n   date_str1=str(randint(2010,2025))+'-'+str(randint(1,30))+'-            '+str(randint(3,12))\n    date_str.append(date_str1)\nD2=date_str\n\n### Creating a dataframe with two date sequences and call them as Start Date and End Date\nDate_frame=pd.DataFrame({'Start Date':D1,'End Date':D2})\nDate_frame['End Date'] = pd.to_datetime(Date_frame['End Date'], format='%Y-%d-%m')\n```", "```py\nf1=lambda x:x-datetime.datetime.today()\nf2=lambda x,y:x-y\nf3=lambda x:pd.to_datetime('2017-28-01', format='%Y-%d-%m')>x\n```", "```py\nDate_frame['diff1']=Date_frame['End Date'].apply(f1)\nDate_frame['diff2']=f2(Date_frame['Start Date'],Date_frame['End Date'])\nDate_frame['Before 28-07-17']=Date_frame['End Date'].apply(f3)\n```", "```py\nDate_frame['diff3']=Date_frame['End Date'].map(f1)\n```", "```py\nsku_sales.apply(sum,axis=0) # axis=0 represents summing across rows\n```", "```py\nsku_sales.apply(sum,axis=1) # axis=1 represents summing across columns\n```", "```py\nsku_sales[['SKU1','SKU2']].map(mean)\n```", "```py\nsku_sales.applymap(mean)\nsku_sales.applymap(sd)\n```", "```py\npandas.options.mode.use_inf_as_na = True\n```", "```py\nimport math\ntest = math.inf\ntest>pow(10,10) #Comparing whether Inf is larger than 10 to the power 10\n```", "```py\npd.isnull(data['body']) *#*returns TRUE if a cell has missing values\npd.notnull(data['body']) *#*returns TRUE if a cell doesn't have missing values\n```", "```py\npd.isnull(data['body']).values.ravel().sum() #returns the total number of missing values\npd.nottnull(data['body']).values.ravel().sum()#returns the total number of non-missing values\n```", "```py\ndata.dropna(axis=0,how='all')# axis=0 means along rows\n```", "```py\ndata.dropna(axis=0,how='any')\n```", "```py\ndata.fillna(0)\n```", "```py\ndata.fillna('text')\n```", "```py\ndata['body'].fillna(0)\n```", "```py\ndata['age'].fillna(data['age'].mean())\n```", "```py\ndata['age'].fillna(method='ffill')\n```", "```py\ndata['age'].fillna(method='backfill')\n```", "```py\nimport numpy as np\nimport pandas as pd\nA=[1,3,np.nan,np.nan,11,np.nan,91,np.nan,52]\npd.Series(A).interpolate()\n```", "```py\npd.Series(A).interpolate(method='spline',order=2)\n```", "```py\npd.Series(A).interpolate(method='polynomial',order=2)\n```", "```py\n#Needed for generating plot inside Jupyter notebook\n%matplotlib inline\n#Setting seed for regenerating the same random number\nnp.random.seed(10)\n#Generate Data\nA=pd.Series(np.arange(1,100,0.5)**3+np.random.normal(5,7,len(np.arange(1,100,0.5))))\n#Sample random places to introduce missing values\nnp.random.seed(5)\nNA=set([np.random.randint(1,100) for i in range(25)])\n#Introduce missing values\nA[NA]=np.nan\n#Define the list of interpolation methods\nmethods=['linear','quadratic','cubic']\n#Apply the interpolation methods and create a DataFrame \ndf = pd.DataFrame({m: A.interpolate(method=m) for m in methods})\n#Find the mean of each column (each interpolation method)\ndf.apply(np.mean,axis=0)\n```", "```py\nnp.random.seed(5)\nNA1=[np.random.randint(1,100) for i in range(25)]\ndf.iloc[NA1,:]\n```", "```py\n#Creating training dataset\nA=np.random.randint(2,size=100)\nB=np.random.normal(7,3,100)\nC=np.random.normal(11,4,100)\nX=(np.vstack((A,B,C))).T\n\n#Creating testing data by replacing column A (outcome variable) with NaNs\nX_with_nan = np.copy(X)\nX_with_nan[:,0]=np.nan\n\n# Load libraries\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Train KNN learner\nclf = KNeighborsClassifier(3, weights='uniform')\ntrained_model = clf.fit(X[:,1:], X[:,0])\n\n#Predicting/Imputing on test dataset\nimputed_values = trained_model.predict(X_with_nan[:,1:])\nimputed_values\n```", "```py\nsample_df = pd.DataFrame([[\"Pulp Fiction\", 62, 46], [\"Forrest Gump\", 38, 46], [\"Matrix\", 26, 39], [\"It's a Wonderful Life\", 6, 0], [\"Casablanca\", 5, 6]], columns = [\"Movie\", \"Wins\", \"Nominations\"])\nsample_df\n```", "```py\nfor item in sample_df[\"Wins\"].items():\nprint(item)\n```", "```py\nfor item in sample_df[\"Wins\"].iteritems():\nprint(item)\n```", "```py\nfor col in sample_df.items():\nprint(col)\n```", "```py\nIn: sample_df[\"Wins\"].keys()\nOut: RangeIndex(start=0, stop=5, step=1)\n\nIn: sample_df.keys()\nOut: Index(['Movie', 'Wins', 'Nominations'], dtype='object')\n```", "```py\nIn: sample_df[\"Wins\"].pop(2)\nOut: 26\n```", "```py\nsample_df.pop(\"Nominations\")\n```", "```py\nsample_df\n```", "```py\nsample_df[\"Wins\"].apply(np.exp)\n```", "```py\ndef div_by_100(x):\nreturn x/100\n\nsample_df[\"Nominations\"].apply(div_by_100)\n```", "```py\nsample_df[\"Wins\"].map({62 : 60, 38 : 20})\n```", "```py\nsample_df[\"Wins\"].drop([0, 2])\n```", "```py\nsample_df.drop(labels=[\"Wins\", \"Nominations\"], axis = 1)\n```", "```py\nmultidf.drop([\"Matrix\"], level = 1 )\n```", "```py\nIn: compare_series = pd.Series([62, 38, 26, 6, 5])\nIn: sample_df[\"Wins\"].equals(compare_series)\nOut: True\n```", "```py\nsample_df[\"Movie\"].sample(3)\\\n```", "```py\nsample_df.sample(frac = 0.5, axis = 1)\n```", "```py\nIn: sample_df[\"Wins\"].ravel()\nOut: array([62, 38, 26, 6, 5], dtype=int64)\n```", "```py\npd.Series([\"Pandas\", \"Pandas\", \"Numpy\", \"Pandas\", \"Numpy\"]).value_counts()\n```", "```py\nsample_df[\"Nominations\"].value_counts()\n```", "```py\nsample_df[\"Nominations\"].value_counts(bins = 2)\n```", "```py\nlin_series = pd.Series([17,19,np.NaN,23,25,np.NaN,29])\n```", "```py\nlin_series.interpolate()\n```", "```py\nlin_series.interpolate(method = \"pad\", limit_direction = \"backward\")\n```", "```py\ns1 = pd.Series([5,6,7,8,9], index = [\"a\",\"b\",\"c\",\"d\",\"e\"])\ns2 = pd.Series([1,2,3,4,5], index = [\"d\",\"b\",\"g\",\"f\",\"a\"])\ns1.align(s2, join=\"outer\")\n```", "```py\ns1.align(s2, join=\"inner\")\n```", "```py\nsample_df[\"Movie\"].str.upper()\n```", "```py\nsample_df[\"Movie\"].str.lower()\n```", "```py\npd.Series([\"elon musk\", \"tim cook\", \"larry page\", \"jeff bezos\"]).str.capitalize()\n```", "```py\npd.Series([\"elon musk\", \"tim cook\", \"larry page\", \"jeff bezos\"]).str.title()\n```", "```py\nsample_df[\"Movie\"].str.swapcase()\n```", "```py\nsample_df[\"Movie\"].str.contains(\"atr\")\n```", "```py\nsample_df[\"Movie\"].str.contains(\"atr|der\", regex = True)\n```", "```py\nsample_df[\"Movie\"].str.contains(\"cas\", case = True)\n```", "```py\nimport re\nsample_df[\"Movie\"].str.contains(\"MATrix\", flags = re.IGNORECASE, regex=True)\n```", "```py\nfind_series = pd.Series([\"abracadabra\", \"mad man\"])\n```", "```py\nfind_series.str.find(\"ra\")\n```", "```py\nfind_series.str.find(\"a\", start = 2)\n```", "```py\nsample_df[\"Movie\"].str.replace(\"i\",\"'rep'\")\n```", "```py\nsample_df[\"Movie\"].str.replace(\"i\",\"'rep'\", n = 1)\n```", "```py\nstrip_series = pd.Series([\"\\tChina\", \"U.S.A \", \"U\\nK\"])\nstrip_series\n```", "```py\nstrip_series.strip()\n```", "```py\nsample_df[\"Movie\"].str.strip(\"opnf\")\n```", "```py\nsplit_series = pd.Series([\"Black, White\", \"Red, Blue, Green\", \"Cyan, Magenta, Yellow\"])\nsplit_series\n```", "```py\nsplit_series.str.split(\", \")\n```", "```py\nsplit_series.str.split(\", \", expand = True)\n```", "```py\nstart_series = pd.Series([\"strange\", \"stock\", \"cost\", \"past\", \"state\"])\nstart_series.str.startswith(\"st\")\n```", "```py\nend_series= pd.Series([\"ramen\", \"program\", \"cram\", \"rammed\", \"grammer\"])\nend_series.str.endswith(\"ram\")\n```", "```py\npd.Series([\"ui26\", \"ui\", \"26\"]).str.isalpha()\n```", "```py\npd.Series([\"ui26\", \"ui\", \"26\"]).str.isalnum()\n```", "```py\npd.Series([\"ui26\", \"ui\", \"26\"]).str.isnumeric()\n```", "```py\npd.Series([\"ui26\", \"ui\", 26]).str.isdigit()\n```", "```py\ndf_1 = pd.DataFrame([[1,2,3],[4,5,6]])\ndf_2 = pd.DataFrame([[6,7,8]])\ndf_1.add(df_2)\n```", "```py\ndf_1.mul(df_2, fill_value = 0)\n```", "```py\ndf_1.sub(2)\n```", "```py\npd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd']).pow(pd.Series([4, 3, 2, 1], index=['a', 'b', 'd', 'e']))\n```", "```py\npd.DataFrame([[27, 33, 44]], columns=[\"a\", \"b\", \"c\"]).mod(pd.DataFrame([[7, 6, 2]], columns=[\"b\", \"a\", \"d\"])).\n```", "```py\ndf = pd.DataFrame([[1, 4, 6], [np.NaN, 5, 3], [2, 7, np.NaN], [5, 9, 4], [1, np.NaN, 11]], columns = [\"ColA\", \"ColB\", \"ColC\"], index = [\"a\", \"b\", \"c\", \"d\", \"e\"])\n\ndf\n```", "```py\ndf_multi = df.iloc[0:4, :]\ndf_multi.index = pd.MultiIndex.from_tuples([(1, 'a'), (1, 'b'), (1, 'c'), (2, 'a')])\ndf_multi\n```", "```py\ndf.div(df_multi, level = 1)\n```", "```py\ndf.lt(df_multi, level = 1)\n```", "```py\ndf.le(df_multi, level = 1)\n```", "```py\npd.Series([6.78923, 8.02344, 0.1982]).round()\n```", "```py\npd.Series([6.78923, 8.02344, 0.1982]).round(2)\n```", "```py\npd.Series([9, 10, 11]).combine(pd.Series([7, 15, 12]), max)\n```", "```py\nbin_data = np.array([1, 5, 2, 12, 3, 25, 9, 10, 11, 4])\npd.cut(bin_data, bins = 3)\n```", "```py\npd.cut(bin_data, bins = [0.5, 7, 10, 20, 30])\n```", "```py\ninterval = pd.interval_range(start = 0, end = 30, periods = 5)\ninterval\n```", "```py\npd.cut(bin_data, bins = interval)\n```", "```py\npd.cut(bin_data, bins = [0.5, 7, 10, 20, 30], right = False)\n```", "```py\npd.cut(bin_data, bins = [0.5, 7, 10, 20, 30], include_lowest= True)\n```", "```py\npd.cut(bin_data, bins = 5, retbins = True)\n```", "```py\npd.cut(bin_data, bins = 3, labels = [\"level1\", \"level2\", \"level3\"])\n```", "```py\npd.cut(bin_data, bins = [0.5, 7, 10, 30, 30], duplicates = \"drop\")\n```", "```py\npd.cut(bin_data, bins = 3, precision = 1)\n```", "```py\npd.qcut(bin_data, q = 5)\n```", "```py\nabs_df = pd.DataFrame({\"Integers\": [-1, -2, -3, 0, 2], \"Complex\": [5+2j, 1+1j, 3+3j, 2+3j, 4+2j]})\nabs_df.abs()\n```", "```py\nsales_df.corr()\n```", "```py\nsales_df.cov()\n```", "```py\nsales_df.cummax()\n```", "```py\nsales_df_na\n```", "```py\nsales_df_na.cumsum()\n```", "```py\nsales_df_na.cumsum(skipna=False)\n```", "```py\nsales_df.cumprod(axis = 1)\n```", "```py\nsales_df.describe()\n```", "```py\nsales_df_full\n```", "```py\nsales_df_full.describe(include = np.object)\n```", "```py\nsales_df.describe(percentiles = [0.1, 0.2, 0.3, 0.4, 0.5])\n```", "```py\nsales_df.diff()\n```", "```py\nsales_df.diff(axis = 1)\n```", "```py\nsales_df.diff(periods = 2)\n```", "```py\nsales_df.rank()\n```", "```py\nsales_df.rank(ascending = False)\n```", "```py\nsales_df.rank(pct = True)\n```", "```py\nsales_df.rank(method = \"min\")\n```", "```py\nsales_df.quantile(q = [0.1, 0.9])\n```", "```py\ntime_col = pd.DataFrame({\"time\": pd.date_range(\"2017-01-01\", \"2017-12-31\")})\ntime_col.quantile(q = [0.1, 0.5], numeric_only = False)\n```", "```py\nsales_df.round()\n```", "```py\nsales_df.round(decimals = 10)\n```", "```py\nsales_df.pct_change()\n```", "```py\nsales_df.min()\n```", "```py\nsales_df.max(axis = 1)\n```", "```py\nsales_df_na\n```", "```py\nsales_df_na.median()\n```", "```py\nsales_df_na.median(skipna = False)\n```", "```py\nmultileveldf\n```", "```py\nmultileveldf.mean()\n```", "```py\nmultileveldf.mean(level = 0)\n```", "```py\nall_any = pd.DataFrame({\"A\": [True, False, False, True, True], \"B\": [1, 1, 1, 1, 1], \"C\": [10, 11, 20, 22, 33], \"D\": [\"abc\", \"xyz\", \"pqr\", \"ijk\", \"def\"], \"E\": [False, False, False, False, False]})\nall_any\n```", "```py\nall_any.all()\n```", "```py\nall_any.any()\n```", "```py\nall_any.all(bool_only = True)\n```", "```py\nsales_df.clip(8, 3000)\n```", "```py\nsales_df_na\n```", "```py\nsales_df_na.count()\n```"]