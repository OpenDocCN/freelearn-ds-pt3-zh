- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finding Optimal Solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ll address various methods for finding the best outcome
    in a given situation. This is called **optimization** and usually involves either
    minimizing or maximizing an objective function. An **objective function** is a
    function with one or more arguments that returns a single scalar value, representing
    the cost or payoff for a given choice of parameters. The problems regarding minimizing
    and maximizing functions are actually equivalent to one another, so we’ll only
    discuss minimizing object functions in this chapter. Minimizing a function, ![](img/Formula_09_001.png),
    is equivalent to maximizing the ![](img/Formula_09_002.png) function. More details
    on this will be provided when we discuss the first recipe.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithms available to us for minimizing a given function depend on the
    nature of the function. For instance, a simple linear function containing one
    or more variables has different algorithms available compared to a non-linear
    function with many variables. The minimization of linear functions falls within
    the category of **linear programming**, which is a well-developed theory. Linear
    functions can be solved with standard linear algebra techniques. For non-linear
    functions, we usually make use of the gradient of a function in order to find
    the minimum points. We will discuss several methods for minimizing various functions
    of different types.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the minima and maxima of the functions of a single variable is especially
    simple and can be done easily if the derivatives of the function are known. If
    not, then the method described in the appropriate recipe will be applicable. The
    notes in the *Minimizing a non-linear function* recipe give some extra details
    about this.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll also provide a very short introduction to *game theory*. Broadly speaking,
    this is a theory surrounding decision-making and has wide-ranging implications
    in subjects such as economics. In particular, we’ll discuss how to represent simple
    two-player games as objects in Python, compute payoffs associated with certain
    choices, and compute Nash equilibria for these games.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by looking at how to minimize linear and non-linear functions
    containing one or more variables. Then, we’ll move on and look at gradient descent
    methods and curve fitting, using least squares. We’ll conclude this chapter by
    analyzing two-player games and Nash equilibria.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Minimizing a simple linear function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimizing a non-linear function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using gradient descent methods in optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using least squares to fit a curve to data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing simple two-player games
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computing Nash equilibria
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will need the NumPy package, the SciPy package, and the
    Matplotlib package, as usual. We will also need the Nashpy package for the final
    two recipes. These packages can be installed using your favorite package manager,
    such as `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The code for this chapter can be found in the `Chapter 09` folder of the GitHub
    repository at [https://github.com/PacktPublishing/Applying-Math-with-Python-2nd-Edition/tree/main/Chapter%2009](https://github.com/PacktPublishing/Applying-Math-with-Python-2nd-Edition/tree/main/Chapter%2009).
  prefs: []
  type: TYPE_NORMAL
- en: Minimizing a simple linear function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The most basic type of problem we face in optimization is finding the parameters
    where a function takes its minimum value. Usually, this problem is *constrained*
    by some bounds on the possible values of the parameters, which increases the complexity
    of the problem. Obviously, the complexity of this problem increases further if
    the function that we are minimizing is also complex. For this reason, we must
    first consider *linear functions*, which are in the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_09_003.png)'
  prefs: []
  type: TYPE_IMG
- en: To solve this kind of problem, we need to convert the constraints into a form
    that can be used by a computer. In this case, we usually convert them into a linear
    algebra problem (matrices and vectors). Once this is done, we can use the tools
    from the linear algebra packages in NumPy and SciPy to find the parameters we
    seek. Fortunately, since this kind of problem occur quite frequently, SciPy has
    routines that handle this conversion and subsequent solving.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we’ll solve the following constrained linear minimization problem
    using routines from the SciPy `optimize` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_09_004.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This will be subject to the following conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_09_005.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_09_006.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_09_007.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_09_008.png)'
  prefs: []
  type: TYPE_IMG
- en: Let’s see how to use the SciPy `optimize` routines to solve this linear programming
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we need to import the NumPy package under the alias `np`,
    the Matplotlib `pyplot` module under the name `plt`, and the SciPy `optimize`
    module. We also need to import the `Axes3D` class from `mpl_toolkits.mplot3d`
    to make 3D plotting available:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Let’s see how to use the routines from the `optimize` module to minimize a constrained
    linear system.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to solve a constrained linear minimization problem using
    SciPy:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Set up the system in a form that SciPy can recognize:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we need to define a routine that evaluates the linear function at a value
    of ![](img/Formula_09_009.png), which is a vector (a NumPy array):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we create a new figure and add a set of `3d` axes that we can plot the
    function on:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we create a grid of values covering the region from the problem and plot
    the value of the function over this region:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we plot the line in the plane of the function values that corresponds
    to the critical line, `2*x0 + x1 == 6`, and plot the values that fall within the
    range on top of our plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We repeat this plotting step for the second critical line, `x0 + x1 == -``4`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we shade the region that lies within the two critical lines, which corresponds
    to the feasible region for the minimization problem:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The plot of the function values over the feasible region can be seen in the
    following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – The values of the linear function with the feasible region highlighted'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/9.1.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.1 – The values of the linear function with the feasible region highlighted
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the minimum value that lies within this shaded region occurs
    at the intersection of the two critical lines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we use `linprog` to solve the constrained minimization problem with the
    bounds we created in *step 1*. We print the resulting object in the terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we plot the minimum function value on top of the feasible region:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The updated plot can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – The minimum value plotted on the feasible region'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/9.2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.2 – The minimum value plotted on the feasible region
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the `linprog` routine has indeed found that the minimum
    is at the intersection of the two critical lines.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Constrained linear minimization problems are common in economic situations,
    where you try to minimize costs while maintaining other aspects of the parameters.
    In fact, a lot of the terminology from optimization theory mirrors this fact.
    A very simple algorithm for solving these kinds of problems is called the **simplex
    method**, which uses a sequence of array operations to find the minimal solution.
    Geometrically, these operations represent changing to different vertices of a
    simplex (which we won’t define here), and it is this that gives the algorithm
    its name.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we continue, we’ll provide a brief outline of the process used by the
    simplex method to solve a constrained linear optimization problem. The problem,
    as presented to us, is not a matrix equation problem but a matrix inequality problem.
    We can remedy this problem by introducing **slack variables**, which turn an inequality
    into an equality. For example, the first constraint inequality can be rewritten
    as follows by introducing the slack variable, ![](img/Formula_09_010.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_09_011.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This satisfies the desired inequality, provided that ![](img/Formula_09_012.png)
    is not negative. The second constraint inequality is greater than or equal to
    type inequality that we must first change so that it’s of the less than or equal
    to type. We do this by multiplying all terms by -1\. This gives us the second
    row of the `A` matrix that we defined in the recipe. After introducing a second
    slack variable,![](img/Formula_09_013.png), we get the second equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_09_014.png)'
  prefs: []
  type: TYPE_IMG
- en: From this, we can construct a matrix whose columns contain the coefficients
    of the two parameter variables, ![](img/Formula_09_015.png) and ![](img/Formula_09_016.png)
    and the two slack variables, ![](img/Formula_09_017.png) and ![](img/Formula_09_018.png).
    The rows of this matrix represent the two bounding equations and the objective
    function. This system of equations can now be solved, using elementary row operations
    on this matrix, to obtain the values of ![](img/Formula_09_019.png) and ![](img/Formula_09_020.png),
    which minimize the objective function. Since solving matrix equations is easy
    and fast, this means that we can minimize linear functions quickly and efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, we don’t need to remember how to reduce our system of inequalities
    into a system of linear equations, since routines such as `linprog` do this for
    us. We can simply provide the bounding inequalities as a matrix and vector pair,
    consisting of the coefficients of each, and a separate vector that defines the
    objective function. The `linprog` routine takes care of formulating and then solving
    the minimization problem.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, the simplex method is not the algorithm used by the `linprog` routine
    to minimize the function. Instead, `linprog` uses an interior point algorithm,
    which is more efficient. (The method can actually be set to `simplex` or `revised-simplex`
    by providing the `method` keyword argument with the appropriate method name. In
    the printed resulting output, we can see that it only took five iterations to
    reach the solution.) The resulting object that is returned by this routine contains
    the parameter values at which the minimum occurs, stored in the `x` attribute,
    the value of the function at this minimum value stored in the `fun` attribute,
    and various other pieces of information about the solving process. If the method
    had failed, then the `status` attribute would have contained a numerical code
    that described why the method failed.
  prefs: []
  type: TYPE_NORMAL
- en: In *step 2* of this recipe, we created a function that represents the objective
    function for this problem. This function takes a single array as input, which
    contains the parameter space values at which the function should be evaluated.
    Here, we used the `tensordot` routine (with `axes=1`) from NumPy to evaluate the
    dot product of the coefficient vector, ![](img/Formula_09_021.png), with each
    input, ![](img/Formula_09_022.png). We have to be quite careful here, since the
    values that we pass into the function will be a 2 × 50 × 50 array in a later step.
    The ordinary matrix multiplication (`np.dot`) would not give the 50 × 50 array
    output that we desire in this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *step 5* and *step 6*, we computed the points on the critical lines as those
    points with the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_09_023.png)'
  prefs: []
  type: TYPE_IMG
- en: We then computed the corresponding ![](img/Formula_09_024.png) values so that
    we could plot the lines that lie on the plane defined by the objective function.
    We also need to *trim* the values so that we only include those that lie in the
    range specified in the problem. This is done by constructing the indexing array
    labeled `I` in the code, consisting of the points that lie within the boundary
    values.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe covered the constrained minimization problem and how to solve it
    using SciPy. However, the same method can be used to solve the constrained *maximization*
    problem. This is because maximization and minimization are *dual* to one another,
    in the sense that maximizing a function,![](img/Formula_09_025.png), is the same
    as minimizing the ![](img/Formula_09_026.png) function and then taking the negative
    of this value. In fact, we used this fact in this recipe to change the second
    constraining inequality from ≥ to ≤.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we solved a problem with only two parameter variables, but the
    same method will work (except for the plotting steps) for a problem involving
    more than two such variables. We just need to add more rows and columns to each
    of the arrays to account for this increased number of variables – this includes
    the tuple of bounds supplied to the routine. The routine can also be used with
    sparse matrices, where appropriate, for extra efficiency when dealing with very
    large amounts of variables.
  prefs: []
  type: TYPE_NORMAL
- en: The `linprog` routine gets its name from *linear programming*, which is used
    to describe problems of this type – finding values of ![](img/Formula_09_027.png)
    that satisfy some matrix inequalities subject to other conditions. Since there
    is a very close connection between the theory of matrices and linear algebra,
    there are many very fast and efficient techniques available for linear programming
    problems that are not available in a non-linear context.
  prefs: []
  type: TYPE_NORMAL
- en: Minimizing a non-linear function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous recipe, we saw how to minimize a very simple linear function.
    Unfortunately, most functions are not linear and usually don’t have nice properties
    that we would like. For these non-linear functions, we cannot use the fast algorithms
    that have been developed for linear problems, so we need to devise new methods
    that can be used in these more general cases. The algorithm that we will use here
    is called the Nelder-Mead algorithm, which is a robust and general-purpose method
    that’s used to find the minimum value of a function and does not rely on its gradient.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we’ll learn how to use the Nelder-Mead simplex method to minimize
    a non-linear function containing two variables.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we will use the NumPy package imported as `np`, the Matplotlib
    `pyplot` module imported as `plt`, the `Axes3D` class imported from `mpl_toolkits.mplot3d`
    to enable 3D plotting, and the SciPy `optimize` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Let’s see how to use these tools to solve a non-linear optimization problem.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps show you how to use the Nelder-Mead simplex method to find
    the minimum of a general non-linear objective function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the objective function that we will minimize:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, create a grid of values that we can plot our objective function on:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we evaluate the function on this grid of points:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we create a new figure with a `3d` axes object and set the axis labels
    and the title:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can plot the objective function as a surface on the axes we just created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We choose an initial point that our minimization routine will start its iteration
    at and plot this on the surface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The plot of the objective function’s surface, along with the initial point,
    can be seen in the following diagram. Here, we can see that the minimum value
    appears to occur at around 0.5 on the x axis and -0.5 on the y axis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3 – A non-linear objective function with a starting point'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/9.3.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.3 – A non-linear objective function with a starting point
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we use the `minimize` routine from the `optimize` package to find the
    minimum value and print the `result` object that it produces:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we plot the minimum value found by the `minimize` routine on top of
    the objective function surface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The updated plot of the objective function, including the minimum point found
    by the `minimize` routine, can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – An objective function with a starting point and a minimum point'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/9.4.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.4 – An objective function with a starting point and a minimum point
  prefs: []
  type: TYPE_NORMAL
- en: This shows that the method has indeed found the minimum point (bottom right)
    within the region starting from the initial point (top left).
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Nelder-Mead simplex method – not to be confused with the simplex method
    for linear optimization problems – is a simple algorithm for finding the minimum
    values of a non-linear function and works even when the objective function does
    not have a known derivative. (This is not the case for the function in this recipe;
    the only gain from using a gradient-based method is the speed of convergence.)
    The method works by comparing the values of the objective function at the vertices
    of a simplex, which is a triangle in a two-dimensional space. The vertex with
    the largest function value is *reflected* through the opposite edge and performs
    an appropriate expansion or contraction that, in effect, moves the simplex *downhill*.
  prefs: []
  type: TYPE_NORMAL
- en: The `minimize` routine from the SciPy `optimize` module is an entry point for
    many non-linear function minimization algorithms. In this recipe, we used the
    Nelder-Mead simplex algorithm, but there are also a number of other algorithms
    available. Many of these algorithms require knowledge of the gradient of the function,
    which might be computed automatically by the algorithm. The algorithm can be used
    by providing the appropriate name to the `method` keyword argument.
  prefs: []
  type: TYPE_NORMAL
- en: The `result` object that’s returned by the `minimize` routine contains lots
    of information about the solution that has been found – or not found, if an error
    occurred – by the solver. In particular, the desired parameters that the calculated
    minimum occurs at are stored in the `x` attribute of the result, while the value
    of the function is stored in the `fun` attribute.
  prefs: []
  type: TYPE_NORMAL
- en: The `minimize` routine requires the function and a starting value of `x0`. In
    this recipe, we also provided a tolerance value that the minimum should be computed
    at using the `tol` keyword argument. Changing this value will modify the accuracy
    of the computed solution.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Nelder-Mead algorithm is an example of a *gradient-free* minimization algorithm,
    since it does not require any information about the gradient (derivative) of the
    objective function. There are several such algorithms, all of which typically
    involve evaluating the objective function at several points, and then using this
    information to move toward the minimum value. In general, gradient-free methods
    tend to converge more slowly than gradient-descent models. However, they can be
    used for almost any objective function, even where it is not easy to compute the
    gradient either exactly or by means of approximation.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing the functions of a single variable is generally easier than the multidimensional
    case and has its own special function in the SciPy `optimize` library. The `minimize_scalar`
    routine performs minimization for functions of a single variable and should be
    used instead of `minimize` in this case.
  prefs: []
  type: TYPE_NORMAL
- en: Using gradient descent methods in optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous recipe, we used the Nelder-Mead simplex algorithm to minimize
    a non-linear function containing two variables. This is a fairly robust method
    that works even if very little is known about the objective function. However,
    in many situations, we do know more about the objective function, and this fact
    allows us to devise faster and more efficient algorithms for minimizing the function.
    We can do this by making use of properties such as the gradient of the function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *gradient* of a function of more than one variable describes the rate of
    change of the function in each of its component directions. This is a vector of
    the partial derivatives of the function with respect to each of the variables.
    From this gradient vector, we can deduce the direction in which the function is
    increasing most rapidly and, conversely, the direction in which the function is
    decreasing most rapidly from any given position. This gives us the basis for **gradient
    descent** methods for minimizing a function. The algorithm is very simple: given
    a starting position,![](img/Formula_09_028.png), we compute the gradient at ![](img/Formula_09_029.png)
    and the corresponding direction in which the gradient is most rapidly decreasing,
    and then make a small step in that direction. After a few iterations, this will
    move from the starting position to the minimum of the function.'
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to implement an algorithm based on the steepest
    descent algorithm to minimize an objective function within a bounded region.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will need the NumPy package imported as `np`, the Matplotlib
    `pyplot` module imported as `plt`, and the `Axes3D` object imported from `mpl_toolkits.mplot3d`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Let’s implement a simple gradient descent algorithm and use it to solve the
    minimization problem described in the previous recipe to see how it works.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the following steps, we will implement a simple gradient descent method
    to minimize an objective function with a known gradient function (we’re actually
    going to use a generator function so that we can see the method as it works):'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by defining a `descend` routine, which will carry out our algorithm.
    The function declaration is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we need to implement this routine. We start by defining the variables
    that will hold the iterate values while the method is running:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then start our loop, which will run the iterations. We immediately check
    whether we are making meaningful progress before continuing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The direction is minus the gradient vector. We compute this once and store
    it in the `direction` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we update the previous and current values, `xnm1` and `xn` respectively,
    ready for the next iteration. This concludes the code for the `descend` routine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can compute the gradient at the current value and yield all the appropriate
    values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This concludes the definition of the `descend` routine.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now define a sample objective function to minimize:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we create a grid that we will evaluate and then plot the objective function
    on:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the grid has been created, we can evaluate our function and store the
    result in the `z` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we create a three-dimensional surface plot of the objective function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Before we can start the minimization process, we need to define an initial
    point, `x0`. We plot this point on the objective function plot we created in the
    previous step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The surface plot of the objective function, along with the initial value, can
    be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5 – The surface of the objective function with the initial position'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/9.5.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.5 – The surface of the objective function with the initial position
  prefs: []
  type: TYPE_NORMAL
- en: 'Our `descend` routine requires a function that evaluates the gradient of the
    objective function, so we will define one:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will plot the iterations on a contour plot, so we set this up as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we create a variable that holds the bounds in the ![](img/Formula_09_027.png)
    and ![](img/Formula_09_031.png) directions as a tuple of tuples. These are the
    same bounds from the `linspace` calls in *step 10*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can now use a `for` loop to drive the `descend` generator to produce each
    of the iterations and add the steps to the contour plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the loop is complete, we print the final values to the Terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of the preceding `print` statements is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see that our routine used 37 iterations to find a minimum at approximately
    (0.5, -0.5), which is correct.
  prefs: []
  type: TYPE_NORMAL
- en: 'The contour plot with its iterations plotted can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.6 – A contour plot of the objective function with the gradient descent
    iterating to a minimum value](img/9.6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 – A contour plot of the objective function with the gradient descent
    iterating to a minimum value
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the direction of each iteration – shown by the dashed
    lines – is in the direction where the objective function is decreasing most rapidly.
    The final iteration lies at the center of the *bowl* of the objective function,
    which is where the minimum occurs.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The heart of this recipe is the `descend` routine. The process that’s defined
    in this routine is a very simple implementation of the gradient descent method.
    Computing the gradient at a given point is handled by the `grad` argument, which
    is then used to deduce the direction of travel for the iteration by taking `direction
    = -grad`. We multiply this direction by a fixed scale factor (sometimes called
    the `0.2*direction` to the current position.
  prefs: []
  type: TYPE_NORMAL
- en: The solution in the recipe took 37 iterations to converge, which is a mild improvement
    on the Nelder-Mead simplex algorithm from the *Minimizing a non-linear function*
    recipe, which took 58 iterations. (This is not a perfect comparison, since we
    changed the starting position for this recipe.) This performance is heavily dependent
    on the step size that we choose. In this case, we fixed the maximum step size
    to be 0.2 times the size of the direction vector. This keeps the algorithm simple,
    but it is not particularly efficient.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we chose to implement the algorithm as a generator function
    so that we could see the output of each step and plot this on our contour plot
    as we stepped through the iteration. In practice, we probably wouldn’t want to
    do this and instead return the calculated minimum once the iterations have finished.
    To do this, we can simply remove the `yield` statement and replace it with `return
    xn` at the very end of the function, at the main function’s indentation (that
    is, not inside the loop). If you want to guard against non-convergence, you can
    use the `else` feature of the `for` loop to catch cases where the loop finishes
    because it has reached the end of its iterator without hitting the `break` keyword.
    This `else` block could raise an exception to indicate that the algorithm has
    failed to stabilize to a solution. The condition we used to end the iteration
    in this recipe does not guarantee that the method has reached a minimum, but this
    will usually be the case.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In practice, you would not usually implement the gradient descent algorithm
    for yourself and instead use a general-purpose routine from a library such as
    the SciPy `optimize` module. We can use the same `minimize` routine that we used
    in the previous recipe to perform minimization with a variety of different algorithms,
    including several gradient descent algorithms. These implementations are likely
    to have much higher performance and be more robust than a custom implementation
    such as this.
  prefs: []
  type: TYPE_NORMAL
- en: 'The gradient descent method we used in this recipe is a very naive implementation
    and can be greatly improved by allowing the routine to choose the step size at
    each step. (Methods that are allowed to choose their own step size are sometimes
    called adaptive methods.) The difficult part of this improvement is choosing the
    size of the step to take in this direction. For this, we need to consider the
    function of a single variable, which is given by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_09_032.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_09_033.png) represents the current point, ![](img/Formula_09_034.png)
    represents the current direction, and ![](img/Formula_09_035.png) is a parameter.
    For simplicity, we can use a minimization routine called `minimize_scalar` for
    scalar-valued functions from the SciPy `optimize` module. Unfortunately, it is
    not quite as simple as passing in this auxiliary function and finding the minimum
    value. We have to bound the possible value of ![](img/Formula_09_036.png) so that
    the computed minimizing point, ![](img/Formula_09_037.png), lies within the region
    that we are interested in.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand how we bound the values of ![](img/Formula_09_038.png), we must
    first look at the construction geometrically. The auxiliary function that we introduce
    evaluates the objective function along a single line in the given direction. We
    can picture this as taking a single cross section through the surface that passes
    through the current ![](img/Formula_09_039.png) point in the ![](img/Formula_09_040.png)
    direction. The next step of the algorithm is finding the step size, ![](img/Formula_09_041.png),
    that minimizes the values of the objective function along this line – this is
    a scalar function, which is much easier to minimize. The bounds should then be
    the range of ![](img/Formula_09_042.png) values, during which this line lies within
    the rectangle defined by the ![](img/Formula_09_043.png) and ![](img/Formula_09_044.png)
    boundary values. We determine the four values at which this line crosses those
    ![](img/Formula_09_045.png) and ![](img/Formula_09_046.png) boundary lines, two
    of which will be negative and two of which will be positive. (This is because
    the current point must lie within the rectangle.) We take the minimum of the two
    positive values and the maximum of the two negative values and pass these bounds
    to the scalar minimization routine. This is achieved using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the step size has been chosen, the only remaining step is to update the
    current `xn` value, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: Using this adaptive step size increases the complexity of the routine, but the
    performance is massively improved. Using this revised routine, the method converged
    in just three iterations, which is far fewer than the number of iterations used
    by the naive code in this recipe (37 iterations) or by the Nelder-Mead simplex
    algorithm in the previous recipe (58 iterations). This reduction in the number
    of iterations is exactly what we expected by providing the method with more information
    in the form of the gradient function.
  prefs: []
  type: TYPE_NORMAL
- en: We created a function that returned the gradient of the function at a given
    point. We computed this gradient by hand before we started, which will not always
    be easy or even possible. Instead, it is much more common to replace the *analytic*
    gradient used here with a numerically computed gradient that’s been estimated
    using finite differences or a similar algorithm. This has an impact on performance
    and accuracy, as all approximations do, but these concerns are usually minor given
    the improvement in the speed of convergence offered by gradient descent methods.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent-type algorithms are particularly popular in machine learning
    applications. Most of the popular Python machine learning libraries – including
    PyTorch, TensorFlow, and Theano – offer utilities for automatically computing
    gradients numerically for data arrays. This allows gradient descent methods to
    be used in the background to improve performance.
  prefs: []
  type: TYPE_NORMAL
- en: A popular variation of the gradient descent method is **stochastic gradient
    descent**, where the gradient is estimated by sampling randomly rather than using
    the whole set of data. This can dramatically reduce the computational burden of
    the method – at the cost of slower convergence – especially for high-dimensional
    problems such as those that are common in machine learning applications. Stochastic
    gradient descent methods are often combined with backpropagation to form the basis
    for training artificial neural networks in machine learning applications.
  prefs: []
  type: TYPE_NORMAL
- en: There are several extensions of the basic stochastic gradient descent algorithm.
    For example, the momentum algorithm incorporates the previous increment into the
    calculation of the next increment. Another example is the adaptive gradient algorithm,
    which incorporates per-parameter learning rates to improve the rate of convergence
    for problems that involve a large number of sparse parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Using least squares to fit a curve to data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Least squares is a powerful technique for finding a function from a relatively
    small family of potential functions that best describe a particular set of data.
    This technique is especially common in statistics. For example, least squares
    is used in linear regression problems – here, the family of potential functions
    is the collection of all linear functions. Usually, the family of functions that
    we try to fit has relatively few parameters that can be adjusted to solve the
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of least squares is relatively simple. For each data point, we compute
    the square of the residual – the difference between the value of the point and
    the expected value given a function – and try to make the sum of these squared
    residuals as small as possible (hence, least squares).
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we’ll learn how to use least squares to fit a curve to a sample
    set of data.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will need the NumPy package imported, as usual, as `np`,
    and the Matplotlib `pyplot` module imported as `plt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also need an instance of the default random number generator from the
    NumPy `random` module imported, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we need the `curve_fit` routine from the SciPy `optimize` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: Let’s see how to use this routine to fit a non-linear curve to some data.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps show you how to use the `curve_fit` routine to fit a curve
    to a set of data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to create the sample data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we produce a scatter plot of the data to see whether we can identify
    the underlying trend in the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE121]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE122]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE123]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The scatter plot that we have produced can be seen in the following diagram.
    Here, we can see that the data certainly doesn’t follow a linear trend (straight
    line). Since we know the trend is a polynomial, our next guess would be a quadratic
    trend. This is what we’re using here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.7 – Scatter plot of the sample data – we can see that it does not
    follow a linear trend'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/9.7.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.7 – Scatter plot of the sample data – we can see that it does not follow
    a linear trend
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we create a function that represents the model that we wish to fit:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE125]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can use the `curve_fit` routine to fit the model function to the sample
    data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE127]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE128]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we plot the best fit curve on top of the scatter plot to evaluate
    how well the fitted curve describes the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE130]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE131]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The updated scatter plot can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.8 – A scatter plot with the curve of the best fit found using superimposed
    least squares'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/9.8.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.8 – A scatter plot with the curve of the best fit found using superimposed
    least squares
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that the curve we have found fits the data reasonably well.
    The coefficients are not exactly equal to the true model – this is the effect
    of the added noise.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `curve_fit` routine performs least-squares fitting to fit the model’s curve
    to the sample data. In practice, this amounts to minimizing the following objective
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_09_047.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, the pairs ![](img/Formula_09_048.png) are the points from the sample data.
    In this case, we are optimizing over a three-dimensional parameter space, with
    one dimension for each of the parameters. The routine returns the estimated coefficients
    – the point in the parameter space at which the objective function is minimized
    – and a second variable that contains estimates for the covariance matrix for
    the fit. We ignored this in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: The estimated covariance matrix that’s returned from the `curve_fit` routine
    can be used to give a confidence interval for the estimated parameters. This is
    done by taking the square root of the diagonal elements divided by the sample
    size (100 in this recipe). This gives the standard error for the estimate that,
    when multiplied by the appropriate values corresponding to the confidence, gives
    us the size of the confidence interval. (We discussed confidence intervals in
    [*Chapter 6*](B19085_06.xhtml#_idTextAnchor226), *Working with Data* *and Statistics*.)
  prefs: []
  type: TYPE_NORMAL
- en: You might have noticed that the parameters estimated by the `curve_fit` routine
    are close, but not exactly equal, to the parameters that we used to define the
    sample data in *step 1*. The fact that these are not exactly equal is due to the
    normally distributed noise that we added to the data. In this recipe, we knew
    that the underlying structure of the data was quadratic – that is, a degree 2
    polynomial – and not some other, more esoteric, function. In practice, we are
    unlikely to know so much about the underlying structure of the data, which is
    the reason we added noise to the sample.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is another routine in the SciPy `optimize` module for performing least-squares
    fitting called `least_squares`. This routine has a slightly less intuitive signature
    but does return an object containing more information about the optimization process.
    However, the way this routine is set up is perhaps more similar to the way that
    we constructed the underlying mathematical problem in the *How it works...* section.
    To use this routine, we define the objective function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: 'We pass this function along with a starting estimate in the parameter space,
    `x0`, such as `(1, 0, 0)`. The additional parameters for the objective function,
    `func`, can be passed using the `args` keyword argument – for example, we could
    use `args=(x_data, y_data)`. These arguments are passed into the `x` and `y` arguments
    of the objective function. To summarize, we could have estimated the parameters
    using the following call to `least_squares`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: The `results` object that’s returned from the `least_squares` routine is actually
    the same as the one returned by the other optimization routines described in this
    chapter. It contains details such as the number of iterations used, whether the
    process was successful, detailed error messages, the parameter values, and the
    value of the objective function at the minimum value.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing simple two-player games
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Game theory is a branch of mathematics concerned with the analysis of decision-making
    and strategy. It has applications in economics, biology, and behavioral science.
    Many seemingly complex situations can be reduced to a relatively simple mathematical
    game that can be analyzed in a systematic way to find *optimal* solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'A classic problem in game theory is the *prisoner’s dilemma*, which, in its
    original form, is as follows: two co-conspirators are caught and must decide whether
    to remain quiet or to testify against the other. If both remain quiet, they both
    serve a 1-year sentence; if one testifies but the other does not, the testifier
    is released and the other serves a 3-year sentence; and if both testify against
    one another, they both serve a 2-year sentence. What should each conspirator do?
    It turns out that the best choice each conspirator can make, given any reasonable
    distrust of the other, is to testify. Adopting this strategy, they will either
    serve no sentence or a 2-year sentence maximum.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since this book is about Python, we will use a variation of this classic problem
    to illustrate just how universal the idea of this problem is. Consider the following
    problem: you and your colleague have to write some code for a client. You think
    that you could write the code faster in Python, but your colleague thinks that
    they could write it faster in C. The question is, which language should you choose
    for the project?'
  prefs: []
  type: TYPE_NORMAL
- en: 'You think that you could write the Python code four times faster than in C,
    so you write C with speed 1 and Python with speed 4\. Your colleague says that
    they can write C slightly faster than Python, so they write C with speed 3 and
    Python with speed 2\. If you both agree on a language, then you write the code
    at the speed you predicted, but if you disagree, then the productivity of the
    faster programmer is reduced by 1\. We can summarize this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Colleague/You | C | Python |'
  prefs: []
  type: TYPE_TB
- en: '| C | 3/1 | 3/2 |'
  prefs: []
  type: TYPE_TB
- en: '| Python | 2/1 | 2/4 |'
  prefs: []
  type: TYPE_TB
- en: Figure 9.9 – A table of the predicted work speed in various configurations
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to construct an object in Python to represent
    this simple two-player game, and then perform some elementary analysis regarding
    the outcomes of this game.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will need the NumPy package imported as `np`, and the Nashpy
    package imported as `nash`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: Let’s see how to use the `nashpy` package to analyze a simple two-player game.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps show you how to create and perform some simple analysis
    of a two-player game using Nashpy:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create matrices that hold the payoff information for each
    player (you and your colleague, in this example):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE136]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we create a `Game` object that holds the game represented by these payoff
    matrices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We compute the utility for the given choices using index notation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE139]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE140]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE141]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can also compute the expected utilities based on the probabilities of making
    a specific choice:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: These expected utilities represent what we’d expect (on average) to see if we
    repeated the game numerous times with the specified probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we built a Python object that represents a very simple two-player
    strategic game. The idea here is that there are two *players* who have decisions
    to make, and each combination of both players’ choices gives a specific payoff
    value. What we’re aiming to do here is find the best choice that each player can
    make. The players are assumed to make a single move simultaneously, in the sense
    that neither is aware of the other’s choice. Each player has a strategy that determines
    the choice they make.
  prefs: []
  type: TYPE_NORMAL
- en: In *step 1*, we create two matrices – one for each player – that are assigned
    to each combination of choices for the payoff value. These two matrices are wrapped
    by the `Game` class from Nashpy, which provides a convenient and intuitive (from
    a game-theoretic point of view) interface for working with games. We can quickly
    calculate the utility of a given combination of choices by passing in the choices
    using index notation.
  prefs: []
  type: TYPE_NORMAL
- en: We can also calculate expected utilities based on a strategy where choices are
    chosen at random according to some probability distribution. The syntax is the
    same as for the deterministic case described previously, except we provide a vector
    of probabilities for each choice. We compute the expected utilities based on the
    probability that you choose Python 90% of the time, while your colleague chooses
    Python 50% of the time. The expected speeds are 2.45 and 2.05 for you and your
    colleague respectively.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is an alternative to computational game theory in Python. The Gambit project
    is a collection of tools used for computation in game theory that has a Python
    interface ([http://www.gambit-project.org/](http://www.gambit-project.org/)).
    This is a mature project built around C libraries and offers more performance
    than Nashpy.
  prefs: []
  type: TYPE_NORMAL
- en: Computing Nash equilibria
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A *Nash equilibrium* is a two-player strategic game – similar to the one we
    saw in the *Analyzing simple two-player games* recipe – that represents a *steady
    state* in which every player sees the *best possible* outcome. However, this doesn’t
    mean that the outcome linked to a Nash equilibrium is the best overall. Nash equilibria
    are more subtle than this. An informal definition of a Nash equilibrium is as
    follows: an action profile in which no individual player can improve their outcome,
    assuming that all other players adhere to the profile.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will explore the notion of a Nash equilibrium with the classic game of rock-paper-scissors.
    The rules are as follows. Each player can choose one of the options: rock, paper,
    or scissors. Rock beats scissors, but loses to paper; paper beats rock, but loses
    to scissors; scissors beats paper, but loses to rock. Any game in which both players
    make the same choice is a draw. Numerically, we represent a win by +1, a loss
    by -1, and a draw by 0\. From this, we can construct a two-player game and compute
    Nash equilibria for this game.'
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will compute Nash equilibria for the classic game of rock-paper-scissors.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we will need the NumPy package imported as `np`, and the Nashpy
    package imported as `nash`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: Let’s see how to use the `nashpy` package to compute Nash equilibria for a two-player
    strategy game.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps show you how to compute Nash equilibria for a simple two-player
    game:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create a payoff matrix for each player. We will start with
    the first player:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE145]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE146]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE147]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE148]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The payoff matrix for the second player is the transpose of `rps_p1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we create the `Game` object to represent the game:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We compute the Nash equilibria for the game using the support enumeration algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We iterate over the equilibria and print the profile for each player:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE153]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE154]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of these print statements is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Nash equilibria are extremely important in game theory because they allow us
    to analyze the outcomes of strategic games and identify advantageous positions.
    They were first described by John F. Nash in 1950 and have played a pivotal role
    in modern game theory. A two-player game may have many Nash equilibria, but any
    finite two-player game must have at least one. The problem is finding all the
    possible Nash equilibria for a given game.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we used the support enumeration, which effectively enumerates
    all possible strategies and filters down to those that are Nash equilibria. In
    this recipe, the support enumeration algorithm found just one Nash equilibrium,
    which is a mixed strategy. This means that the only strategy for which there is
    no improvement involves picking one of the choices at random, each with a 1/3
    probability. This is hardly a surprise to anyone who has played rock-paper-scissors,
    since for any choice we make, our opponent has a 1 in 3 chance of choosing (at
    random) the move that beats our choice. Equally, we have a 1 in 3 chance of drawing
    or winning the game, so our expected value over all these possibilities is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_09_049.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Without knowing exactly which of the choices our opponent will choose, there
    is no way to improve this expected outcome.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Nashpy package also provides other algorithms for computing Nash equilibria.
    Specifically, the `vertex_enumeration` method, when used on a `Game` object, uses
    the *vertex enumeration* algorithm, while the `lemke_howson_enumeration` method
    uses the *Lemke-Howson* algorithm. These alternative algorithms have different
    characteristics and may be more efficient for some problems.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The documentation for the Nashpy package contains more detailed information
    about the algorithms and game theory involved. This includes a number of references
    to texts on game theory. This documentation can be found at [https://nashpy.readthedocs.io/en/latest/](https://nashpy.readthedocs.io/en/latest/).
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As usual, the *Numerical Recipes* book is a good source of numerical algorithms.
    [*Chapter 10*](B19085_10.xhtml#_idTextAnchor395), *Minimization or Maximization
    of Functions*, deals with the maximization and minimization of functions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Press, W.H., Teukolsky, S.A., Vetterling, W.T., and Flannery, B.P., 2017\.
    *Numerical recipes: the art of scientific computing*. 3rd ed. Cambridge: Cambridge
    University Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'More specific information on optimization can be found in the following books:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Boyd, S.P. and Vandenberghe, L., 2018\. *Convex optimization*. Cambridge: Cambridge
    University Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Griva, I., Nash, S., and Sofer, A., 2009\. *Linear and nonlinear optimization*.
    2nd ed. Philadelphia: Society for Industrial and Applied Mathematics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, the following book is a good introduction to game theory:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Osborne, M.J., 2017\. *An introduction to game theory*. Oxford: Oxford University
    Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
