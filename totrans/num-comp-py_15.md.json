["```py\n>>> names = pd.read_csv('data/names.csv')\n>>> names\n```", "```py\n>>> new_data_list = ['Aria', 1]\n>>> names.loc[4] = new_data_list\n>>> names\n```", "```py\n>>> names.loc['five'] = ['Zach', 3]\n>>> names\n```", "```py\n>>> names.loc[len(names)] = {'Name':'Zayd', 'Age':2}\n>>> names\n```", "```py\n>>> names.loc[len(names)] = pd.Series({'Age':32,\n                                       'Name':'Dean'})\n>>> names\n```", "```py\n>>> names = pd.read_csv('data/names.csv')\n>>> names.append({'Name':'Aria', 'Age':1})\nTypeError: Can only append a Series if ignore_index=True or if the Series has a name\n```", "```py\n>>> names.append({'Name':'Aria', 'Age':1}, ignore_index=True)\n```", "```py\n>>> names.index = ['Canada', 'Canada', 'USA', 'USA']\n>>> names\n```", "```py\n>>> s = pd.Series({'Name': 'Zach', 'Age': 3}, name=len(names))\n>>> s\nAge        3\nName    Zach\nName: 4, dtype: object\n\n>>> names.append(s)\n```", "```py\n>>> s1 = pd.Series({'Name': 'Zach', 'Age': 3}, name=len(names))\n>>> s2 = pd.Series({'Name': 'Zayd', 'Age': 2}, name='USA')\n>>> names.append([s1, s2])\n```", "```py\n>>> bball_16 = pd.read_csv('data/baseball16.csv')\n>>> bball_16.head()\n```", "```py\n>>> data_dict = bball_16.iloc[0].to_dict()\n>>> print(data_dict)\n{'playerID': 'altuvjo01', 'yearID': 2016, 'stint': 1, 'teamID': 'HOU', 'lgID': 'AL', 'G': 161, 'AB': 640, 'R': 108, 'H': 216, '2B': 42, '3B': 5, 'HR': 24, 'RBI': 96.0, 'SB': 30.0, 'CS': 10.0, 'BB': 60, 'SO': 70.0, 'IBB': 11.0, 'HBP': 7.0, 'SH': 3.0, 'SF': 7.0, 'GIDP': 15.0}\n```", "```py\n>>> new_data_dict = {k: '' if isinstance(v, str) else \n                        np.nan for k, v in data_dict.items()}\n>>> print(new_data_dict)\n{'playerID': '', 'yearID': nan, 'stint': nan, 'teamID': '', 'lgID': '', 'G': nan, 'AB': nan, 'R': nan, 'H': nan, '2B': nan, '3B': nan, 'HR': nan, 'RBI': nan, 'SB': nan, 'CS': nan, 'BB': nan, 'SO': nan, 'IBB': nan, 'HBP': nan, 'SH': nan, 'SF': nan, 'GIDP': nan}\n```", "```py\n>>> random_data = []\n>>> for i in range(1000):\n        d = dict()\n        for k, v in data_dict.items():\n            if isinstance(v, str):\n                d[k] = np.random.choice(list('abcde'))\n            else:\n                d[k] = np.random.randint(10)\n        random_data.append(pd.Series(d, name=i + len(bball_16)))\n\n>>> random_data[0].head()\n2B    3\n3B    9\nAB    3\nBB    9\nCS    4\nName: 16, dtype: object\n```", "```py\n>>> %%timeit\n>>> bball_16_copy = bball_16.copy()\n>>> for row in random_data:\n        bball_16_copy = bball_16_copy.append(row)\n4.88 s ± 190 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n```", "```py\n>>> %%timeit\n>>> bball_16_copy = bball_16.copy()\n>>> bball_16_copy = bball_16_copy.append(random_data)\n78.4 ms ± 6.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n```", "```py\n>>> stocks_2016 = pd.read_csv('data/stocks_2016.csv', \n                              index_col='Symbol')\n>>> stocks_2017 = pd.read_csv('data/stocks_2017.csv',\n                              index_col='Symbol')\n```", "```py\n>>> s_list = [stocks_2016, stocks_2017]\n>>> pd.concat(s_list)\n```", "```py\n>>> pd.concat(s_list, keys=['2016', '2017'], \n              names=['Year', 'Symbol'])\n```", "```py\n>>> pd.concat(s_list, keys=['2016', '2017'],\n              axis='columns', names=['Year', None])\n```", "```py\n>>> pd.concat(s_list, join='inner', keys=['2016', '2017'],\n              axis='columns', names=['Year', None])\n```", "```py\n>>> stocks_2016.append(stocks_2017)\n```", "```py\n>>> base_url = 'http://www.presidency.ucsb.edu/data/popularity.php?pres={}'\n>>> trump_url = base_url.format(45)\n>>> df_list = pd.read_html(trump_url)\n>>> len(df_list)\n14\n```", "```py\n>>> df0 = df_list[0]\n>>> df0.shape\n(308, 1794)\n\n>>> df0.head(7)\n```", "```py\n>>> df_list = pd.read_html(trump_url, match='Start Date')\n>>> len(df_list)\n3\n```", "```py\n>>> df_list = pd.read_html(trump_url, match='Start Date',\n                           attrs={'align':'center'})\n>>> len(df_list)\n1\n\n>>> trump = df_list[0]\n>>> trump.shape\n(249, 19)\n\n>>> trump.head(8)\n```", "```py\n>>> df_list = pd.read_html(trump_url, match='Start Date',\n                           attrs={'align':'center'}, \n                           header=0, skiprows=[0,1,2,3,5], \n                           parse_dates=['Start Date',\n                                        'End Date'])\n>>> trump = df_list[0]\n>>> trump.head()\n```", "```py\n>>> trump = trump.dropna(axis=1, how='all')\n>>> trump.head()\n```", "```py\n>>> trump.isnull().sum()\nPresident         242\nStart Date          0\nEnd Date            0\nApproving           0\nDisapproving        0\nunsure/no data      0\ndtype: int64\n\n>>> trump = trump.ffill()\ntrump.head()\n```", "```py\n>>> trump.dtypes\nPresident                 object\nStart Date        datetime64[ns]\nEnd Date          datetime64[ns]\nApproving                  int64\nDisapproving               int64\nunsure/no data             int64\ndtype: object\n```", "```py\n>>> def get_pres_appr(pres_num):\n        base_url =\\\n'http://www.presidency.ucsb.edu/data/popularity.php?pres={}'\n        pres_url = base_url.format(pres_num)\n        df_list = pd.read_html(pres_url, match='Start Date',\n                               attrs={'align':'center'}, \n                               header=0, skiprows=[0,1,2,3,5], \n                               parse_dates=['Start Date',\n                                            'End Date'])\n        pres = df_list[0].copy()\n        pres = pres.dropna(axis=1, how='all')\n        pres['President'] = pres['President'].ffill()\n        return pres.sort_values('End Date') \\\n                   .reset_index(drop=True)\n```", "```py\n>>> obama = get_pres_appr(44)\n>>> obama.head()\n```", "```py\n>>> pres_41_45 = pd.concat([get_pres_appr(x) for x in range(41,46)],\n                            ignore_index=True)\n>>> pres_41_45.groupby('President').head(3)\n```", "```py\n>>> pres_41_45['End Date'].value_counts().head(8)\n1990-08-26    2\n1990-03-11    2\n1999-02-09    2\n2013-10-10    2\n1990-08-12    2\n1992-11-22    2\n1990-05-22    2\n1991-09-30    1\nName: End Date, dtype: int64\n```", "```py\n>>> pres_41_45 = pres_41_45.drop_duplicates(subset='End Date')\n```", "```py\n>>> pres_41_45.shape\n(3679, 6)\n\n>>> pres_41_45['President'].value_counts()\nBarack Obama          2786\nGeorge W. Bush         270\nDonald J. Trump        243\nWilliam J. Clinton     227\nGeorge Bush            153\nName: President, dtype: int64\n\n>>> pres_41_45.groupby('President', sort=False) \\\n                       .median().round(1)\n```", "```py\n>>> from matplotlib import cm\n>>> fig, ax = plt.subplots(figsize=(16,6))\n\n>>> styles = ['-.', '-', ':', '-', ':']\n>>> colors = [.9, .3, .7, .3, .9]\n>>> groups = pres_41_45.groupby('President', sort=False)\n\n>>> for style, color, (pres, df) in zip(styles, colors, groups):\n        df.plot('End Date', 'Approving', ax=ax,\n                label=pres, style=style, color=cm.Greys(color), \n                title='Presedential Approval Rating')\n```", "```py\n>>> days_func = lambda x: x - x.iloc[0]\n>>> pres_41_45['Days in Office'] = pres_41_45.groupby('President') \\\n                                             ['End Date'] \\\n                                             .transform(days_func)\n>>> pres_41_45.groupby('President').head(3)\n```", "```py\n>>> pres_41_45.dtypes\n...\nDays in Office    timedelta64[ns]\ndtype: object\n```", "```py\n>>> pres_41_45['Days in Office'] = pres_41_45['Days in Office'] \\\n                                             .dt.days\n>>> pres_41_45['Days in Office'].head()\n0     0\n1    32\n2    35\n3    43\n4    46\nName: Days in Office, dtype: int64\n```", "```py\n>>> pres_pivot = pres_41_45.pivot(index='Days in Office',\n                                  columns='President',\n                                  values='Approving')\n>>> pres_pivot.head()\n```", "```py\n>>> plot_kwargs = dict(figsize=(16,6), color=cm.gray([.3, .7]), \n                       style=['-', '--'], title='Approval Rating')\n>>> pres_pivot.loc[:250, ['Donald J. Trump', 'Barack Obama']] \\\n              .ffill().plot(**plot_kwargs)\n```", "```py\n>>> pres_rm = pres_41_45.groupby('President', sort=False) \\\n                        .rolling('90D', on='End Date')['Approving'] \\\n                        .mean()\n>>> pres_rm.head()\nPresident    End Date   \nGeorge Bush  1989-01-26    51.000000\n             1989-02-27    55.500000\n             1989-03-02    57.666667\n             1989-03-10    58.750000\n             1989-03-13    58.200000\nName: Approving, dtype: float64\n```", "```py\n>>> styles = ['-.', '-', ':', '-', ':']\n>>> colors = [.9, .3, .7, .3, .9]\n>>> color = cm.Greys(colors)\n>>> title='90 Day Approval Rating Rolling Average'\n>>> plot_kwargs = dict(figsize=(16,6), style=styles,\n                       color = color, title=title)\n>>> correct_col_order = pres_41_45.President.unique()\n\n>>> pres_rm.unstack('President')[correct_col_order].plot(**plot_kwargs)\n```", "```py\n>>> from IPython.display import display_html\n\n>>> years = 2016, 2017, 2018\n>>> stock_tables = [pd.read_csv('data/stocks_{}.csv'.format(year),\n                                index_col='Symbol') \n                    for year in years]\n\n>>> def display_frames(frames, num_spaces=0):\n        t_style = '<table style=\"display: inline;\"'\n        tables_html = [df.to_html().replace('<table', t_style) \n                       for df in frames]\n\n        space = '&nbsp;' * num_spaces\n        display_html(space.join(tables_html), raw=True)\n\n>>> display_frames(stock_tables, 30)\n>>> stocks_2016, stocks_2017, stocks_2018 = stock_tables\n```", "```py\n>>> pd.concat(stock_tables, keys=[2016, 2017, 2018])\n```", "```py\n>>> pd.concat(dict(zip(years,stock_tables)), axis='columns')\n```", "```py\n>>> stocks_2016.join(stocks_2017, lsuffix='_2016',\n                     rsuffix='_2017', how='outer')\n```", "```py\n>>> other = [stocks_2017.add_suffix('_2017'),\n             stocks_2018.add_suffix('_2018')]\n>>> stocks_2016.add_suffix('_2016').join(other, how='outer')\n```", "```py\n>>> stock_join = stocks_2016.add_suffix('_2016').join(other, \n                                                      how='outer')\n>>> stock_concat = pd.concat(dict(zip(years,stock_tables)),\n                             axis='columns')\n>>> level_1 = stock_concat.columns.get_level_values(1)\n>>> level_0 = stock_concat.columns.get_level_values(0).astype(str)\n>>> stock_concat.columns = level_1 + '_' + level_0\n>>> stock_join.equals(stock_concat)\nTrue\n```", "```py\n>>> stocks_2016.merge(stocks_2017, left_index=True, \n                      right_index=True)\n```", "```py\n>>> step1 = stocks_2016.merge(stocks_2017, left_index=True, \n                              right_index=True, how='outer',\n                              suffixes=('_2016', '_2017'))\n\n>>> stock_merge = step1.merge(stocks_2018.add_suffix('_2018'), \n                              left_index=True, right_index=True,\n                              how='outer')\n\n>>> stock_concat.equals(stock_merge)\nTrue\n```", "```py\n>>> names = ['prices', 'transactions']\n>>> food_tables = [pd.read_csv('data/food_{}.csv'.format(name)) \n                    for name in names]\n>>> food_prices, food_transactions = food_tables\n>>> display_frames(food_tables, 30)\n```", "```py\n>>> food_transactions.merge(food_prices, on=['item', 'store'])\n```", "```py\n>>> food_transactions.merge(food_prices.query('Date == 2017'),\n                            how='left')\n```", "```py\n>>> food_prices_join = food_prices.query('Date == 2017') \\\n                                  .set_index(['item', 'store'])\n>>> food_prices_join\n```", "```py\n>>> food_transactions.join(food_prices_join, on=['item', 'store'])\n```", "```py\n>>> pd.concat([food_transactions.set_index(['item', 'store']), \n               food_prices.set_index(['item', 'store'])],\n              axis='columns')\nException: cannot handle a non-unique multi-index!\n```", "```py\n>>> import glob\n\n>>> df_list = []\n>>> for filename in glob.glob('data/gas prices/*.csv'):\n        df_list.append(pd.read_csv(filename, index_col='Week',\n                       parse_dates=['Week']))\n\n>>> gas = pd.concat(df_list, axis='columns')\n>>> gas.head()\n```", "```py\n>>> from sqlalchemy import create_engine\n>>> engine = create_engine('sqlite:///data/chinook.db')\n```", "```py\n>>> tracks = pd.read_sql_table('tracks', engine)\n>>> tracks.head()\n>>> genres = pd.read_sql_table('genres', engine)\n```", "```py\n>>> genre_track = genres.merge(tracks[['GenreId', 'Milliseconds']], \n                               on='GenreId', how='left') \\\n                        .drop('GenreId', axis='columns')\n\n>>> genre_track.head()\n```", "```py\n>>> genre_time = genre_track.groupby('Name')['Milliseconds'].mean()\n>>> pd.to_timedelta(genre_time, unit='ms').dt.floor('s')\n                                             .sort_values()\nName\nRock And Roll        00:02:14\nOpera                00:02:54\nHip Hop/Rap          00:02:58\n...\nDrama                00:42:55\nScience Fiction      00:43:45\nSci Fi & Fantasy     00:48:31\nName: Milliseconds, dtype: timedelta64[ns]\n```", "```py\n>>> cust = pd.read_sql_table('customers', engine, \n                             columns=['CustomerId','FirstName',\n                                      'LastName'])\n>>> invoice = pd.read_sql_table('invoices', engine, \n                                 columns=['InvoiceId','CustomerId'])\n>>> ii = pd.read_sql_table('invoice_items', engine, \n                            columns=['InvoiceId', 'UnitPrice',\n                                     'Quantity'])\n\n>>> cust_inv = cust.merge(invoice, on='CustomerId') \\\n                   .merge(ii, on='InvoiceId')\n>>> cust_inv.head()\n```", "```py\n>>> total = cust_inv['Quantity'] * cust_inv['UnitPrice']\n>>> cols = ['CustomerId', 'FirstName', 'LastName']\n>>> cust_inv.assign(Total = total).groupby(cols)['Total'] \\\n                                  .sum() \\\n                                  .sort_values(ascending=False) \\\n                                  .head()\nCustomerId  FirstName  LastName  \n6           Helena     Holý          49.62\n26          Richard    Cunningham    47.62\n57          Luis       Rojas         46.62\n46          Hugh       O'Reilly      45.62\n45          Ladislav   Kovács        45.62\nName: Total, dtype: float64\n```", "```py\ncust_inv['Total'] = cust_inv['Quantity'] * cust_inv['UnitPrice']\n```", "```py\n>>> sql_string1 = '''\n    select \n        Name, \n        time(avg(Milliseconds) / 1000, 'unixepoch') as avg_time\n    from (\n            select \n                g.Name, \n                t.Milliseconds\n            from \n                genres as g \n            join\n                tracks as t\n                on \n                    g.genreid == t.genreid\n         )\n    group by \n        Name\n    order by \n         avg_time\n'''\n>>> pd.read_sql_query(sql_string1, engine)\n```", "```py\n>>> sql_string2 = '''\n    select \n          c.customerid, \n          c.FirstName, \n          c.LastName, \n          sum(ii.quantity * ii.unitprice) as Total\n    from\n         customers as c\n    join\n         invoices as i\n              on c.customerid = i.customerid\n    join\n        invoice_items as ii\n              on i.invoiceid = ii.invoiceid\n    group by\n        c.customerid, c.FirstName, c.LastName\n    order by\n        Total desc\n'''\n>>> pd.read_sql_query(sql_string2, engine)\n```"]