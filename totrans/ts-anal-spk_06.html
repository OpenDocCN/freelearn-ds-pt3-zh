<html><head></head><body>
<div epub:type="chapter" id="_idContainer106">
<h1 class="chapter-number" id="_idParaDest-116"><a id="_idTextAnchor116"/><span class="koboSpan" id="kobo.1.1">6</span></h1>
<h1 id="_idParaDest-117"><a id="_idTextAnchor117"/><span class="koboSpan" id="kobo.2.1">Exploratory Data Analysis</span></h1>
<p><span class="koboSpan" id="kobo.3.1">After loading and preparing data (covered in the previous chapter), we will now go through exploratory data analysis to uncover patterns and insights in time series data. </span><span class="koboSpan" id="kobo.3.2">We will use statistical analysis techniques, including those specific to temporal patterns. </span><span class="koboSpan" id="kobo.3.3">The outcomes of these steps are crucial for identifying trends and seasonality, informing subsequent modeling decisions. </span><span class="koboSpan" id="kobo.3.4">Robust exploratory data analysis using Apache Spark ensures a comprehensive grasp of the dataset’s characteristics, enhancing the accuracy and relevance of subsequent time series models </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">and analyses.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">In this chapter, we’re going to cover the following </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">main topics:</span></span></p>
<ul>
<li><span class="No-Break"><span class="koboSpan" id="kobo.7.1">Statistical analysis</span></span></li>
<li><span class="koboSpan" id="kobo.8.1">Resampling, decomposition, </span><span class="No-Break"><span class="koboSpan" id="kobo.9.1">and stationarity</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.10.1">Correlation analysis</span></span></li>
</ul>
<h1 id="_idParaDest-118"><a id="_idTextAnchor118"/><span class="koboSpan" id="kobo.11.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.12.1">The hands-on coding predominant in this chapter covers the frequently used data exploration techniques for a time series analysis project. </span><span class="koboSpan" id="kobo.12.2">The code for this chapter can be found in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.13.1">ch6</span></strong><span class="koboSpan" id="kobo.14.1"> folder of the book’s GitHub repository at this </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">URL: </span></span><a href="https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/tree/main/ch6"><span class="No-Break"><span class="koboSpan" id="kobo.16.1">https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/tree/main/ch6</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.17.1">.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.18.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.19.1">We will use Spark DataFrames in the code examples and convert them to pandas DataFrames for libraries supporting pandas. </span><span class="koboSpan" id="kobo.19.2">This shows how to interchangeably use both. </span><span class="koboSpan" id="kobo.19.3">The use of pandas will be mentioned when this is </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">the case.</span></span></p>
<h1 id="_idParaDest-119"><a id="_idTextAnchor119"/><span class="koboSpan" id="kobo.21.1">Statistical analysis</span></h1>
<p><span class="koboSpan" id="kobo.22.1">This section starts with the statistical analysis of time series data and covers data profiling to </span><a id="_idIndexMarker517"/><span class="koboSpan" id="kobo.23.1">gather these statistics, distribution analysis, </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">and visualizations.</span></span></p>
<p><span class="koboSpan" id="kobo.25.1">The examples in this chapter are based on the code in </span><strong class="source-inline"><span class="koboSpan" id="kobo.26.1">ts-spark_ch6_1.dbc</span></strong><span class="koboSpan" id="kobo.27.1">, which we can import from the GitHub location for </span><a href="B18568_06.xhtml#_idTextAnchor116"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.28.1">Chapter 6</span></em></span></a><span class="koboSpan" id="kobo.29.1">, mentioned in the </span><em class="italic"><span class="koboSpan" id="kobo.30.1">Technical requirements</span></em><span class="koboSpan" id="kobo.31.1"> section, into Databricks Community Edition, as per the approach explained in </span><a href="B18568_01.xhtml#_idTextAnchor016"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.32.1">Chapter 1</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.33.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.34.1">The code URL is as </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">follows</span></span><span class="No-Break"><span class="koboSpan" id="kobo.36.1">: </span></span><a href="https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch6/ts-spark_ch6_1.dbc"><span class="No-Break"><span class="koboSpan" id="kobo.37.1">https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch6/ts-spark_ch6_1.dbc</span></span></a></p>
<p><span class="koboSpan" id="kobo.38.1">We will start the hands-on examples with the household energy consumption dataset, which we also used in </span><a href="B18568_02.xhtml#_idTextAnchor044"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.39.1">Chapter 2</span></em></span></a><span class="koboSpan" id="kobo.40.1"> and </span><a href="B18568_05.xhtml#_idTextAnchor103"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.41.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.42.1">. </span><span class="koboSpan" id="kobo.42.2">After loading the dataset with </span><strong class="source-inline"><span class="koboSpan" id="kobo.43.1">spark.read</span></strong><span class="koboSpan" id="kobo.44.1">, as per the following code extract, we cache the DataFrame in memory with </span><strong class="source-inline"><span class="koboSpan" id="kobo.45.1">df.cache()</span></strong><span class="koboSpan" id="kobo.46.1"> to accelerate subsequent processing. </span><span class="koboSpan" id="kobo.46.2">Due to lazy evaluation, the caching will happen on the next action and not immediately. </span><span class="koboSpan" id="kobo.46.3">As we want the caching to happen, we have added an </span><strong class="source-inline"><span class="koboSpan" id="kobo.47.1">df.count()</span></strong><span class="koboSpan" id="kobo.48.1"> action to force this. </span><span class="koboSpan" id="kobo.48.2">We then create a </span><strong class="source-inline"><span class="koboSpan" id="kobo.49.1">timestamp</span></strong><span class="koboSpan" id="kobo.50.1"> column combining the </span><strong class="source-inline"><span class="koboSpan" id="kobo.51.1">Date</span></strong><span class="koboSpan" id="kobo.52.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.53.1">Time</span></strong><span class="koboSpan" id="kobo.54.1"> columns. </span><span class="koboSpan" id="kobo.54.2">As the numerical columns have been loaded as strings, we must convert them to the numerical </span><strong class="source-inline"><span class="koboSpan" id="kobo.55.1">double</span></strong><span class="koboSpan" id="kobo.56.1"> data type to be able to do calculations. </span><span class="koboSpan" id="kobo.56.2">Note that we have coded the operations on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.57.1">df</span></strong><span class="koboSpan" id="kobo.58.1"> DataFrame in separate lines for readability. </span><span class="koboSpan" id="kobo.58.2">We could alternatively chain the multiple operations in a </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">single line:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.60.1">
…
# Code in cell 5
df = </span><strong class="bold"><span class="koboSpan" id="kobo.61.1">spark.read</span></strong><span class="koboSpan" id="kobo.62.1">.csv(
    "file:///" + SparkFiles.get(DATASET_FILE),
    header=True, sep=";", </span><strong class="bold"><span class="koboSpan" id="kobo.63.1">inferSchema</span></strong><span class="koboSpan" id="kobo.64.1">=True)
</span><strong class="bold"><span class="koboSpan" id="kobo.65.1">df.cache()</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.66.1">df.count()</span></strong><span class="koboSpan" id="kobo.67.1">
…
# Code in cell 7
df = df.withColumn('Time', F.date_format('Time', 'HH:mm:ss'))
# Create timestamp column
df = df.withColumn('</span><strong class="bold"><span class="koboSpan" id="kobo.68.1">timestamp</span></strong><span class="koboSpan" id="kobo.69.1">', F.concat(df.Date, F.lit(" "), df.Time))
df = df.withColumn(
    '</span><strong class="bold"><span class="koboSpan" id="kobo.70.1">timestamp</span></strong><span class="koboSpan" id="kobo.71.1">',
    F.to_timestamp(df.</span><strong class="bold"><span class="koboSpan" id="kobo.72.1">timestamp</span></strong><span class="koboSpan" id="kobo.73.1">, 'yyyy-MM-dd HH:mm:ss'))
# Fix data types
df = df \
    .withColumn('Global_active_power',
    df.Global_active_power.cast('</span><strong class="bold"><span class="koboSpan" id="kobo.74.1">double</span></strong><span class="koboSpan" id="kobo.75.1">')) \
…
print("Schema:")
df.</span><strong class="bold"><span class="koboSpan" id="kobo.76.1">printSchema()</span></strong></pre> <p><span class="koboSpan" id="kobo.77.1">The schema </span><a id="_idIndexMarker518"/><span class="koboSpan" id="kobo.78.1">is inferred by the </span><strong class="source-inline"><span class="koboSpan" id="kobo.79.1">spark.read</span></strong><span class="koboSpan" id="kobo.80.1"> option </span><strong class="source-inline"><span class="koboSpan" id="kobo.81.1">inferSchema</span></strong><span class="koboSpan" id="kobo.82.1">. </span><span class="koboSpan" id="kobo.82.2">The data types before conversion, displayed with </span><strong class="source-inline"><span class="koboSpan" id="kobo.83.1">printSchema()</span></strong><span class="koboSpan" id="kobo.84.1">, are shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.85.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.86.1">.1</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.87.1">.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer077">
<span class="koboSpan" id="kobo.88.1"><img alt="" src="image/B18568_06_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.89.1">Figure 6.1: Inferred schema with data types</span></p>
<p><span class="koboSpan" id="kobo.90.1">The updated schema is as per </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.91.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.92.1">.2</span></em><span class="koboSpan" id="kobo.93.1">, showing the converted </span><span class="No-Break"><span class="koboSpan" id="kobo.94.1">data types.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer078">
<span class="koboSpan" id="kobo.95.1"><img alt="" src="image/B18568_06_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.96.1">Figure 6.2: Updated schema with converted data types</span></p>
<p><span class="koboSpan" id="kobo.97.1">We are now </span><a id="_idIndexMarker519"/><span class="koboSpan" id="kobo.98.1">ready to profile </span><span class="No-Break"><span class="koboSpan" id="kobo.99.1">the data.</span></span></p>
<h2 id="_idParaDest-120"><a id="_idTextAnchor120"/><span class="koboSpan" id="kobo.100.1">Data profiling</span></h2>
<p><span class="koboSpan" id="kobo.101.1">Data profiling involves analyzing the dataset’s structure, quality, and statistical properties. </span><span class="koboSpan" id="kobo.101.2">This helps </span><a id="_idIndexMarker520"/><span class="koboSpan" id="kobo.102.1">to identify anomalies, missing values, and </span><a id="_idIndexMarker521"/><span class="koboSpan" id="kobo.103.1">outliers, ensuring data integrity. </span><span class="koboSpan" id="kobo.103.2">This process can also be comprehensive, including the analysis of trends, seasonal patterns, and correlations, guiding more accurate forecasting </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">and modeling.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.105.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.106.1">Data profiling can also guide preprocessing steps such as normalization and transformation, covered in </span><a href="B18568_05.xhtml#_idTextAnchor103"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.107.1">Chapter 5</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.108.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.109.1">Apache Spark provides the convenient </span><strong class="source-inline"><span class="koboSpan" id="kobo.110.1">summary()</span></strong><span class="koboSpan" id="kobo.111.1"> function, as per the following code, for </span><span class="No-Break"><span class="koboSpan" id="kobo.112.1">summary statistics:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.113.1">
#### Summary Statistics
# Code in cell 10
df.</span><strong class="bold"><span class="koboSpan" id="kobo.114.1">summary()</span></strong><span class="koboSpan" id="kobo.115.1">.display()</span></pre> <p><span class="koboSpan" id="kobo.116.1">This generates the </span><span class="No-Break"><span class="koboSpan" id="kobo.117.1">following outcome:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer079">
<span class="koboSpan" id="kobo.118.1"><img alt="" src="image/B18568_06_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.119.1">Figure 6.3: Summary statistics</span></p>
<p><span class="koboSpan" id="kobo.120.1">While these summary statistics are useful, they are usually not sufficient. </span><span class="koboSpan" id="kobo.120.2">A data profiling tool such as YData Profiling, which we will look at next, provides more extensive analysis </span><span class="No-Break"><span class="koboSpan" id="kobo.121.1">and reporting.</span></span></p>
<p><span class="koboSpan" id="kobo.122.1">The following </span><a id="_idIndexMarker522"/><span class="koboSpan" id="kobo.123.1">code extract shows how to launch a Profile Report with YData. </span><span class="koboSpan" id="kobo.123.2">Notable </span><a id="_idIndexMarker523"/><span class="koboSpan" id="kobo.124.1">here is the use of a Pandas DataFrame, </span><strong class="source-inline"><span class="koboSpan" id="kobo.125.1">pdf</span></strong><span class="koboSpan" id="kobo.126.1">, and of the time series mode (</span><strong class="source-inline"><span class="koboSpan" id="kobo.127.1">tsmode</span></strong><span class="koboSpan" id="kobo.128.1"> parameter), with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.129.1">sortby</span></strong><span class="koboSpan" id="kobo.130.1"> parameter to sort by timestamp. </span><span class="koboSpan" id="kobo.130.2">We also want correlations to be included in the report. </span><span class="koboSpan" id="kobo.130.3">After the report is generated, it is converted to HTML for display with the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.131.1">to_html()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.132.1"> function.</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.133.1">
# Code in cell 12
…
profile = </span><strong class="bold"><span class="koboSpan" id="kobo.134.1">ProfileReport</span></strong><span class="koboSpan" id="kobo.135.1">(
    </span><strong class="bold"><span class="koboSpan" id="kobo.136.1">pdf</span></strong><span class="koboSpan" id="kobo.137.1">,
    title='Time Series Data Profiling',
    </span><strong class="bold"><span class="koboSpan" id="kobo.138.1">tsmode</span></strong><span class="koboSpan" id="kobo.139.1">=True,
    </span><strong class="bold"><span class="koboSpan" id="kobo.140.1">sortby</span></strong><span class="koboSpan" id="kobo.141.1">='</span><strong class="bold"><span class="koboSpan" id="kobo.142.1">timestamp</span></strong><span class="koboSpan" id="kobo.143.1">',
    infer_dtypes=False,
    interactions=None,
    missing_diagrams=None,
    </span><strong class="bold"><span class="koboSpan" id="kobo.144.1">correlations</span></strong><span class="koboSpan" id="kobo.145.1">={
        "auto": {"calculate": False},
        "pearson": {"calculate": True},
        "spearman": {"calculate": True}})
# Save the profiling report to an HTML file
profile.to_file("time_series_data_profiling_report.html")
# Show the profiling report in the notebook
report_html = profile.</span><strong class="bold"><span class="koboSpan" id="kobo.146.1">to_html()</span></strong><span class="koboSpan" id="kobo.147.1">
displayHTML(report_html)</span></pre> <p><span class="koboSpan" id="kobo.148.1">The generated </span><a id="_idIndexMarker524"/><span class="koboSpan" id="kobo.149.1">report contains an </span><strong class="bold"><span class="koboSpan" id="kobo.150.1">Overview</span></strong><span class="koboSpan" id="kobo.151.1"> section, as per </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.152.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.153.1">.4</span></em><span class="koboSpan" id="kobo.154.1">, with </span><a id="_idIndexMarker525"/><span class="koboSpan" id="kobo.155.1">an indication, among other things, of the number of variables (columns), observations (rows), and missing values and </span><span class="No-Break"><span class="koboSpan" id="kobo.156.1">duplicate counts.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer080">
<span class="koboSpan" id="kobo.157.1"><img alt="" src="image/B18568_06_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.158.1">Figure 6.4: Data profile report – Overview</span></p>
<p><span class="koboSpan" id="kobo.159.1">Scrolling down from </span><strong class="bold"><span class="koboSpan" id="kobo.160.1">Overview</span></strong><span class="koboSpan" id="kobo.161.1">, we can see column-specific statistics, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.162.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.163.1">.5</span></em><span class="koboSpan" id="kobo.164.1">, such as the minimum, maximum, mean, number of zeros, and number of </span><span class="No-Break"><span class="koboSpan" id="kobo.165.1">distinct values.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer081">
<span class="koboSpan" id="kobo.166.1"><img alt="" src="image/B18568_06_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.167.1">Figure 6.5: Data profile report – Details</span></p>
<p><span class="koboSpan" id="kobo.168.1">This section </span><a id="_idIndexMarker526"/><span class="koboSpan" id="kobo.169.1">has further sub-sections, such as </span><strong class="bold"><span class="koboSpan" id="kobo.170.1">Histogram</span></strong><span class="koboSpan" id="kobo.171.1">, showing the </span><a id="_idIndexMarker527"/><span class="koboSpan" id="kobo.172.1">distribution of values, and </span><strong class="bold"><span class="koboSpan" id="kobo.173.1">Gap analysis</span></strong><span class="koboSpan" id="kobo.174.1">, as per </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.175.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.176.1">.6</span></em><span class="koboSpan" id="kobo.177.1">, with indications of data gaps for </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">the column.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer082">
<span class="koboSpan" id="kobo.179.1"><img alt="" src="image/B18568_06_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.180.1">Figure 6.6: Data profile report – Gap analysis</span></p>
<p><span class="koboSpan" id="kobo.181.1">With the time series mode specified earlier, we also get a basic </span><strong class="bold"><span class="koboSpan" id="kobo.182.1">Time Series</span></strong><span class="koboSpan" id="kobo.183.1"> part of the report, shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.184.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.185.1">.7</span></em></span></p>
<div>
<div class="IMG---Figure" id="_idContainer083">
<span class="koboSpan" id="kobo.186.1"><img alt="" src="image/B18568_06_07.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.187.1">Figure 6.7: Data profile report – Time Series</span></p>
<p><span class="koboSpan" id="kobo.188.1">Other sections </span><a id="_idIndexMarker528"/><span class="koboSpan" id="kobo.189.1">of the report cover </span><strong class="bold"><span class="koboSpan" id="kobo.190.1">Alerts</span></strong><span class="koboSpan" id="kobo.191.1">, shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.192.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.193.1">.8</span></em><span class="koboSpan" id="kobo.194.1">, with outcomes </span><a id="_idIndexMarker529"/><span class="koboSpan" id="kobo.195.1">of tests run on the dataset, including time-series-specific ones, and a </span><strong class="bold"><span class="koboSpan" id="kobo.196.1">Reproduction</span></strong><span class="koboSpan" id="kobo.197.1"> section with details on the </span><span class="No-Break"><span class="koboSpan" id="kobo.198.1">profiling run.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer084">
<span class="koboSpan" id="kobo.199.1"><img alt="" src="image/B18568_06_08.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.200.1">Figure 6.8: Data profile report – Time Series</span></p>
<p><span class="koboSpan" id="kobo.201.1">This section </span><a id="_idIndexMarker530"/><span class="koboSpan" id="kobo.202.1">provided an example of how to perform data profiling on time series </span><a id="_idIndexMarker531"/><span class="koboSpan" id="kobo.203.1">data using YData Profiling and Apache Spark. </span><span class="koboSpan" id="kobo.203.2">Further </span><a id="_idIndexMarker532"/><span class="koboSpan" id="kobo.204.1">information on YData Profiling can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.205.1">here: </span></span><a href="https://github.com/ydataai/ydata-profiling"><span class="No-Break"><span class="koboSpan" id="kobo.206.1">https://github.com/ydataai/ydata-profiling</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.207.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.208.1">We will now drill down further in our understanding of the data, by analyzing the gaps in </span><span class="No-Break"><span class="koboSpan" id="kobo.209.1">the dataset.</span></span></p>
<h2 id="_idParaDest-121"><a id="_idTextAnchor121"/><span class="koboSpan" id="kobo.210.1">Gap analysis</span></h2>
<p><span class="koboSpan" id="kobo.211.1">In the </span><a id="_idIndexMarker533"/><span class="koboSpan" id="kobo.212.1">previous section, we mentioned gap analysis for </span><a id="_idIndexMarker534"/><span class="koboSpan" id="kobo.213.1">gaps in value for a specific column. </span><span class="koboSpan" id="kobo.213.2">Another consideration for time series data is gaps in the timeline itself, as in the following example with the household energy consumption dataset, where we are expecting values </span><span class="No-Break"><span class="koboSpan" id="kobo.214.1">every minute.</span></span></p>
<p><span class="koboSpan" id="kobo.215.1">In this case, we first calculate the time difference between consecutive timestamps using </span><strong class="source-inline"><span class="koboSpan" id="kobo.216.1">diff()</span></strong><span class="koboSpan" id="kobo.217.1">, as in the following code, with a pandas DataFrame, </span><strong class="source-inline"><span class="koboSpan" id="kobo.218.1">pdf</span></strong><span class="koboSpan" id="kobo.219.1">. </span><span class="koboSpan" id="kobo.219.2">If this is greater than </span><strong class="source-inline"><span class="koboSpan" id="kobo.220.1">1 minute</span></strong><span class="koboSpan" id="kobo.221.1">, we can flag the timestamp as having a </span><span class="No-Break"><span class="koboSpan" id="kobo.222.1">prior gap:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.223.1">
# test for gaps
# Code in cell 15
# test for gaps
pdf['gap_val'] = </span><strong class="bold"><span class="koboSpan" id="kobo.224.1">pdf</span></strong><span class="koboSpan" id="kobo.225.1">['timestamp'].sort_values().</span><strong class="bold"><span class="koboSpan" id="kobo.226.1">diff()</span></strong><span class="koboSpan" id="kobo.227.1">
pdf['gap'] = pdf['gap_val'] &gt; ps.to_timedelta('</span><strong class="bold"><span class="koboSpan" id="kobo.228.1">1 minute</span></strong><span class="koboSpan" id="kobo.229.1">')
pdf[pdf.gap]</span></pre> <p><span class="koboSpan" id="kobo.230.1">As </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.231.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.232.1">.9</span></em><span class="koboSpan" id="kobo.233.1"> shows, we found </span><a id="_idIndexMarker535"/><span class="koboSpan" id="kobo.234.1">3 gaps of 2 minutes each in </span><span class="No-Break"><span class="koboSpan" id="kobo.235.1">this example.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer085">
<span class="koboSpan" id="kobo.236.1"><img alt="" src="image/B18568_06_09.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.237.1">Figure 6.9: Gap analysis</span></p>
<p><span class="koboSpan" id="kobo.238.1">Depending </span><a id="_idIndexMarker536"/><span class="koboSpan" id="kobo.239.1">on the size of the gap and the nature of the dataset, we can adopt one of the </span><span class="No-Break"><span class="koboSpan" id="kobo.240.1">following approaches:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.241.1">Ignore </span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">the gap</span></span></li>
<li><span class="koboSpan" id="kobo.243.1">Aggregate, for example, use the mean value at a </span><span class="No-Break"><span class="koboSpan" id="kobo.244.1">higher interval</span></span></li>
<li><span class="koboSpan" id="kobo.245.1">Use one of the missing-value handling techniques we saw in </span><a href="B18568_05.xhtml#_idTextAnchor103"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.246.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.247.1">, such as </span><span class="No-Break"><span class="koboSpan" id="kobo.248.1">forward filling</span></span></li>
</ul>
<p class="callout-heading"><span class="koboSpan" id="kobo.249.1">Regular or irregular time series</span></p>
<p class="callout"><span class="koboSpan" id="kobo.250.1">The gap </span><a id="_idIndexMarker537"/><span class="koboSpan" id="kobo.251.1">analysis presented here assumes a regular time series. </span><span class="koboSpan" id="kobo.251.2">The approach </span><a id="_idIndexMarker538"/><span class="koboSpan" id="kobo.252.1">is slightly different in detecting gaps in the timeline of irregular time series. </span><span class="koboSpan" id="kobo.252.2">The previous example of checking for the absence of values at every minute interval is not applicable for an irregular time series. </span><span class="koboSpan" id="kobo.252.3">We will have to look at the distribution of the count of values over the timeline of the irregular time series and make reasonable assumptions about how regularly we expect values in the irregular time series. </span><span class="koboSpan" id="kobo.252.4">For instance, if we are considering the energy consumption of a household, the time series may be irregular at minute intervals, but based on historical data, we expect energy use every hour or daily. </span><span class="koboSpan" id="kobo.252.5">In this case, not having a data point on a given hour or day can be indicative of a gap. </span><span class="koboSpan" id="kobo.252.6">Once we have identified a gap, we can use the same approaches as discussed for regular time series, that is, forward filling or similar imputation, aggregation at higher intervals, or just ignoring </span><span class="No-Break"><span class="koboSpan" id="kobo.253.1">the gap.</span></span></p>
<p><span class="koboSpan" id="kobo.254.1">We discussed </span><a id="_idIndexMarker539"/><span class="koboSpan" id="kobo.255.1">here the specific problem of gaps in the time </span><a id="_idIndexMarker540"/><span class="koboSpan" id="kobo.256.1">series. </span><span class="koboSpan" id="kobo.256.2">We mentioned that, to identify gaps, we can look at the distribution of the data, which will be </span><span class="No-Break"><span class="koboSpan" id="kobo.257.1">covered next.</span></span></p>
<h2 id="_idParaDest-122"><a id="_idTextAnchor122"/><span class="koboSpan" id="kobo.258.1">Distribution analysis</span></h2>
<p><span class="koboSpan" id="kobo.259.1">Distribution analysis of time series provides an understanding of the underlying patterns and characteristics </span><a id="_idIndexMarker541"/><span class="koboSpan" id="kobo.260.1">of the data, such as skewness, kurtosis, and outliers. </span><span class="koboSpan" id="kobo.260.2">This </span><a id="_idIndexMarker542"/><span class="koboSpan" id="kobo.261.1">helps detect deviations from normal distribution, trends, and seasonal patterns, and visualize the variability of the time series. </span><span class="koboSpan" id="kobo.261.2">This understanding then feeds into choosing the appropriate statistical models and forecasting methods. </span><span class="koboSpan" id="kobo.261.3">This is required as models are built on assumptions of the distribution of the time series. </span><span class="koboSpan" id="kobo.261.4">Done correctly, distribution analysis ensures that model assumptions are met. </span><span class="koboSpan" id="kobo.261.5">This also improves the accuracy and reliability of </span><span class="No-Break"><span class="koboSpan" id="kobo.262.1">the predictions.</span></span></p>
<p><span class="koboSpan" id="kobo.263.1">In this section, we will examine a few examples of distribution analysis, starting with the profiling output of </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.264.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.265.1">.5</span></em><span class="koboSpan" id="kobo.266.1">, which shows a kurtosis of 2.98 and a skewness of 1.46. </span><span class="koboSpan" id="kobo.266.2">Let’s explain what this means by first defining </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">these terms.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.268.1">Kurtosis</span></strong><span class="koboSpan" id="kobo.269.1"> indicates how </span><a id="_idIndexMarker543"/><span class="koboSpan" id="kobo.270.1">peaked or flat a distribution is compared to a normal distribution. </span><span class="koboSpan" id="kobo.270.2">A value greater than 2, as in our example in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.271.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.272.1">.5</span></em><span class="koboSpan" id="kobo.273.1">, indicates the distribution is too peaked. </span><span class="koboSpan" id="kobo.273.2">Less than -2 means </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">too flat.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.275.1">Skewness</span></strong><span class="koboSpan" id="kobo.276.1"> indicates how </span><a id="_idIndexMarker544"/><span class="koboSpan" id="kobo.277.1">centered and symmetric the distribution is compared to a normal distribution. </span><span class="koboSpan" id="kobo.277.2">A value between -1 and 1 is considered near normal, between -2 and 2, as in the example in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.278.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.279.1">.5</span></em><span class="koboSpan" id="kobo.280.1">, is acceptable, and below -2 or above 2 is </span><span class="No-Break"><span class="koboSpan" id="kobo.281.1">not normal.</span></span></p>
<p><span class="koboSpan" id="kobo.282.1">When both kurtosis and skewness are zero, we have a perfectly normal distribution, which is quite unlikely to be seen with </span><span class="No-Break"><span class="koboSpan" id="kobo.283.1">real data.</span></span></p>
<p><span class="koboSpan" id="kobo.284.1">Let’s now do some further distribution analysis with the following code extract. </span><span class="koboSpan" id="kobo.284.2">We want to understand the frequency distribution of </span><strong class="source-inline"><span class="koboSpan" id="kobo.285.1">Global_active_power</span></strong><span class="koboSpan" id="kobo.286.1">, the distribution </span><a id="_idIndexMarker545"/><span class="koboSpan" id="kobo.287.1">by day of the week, </span><strong class="source-inline"><span class="koboSpan" id="kobo.288.1">dayOfWeek</span></strong><span class="koboSpan" id="kobo.289.1">, and the </span><a id="_idIndexMarker546"/><span class="koboSpan" id="kobo.290.1">hour of the day. </span><span class="koboSpan" id="kobo.290.2">We will use the Seaborn (</span><strong class="source-inline"><span class="koboSpan" id="kobo.291.1">sns</span></strong><span class="koboSpan" id="kobo.292.1">) visualization library for the plots, with the pandas DataFrame, </span><strong class="source-inline"><span class="koboSpan" id="kobo.293.1">pdf</span></strong><span class="koboSpan" id="kobo.294.1">, passed as </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">a parameter:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.296.1">
#### Distribution Analysis
# Code in cell 17
…
# Extract day and hour
df = df.withColumn("</span><strong class="bold"><span class="koboSpan" id="kobo.297.1">dayOfWeek</span></strong><span class="koboSpan" id="kobo.298.1">", F.dayofweek(F.col("timestamp")))
df = df.withColumn("</span><strong class="bold"><span class="koboSpan" id="kobo.299.1">hour</span></strong><span class="koboSpan" id="kobo.300.1">", F.hour(F.col("timestamp")))
…
# Distribution analysis using Seaborn and Matplotlib
…
</span><strong class="bold"><span class="koboSpan" id="kobo.301.1">sns</span></strong><span class="koboSpan" id="kobo.302.1">.histplot(</span><strong class="bold"><span class="koboSpan" id="kobo.303.1">pdf</span></strong><span class="koboSpan" id="kobo.304.1">['</span><strong class="bold"><span class="koboSpan" id="kobo.305.1">Global_active_power</span></strong><span class="koboSpan" id="kobo.306.1">'], kde=True, bins=30)
plt.title(
    'Distribution of Global_active_power in Time Series Data'
)
…
# Boxplot to visualize the distribution per dayOfWeek
…
sns.boxplot(x='</span><strong class="bold"><span class="koboSpan" id="kobo.307.1">dayOfWeek</span></strong><span class="koboSpan" id="kobo.308.1">', y='</span><strong class="bold"><span class="koboSpan" id="kobo.309.1">Global_active_power</span></strong><span class="koboSpan" id="kobo.310.1">', data=pdf)
plt.title(
    'Daily Distribution of Global_active_power in Time Series Data'
)
…
# Boxplot to visualize the distribution per hour
…
sns.boxplot(x='</span><strong class="bold"><span class="koboSpan" id="kobo.311.1">hour</span></strong><span class="koboSpan" id="kobo.312.1">', y='</span><strong class="bold"><span class="koboSpan" id="kobo.313.1">Global_active_power</span></strong><span class="koboSpan" id="kobo.314.1">', data=pdf)
plt.title(
    'Hourly Distribution of Global_active_power in Time Series Data'
)
…</span></pre> <p><span class="koboSpan" id="kobo.315.1">We can </span><a id="_idIndexMarker547"/><span class="koboSpan" id="kobo.316.1">see the frequency of occurrence of the </span><a id="_idIndexMarker548"/><span class="koboSpan" id="kobo.317.1">different values of </span><strong class="source-inline"><span class="koboSpan" id="kobo.318.1">Global_active_power</span></strong><span class="koboSpan" id="kobo.319.1"> in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.320.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.321.1">.10</span></em><span class="koboSpan" id="kobo.322.1">, with the skewness to </span><span class="No-Break"><span class="koboSpan" id="kobo.323.1">the left.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer086">
<span class="koboSpan" id="kobo.324.1"><img alt="" src="image/B18568_06_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.325.1">Figure 6.10: Distribution by frequency</span></p>
<p><span class="koboSpan" id="kobo.326.1">If we look at the distribution by day of the week, as in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.327.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.328.1">.11</span></em><span class="koboSpan" id="kobo.329.1">, power consumption during the weekends is higher, as can be expected for a household, with 1 on the </span><em class="italic"><span class="koboSpan" id="kobo.330.1">x</span></em><span class="koboSpan" id="kobo.331.1"> axis representing Sundays and 7 Saturdays. </span><span class="koboSpan" id="kobo.331.2">The distribution is also over a broader range of values </span><span class="No-Break"><span class="koboSpan" id="kobo.332.1">these days.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer087">
<span class="koboSpan" id="kobo.333.1"><img alt="" src="image/B18568_06_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.334.1">Figure 6.11: Distribution by day of the week</span></p>
<p><span class="koboSpan" id="kobo.335.1">The distribution </span><a id="_idIndexMarker549"/><span class="koboSpan" id="kobo.336.1">by hour of the day, as in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.337.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.338.1">.12</span></em><span class="koboSpan" id="kobo.339.1">, shows higher </span><a id="_idIndexMarker550"/><span class="koboSpan" id="kobo.340.1">power consumption during the morning and evening, again as can be expected for </span><span class="No-Break"><span class="koboSpan" id="kobo.341.1">a household.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer088">
<span class="koboSpan" id="kobo.342.1"><img alt="" src="image/B18568_06_12.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.343.1">Figure 6.12: Distribution by hour of the day</span></p>
<p><span class="koboSpan" id="kobo.344.1">You will also notice in the distribution plots the values that are flagged as outliers, lying beyond the </span><a id="_idIndexMarker551"/><span class="koboSpan" id="kobo.345.1">whiskers. </span><span class="koboSpan" id="kobo.345.2">These are at a 1.5 </span><strong class="bold"><span class="koboSpan" id="kobo.346.1">inter-quartile range</span></strong><span class="koboSpan" id="kobo.347.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.348.1">IQR</span></strong><span class="koboSpan" id="kobo.349.1">) above the third quartile. </span><span class="koboSpan" id="kobo.349.2">You can use other thresholds for outliers, as in </span><a href="B18568_05.xhtml#_idTextAnchor103"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.350.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.351.1">, where we used a cutoff on the </span><span class="No-Break"><span class="koboSpan" id="kobo.352.1">z-score value.</span></span></p>
<h2 id="_idParaDest-123"><a id="_idTextAnchor123"/><span class="koboSpan" id="kobo.353.1">Visualizations</span></h2>
<p><span class="koboSpan" id="kobo.354.1">As we have seen so far in this book and, more specifically, this chapter, visualizations play an important </span><a id="_idIndexMarker552"/><span class="koboSpan" id="kobo.355.1">role in time series analysis. </span><span class="koboSpan" id="kobo.355.2">By providing us </span><a id="_idIndexMarker553"/><span class="koboSpan" id="kobo.356.1">with an intuitive and immediate understanding of the data’s underlying patterns, they help to identify seasonal variations, trends, and anomalies that might not otherwise be seen from raw data alone. </span><span class="koboSpan" id="kobo.356.2">Furthermore, visualizations facilitate the detection of correlations, cycles, and structural changes over time, contributing to better forecasting </span><span class="No-Break"><span class="koboSpan" id="kobo.357.1">and decision-making.</span></span></p>
<p><span class="koboSpan" id="kobo.358.1">Fundamentally, (and this is not only true for time series analysis) visualizations aid in communicating complex insights to stakeholders and, in doing so, improve their ability to understand and </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">act accordingly.</span></span></p>
<p><span class="koboSpan" id="kobo.360.1">Building on the techniques for statistical analysis seen in this chapter, we will now move on to other important techniques to consider while analyzing  time series—resampling, decomposition, </span><span class="No-Break"><span class="koboSpan" id="kobo.361.1">and stationarity.</span></span></p>
<h1 id="_idParaDest-124"><a id="_idTextAnchor124"/><span class="koboSpan" id="kobo.362.1">Resampling, decomposition, and stationarity</span></h1>
<p><span class="koboSpan" id="kobo.363.1">This section </span><a id="_idIndexMarker554"/><span class="koboSpan" id="kobo.364.1">details additional techniques used in time series analysis, introduced in </span><a href="B18568_01.xhtml#_idTextAnchor016"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.365.1">Chapter 1</span></em></span></a><span class="koboSpan" id="kobo.366.1">. </span><span class="koboSpan" id="kobo.366.2">We will see code examples of how to implement </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">these techniques.</span></span></p>
<h2 id="_idParaDest-125"><a id="_idTextAnchor125"/><span class="koboSpan" id="kobo.368.1">Resampling and aggregation</span></h2>
<p><span class="koboSpan" id="kobo.369.1">Resampling and aggregation are used in time series analysis to transform and analyze data at different time scales. </span><strong class="bold"><span class="koboSpan" id="kobo.370.1">Resampling</span></strong><span class="koboSpan" id="kobo.371.1"> is changing the frequency of the time series, such as </span><a id="_idIndexMarker555"/><span class="koboSpan" id="kobo.372.1">converting hourly data to daily data, which can reveal trends and patterns at different time frequencies. </span><strong class="bold"><span class="koboSpan" id="kobo.373.1">Aggregation</span></strong><span class="koboSpan" id="kobo.374.1">, on the other hand, is the summarizing of data over specified intervals and is used in conjunction with resampling to calculate the resampled value. </span><span class="koboSpan" id="kobo.374.2">This can reduce noise, handle missing values, and convert an irregular time series to a </span><span class="No-Break"><span class="koboSpan" id="kobo.375.1">regular series.</span></span></p>
<p><span class="koboSpan" id="kobo.376.1">The following code extract shows the resampling at different intervals, together with the aggregation. </span><span class="koboSpan" id="kobo.376.2">The original dataset has data every minute. </span><span class="koboSpan" id="kobo.376.3">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.377.1">resample('h').mean()</span></strong><span class="koboSpan" id="kobo.378.1"> applied to the pandas DataFrame, </span><strong class="source-inline"><span class="koboSpan" id="kobo.379.1">pdf</span></strong><span class="koboSpan" id="kobo.380.1">, we resample this value to the mean over </span><span class="No-Break"><span class="koboSpan" id="kobo.381.1">the hour:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.382.1">
#### Resampling and Aggregation
# Code in cell 22
…
# Resample data to hourly, daily and weekly frequency and aggregate by # mean
hourly_resampled = </span><strong class="bold"><span class="koboSpan" id="kobo.383.1">pdf</span></strong><span class="koboSpan" id="kobo.384.1">.</span><strong class="bold"><span class="koboSpan" id="kobo.385.1">resample('h').mean()</span></strong><span class="koboSpan" id="kobo.386.1">
hourly_resampled_s = pdf.resample('h').std()
daily_resampled = pdf.resample('d').mean()
daily_resampled_s = pdf.resample('d').std()
weekly_resampled = pdf.resample('w').mean()
weekly_resampled_s = pdf.resample('w').std()
…</span></pre> <p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.387.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.388.1">.13</span></em><span class="koboSpan" id="kobo.389.1"> shows the </span><a id="_idIndexMarker556"/><span class="koboSpan" id="kobo.390.1">outcome of the </span><span class="No-Break"><span class="koboSpan" id="kobo.391.1">hourly resampling.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer089">
<span class="koboSpan" id="kobo.392.1"><img alt="" src="image/B18568_06_13.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.393.1">Figure 6.13: Resampled hourly</span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.394.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.395.1">.14</span></em><span class="koboSpan" id="kobo.396.1"> shows the outcome of the </span><span class="No-Break"><span class="koboSpan" id="kobo.397.1">daily resampling.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer090">
<span class="koboSpan" id="kobo.398.1"><img alt="" src="image/B18568_06_14.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.399.1">Figure 6.14: Resampled daily</span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.400.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.401.1">.15</span></em><span class="koboSpan" id="kobo.402.1"> shows the </span><a id="_idIndexMarker557"/><span class="koboSpan" id="kobo.403.1">outcome of the </span><span class="No-Break"><span class="koboSpan" id="kobo.404.1">weekly resampling.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer091">
<span class="koboSpan" id="kobo.405.1"><img alt="" src="image/B18568_06_15.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.406.1">Figure 6.15: Resampled weekly</span></p>
<p><span class="koboSpan" id="kobo.407.1">With these examples, we have resampled and aggregated time series data using Apache Spark. </span><span class="koboSpan" id="kobo.407.2">We will next expand on the time series decomposition of the resampled </span><span class="No-Break"><span class="koboSpan" id="kobo.408.1">time series.</span></span></p>
<h2 id="_idParaDest-126"><a id="_idTextAnchor126"/><span class="koboSpan" id="kobo.409.1">Decomposition</span></h2>
<p><span class="koboSpan" id="kobo.410.1">As introduced in </span><a href="B18568_01.xhtml#_idTextAnchor016"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.411.1">Chapter 1</span></em></span></a><span class="koboSpan" id="kobo.412.1">, decomposition breaks down the time series into its fundamental </span><a id="_idIndexMarker558"/><span class="koboSpan" id="kobo.413.1">components: trend, seasonality, and residuals. </span><span class="koboSpan" id="kobo.413.2">This separation helps uncover underlying patterns within the data more clearly. </span><span class="koboSpan" id="kobo.413.3">The trend shows long-term movement, while seasonal components show repeating patterns. </span><span class="koboSpan" id="kobo.413.4">Residuals highlight any deviation from the trend and seasonal components. </span><span class="koboSpan" id="kobo.413.5">This decomposition allows for each component to be analyzed and </span><span class="No-Break"><span class="koboSpan" id="kobo.414.1">addressed individually.</span></span></p>
<p><span class="koboSpan" id="kobo.415.1">The following code extract shows the decomposition of time series using </span><strong class="source-inline"><span class="koboSpan" id="kobo.416.1">seasonal_decompose</span></strong><span class="koboSpan" id="kobo.417.1"> from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.418.1">statsmodels</span></strong><span class="koboSpan" id="kobo.419.1"> library. </span><span class="koboSpan" id="kobo.419.2">In </span><a href="B18568_01.xhtml#_idTextAnchor016"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.420.1">Chapter 1</span></em></span></a><span class="koboSpan" id="kobo.421.1">, we used a different </span><span class="No-Break"><span class="koboSpan" id="kobo.422.1">library, </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.423.1">Prophet</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.424.1">.</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.425.1">
# Code in cell 30
…
from </span><strong class="bold"><span class="koboSpan" id="kobo.426.1">statsmodels</span></strong><span class="koboSpan" id="kobo.427.1">.tsa.seasonal import </span><strong class="bold"><span class="koboSpan" id="kobo.428.1">seasonal_decompose</span></strong><span class="koboSpan" id="kobo.429.1">
# Perform seasonal decomposition
hourly_result = </span><strong class="bold"><span class="koboSpan" id="kobo.430.1">seasonal_decompose</span></strong><span class="koboSpan" id="kobo.431.1">(
    hourly_resampled['Global_active_power'])
daily_result = </span><strong class="bold"><span class="koboSpan" id="kobo.432.1">seasonal_decompose</span></strong><span class="koboSpan" id="kobo.433.1">(
    daily_resampled['Global_active_power'])
…</span></pre> <p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.434.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.435.1">.16</span></em><span class="koboSpan" id="kobo.436.1"> shows the components of the hourly resampled time series. </span><span class="koboSpan" id="kobo.436.2">The seasonal component </span><a id="_idIndexMarker559"/><span class="koboSpan" id="kobo.437.1">shows a pattern, with each repeating pattern corresponding to a day, and the ups in power consumption every morning and evening </span><span class="No-Break"><span class="koboSpan" id="kobo.438.1">are visible.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer092">
<span class="koboSpan" id="kobo.439.1"><img alt="" src="image/B18568_06_16.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.440.1">Figure 6.16: Decomposition of hourly data</span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.441.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.442.1">.17</span></em><span class="koboSpan" id="kobo.443.1"> shows the components of the daily resampled time series. </span><span class="koboSpan" id="kobo.443.2">The seasonal component shows a pattern, with each repeating pattern corresponding to a week, and the ups in power consumption every weekend </span><span class="No-Break"><span class="koboSpan" id="kobo.444.1">are visible.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer093">
<span class="koboSpan" id="kobo.445.1"><img alt="" src="image/B18568_06_17.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.446.1">Figure 6.17: Decomposition of daily data</span></p>
<p><span class="koboSpan" id="kobo.447.1">Now that we have performed time series decomposition using Apache Spark and </span><strong class="source-inline"><span class="koboSpan" id="kobo.448.1">statsmodels</span></strong><span class="koboSpan" id="kobo.449.1"> for time series at different resampling intervals, let's discuss the next technique. </span></p>
<h2 id="_idParaDest-127"><a id="_idTextAnchor127"/><span class="koboSpan" id="kobo.450.1">Stationarity</span></h2>
<p><span class="koboSpan" id="kobo.451.1">Another key concept related to time series data, introduced in </span><a href="B18568_01.xhtml#_idTextAnchor016"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.452.1">Chapter 1</span></em></span></a><span class="koboSpan" id="kobo.453.1">, stationarity concerns the </span><a id="_idIndexMarker560"/><span class="koboSpan" id="kobo.454.1">statistical properties of the series, such as mean, variance, and autocorrelation remaining constant over time. </span><span class="koboSpan" id="kobo.454.2">This is an assumption on which </span><a id="_idIndexMarker561"/><span class="koboSpan" id="kobo.455.1">time series models, such as </span><strong class="bold"><span class="koboSpan" id="kobo.456.1">AutoRegressive Integrated Moving Average</span></strong><span class="koboSpan" id="kobo.457.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.458.1">ARIMA</span></strong><span class="koboSpan" id="kobo.459.1">) are built. </span><span class="koboSpan" id="kobo.459.2">A series must be identified and converted to stationary before using such models. </span><span class="koboSpan" id="kobo.459.3">In general, stationary time series facilitate analysis and improve </span><span class="No-Break"><span class="koboSpan" id="kobo.460.1">model accuracy.</span></span></p>
<p><span class="koboSpan" id="kobo.461.1">The first step in handling non-stationarity is to check the time series, which we will look </span><span class="No-Break"><span class="koboSpan" id="kobo.462.1">at next.</span></span></p>
<h3><span class="koboSpan" id="kobo.463.1">Check</span></h3>
<p><span class="koboSpan" id="kobo.464.1">The </span><strong class="bold"><span class="koboSpan" id="kobo.465.1">Augmented Dickey-Fuller</span></strong><span class="koboSpan" id="kobo.466.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.467.1">ADF</span></strong><span class="koboSpan" id="kobo.468.1">) test and the </span><strong class="bold"><span class="koboSpan" id="kobo.469.1">Kwiatkowski-Phillips-Schmidt-Shin</span></strong><span class="koboSpan" id="kobo.470.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.471.1">KPSS</span></strong><span class="koboSpan" id="kobo.472.1">) test </span><a id="_idIndexMarker562"/><span class="koboSpan" id="kobo.473.1">are commonly used statistical </span><a id="_idIndexMarker563"/><span class="koboSpan" id="kobo.474.1">tests to check for stationarity. </span><span class="koboSpan" id="kobo.474.2">Without going into the details of these tests, we can say they calculate a value, which is called the p-value. </span><span class="koboSpan" id="kobo.474.3">A value of p &lt; 0.05 for ADF means that the series is stationary. </span><span class="koboSpan" id="kobo.474.4">Additionally, we </span><a id="_idIndexMarker564"/><span class="koboSpan" id="kobo.475.1">can check for stationarity </span><a id="_idIndexMarker565"/><span class="koboSpan" id="kobo.476.1">by visual inspection of the time series plot and </span><strong class="bold"><span class="koboSpan" id="kobo.477.1">autocorrelation function</span></strong><span class="koboSpan" id="kobo.478.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.479.1">ACF</span></strong><span class="koboSpan" id="kobo.480.1">) plots, and by comparing summary statistics over different time periods. </span><span class="koboSpan" id="kobo.480.2">Mean, variance, and autocorrelation remaining constant across time suggest stationarity. </span><span class="koboSpan" id="kobo.480.3">Significant changes </span><span class="No-Break"><span class="koboSpan" id="kobo.481.1">indicate non-stationarity.</span></span></p>
<p><span class="koboSpan" id="kobo.482.1">The following example code checks for stationarity using the ADF test, </span><strong class="source-inline"><span class="koboSpan" id="kobo.483.1">adfuller</span></strong><span class="koboSpan" id="kobo.484.1">, from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.485.1">statsmodels</span></strong><span class="koboSpan" id="kobo.486.1"> library. </span><span class="koboSpan" id="kobo.486.2">We will use the hourly resampled data in </span><span class="No-Break"><span class="koboSpan" id="kobo.487.1">this example.</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.488.1">
#### Stationarity
# Code in cell 33
…
from </span><strong class="bold"><span class="koboSpan" id="kobo.489.1">statsmodels</span></strong><span class="koboSpan" id="kobo.490.1">.tsa.stattools import </span><strong class="bold"><span class="koboSpan" id="kobo.491.1">adfuller</span></strong><span class="koboSpan" id="kobo.492.1">
# Perform Augmented Dickey-Fuller test
result = </span><strong class="bold"><span class="koboSpan" id="kobo.493.1">adfuller</span></strong><span class="koboSpan" id="kobo.494.1">(hourly_resampled)
# if Test statistic &lt; Critical Value and p-value &lt; 0.05
#   reject the Null hypothesis, time series does not have a unit root
#   series is stationary
…</span></pre> <p><span class="koboSpan" id="kobo.495.1">In this case, the p-value, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.496.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.497.1">.18</span></em><span class="koboSpan" id="kobo.498.1">, is less than 0.05, and we can conclude the time series is stationary from the </span><span class="No-Break"><span class="koboSpan" id="kobo.499.1">ADF test.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer094">
<span class="koboSpan" id="kobo.500.1"><img alt="" src="image/B18568_06_18.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.501.1">Figure 6.18: ADF test results – Power consumption dataset</span></p>
<p><span class="koboSpan" id="kobo.502.1">Running the </span><a id="_idIndexMarker566"/><span class="koboSpan" id="kobo.503.1">ADF test on the dataset for the annual mean temperature of Mauritius, used in </span><a href="B18568_01.xhtml#_idTextAnchor016"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.504.1">Chapter 1</span></em></span></a><span class="koboSpan" id="kobo.505.1">, gives a p-value greater than 0.05, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.506.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.507.1">.19</span></em><span class="koboSpan" id="kobo.508.1">. </span><span class="koboSpan" id="kobo.508.2">In this case, we can conclude that the time series </span><span class="No-Break"><span class="koboSpan" id="kobo.509.1">is non-stationary.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer095">
<span class="koboSpan" id="kobo.510.1"><img alt="" src="image/B18568_06_19.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.511.1">Figure 6.19: ADF test results – Annual mean temperature dataset</span></p>
<p><span class="koboSpan" id="kobo.512.1">As we now have a non-stationary series, we will next consider converting it to a stationary series </span><span class="No-Break"><span class="koboSpan" id="kobo.513.1">using differencing.</span></span></p>
<h3><span class="koboSpan" id="kobo.514.1">Differencing</span></h3>
<p><span class="koboSpan" id="kobo.515.1">The following code extract shows the conversion of a non-stationary time series to a stationary </span><a id="_idIndexMarker567"/><span class="koboSpan" id="kobo.516.1">one. </span><span class="koboSpan" id="kobo.516.2">We’ll use differencing, a common method to remove trends and seasonality, which can make the time series stationary. </span><span class="koboSpan" id="kobo.516.3">By using a combination of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.517.1">Window</span></strong><span class="koboSpan" id="kobo.518.1"> function and </span><strong class="source-inline"><span class="koboSpan" id="kobo.519.1">lag</span></strong><span class="koboSpan" id="kobo.520.1"> of 1, we can find the difference between an annual mean and the previous </span><span class="No-Break"><span class="koboSpan" id="kobo.521.1">year’s value.</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.522.1">
###### Differencing
# Code in cell 41
…
from pyspark.sql.window import </span><strong class="bold"><span class="koboSpan" id="kobo.523.1">Window</span></strong><span class="koboSpan" id="kobo.524.1">
# Calculate the difference (differencing)
window = </span><strong class="bold"><span class="koboSpan" id="kobo.525.1">Window</span></strong><span class="koboSpan" id="kobo.526.1">.orderBy("year")
df2_ = df2.withColumn(
    "annual_mean_diff",
    F.col("annual_mean") - F.</span><strong class="bold"><span class="koboSpan" id="kobo.527.1">lag</span></strong><span class="koboSpan" id="kobo.528.1">(
        F.col("annual_mean"), 1
    ).over(window))
…</span></pre> <p><span class="koboSpan" id="kobo.529.1">We can see </span><a id="_idIndexMarker568"/><span class="koboSpan" id="kobo.530.1">the original time series compared to the differenced time series in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.531.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.532.1">.20</span></em><span class="koboSpan" id="kobo.533.1">. </span><span class="koboSpan" id="kobo.533.2">The removal of the trend </span><span class="No-Break"><span class="koboSpan" id="kobo.534.1">is visible.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer096">
<span class="koboSpan" id="kobo.535.1"><img alt="" src="image/B18568_06_20.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.536.1">Figure 6.20: Differencing – Annual mean temperature dataset</span></p>
<p><span class="koboSpan" id="kobo.537.1">Running the ADF test after differencing, gives a p-value less than 0.05, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.538.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.539.1">.21</span></em><span class="koboSpan" id="kobo.540.1">. </span><span class="koboSpan" id="kobo.540.2">We can conclude that the difference in time series </span><span class="No-Break"><span class="koboSpan" id="kobo.541.1">is stationary.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer097">
<span class="koboSpan" id="kobo.542.1"><img alt="" src="image/B18568_06_21.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.543.1">Figure 6.21: ADF test results – Differenced annual mean temperature dataset</span></p>
<p><span class="koboSpan" id="kobo.544.1">Building on our understanding of </span><a id="_idIndexMarker569"/><span class="koboSpan" id="kobo.545.1">techniques for exploratory analysis learned in this section, we will now move on to the last section of this chapter, which is about correlation of  time </span><span class="No-Break"><span class="koboSpan" id="kobo.546.1">series data.</span></span></p>
<h1 id="_idParaDest-128"><a id="_idTextAnchor128"/><span class="koboSpan" id="kobo.547.1">Correlation analysis</span></h1>
<p><span class="koboSpan" id="kobo.548.1">Correlation </span><a id="_idIndexMarker570"/><span class="koboSpan" id="kobo.549.1">measures the relationship between two variables. </span><span class="koboSpan" id="kobo.549.2">This relationship can be causal, whether one is the result of the other. </span><span class="koboSpan" id="kobo.549.3">This section will explore the different types of correlation applicable to </span><span class="No-Break"><span class="koboSpan" id="kobo.550.1">time series.</span></span></p>
<h2 id="_idParaDest-129"><a id="_idTextAnchor129"/><span class="koboSpan" id="kobo.551.1">Autocorrelation</span></h2>
<p><span class="koboSpan" id="kobo.552.1">The </span><strong class="bold"><span class="koboSpan" id="kobo.553.1">AutoCorrelation Function</span></strong><span class="koboSpan" id="kobo.554.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.555.1">ACF</span></strong><span class="koboSpan" id="kobo.556.1">) measures the relationship between a time series and </span><a id="_idIndexMarker571"/><span class="koboSpan" id="kobo.557.1">its past values. </span><span class="koboSpan" id="kobo.557.2">High autocorrelation indicates </span><a id="_idIndexMarker572"/><span class="koboSpan" id="kobo.558.1">that past values have a strong influence on future values. </span><span class="koboSpan" id="kobo.558.2">This information can then be used to build predictive models, for instance, in selecting the right parameters for models such as ARIMA, thereby enhancing the robustness of the analysis. </span><span class="koboSpan" id="kobo.558.3">Understanding autocorrelation also helps in </span><a id="_idIndexMarker573"/><span class="koboSpan" id="kobo.559.1">identifying seasonal effects </span><span class="No-Break"><span class="koboSpan" id="kobo.560.1">and cycles.</span></span></p>
<p><span class="koboSpan" id="kobo.561.1">The </span><strong class="bold"><span class="koboSpan" id="kobo.562.1">Partial AutoCorrelation Function</span></strong><span class="koboSpan" id="kobo.563.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.564.1">PACF</span></strong><span class="koboSpan" id="kobo.565.1">) similarly measures the relationship between a variable and its past values, but contrary to the ACF, with the PACF we discount the effect of values of the time series at all </span><span class="No-Break"><span class="koboSpan" id="kobo.566.1">shorter lags.</span></span></p>
<h3><span class="koboSpan" id="kobo.567.1">Check</span></h3>
<p><span class="koboSpan" id="kobo.568.1">The following </span><a id="_idIndexMarker574"/><span class="koboSpan" id="kobo.569.1">code shows how you can check for autocorrelation and partial autocorrelation using Apache Spark and </span><strong class="source-inline"><span class="koboSpan" id="kobo.570.1">plot_acf</span></strong><span class="koboSpan" id="kobo.571.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.572.1">plt_pacf</span></strong><span class="koboSpan" id="kobo.573.1"> from the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.574.1">statsmodels</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.575.1"> library.</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.576.1">
#### Autocorrelation
# Code in cell 45
from </span><strong class="bold"><span class="koboSpan" id="kobo.577.1">statsmodels</span></strong><span class="koboSpan" id="kobo.578.1">.graphics.tsaplots import </span><strong class="bold"><span class="koboSpan" id="kobo.579.1">plot_acf</span></strong><span class="koboSpan" id="kobo.580.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.581.1">plot_pacf</span></strong><span class="koboSpan" id="kobo.582.1">
# Plot Autocorrelation Function (ACF)
plt.figure(figsize=(12, 6))
</span><strong class="bold"><span class="koboSpan" id="kobo.583.1">plot_acf</span></strong><span class="koboSpan" id="kobo.584.1">(hourly_resampled['Global_active_power'], lags=3*24)
plt.title('Autocorrelation Function (ACF)')
plt.show()
# Plot Partial Autocorrelation Function (PACF)
plt.figure(figsize=(12, 6))
</span><strong class="bold"><span class="koboSpan" id="kobo.585.1">plot_pacf</span></strong><span class="koboSpan" id="kobo.586.1">(hourly_resampled['Global_active_power'], lags=3*24)
plt.title('Partial Autocorrelation Function (PACF)')
plt.show()
…</span></pre> <p><span class="koboSpan" id="kobo.587.1">The resulting </span><a id="_idIndexMarker575"/><span class="koboSpan" id="kobo.588.1">ACF and PACF plots are shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.589.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.590.1">.22</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.591.1">.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer098">
<span class="koboSpan" id="kobo.592.1"><img alt="" src="image/B18568_06_22.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.593.1">Figure 6.22: ACF and PACF plots</span></p>
<p><span class="koboSpan" id="kobo.594.1">The outcomes </span><a id="_idIndexMarker576"/><span class="koboSpan" id="kobo.595.1">of ACF and PACF indicate the nature of the time series and guide the selection of the appropriate models and parameters for forecasting. </span><span class="koboSpan" id="kobo.595.2">Let’s now make sense of these plots and how we can use </span><span class="No-Break"><span class="koboSpan" id="kobo.596.1">their outcome.</span></span></p>
<h3><span class="koboSpan" id="kobo.597.1">Interpretation of ACF</span></h3>
<p><span class="koboSpan" id="kobo.598.1">We will consider the peaks and the decay from the ACF plot to interpret the outcome, using the upper graph in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.599.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.600.1">.22</span></em><span class="koboSpan" id="kobo.601.1"> as </span><span class="No-Break"><span class="koboSpan" id="kobo.602.1">an example.</span></span></p>
<p><span class="koboSpan" id="kobo.603.1">Peaks in the autocorrelation plot outside the confidence interval indicate notable autocorrelations. </span><span class="koboSpan" id="kobo.603.2">Regular intervals point to seasonality. </span><span class="koboSpan" id="kobo.603.3">From the example, we can see autocorrelation at lags 1, 2, and 3 and seasonality at lags 12 and 24, which correspond to a 12- and </span><span class="No-Break"><span class="koboSpan" id="kobo.604.1">24-hour interval.</span></span></p>
<p><span class="koboSpan" id="kobo.605.1">A slow </span><a id="_idIndexMarker577"/><span class="koboSpan" id="kobo.606.1">decay in the autocorrelation plot suggests that the series is non-stationary with a trend. </span><span class="koboSpan" id="kobo.606.2">In this case, we can convert the series to stationary by differencing it, as discussed in the previous section on </span><em class="italic"><span class="koboSpan" id="kobo.607.1">Differencing</span></em><span class="koboSpan" id="kobo.608.1">. </span><span class="koboSpan" id="kobo.608.2">This, however, is not the case in our example in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.609.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.610.1">.22</span></em><span class="koboSpan" id="kobo.611.1">, as there is no </span><span class="No-Break"><span class="koboSpan" id="kobo.612.1">slow decay.</span></span></p>
<p><span class="koboSpan" id="kobo.613.1">The outcome </span><a id="_idIndexMarker578"/><span class="koboSpan" id="kobo.614.1">of the ACF can be used to define the </span><strong class="bold"><span class="koboSpan" id="kobo.615.1">moving average</span></strong><span class="koboSpan" id="kobo.616.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.617.1">MA</span></strong><span class="koboSpan" id="kobo.618.1">) parameter </span><strong class="source-inline"><span class="koboSpan" id="kobo.619.1">q</span></strong><span class="koboSpan" id="kobo.620.1"> of an ARIMA model. </span><span class="koboSpan" id="kobo.620.2">Major peaks at lags 1, 2 and 3 in our example, means q=1, q=2, </span><span class="No-Break"><span class="koboSpan" id="kobo.621.1">and q=3.</span></span></p>
<h3><span class="koboSpan" id="kobo.622.1">Interpretation of PACF</span></h3>
<p><span class="koboSpan" id="kobo.623.1">We will </span><a id="_idIndexMarker579"/><span class="koboSpan" id="kobo.624.1">consider the peaks and the cut-off from the PACF plot to interpret the outcome, using the lower graph in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.625.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.626.1">.22</span></em><span class="koboSpan" id="kobo.627.1"> as </span><span class="No-Break"><span class="koboSpan" id="kobo.628.1">an example.</span></span></p>
<p><span class="koboSpan" id="kobo.629.1">Peaks in the partial autocorrelation plot outside the confidence interval indicate notable partial autocorrelations. </span><span class="koboSpan" id="kobo.629.2">In the example, this is seen at lags 1, 12, </span><span class="No-Break"><span class="koboSpan" id="kobo.630.1">and 24.</span></span></p>
<p><span class="koboSpan" id="kobo.631.1">An immediate </span><a id="_idIndexMarker580"/><span class="koboSpan" id="kobo.632.1">cut-off after some lags indicates an </span><strong class="bold"><span class="koboSpan" id="kobo.633.1">autoregressive</span></strong><span class="koboSpan" id="kobo.634.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.635.1">AR</span></strong><span class="koboSpan" id="kobo.636.1">) component. </span><span class="koboSpan" id="kobo.636.2">In the example, this is after </span><span class="No-Break"><span class="koboSpan" id="kobo.637.1">lag 1.</span></span></p>
<p><span class="koboSpan" id="kobo.638.1">The outcome of the PACF can be used to define the AR parameter </span><strong class="source-inline"><span class="koboSpan" id="kobo.639.1">p</span></strong><span class="koboSpan" id="kobo.640.1"> of an ARIMA model. </span><span class="koboSpan" id="kobo.640.2">Major peaks at lag 1 in our example, </span><span class="No-Break"><span class="koboSpan" id="kobo.641.1">means p=1.</span></span></p>
<h3><span class="koboSpan" id="kobo.642.1">Model parameters</span></h3>
<p><span class="koboSpan" id="kobo.643.1">Based on </span><a id="_idIndexMarker581"/><span class="koboSpan" id="kobo.644.1">the interpretation of the ACF and PACF plots in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.645.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.646.1">.22</span></em><span class="koboSpan" id="kobo.647.1">, we can consider the following candidate ARIMA(p, d, q) models, where p is the PACF cut-off point, d is the order of differencing, and q is the ACF </span><span class="No-Break"><span class="koboSpan" id="kobo.648.1">autocorrelation lag:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.649.1">ARIMA(1, </span><span class="No-Break"><span class="koboSpan" id="kobo.650.1">0, 1)</span></span></li>
<li><span class="koboSpan" id="kobo.651.1">ARIMA(1, </span><span class="No-Break"><span class="koboSpan" id="kobo.652.1">0, 2)</span></span></li>
<li><span class="koboSpan" id="kobo.653.1">ARIMA(1, </span><span class="No-Break"><span class="koboSpan" id="kobo.654.1">0, 3)</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.655.1">We will discuss model selection and parameters in detail in the next chapter. </span><span class="koboSpan" id="kobo.655.2">The depth of our discussion </span><a id="_idIndexMarker582"/><span class="koboSpan" id="kobo.656.1">here is just enough to conclude the discussion on ACF and PACF. </span><span class="koboSpan" id="kobo.656.2">Let’s move on to other lag </span><span class="No-Break"><span class="koboSpan" id="kobo.657.1">analysis methods.</span></span></p>
<h3><span class="koboSpan" id="kobo.658.1">Lag analysis</span></h3>
<p><span class="koboSpan" id="kobo.659.1">In addition </span><a id="_idIndexMarker583"/><span class="koboSpan" id="kobo.660.1">to ACF and PACF plots seen previously, we will explore another lag analysis method in </span><span class="No-Break"><span class="koboSpan" id="kobo.661.1">this section.</span></span></p>
<p><span class="koboSpan" id="kobo.662.1">We’ll start by calculating the different lag values of interest, as per the following code extract, using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.663.1">Window</span></strong><span class="koboSpan" id="kobo.664.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.665.1">lag</span></strong><span class="koboSpan" id="kobo.666.1"> functions we have </span><span class="No-Break"><span class="koboSpan" id="kobo.667.1">seen previously.</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.668.1">
#### Lag Analysis
# Code in cell 49
…
window = </span><strong class="bold"><span class="koboSpan" id="kobo.669.1">Window</span></strong><span class="koboSpan" id="kobo.670.1">.orderBy("timestamp")
# Create lagged features
hourly_df = hourly_df.withColumn(
    "lag1", F.</span><strong class="bold"><span class="koboSpan" id="kobo.671.1">lag</span></strong><span class="koboSpan" id="kobo.672.1">(F.col("Global_active_power"), 1).over(window))
hourly_df = hourly_df.withColumn(
    "lag2", F.</span><strong class="bold"><span class="koboSpan" id="kobo.673.1">lag</span></strong><span class="koboSpan" id="kobo.674.1">(F.col("Global_active_power"), 2).over(window))
hourly_df = hourly_df.withColumn(
    "lag12", F.</span><strong class="bold"><span class="koboSpan" id="kobo.675.1">lag</span></strong><span class="koboSpan" id="kobo.676.1">(F.col("Global_active_power"), 12).over(window))
hourly_df = hourly_df.withColumn(
    "lag24", F.</span><strong class="bold"><span class="koboSpan" id="kobo.677.1">lag</span></strong><span class="koboSpan" id="kobo.678.1">(F.col("Global_active_power"), 24).over(window))
…</span></pre> <p><span class="koboSpan" id="kobo.679.1">This creates </span><a id="_idIndexMarker584"/><span class="koboSpan" id="kobo.680.1">the lag columns, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.681.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.682.1">.23</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.683.1">.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer099">
<span class="koboSpan" id="kobo.684.1"><img alt="" src="image/B18568_06_23.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.685.1">Figure 6.23: Lag values</span></p>
<p><span class="koboSpan" id="kobo.686.1">We then calculate the correlation of the current values with their lag values, as in the following code, using the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.687.1">stat.corr()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.688.1"> function.</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.689.1">
# Code in cell 50
…
# Calculate autocorrelation for lag 1
df_lag1 = hourly_df.dropna(subset=["lag1"])
autocorr_lag1 = df_lag1.</span><strong class="bold"><span class="koboSpan" id="kobo.690.1">stat.corr</span></strong><span class="koboSpan" id="kobo.691.1">("Global_active_power", "lag1")
…
# Calculate autocorrelation for lag 24
df_lag24 = hourly_df.dropna(subset=["lag24"])
autocorr_lag24 = df_lag24.</span><strong class="bold"><span class="koboSpan" id="kobo.692.1">stat.corr</span></strong><span class="koboSpan" id="kobo.693.1">("Global_active_power", "lag24")
…</span></pre> <p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.694.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.695.1">.24</span></em><span class="koboSpan" id="kobo.696.1"> shows the </span><a id="_idIndexMarker585"/><span class="koboSpan" id="kobo.697.1">autocorrelation values, significant at lag 1, 2, and 24, as we saw on the ACF </span><span class="No-Break"><span class="koboSpan" id="kobo.698.1">plot previously.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer100">
<span class="koboSpan" id="kobo.699.1"><img alt="" src="image/B18568_06_24.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.700.1">Figure 6.24: Autocorrelation at different lag values</span></p>
<p><span class="koboSpan" id="kobo.701.1">Finally, by plotting the current and lag values together, we can see in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.702.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.703.1">.25</span></em><span class="koboSpan" id="kobo.704.1"> how they compare to each other. </span><span class="koboSpan" id="kobo.704.2">We can visually confirm here the greater correlation at lag 1, 2, </span><span class="No-Break"><span class="koboSpan" id="kobo.705.1">and 24.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer101">
<span class="koboSpan" id="kobo.706.1"><img alt="" src="image/B18568_06_25.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.707.1">Figure 6.25: Comparison of current and lag values</span></p>
<p><span class="koboSpan" id="kobo.708.1">This concludes </span><a id="_idIndexMarker586"/><span class="koboSpan" id="kobo.709.1">the section on autocorrelation, where we looked at ACF and PACF, and how to calculate lagged features and their correlation using Apache Spark. </span><span class="koboSpan" id="kobo.709.2">While the lag analysis methods in this section have been used for autocorrelation, they can also be used for cross-correlation, which we will cover next, as another type of correlation, this time between different </span><span class="No-Break"><span class="koboSpan" id="kobo.710.1">time series.</span></span></p>
<h2 id="_idParaDest-130"><a id="_idTextAnchor130"/><span class="koboSpan" id="kobo.711.1">Cross-correlation</span></h2>
<p><span class="koboSpan" id="kobo.712.1">Cross-correlation </span><a id="_idIndexMarker587"/><span class="koboSpan" id="kobo.713.1">measures the relationship between </span><a id="_idIndexMarker588"/><span class="koboSpan" id="kobo.714.1">two different time series. </span><span class="koboSpan" id="kobo.714.2">One series may influence or predict the other </span><a id="_idIndexMarker589"/><span class="koboSpan" id="kobo.715.1">over different time lags, in what is called a </span><strong class="bold"><span class="koboSpan" id="kobo.716.1">lead-lag relationship</span></strong><span class="koboSpan" id="kobo.717.1">. </span><span class="koboSpan" id="kobo.717.2">Cross-correlation is used for multivariate time series modeling and </span><span class="No-Break"><span class="koboSpan" id="kobo.718.1">causality analysis.</span></span></p>
<p><span class="koboSpan" id="kobo.719.1">Going back to the profiling report we saw earlier, we can see a graph of the correlation of the different columns of the example dataset included in the report, as in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.720.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.721.1">.26</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.722.1">.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer102">
<span class="koboSpan" id="kobo.723.1"><img alt="" src="image/B18568_06_26.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.724.1">Figure 6.26: Cross-correlation heatmap</span></p>
<p><span class="koboSpan" id="kobo.725.1">We can calculate the cross-correlation directly with the </span><span class="No-Break"><span class="koboSpan" id="kobo.726.1">following code.</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.727.1">
#### Cross-correlation
# Code in cell 53
…
# Compute cross-correlation between value1 and value2
cross_corr = hourly_df.stat.corr("Global_active_power", "Voltage")
…</span></pre> <p><span class="koboSpan" id="kobo.728.1">The cross-correlation calculation yields the value in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.729.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.730.1">.26</span></em><span class="koboSpan" id="kobo.731.1">. </span><span class="koboSpan" id="kobo.731.2">As this correlation is at the same lag, it does not have predictive value, in the sense that we are not using the past to predict </span><a id="_idIndexMarker590"/><span class="koboSpan" id="kobo.732.1">the future. </span><span class="koboSpan" id="kobo.732.2">However, this pair of </span><a id="_idIndexMarker591"/><span class="koboSpan" id="kobo.733.1">attributes is still worth further analysis at different lags, due to the </span><span class="No-Break"><span class="koboSpan" id="kobo.734.1">significant cross-correlation.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer103">
<span class="koboSpan" id="kobo.735.1"><img alt="" src="image/B18568_06_27.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.736.1">Figure 6.27: Cross-correlation value</span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.737.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.738.1">We know that P=IV, where P is electrical power, I is current, and V is voltage, indicates how power and voltage are related. </span><span class="koboSpan" id="kobo.738.2">Hence, these two time series are not independent of each other. </span><span class="koboSpan" id="kobo.738.3">Even if there is no further insight into the P and V relationship, we will continue this analysis as an example of </span><span class="No-Break"><span class="koboSpan" id="kobo.739.1">cross-correlation analysis.</span></span></p>
<p><span class="koboSpan" id="kobo.740.1">As cross-correlation at the same lag does not help much for prediction, we will now look at using different lag values with the following code. </span><span class="koboSpan" id="kobo.740.2">This uses the cross-correlation </span><strong class="source-inline"><span class="koboSpan" id="kobo.741.1">ccf()</span></strong><span class="koboSpan" id="kobo.742.1"> function, which calculates the cross-correlation at different </span><span class="No-Break"><span class="koboSpan" id="kobo.743.1">lag values.</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.744.1">
# Code in cell 54
…
from statsmodels.tsa.stattools import </span><strong class="bold"><span class="koboSpan" id="kobo.745.1">ccf</span></strong><span class="koboSpan" id="kobo.746.1">
hourly_ = hourly_resampled.iloc[:36]
# Calculate cross-correlation function
ccf_values = </span><strong class="bold"><span class="koboSpan" id="kobo.747.1">ccf</span></strong><span class="koboSpan" id="kobo.748.1">(hourly_['Global_active_power'], hourly_['Voltage'])
# Plot cross-correlation function
plt.figure(figsize=(12, 6))
plt.stem(range(len(ccf_values)),
         ccf_values, use_line_collection=True, markerfmt="-")
plt.title('Cross-Correlation Function (CCF)')
…</span></pre> <p><span class="koboSpan" id="kobo.749.1">This generates </span><a id="_idIndexMarker592"/><span class="koboSpan" id="kobo.750.1">the plot in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.751.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.752.1">.27</span></em><span class="koboSpan" id="kobo.753.1">, which shows the correlation </span><a id="_idIndexMarker593"/><span class="koboSpan" id="kobo.754.1">of the two attributes at </span><span class="No-Break"><span class="koboSpan" id="kobo.755.1">different lags.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer104">
<span class="koboSpan" id="kobo.756.1"><img alt="" src="image/B18568_06_28.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.757.1">Figure 6.28: Cross-correlation function</span></p>
<p><span class="koboSpan" id="kobo.758.1">To conclude, this section showed how to perform cross-correlation analysis by creating lagged features, and calculating and </span><span class="No-Break"><span class="koboSpan" id="kobo.759.1">visualizing cross-correlation.</span></span></p>
<h1 id="_idParaDest-131"><a id="_idTextAnchor131"/><span class="koboSpan" id="kobo.760.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.761.1">In this chapter, we used exploratory data analysis to uncover patterns and insights in time series data. </span><span class="koboSpan" id="kobo.761.2">Starting with statistical analysis techniques, where we profiled the data and analyzed its distribution, we then resampled and decomposed the series into its components. </span><span class="koboSpan" id="kobo.761.3">To understand the nature of the time series, we also checked for stationarity, autocorrelation, and cross-correlation. </span><span class="koboSpan" id="kobo.761.4">By this point, we have gathered enough information on time series to guide us into the next step of building predictive models for </span><span class="No-Break"><span class="koboSpan" id="kobo.762.1">time series.</span></span></p>
<p><span class="koboSpan" id="kobo.763.1">In the next chapter, we will dive into the core topic of this book, which is developing and testing models for time </span><span class="No-Break"><span class="koboSpan" id="kobo.764.1">series analysis.</span></span></p>
<h1 id="_idParaDest-132"><a id="_idTextAnchor132"/><span class="koboSpan" id="kobo.765.1">Join our community on Discord</span></h1>
<p><span class="koboSpan" id="kobo.766.1">Join our community’s Discord space for discussions with the authors and </span><span class="No-Break"><span class="koboSpan" id="kobo.767.1">other readers:</span></span></p>
<p><a href="https://packt.link/ds"><span class="No-Break"><span class="koboSpan" id="kobo.768.1">https://packt.link/ds</span></span></a></p>
<div>
<div class="IMG---Figure" id="_idContainer105">
<span class="koboSpan" id="kobo.769.1"><img alt="" src="image/ds_(1).jpg"/></span>
</div>
</div>
</div>
</body></html>