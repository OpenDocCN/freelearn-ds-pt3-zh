["```py\npython3.10 -m pip install pandas bokeh\n```", "```py\nimport pandas as pd\n```", "```py\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\n    diff_data = rng.normal(0, 1, size=100)\n    ```", "```py\n    cumulative = diff_data.cumsum()\n    ```", "```py\n    data_series = pd.Series(diff_data)\n    ```", "```py\n    print(data_series)\n    ```", "```py\n    data_frame = pd.DataFrame({\n    ```", "```py\n        \"diffs\": data_series,\n    ```", "```py\n        \"cumulative\": cumulative\n    ```", "```py\n    })\n    ```", "```py\n    print(data_frame)\n    ```", "```py\n                                     diffs  cumulative\n0    -1.423825                0  -1.423825   -1.423825\n1     1.263728                1   1.263728   -0.160097\n2    -0.870662                2  -0.870662   -1.030758\n3    -0.259173                3  -0.259173   -1.289932\n4    -0.075343                4  -0.075343   -1.365275\n        ...                  ..       ...         ...\n95   -0.061905               95 -0.061905   -1.107210\n96   -0.359480               96 -0.359480   -1.466690\n97   -0.748644               97 -0.748644   -2.215334\n98   -0.965479               98 -0.965479   -3.180813\n99    0.360035               99  0.360035   -2.820778\nLength: 100, dtype: float64  [100 rows x 2 columns]\n```", "```py\nfrom numpy.random import default_rng\nrng = default_rng(12345) # seed for example\n```", "```py\n    diffs = rng.normal(0, 1, size=100)\n    ```", "```py\n    cumulative = diffs.cumsum()\n    ```", "```py\n    data_frame = pd.DataFrame({\n    ```", "```py\n        \"diffs\": diffs, \n    ```", "```py\n        \"cumulative\": cumulative\n    ```", "```py\n    })\n    ```", "```py\n    print(data_frame)\n    ```", "```py\n    data_frame.to_csv(\"sample.csv\", index=False)\n    ```", "```py\n    df = pd.read_csv(\"sample.csv\", index_col=False)\n    ```", "```py\n    print(df)\n    ```", "```py\n    diffs      cumulative          diffs       cumulative\n0  -1.423825   -1.423825        0  -1.423825   -1.423825\n1   1.263728   -0.160097        1   1.263728   -0.160097\n2  -0.870662   -1.030758        2  -0.870662   -1.030758\n3  -0.259173   -1.289932        3  -0.259173   -1.289932\n4  -0.075343   -1.365275        4  -0.075343   -1.365275\n..         ...            ...        ..         ...            ...\n95 -0.061905   -1.107210        95 -0.061905   -1.107210\n96 -0.359480   -1.466690        96 -0.359480   -1.466690\n97 -0.748644   -2.215334        97 -0.748644   -2.215334\n98 -0.965479   -3.180813        98 -0.965479   -3.180813\n99  0.360035   -2.820778        99  0.360035   -2.820778\n[100 rows x 2 columns]           [100 rows x 2 columns]\n```", "```py\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\n    three = rng.uniform(-0.2, 1.0, size=100)\n    ```", "```py\n    three[three < 0] = np.nan\n    ```", "```py\n    data_frame = pd.DataFrame({\n    ```", "```py\n        \"one\": rng.random(size=100),\n    ```", "```py\n        \"two\": rng.normal(0, 1, size=100).cumsum(),\n    ```", "```py\n        \"three\": three\n    ```", "```py\n    })\n    ```", "```py\n    data_frame[\"four\"] = data_frame[\"one\"] > 0.5\n    ```", "```py\n    def transform_function(row):\n    ```", "```py\n        if row[\"four\"]:\n    ```", "```py\n            return 0.5*row[\"two\"]\n    ```", "```py\n            return row[\"one\"]*row[\"two\"]\n    ```", "```py\n    data_frame[\"five\"] = data_frame.apply(\n    ```", "```py\n        transform_function, axis=1)\n    ```", "```py\n    print(data_frame)\n    ```", "```py\n    df = data_frame.dropna()\n    ```", "```py\n    print(df)\n    ```", "```py\n         one       two     three   four      five\n0   0.168629  1.215005  0.072803  False  0.204885\n1   0.240144  1.431064  0.180110  False  0.343662\n2   0.780008  0.466240  0.756839   True  0.233120\n3   0.203768 -0.090367  0.611506  False -0.018414\n4   0.552051 -2.388755  0.269331   True -1.194377\n..         ...         ...         ...     ...         ...\n95  0.437305  2.262327  0.254499  False  0.989326\n96  0.143115  1.624691  0.131136  False  0.232517\n97  0.422742  2.769187  0.959325  False  1.170652\n98  0.764412  1.128285         NaN   True  0.564142\n99  0.413983 -0.185719  0.290481  False -0.076885\n[100 rows x 5 columns]\n```", "```py\n         one       two     three   four      five\n0   0.168629  1.215005  0.072803  False  0.204885\n1   0.240144  1.431064  0.180110  False  0.343662\n2   0.780008  0.466240  0.756839   True  0.233120\n3   0.203768 -0.090367  0.611506  False -0.018414\n4   0.552051 -2.388755  0.269331   True -1.194377\n..         ...         ...         ...     ...         ...\n94  0.475131  3.065343  0.330151  False  1.456440\n95  0.437305  2.262327  0.254499  False  0.989326\n96  0.143115  1.624691  0.131136  False  0.232517\n97  0.422742  2.769187  0.959325  False  1.170652\n99  0.413983 -0.185719  0.290481  False -0.076885\n[88 rows x 5 columns]\n```", "```py\nrng = default_rng(12345)\ndf1 = pd.DataFrame({\n    \"label\": rng.choice([\"A\", \"B\", \"C\"], size=5),\n    \"data1\": rng.standard_normal(size=5)\n})\ndf2 = pd.DataFrame({\n    \"label\": rng.choice([\"A\", \"B\", \"C\", \"D\"], size=4),\n    \"data2\": rng.standard_normal(size=4)\n})\ndf3 = df1.merge(df2, how=\"inner\", on=\"label\")\n```", "```py\n>>> print(df1)                          >>> print(df2)\n  label      data1                        label      data2\n0      C -0.259173                     0      D  2.347410\n1      A -0.075343                     1      A  0.968497\n2      C -0.740885                     2      C -0.759387\n3      A -1.367793                     3      C  0.902198\n4      A  0.648893\n>>> df3\n  label      data1      data2\n0      C -0.259173 -0.759387\n1      C -0.259173  0.902198\n2      C -0.740885 -0.759387\n3      C -0.740885  0.902198\n4      A -0.075343  0.968497\n5      A -1.367793  0.968497\n6      A  0.648893  0.968497\n```", "```py\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\n    diffs = rng.standard_normal(size=100)\n    ```", "```py\n    walk = diffs.cumsum()\n    ```", "```py\n    df = pd.DataFrame({\n    ```", "```py\n        \"diffs\": diffs,\n    ```", "```py\n        \"walk\": walk\n    ```", "```py\n    })\n    ```", "```py\n    fig, (ax1, ax2) = plt.subplots(1, 2, tight_layout=True)\n    ```", "```py\n    df[\"walk\"].plot(ax=ax1, title=\"Random walk\", color=\"k\")\n    ```", "```py\n    ax1.set_xlabel(\"Index\")\n    ```", "```py\n    ax1.set_ylabel(\"Value\")\n    ```", "```py\n    df[\"diffs\"].plot(kind=\"hist\", ax=ax2, \n    ```", "```py\n        title=\"Histogram of diffs\", color=\"k\", alpha=0.6)\n    ```", "```py\n    ax2.set_xlabel(\"Difference\")\n    ```", "```py\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\n    uniform = rng.uniform(1, 5, size=100)\n    ```", "```py\n    normal = rng.normal(1, 2.5, size=100)\n    ```", "```py\n    bimodal = np.concatenate([rng.normal(0, 1, size=50), \n    ```", "```py\n        rng.normal(6, 1, size=50)])\n    ```", "```py\n    df = pd.DataFrame({\n    ```", "```py\n        \"uniform\": uniform, \n    ```", "```py\n        \"normal\": normal, \n    ```", "```py\n        \"bimodal\": bimodal\n    ```", "```py\n    })\n    ```", "```py\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3,\n    ```", "```py\n                                        tight_layout=True)\n    ```", "```py\n    df[\"uniform\"].plot(kind=\"hist\",\n    ```", "```py\n        title=\"Uniform\", ax=ax1, color=\"k\", alpha=0.6)\n    ```", "```py\n    df[\"normal\"].plot(kind=\"hist\",\n    ```", "```py\n        title=\"Normal\", ax=ax2, color=\"k\", alpha=0.6)\n    ```", "```py\n    df[\"bimodal\"].plot(kind=\"hist\", title=\"Bimodal\",\n    ```", "```py\n        ax=ax3, bins=20, color=\"k\", alpha=0.6)\n    ```", "```py\n    descriptive = df.describe()\n    ```", "```py\n    descriptive.loc[\"kurtosis\"] = df.kurtosis()\n    ```", "```py\n    print(descriptive)\n    ```", "```py\n    #             uniform      normal     bimodal\n    ```", "```py\n    # count     100.000000 100.000000 100.000000\n    ```", "```py\n    # mean         2.813878   1.087146   2.977682\n    ```", "```py\n    # std           1.093795   2.435806   3.102760\n    ```", "```py\n    # min           1.020089  -5.806040  -2.298388\n    ```", "```py\n    # 25%           1.966120  -0.498995   0.069838\n    ```", "```py\n    # 50%           2.599687   1.162897   3.100215\n    ```", "```py\n    # 75%           3.674468   2.904759   5.877905\n    ```", "```py\n    # max           4.891319   6.375775   8.471313\n    ```", "```py\n    # kurtosis  -1.055983   0.061679  -1.604305\n    ```", "```py\n    uniform_mean = descriptive.loc[\"mean\", \"uniform\"]\n    ```", "```py\n    normal_mean = descriptive.loc[\"mean\", \"normal\"]\n    ```", "```py\n    bimodal_mean = descriptive.loc[\"mean\", \"bimodal\"]\n    ```", "```py\n    ax1.vlines(uniform_mean, 0, 20, \"k\")\n    ```", "```py\n    ax2.vlines(normal_mean, 0, 25, \"k\")\n    ```", "```py\n    ax3.vlines(bimodal_mean, 0, 20, \"k\")\n    ```", "```py\nfrom scipy import stats\n```", "```py\n    sample_data = pd.Series(\n    ```", "```py\n        [172.3, 171.3, 164.7, 162.9, 172.5, 176.3, 174.8,\n    ```", "```py\n        171.9,176.8, 167.8, 164.5, 179.7, 157.8, 170.6,\n    ```", "```py\n        189.9, 185., 172.7, 165.5, 174.5, 171.5]\n    ```", "```py\n    )\n    ```", "```py\n    sample_mean = sample_data.mean()\n    ```", "```py\n    sample_std = sample_data.std()\n    ```", "```py\n    print(f\"Mean {sample_mean}, st. dev {sample_std}\")\n    ```", "```py\n    # Mean 172.15, st. dev 7.473778724383846\n    ```", "```py\n    N = sample_data.count()\n    ```", "```py\n    std_err = sample_std/math.sqrt(N)\n    ```", "```py\n    cv_95, cv_99 = stats.t.ppf([0.975, 0.995], df=N-1)\n    ```", "```py\n    pm_95 = cv_95*std_err\n    ```", "```py\n    conf_interval_95 = [sample_mean - pm_95,\n    ```", "```py\n        sample_mean + pm_95]\n    ```", "```py\n    pm_99 = cv_99*std_err\n    ```", "```py\n    conf_interval_99 = [sample_mean - pm_99,\n    ```", "```py\n        sample_mean + pm_99]\n    ```", "```py\n    print(\"95% confidence\", conf_interval_95)\n    ```", "```py\n    # 95% confidence [168.65216388659374, 175.64783611340627]\n    ```", "```py\n    print(\"99% confidence\", conf_interval_99)\n    ```", "```py\n    # 99% confidence [167.36884119608774, 176.93115880391227]\n    ```", "```py\nrng = np.random.default_rng(12345)\n```", "```py\nfrom matplotlib.rcsetup import cycler\nplt.rc(\"axes\", prop_cycle=cycler(\n    c=[\"k\"]*3, ls=[\"-\", \"--\", \"-.\"]))\n```", "```py\n    labels1 = rng.choice([\"A\", \"B\", \"C\"], size=50)\n    ```", "```py\n    labels2 = rng.choice([1, 2], size=50)\n    ```", "```py\n    data = rng.normal(0.0, 2.0, size=50)\n    ```", "```py\n    df = pd.DataFrame({\"label1\": labels1, \"label2\": labels2, \"data\": data})\n    ```", "```py\n    df[“first_group”] = df.groupby(“label1”)[“data”].cumsum()\n    ```", "```py\n    print(df.head())\n    ```", "```py\n  label1  label2      data  first_group\n0      C       2  0.867309     0.867309\n1      A       2  0.554967     0.554967\n2      C       1  1.060505     1.927814\n3      A       1  1.073442     1.628409\n4      A       1  1.236700     2.865109\n```", "```py\n    grouped = df.groupby([\"label1\", \"label2\"])\n    ```", "```py\n    df[\"second_group\"] = grouped[\"data\"].transform(lambda d:\n    ```", "```py\n        d.rolling(2, min_periods=1).mean())\n    ```", "```py\n    print(df.head())\n    ```", "```py\n    print(df[df[\"label1\"]==\"C\"].head())\n    ```", "```py\n  label1  label2      data  first_group  second_group\n0      C       2  0.867309     0.867309      0.867309\n1      A       2  0.554967     0.554967      0.554967\n2      C       1  1.060505     1.927814      1.060505\n3      A       1  1.073442     1.628409      1.073442\n4      A       1  1.236700     2.865109      1.155071\n```", "```py\n  label1  label2      data  first_group  second_group\n0      C       2  0.867309     0.867309      0.867309\n2      C       1  1.060505     1.927814      1.060505\n5      C       1 -1.590035     0.337779     -0.264765\n7      C       1 -3.205403    -2.867624     -2.397719\n8      C       1  0.533598    -2.334027     -1.335903\n```", "```py\n    fig, ax = plt.subplots()\n    ```", "```py\n    df.groupby(\"label1\")[\"first_group\"].plot(ax=ax)\n    ```", "```py\n    ax.set(title=\"Grouped data cumulative sums\",     xlabel=\"Index\", ylabel=\"value\")\n    ```", "```py\n    ax.legend()\n    ```", "```py\nfrom scipy import stats\n```", "```py\n    sample = pd.Series([\n    ```", "```py\n        2.4, 2.4, 2.9, 2.6, 1.8, 2.7, 2.6, 2.4, 2.8, \n    ```", "```py\n        2.4, 2.4, 2.4, 2.7, 2.7, 2.3, 2.4, 2.4, 3.2, \n    ```", "```py\n        2.9, 2.5, 2.5, 3.2, 2\\. , 2.3, 3\\. , 1.5, 3.1,\n    ```", "```py\n        2.5, 2.2, 2.5, 2.1,1.8, 3.1, 2.4, 3\\. , 2.5,\n    ```", "```py\n        2.7, 2.1, 2.3, 2.2, 2.5, 2.6, 2.5, 2.8, 2.5,\n    ```", "```py\n        2.9, 2.1, 2.8, 2.1, 2.3\n    ```", "```py\n    ])\n    ```", "```py\n    mu0 = 2.0\n    ```", "```py\n    significance = 0.05\n    ```", "```py\n    t_statistic, p_value = stats.ttest_1samp(sample, mu0)\n    ```", "```py\n    print(f\"t stat: {t_statistic}, p value: {p_value}\")\n    ```", "```py\n    # t stat: 9.752368720068665, p value: 4.596949515944238e-13\n    ```", "```py\n    if p_value <= significance:\n    ```", "```py\n        print(\"Reject H0 in favour of H1: mu != 2.0\")\n    ```", "```py\n    else:\n    ```", "```py\n        print(\"Accept H0: mu = 2.0\")\n    ```", "```py\n    # Reject H0 in favour of H1: mu != 2.0\n    ```", "```py\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\n    current = rng.normal(4.0, 2.0, size=40)\n    ```", "```py\n    process_a = rng.normal(6.2, 2.0, size=25)\n    ```", "```py\n    process_b = rng.normal(4.5, 2.0, size=64)\n    ```", "```py\n    significance = 0.05\n    ```", "```py\n    F_stat, p_value = stats.f_oneway(\n    ```", "```py\n        current, process_a, process_b)\n    ```", "```py\n    print(f\"F stat: {F_stat}, p value: {p_value}\")\n    ```", "```py\n    # F stat: 9.949052026027028, p value: 9.732322721019206e-05\n    ```", "```py\n    if p_value <= significance:\n    ```", "```py\n        print(\"Reject H0: there is a difference between means\")\n    ```", "```py\n    else:\n    ```", "```py\n        print(\"Accept H0: all means equal\")\n    ```", "```py\n    # Reject H0: there is a difference between means\n    ```", "```py\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\n    sample_A = rng.uniform(2.5, 3.5, size=25)\n    ```", "```py\n    sample_B = rng.uniform(3.0, 4.4, size=25)\n    ```", "```py\n    sample_C = rng.uniform(3.1, 4.5, size=25)\n    ```", "```py\n    significance = 0.05\n    ```", "```py\n    statistic, p_value = stats.kruskal(sample_A, sample_B,\n    ```", "```py\n        sample_C)\n    ```", "```py\n    print(f\"Statistic: {statistic}, p value: {p_value}\")\n    ```", "```py\n    # Statistic: 40.22214736842102, p value: 1.8444703308682906e-09\n    ```", "```py\n    if p_value <= significance:\n    ```", "```py\n        print(\"There are differences between population  medians\")\n    ```", "```py\n    else:\n    ```", "```py\n        print(\"Accept H0: all medians equal\")\n    ```", "```py\n    # There are differences between population medians\n    ```", "```py\n    _, p_A_B = stats.ranksums(sample_A, sample_B)\n    ```", "```py\n    _, p_A_C = stats.ranksums(sample_A, sample_C)\n    ```", "```py\n    _, p_B_C = stats.ranksums(sample_B, sample_C)\n    ```", "```py\n    if p_A_B <= significance:\n    ```", "```py\n        print(\"Significant differences between A and B,\n    ```", "```py\n            p value\", p_A_B)\n    ```", "```py\n    # Significant differences between A and B, p value\n    ```", "```py\n    1.0035366080480683e-07\n    ```", "```py\n    if p_A_C <= significance:\n    ```", "```py\n        print(\"Significant differences between A and C,\n    ```", "```py\n            p value\", p_A_C)\n    ```", "```py\n    # Significant differences between A and C, p value\n    ```", "```py\n    2.428534673701913e-08\n    ```", "```py\n    if p_B_C <= significance:\n    ```", "```py\n        print(\"Significant differences between B and C,\n    ```", "```py\n            p value\", p_B_C)\n    ```", "```py\n    else:\n    ```", "```py\n        print(\"No significant differences between B and C,\n    ```", "```py\n            p value\", p_B_C)\n    ```", "```py\n    # No significant differences between B and C, p value\n    ```", "```py\n    0.3271631660572756\n    ```", "```py\nfrom bokeh import plotting as bk\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\n    date_range = pd.date_range(\"2020-01-01\", periods=50)\n    ```", "```py\n    data = rng.normal(0, 3, size=50).cumsum()\n    ```", "```py\n    series = pd.Series(data, index=date_range)\n    ```", "```py\n    bk.output_file(\"sample.html\")\n    ```", "```py\n    fig = bk.figure(title=\"Time series data\", \n    ```", "```py\n                           x_axis_label=\"date\",\n    ```", "```py\n                           x_axis_type=\"datetime\",\n    ```", "```py\n                           y_axis_label=\"value\")\n    ```", "```py\n    fig.line(date_range, series)\n    ```", "```py\n    bk.show(fig)\n    ```"]