<html><head></head><body>
		<div id="_idContainer1042">
			<h1 class="chapter-number" id="_idParaDest-361"><a id="_idTextAnchor360"/>9</h1>
			<h1 id="_idParaDest-362"><a id="_idTextAnchor361"/>Finding Optimal Solutions</h1>
			<p>In this chapter, we’ll address various methods for finding the best outcome in a given situation. This is called <strong class="bold">optimization</strong> and<a id="_idIndexMarker934"/> usually involves either minimizing or maximizing an objective function. An <strong class="bold">objective function</strong> is a function with<a id="_idIndexMarker935"/> one or more arguments that returns a single scalar value, representing the cost or payoff for a given choice of parameters. The problems regarding minimizing and maximizing functions are actually equivalent to one another, so we’ll only discuss minimizing object functions in this chapter. Minimizing a function, <img alt="" src="image/Formula_09_001.png"/>, is equivalent to maximizing the <img alt="" src="image/Formula_09_002.png"/> function. More details on this will be provided when we discuss the <span class="No-Break">first recipe.</span></p>
			<p>The algorithms available to us for minimizing a given function depend on the nature of the function. For instance, a simple linear function containing one or more variables has different algorithms available compared to a non-linear function with many variables. The minimization of linear functions falls within the category of <strong class="bold">linear programming</strong>, which is a well-developed theory. Linear functions<a id="_idIndexMarker936"/> can be solved with standard linear<a id="_idIndexMarker937"/> algebra techniques. For non-linear functions, we usually make <a id="_idIndexMarker938"/>use of the gradient of a function in order to find the minimum points. We will discuss several methods for minimizing various functions of <span class="No-Break">different types.</span></p>
			<p>Finding the minima<a id="_idIndexMarker939"/> and maxima<a id="_idIndexMarker940"/> of the functions of a single variable is especially simple and can be done easily if the derivatives of the function are known. If not, then the method described in the appropriate recipe will be applicable. The notes in the <em class="italic">Minimizing a non-linear function</em> recipe give some extra details <span class="No-Break">about this.</span></p>
			<p>We’ll also provide a very short introduction<a id="_idIndexMarker941"/> to <em class="italic">game theory</em>. Broadly speaking, this is a theory surrounding decision-making and has wide-ranging implications in subjects such as economics. In particular, we’ll discuss how to represent simple two-player games as objects in Python, compute payoffs associated with certain choices, and compute Nash equilibria for <span class="No-Break">these games.</span></p>
			<p>We will start by looking at how to minimize linear and non-linear functions containing one or more variables. Then, we’ll move on and look at gradient descent methods and curve fitting, using least squares. We’ll conclude this chapter by analyzing two-player games and <span class="No-Break">Nash equilibria.</span></p>
			<p>In this chapter, we will cover the <span class="No-Break">following recipes:</span></p>
			<ul>
				<li>Minimizing a simple <span class="No-Break">linear function</span></li>
				<li>Minimizing a <span class="No-Break">non-linear function</span></li>
				<li>Using gradient descent methods <span class="No-Break">in optimization</span></li>
				<li>Using least squares to fit a curve <span class="No-Break">to data</span></li>
				<li>Analyzing simple <span class="No-Break">two-player games</span></li>
				<li>Computing <span class="No-Break">Nash equilibria</span></li>
			</ul>
			<p>Let’s <span class="No-Break">get started!</span></p>
			<h1 id="_idParaDest-363"><a id="_idTextAnchor362"/>Technical requirements</h1>
			<p>In this chapter, we will need the NumPy package, the SciPy package, and the Matplotlib package, as usual. We will also need the Nashpy package for the final two recipes. These packages can be installed using your favorite package manager, such <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">pip</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
python3.10 -m pip install numpy scipy matplotlib nashpy</pre>
			<p>The code for this chapter can be found in the <span class="No-Break"><strong class="source-inline">Chapter 09</strong></span> folder of the GitHub repository <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Applying-Math-with-Python-2nd-Edition/tree/main/Chapter%2009"><span class="No-Break">https://github.com/PacktPublishing/Applying-Math-with-Python-2nd-Edition/tree/main/Chapter%2009</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-364"><a id="_idTextAnchor363"/>Minimizing a simple linear function</h1>
			<p>The <a id="_idIndexMarker942"/>most basic type of problem we face in optimization is finding the parameters where a function takes its minimum value. Usually, this problem is <em class="italic">constrained</em> by some bounds on the possible values of the parameters, which increases the complexity of the problem. Obviously, the complexity of this problem increases further if the function that we are minimizing is also complex. For this reason, we must first consider <em class="italic">linear functions</em>, which are in the <span class="No-Break">following form:</span></p>
			<p class="IMG---Figure"><img alt="" src="image/Formula_09_003.png"/></p>
			<p>To solve <a id="_idIndexMarker943"/>this kind of problem, we need to convert the constraints into a form that can be used by a computer. In this case, we usually convert them into a linear algebra problem (matrices and vectors). Once this is done, we can use the tools from the linear algebra packages in NumPy and SciPy to find the parameters we seek. Fortunately, since this kind of problem occur quite frequently, SciPy has routines that handle this conversion and <span class="No-Break">subsequent solving.</span></p>
			<p>In this recipe, we’ll solve the following constrained linear minimization problem using routines from the SciPy <span class="No-Break"><strong class="source-inline">optimize</strong></span><span class="No-Break"> module:</span></p>
			<p class="IMG---Figure"><img alt="" src="image/Formula_09_004.png"/></p>
			<p>This will be subject to the <span class="No-Break">following conditions:</span></p>
			<p class="IMG---Figure"><img alt="" src="image/Formula_09_005.png"/></p>
			<p class="IMG---Figure"><img alt="" src="image/Formula_09_006.png"/></p>
			<p class="IMG---Figure"><img alt="" src="image/Formula_09_007.png"/></p>
			<p class="IMG---Figure"><img alt="" src="image/Formula_09_008.png"/></p>
			<p>Let’s see how to use the SciPy <strong class="source-inline">optimize</strong> routines to solve this linear <span class="No-Break">programming problem.</span></p>
			<h2 id="_idParaDest-365"><a id="_idTextAnchor364"/>Getting ready</h2>
			<p>For this recipe, we need to import the NumPy package under the alias <strong class="source-inline">np</strong>, the Matplotlib <strong class="source-inline">pyplot</strong> module under the name <strong class="source-inline">plt</strong>, and the SciPy <strong class="source-inline">optimize</strong> module. We also need to import the <strong class="source-inline">Axes3D</strong> class from <strong class="source-inline">mpl_toolkits.mplot3d</strong> to make 3D <span class="No-Break">plotting available:</span></p>
			<pre class="source-code">
import numpy as np
from scipy import optimize
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D</pre>
			<p>Let’s see how to use the routines from the <strong class="source-inline">optimize</strong> module to minimize a constrained <span class="No-Break">linear system.</span></p>
			<h2 id="_idParaDest-366"><a id="_idTextAnchor365"/>How to do it...</h2>
			<p>Follow these<a id="_idIndexMarker944"/> steps to solve a <a id="_idIndexMarker945"/>constrained linear minimization problem<a id="_idIndexMarker946"/> <span class="No-Break">using SciPy:</span></p>
			<ol>
				<li>Set up the system in a form that SciPy <span class="No-Break">can recognize:</span><pre class="console">
A = np.array([</pre><pre class="console">
    [2, 1], # 2*x0 + x1 &lt;= 6</pre><pre class="console">
    [-1, -1] # -x0 - x1 &lt;= -4</pre><pre class="console">
])</pre><pre class="console">
b = np.array([6, -4])</pre><pre class="console">
x0_bounds = (-3, 14) # -3 &lt;= x0 &lt;= 14</pre><pre class="console">
x1_bounds = (2, 12)      # 2 &lt;= x1 &lt;= 12</pre><pre class="console">
c = np.array([1, 5])</pre></li>
				<li>Next, we need to define a routine that evaluates the linear function at a value of <img alt="" src="image/Formula_09_009.png"/>, which is a vector (a <span class="No-Break">NumPy array):</span><pre class="console">
def func(x):</pre><pre class="console">
    return np.tensordot(c, x, axes=1)</pre></li>
				<li>Then, we create a new figure and add a set of <strong class="source-inline">3d</strong> axes that we can plot the <span class="No-Break">function on:</span><pre class="console">
fig = plt.figure()</pre><pre class="console">
ax = fig.add_subplot(projection="3d")</pre><pre class="console">
ax.set(xlabel="x0", ylabel="x1", zlabel="func")</pre><pre class="console">
ax.set_title("Values in Feasible region")</pre></li>
				<li>Next, we create a grid of values covering the region from the problem and plot the value of the function over <span class="No-Break">this region:</span><pre class="console">
X0 = np.linspace(*x0_bounds)</pre><pre class="console">
X1 = np.linspace(*x1_bounds)</pre><pre class="console">
x0, x1 = np.meshgrid(X0, X1)</pre><pre class="console">
z = func([x0, x1])</pre><pre class="console">
ax.plot_surface(x0, x1, z, cmap="gray",</pre><pre class="console">
    vmax=100.0, alpha=0.3)</pre></li>
				<li>Now, we <a id="_idIndexMarker947"/>plot the line in the plane of the function values<a id="_idIndexMarker948"/> that corresponds to<a id="_idIndexMarker949"/> the critical line, <strong class="source-inline">2*x0 + x1 == 6</strong>, and plot the values that fall within the range on top of <span class="No-Break">our plot:</span><pre class="console">
Y = (b[0] - A[0, 0]*X0) / A[0, 1]</pre><pre class="console">
I = np.logical_and(Y &gt;= x1_bounds[0], Y &lt;= x1_bounds[1])</pre><pre class="console">
ax.plot(X0[I], Y[I], func([X0[I], Y[I]]), </pre><pre class="console">
    "k", lw=1.5, alpha=0.6)</pre></li>
				<li>We repeat this plotting step for the second critical line, <strong class="source-inline">x0 + x1 == -</strong><span class="No-Break"><strong class="source-inline">4</strong></span><span class="No-Break">:</span><pre class="console">
Y = (b[1] - A[1, 0]*X0) / A[1, 1]</pre><pre class="console">
I = np.logical_and(Y &gt;= x1_bounds[0], Y &lt;= x1_bounds[1])</pre><pre class="console">
ax.plot(X0[I], Y[I], func([X0[I], Y[I]]), </pre><pre class="console">
    "k", lw=1.5, alpha=0.6)</pre></li>
				<li>Next, we shade the region that lies within the two critical lines, which corresponds to the feasible region for the <span class="No-Break">minimization problem:</span><pre class="console">
B = np.tensordot(A, np.array([x0, x1]), axes=1)</pre><pre class="console">
II = np.logical_and(B[0, ...] &lt;= b[0], B[1, ...] &lt;= b[1])</pre><pre class="console">
ax.plot_trisurf(x0[II], x1[II], z[II], </pre><pre class="console">
    color="k", alpha=0.5)</pre></li>
			</ol>
			<p>The plot of the function values over the feasible region can be seen in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer993">
					<img alt="Figure 9.1 – The values of the linear function with the feasible region highlighted&#13;&#10;" src="image/9.1.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1 – The values of the linear function with the feasible region highlighted</p>
			<p>As we can see, the minimum value that lies within this shaded region occurs at the intersection of the two <span class="No-Break">critical lines.</span></p>
			<ol>
				<li value="8">Next, we<a id="_idIndexMarker950"/> use <strong class="source-inline">linprog</strong> to <a id="_idIndexMarker951"/>solve the constrained <a id="_idIndexMarker952"/>minimization problem <a id="_idIndexMarker953"/>with the bounds we created in <em class="italic">step 1</em>. We print the resulting object in <span class="No-Break">the terminal:</span><pre class="console">
res = optimize.linprog(c, A_ub=A, b_ub=b,</pre><pre class="console">
    bounds= (x0_bounds, x1_bounds))</pre><pre class="console">
print(res)</pre></li>
				<li>Finally, we plot the minimum function value on top of the <span class="No-Break">feasible region:</span><pre class="console">
ax.plot([res.x[0]], [res.x[1]], [res.fun], "kx")</pre></li>
			</ol>
			<p>The updated <a id="_idIndexMarker954"/>plot can be<a id="_idIndexMarker955"/> seen in the <span class="No-Break">following</span><span class="No-Break"><a id="_idIndexMarker956"/></span><span class="No-Break"> diagram:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer994">
					<img alt="Figure 9.2 – The minimum value plotted on the feasible region&#13;&#10;" src="image/9.2.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.2 – The minimum value plotted on the feasible region</p>
			<p>Here, we can see that<a id="_idIndexMarker957"/> the <strong class="source-inline">linprog</strong> routine has indeed found that the minimum is at the intersection of the two <span class="No-Break">critical lines.</span></p>
			<h2 id="_idParaDest-367"><a id="_idTextAnchor366"/>How it works...</h2>
			<p>Constrained <a id="_idIndexMarker958"/>linear minimization problems are common in <a id="_idIndexMarker959"/>economic situations, where you<a id="_idIndexMarker960"/> try to minimize costs while maintaining other aspects of the parameters. In fact, a lot of the terminology from optimization theory mirrors this fact. A very simple algorithm for solving these kinds of problems is called the <strong class="bold">simplex method</strong>, which<a id="_idIndexMarker961"/> uses a sequence of array operations to find the minimal solution. Geometrically, these operations represent changing to different vertices of a simplex (which we won’t define here), and it is this that gives the algorithm <span class="No-Break">its name.</span></p>
			<p>Before we continue, we’ll provide a brief outline of the process used by the simplex method to solve a constrained linear optimization problem. The problem, as presented to us, is not a matrix equation problem but a matrix inequality problem. We can remedy this problem by introducing <strong class="bold">slack variables</strong>, which turn an inequality into an equality. For example, the first constraint <a id="_idIndexMarker962"/>inequality can be rewritten as follows by introducing the slack <span class="No-Break">variable, <img alt="" src="image/Formula_09_010.png"/>:</span></p>
			<p class="IMG---Figure"><img alt="" src="image/Formula_09_011.png"/></p>
			<p>This satisfies the desired inequality, provided that <img alt="" src="image/Formula_09_012.png"/> is not negative. The second constraint inequality is greater than or equal to type inequality that we must first change so that it’s of the less than or equal to type. We do this by multiplying all terms by -1. This gives us the second row of the <strong class="source-inline">A</strong> matrix that we defined in the recipe. After introducing a second slack variable,<img alt="" src="image/Formula_09_013.png"/>, we get the <span class="No-Break">second equation:</span></p>
			<p class="IMG---Figure"><img alt="" src="image/Formula_09_014.png"/></p>
			<p>From this, we <a id="_idIndexMarker963"/>can construct a matrix whose columns contain <a id="_idIndexMarker964"/>the coefficients of the two parameter variables, <img alt="" src="image/Formula_09_015.png"/> and <img alt="" src="image/Formula_09_016.png"/> and the two slack variables, <img alt="" src="image/Formula_09_017.png"/> and <img alt="" src="image/Formula_09_018.png"/>. The rows of this matrix represent the two bounding equations and the objective function. This system of equations can now be solved, using elementary row operations on this matrix, to obtain the values of <img alt="" src="image/Formula_09_019.png"/> and <img alt="" src="image/Formula_09_020.png"/>, which minimize the objective function. Since solving matrix equations is easy and fast, this means that we can minimize linear functions quickly <span class="No-Break">and efficiently.</span></p>
			<p>Fortunately, we don’t need to remember how to reduce our system of inequalities into a system of linear equations, since <a id="_idIndexMarker965"/>routines such as <strong class="source-inline">linprog</strong> do this for us. We can simply provide the bounding inequalities as a matrix and vector pair, consisting of the coefficients of each, and a separate vector that defines the objective function. The <strong class="source-inline">linprog</strong> routine takes care of formulating and then solving the <span class="No-Break">minimization problem.</span></p>
			<p>In practice, the simplex method is not the algorithm used by the <strong class="source-inline">linprog</strong> routine to minimize the function. Instead, <strong class="source-inline">linprog</strong> uses an interior point algorithm, which is more efficient. (The method can actually be set to <strong class="source-inline">simplex</strong> or <strong class="source-inline">revised-simplex</strong> by providing the <strong class="source-inline">method</strong> keyword argument with the appropriate method name. In the printed resulting output, we can see that it only took five iterations to reach the solution.) The resulting object that is returned by this routine contains the parameter values at which the minimum occurs, stored in the <strong class="source-inline">x</strong> attribute, the value of the function at this minimum value stored in the <strong class="source-inline">fun</strong> attribute, and various other pieces of information about the solving process. If the method had failed, then the <strong class="source-inline">status</strong> attribute would have contained a numerical code that described why the <span class="No-Break">method failed.</span></p>
			<p>In <em class="italic">step 2</em> of this recipe, we created a function that represents the objective function for this problem. This function takes a single array as input, which contains the parameter space values at which the function should be evaluated. Here, we used the <strong class="source-inline">tensordot</strong> routine (with <strong class="source-inline">axes=1</strong>) from<a id="_idIndexMarker966"/> NumPy to evaluate the dot product of the coefficient vector, <img alt="" src="image/Formula_09_021.png"/>, with each input, <img alt="" src="image/Formula_09_022.png"/>. We have to be quite careful here, since the values that we pass into the function will be a 2 × 50 × 50 array in a later step. The ordinary matrix multiplication (<strong class="source-inline">np.dot</strong>) would not give the 50 × 50 array output that we desire in <span class="No-Break">this case.</span></p>
			<p>In <em class="italic">step 5</em> and <em class="italic">step 6</em>, we computed the points on the critical lines as those points with the <span class="No-Break">following equation:</span></p>
			<p class="IMG---Figure"><img alt="" src="image/Formula_09_023.png"/></p>
			<p>We then computed the <a id="_idIndexMarker967"/>corresponding <img alt="" src="image/Formula_09_024.png"/> values <a id="_idIndexMarker968"/>so that we could plot the lines that lie on the <a id="_idIndexMarker969"/>plane defined by the objective function. We also need to <em class="italic">trim</em> the values so that we only include those that lie in the range specified in the problem. This is done by constructing the indexing array labeled <strong class="source-inline">I</strong> in the code, consisting of the points that lie within the <span class="No-Break">boundary values.</span></p>
			<h2 id="_idParaDest-368"><a id="_idTextAnchor367"/>There’s more...</h2>
			<p>This recipe covered the constrained minimization problem and how to solve it using SciPy. However, the same method can be used to solve the constrained <em class="italic">maximization</em> problem. This is because maximization and minimization are <em class="italic">dual</em> to one another, in the sense that maximizing a function,<img alt="" src="image/Formula_09_025.png"/>, is the same as minimizing the <img alt="" src="image/Formula_09_026.png"/> function and then taking the negative of this value. In fact, we used this fact in this recipe to change the second constraining inequality from ≥ <span class="No-Break">to ≤.</span></p>
			<p>In this recipe, we solved a problem with only two parameter variables, but the same method will work (except for the plotting steps) for a problem involving more than two such variables. We just need to add more rows and columns to each of the arrays to account for this increased number of variables – this includes the tuple of bounds supplied to the routine. The routine can also be used with sparse matrices, where appropriate, for extra efficiency when dealing with very large amounts <span class="No-Break">of variables.</span></p>
			<p>The <strong class="source-inline">linprog</strong> routine<a id="_idIndexMarker970"/> gets its name from <em class="italic">linear programming</em>, which is used to describe problems of this type – finding values of <img alt="" src="image/Formula_09_027.png"/> that satisfy some matrix inequalities subject to other conditions. Since there is a very close connection between the theory of matrices and linear algebra, there are many very fast and efficient techniques available for linear programming problems that are not available in a <span class="No-Break">non-linear context.</span></p>
			<h1 id="_idParaDest-369"><a id="_idTextAnchor368"/>Minimizing a non-linear function</h1>
			<p>In the previous recipe, we <a id="_idIndexMarker971"/>saw how to minimize a very simple linear function. Unfortunately, most functions are not linear and usually don’t have nice properties that we would like. For these non-linear functions, we cannot use the fast algorithms that have been developed for linear problems, so we need to devise new methods that can be used in these more general cases. The algorithm that we will use here is called the<a id="_idIndexMarker972"/> Nelder-Mead algorithm, which is a robust and general-purpose method that’s used to find the minimum value of a function and does not rely on <span class="No-Break">its gradient.</span></p>
			<p>In this recipe, we’ll learn how to use the Nelder-Mead simplex method to minimize a non-linear function containing <span class="No-Break">two variables.</span></p>
			<h2 id="_idParaDest-370"><a id="_idTextAnchor369"/>Getting ready</h2>
			<p>In this recipe, we <a id="_idIndexMarker973"/>will use the NumPy package imported as <strong class="source-inline">np</strong>, the Matplotlib <strong class="source-inline">pyplot</strong> module imported as <strong class="source-inline">plt</strong>, the <strong class="source-inline">Axes3D</strong> class imported from <strong class="source-inline">mpl_toolkits.mplot3d</strong> to enable 3D plotting, and the SciPy <span class="No-Break"><strong class="source-inline">optimize</strong></span><span class="No-Break"> module:</span></p>
			<pre class="source-code">
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from scipy import optimize</pre>
			<p>Let’s see how to use these tools to solve a non-linear <span class="No-Break">optimization problem.</span></p>
			<h2 id="_idParaDest-371"><a id="_idTextAnchor370"/>How to do it...</h2>
			<p>The following steps <a id="_idIndexMarker974"/>show you how to use the Nelder-Mead simplex method to find the minimum of a general non-linear <span class="No-Break">objective function:</span></p>
			<ol>
				<li value="1">Define the objective function that we <span class="No-Break">will minimize:</span><pre class="console">
def func(x):</pre><pre class="console">
    return ((x[0] - 0.5)**2 + (</pre><pre class="console">
        x[1] + 0.5)**2)*np.cos(0.5*x[0]*x[1])</pre></li>
				<li>Next, create a grid of values that we can plot our objective <span class="No-Break">function on:</span><pre class="console">
x_r = np.linspace(-1, 1)</pre><pre class="console">
y_r = np.linspace(-2, 2)</pre><pre class="console">
x, y = np.meshgrid(x_r, y_r)</pre></li>
				<li>Now, we evaluate the function on this grid <span class="No-Break">of points:</span><pre class="console">
z = func([x, y])</pre></li>
				<li>Next, we create a new figure with a <strong class="source-inline">3d</strong> axes object and set the axis labels and <span class="No-Break">the title:</span><pre class="console">
fig = plt.figure(tight_layout=True)</pre><pre class="console">
ax = fig.add_subplot(projection="3d")</pre><pre class="console">
ax.tick_params(axis="both", which="major", labelsize=9)</pre><pre class="console">
ax.set(xlabel="x", ylabel="y", zlabel="z")</pre><pre class="console">
ax.set_title("Objective function")</pre></li>
				<li>Now, we can <a id="_idIndexMarker975"/>plot the objective function as a surface on the <a id="_idIndexMarker976"/>axes we <span class="No-Break">just created:</span><pre class="console">
ax.plot_surface(x, y, z, cmap="gray",</pre><pre class="console">
    vmax=8.0, alpha=0.5)</pre></li>
				<li>We choose an initial point that our minimization routine will start its iteration at and plot this on <span class="No-Break">the surface:</span><pre class="console">
x0 = np.array([-0.5, 1.0])</pre><pre class="console">
ax.plot([x0[0]], [x0[1]], func(x0), "k*")</pre></li>
			</ol>
			<p>The plot of the objective function’s surface, along with the initial point, can be seen in the following diagram. Here, we can see that the minimum value appears to occur at around 0.5 on the x axis and -0.5 on the <span class="No-Break">y axis:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer1013">
					<img alt="Figure 9.3 – A non-linear objective function with a starting point&#13;&#10;" src="image/9.3.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.3 – A non-linear objective function with a starting point</p>
			<ol>
				<li value="7">Now, we<a id="_idIndexMarker977"/> use <a id="_idIndexMarker978"/>the <strong class="source-inline">minimize</strong> routine from the <strong class="source-inline">optimize</strong> package<a id="_idIndexMarker979"/> to find the minimum value and print the <strong class="source-inline">result</strong> object that <span class="No-Break">it produces:</span><pre class="console">
result = optimize.minimize(</pre><pre class="console">
    func, x0, tol=1e-6, method= "Nelder-Mead")</pre><pre class="console">
print(result)</pre></li>
				<li>Finally, we plot the minimum value found by the <strong class="source-inline">minimize</strong> routine on top of the objective <span class="No-Break">function surface:</span><pre class="console">
ax.plot([result.x[0]], [result.x[1]], [result.fun], "kx")</pre></li>
			</ol>
			<p>The updated plot of the objective function, including the minimum point found by the <strong class="source-inline">minimize</strong> routine, can be <a id="_idIndexMarker980"/>seen in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer1014">
					<img alt="Figure 9.4 – An objective function with a starting point and a minimum point&#13;&#10;" src="image/9.4.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.4 – An objective function with a starting point and a minimum point</p>
			<p>This shows that the <a id="_idIndexMarker981"/>method has indeed found the minimum point (bottom right) within <a id="_idIndexMarker982"/>the region starting from the initial point (<span class="No-Break">top left).</span></p>
			<h2 id="_idParaDest-372"><a id="_idTextAnchor371"/>How it works...</h2>
			<p>The Nelder-Mead simplex method – not to be confused with the simplex method for linear optimization problems – is a simple algorithm for finding the minimum values of a non-linear function and works even when the objective function does not have a known derivative. (This is not the case for the function in this recipe; the only gain from using a gradient-based method is the speed of convergence.) The method works by comparing the values of the objective function at the vertices of a simplex, which is a triangle in a two-dimensional space. The vertex with the largest function value is <em class="italic">reflected</em> through the opposite edge and performs an appropriate expansion or contraction that, in effect, moves the <span class="No-Break">simplex </span><span class="No-Break"><em class="italic">downhill</em></span><span class="No-Break">.</span></p>
			<p>The <strong class="source-inline">minimize</strong> routine<a id="_idIndexMarker983"/> from the SciPy <strong class="source-inline">optimize</strong> module is an entry point for many <a id="_idIndexMarker984"/>non-linear function minimization algorithms. In this recipe, we used the Nelder-Mead simplex algorithm, but there are also a number of other algorithms available. Many of these algorithms require knowledge of the gradient of the function, which might be computed automatically by the algorithm. The algorithm can be used by providing the appropriate name to the <strong class="source-inline">method</strong> <span class="No-Break">keyword argument.</span></p>
			<p>The <strong class="source-inline">result</strong> object that’s returned by the <strong class="source-inline">minimize</strong> routine contains lots of information about the solution that has been found – or not found, if an error occurred – by the solver. In particular, the desired parameters that the calculated minimum occurs at are stored in the <strong class="source-inline">x</strong> attribute of the result, while the value of the function is stored in the <span class="No-Break"><strong class="source-inline">fun</strong></span><span class="No-Break"> attribute.</span></p>
			<p>The <strong class="source-inline">minimize</strong> routine <a id="_idIndexMarker985"/>requires the function and a starting value of <strong class="source-inline">x0</strong>. In this recipe, we also provided a tolerance value that the minimum should be computed at using the <strong class="source-inline">tol</strong> keyword argument. Changing this value will modify the accuracy of the <span class="No-Break">computed solution.</span></p>
			<h2 id="_idParaDest-373"><a id="_idTextAnchor372"/>There’s more...</h2>
			<p>The Nelder-Mead algorithm<a id="_idIndexMarker986"/> is an example of<a id="_idIndexMarker987"/> a <em class="italic">gradient-free</em> minimization algorithm, since it does not require any information about the gradient (derivative) of the objective function. There are several such algorithms, all of which typically involve evaluating the objective function at several points, and then using this information to move toward the minimum value. In general, gradient-free methods tend to converge more slowly than gradient-descent models. However, they can be used for almost any objective function, even where it is not easy to compute the gradient either exactly or by means <span class="No-Break">of approximation.</span></p>
			<p>Optimizing the functions of a single variable is generally easier than the multidimensional case and has its own special function in the SciPy <strong class="source-inline">optimize</strong> library. The <strong class="source-inline">minimize_scalar</strong> routine<a id="_idIndexMarker988"/> performs minimization for functions of a single variable and should be used instead of <strong class="source-inline">minimize</strong> in <span class="No-Break">this case.</span></p>
			<h1 id="_idParaDest-374"><a id="_idTextAnchor373"/>Using gradient descent methods in optimization</h1>
			<p>In the previous recipe, we used the Nelder-Mead simplex algorithm to minimize a non-linear function containing two variables. This is a fairly robust method that works even if very little is known about the objective function. However, in many situations, we do know more about the objective function, and this fact allows us to devise faster and more efficient algorithms for minimizing the function. We can do this by making use of properties such as the gradient of <span class="No-Break">the function.</span></p>
			<p>The <em class="italic">gradient</em> of a function of more than one variable describes the rate of change of the function in each of its component directions. This is a vector of the partial derivatives of the function with respect to each of the variables. From this gradient vector, we can deduce the direction in which the function is increasing most rapidly and, conversely, the direction in which the function is decreasing most rapidly from any given position. This gives us the <a id="_idIndexMarker989"/>basis for <strong class="bold">gradient descent</strong> methods for minimizing a function. The algorithm is very simple: given a starting position,<img alt="" src="image/Formula_09_028.png"/>, we compute the gradient at <img alt="" src="image/Formula_09_029.png"/> and the corresponding direction in which the gradient is most rapidly decreasing, and then make a small step in that direction. After a few iterations, this will move from the starting position to the minimum of <span class="No-Break">the function.</span></p>
			<p>In this recipe, we will learn how to implement an algorithm based on the steepest descent algorithm to minimize an objective function within a <span class="No-Break">bounded region.</span></p>
			<h2 id="_idParaDest-375"><a id="_idTextAnchor374"/>Getting ready</h2>
			<p>For this recipe, we <a id="_idIndexMarker990"/>will need the NumPy package <a id="_idIndexMarker991"/>imported as <strong class="source-inline">np</strong>, the Matplotlib <strong class="source-inline">pyplot</strong> module imported as <strong class="source-inline">plt</strong>, and the <strong class="source-inline">Axes3D</strong> object imported <span class="No-Break">from </span><span class="No-Break"><strong class="source-inline">mpl_toolkits.mplot3d</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D</pre>
			<p>Let’s implement a simple gradient descent algorithm and use it to solve the minimization problem described in the previous recipe to see how <span class="No-Break">it works.</span></p>
			<h2 id="_idParaDest-376"><a id="_idTextAnchor375"/>How to do it...</h2>
			<p>In the<a id="_idIndexMarker992"/> following steps, we will implement<a id="_idIndexMarker993"/> a simple gradient descent method to minimize an objective function with a known gradient function (we’re actually going to use a generator function so that we can see the method as <span class="No-Break">it works):</span></p>
			<ol>
				<li value="1">We will start by defining a <strong class="source-inline">descend</strong> routine, which will carry out our algorithm. The function declaration is <span class="No-Break">as follows:</span><pre class="console">
def descend(func,x0,grad,bounds,tol=1e-8,max_iter=100):</pre></li>
				<li>Next, we need to implement this routine. We start by defining the variables that will hold the iterate values while the method <span class="No-Break">is running:</span><pre class="console">
    xn = x0</pre><pre class="console">
    previous = np.inf</pre><pre class="console">
    grad_xn = grad(x0)</pre></li>
				<li>We then start our loop, which will run the iterations. We immediately check whether we are making meaningful progress <span class="No-Break">before continuing:</span><pre class="console">
    for i in range(max_iter):</pre><pre class="console">
        if np.linalg.norm(xn - previous) &lt; tol:</pre><pre class="console">
            break</pre></li>
				<li>The direction is minus the gradient vector. We compute this once and store it in the <span class="No-Break"><strong class="source-inline">direction</strong></span><span class="No-Break"> variable:</span><pre class="console">
        direction = -grad_xn</pre></li>
				<li>Now, we update the previous and current values, <strong class="source-inline">xnm1</strong> and <strong class="source-inline">xn</strong> respectively, ready for the next iteration. This concludes the code for the <span class="No-Break"><strong class="source-inline">descend</strong></span><span class="No-Break"> routine:</span><pre class="console">
        previous = xn</pre><pre class="console">
        xn = xn + 0.2*direction</pre></li>
				<li>Now, we can compute the gradient at the current value and yield all the <span class="No-Break">appropriate values:</span><pre class="console">
        grad_xn = grad(xn)</pre><pre class="console">
        yield i, xn, func(xn), grad_xn</pre></li>
			</ol>
			<p>This concludes the definition of the <span class="No-Break"><strong class="source-inline">descend</strong></span><span class="No-Break"> routine.</span></p>
			<ol>
				<li value="7">We can now define a sample objective function <span class="No-Break">to minimize:</span><pre class="console">
def func(x):</pre><pre class="console">
    return ((x[0] - 0.5)**2 + (</pre><pre class="console">
        x[1] + 0.5)**2)*np.cos(0.5*x[0]*x[1])</pre></li>
				<li>Next, we<a id="_idIndexMarker994"/> create a grid that we will<a id="_idIndexMarker995"/> evaluate and then plot the objective <span class="No-Break">function on:</span><pre class="console">
x_r = np.linspace(-1, 1)</pre><pre class="console">
y_r = np.linspace(-2, 2)</pre><pre class="console">
x, y = np.meshgrid(x_r, y_r)</pre></li>
				<li>Once the grid has been created, we can evaluate our function and store the result in the <span class="No-Break"><strong class="source-inline">z</strong></span><span class="No-Break"> variable:</span><pre class="console">
z = func([x, y])</pre></li>
				<li>Next, we create a three-dimensional surface plot of the <span class="No-Break">objective function:</span><pre class="console">
surf_fig = plt.figure(tight_layout=True)</pre><pre class="console">
surf_ax = surf_fig.add_subplot(projection="3d")</pre><pre class="console">
surf_ax.tick_params(axis="both", which="major",</pre><pre class="console">
    labelsize=9)</pre><pre class="console">
surf_ax.set(xlabel="x", ylabel="y", zlabel="z")</pre><pre class="console">
surf_ax.set_title("Objective function")</pre><pre class="console">
surf_ax.plot_surface(x, y, z, cmap="gray", </pre><pre class="console">
    vmax=8.0, alpha=0.5)</pre></li>
				<li>Before we <a id="_idIndexMarker996"/>can start the minimization <a id="_idIndexMarker997"/>process, we need to define an initial point, <strong class="source-inline">x0</strong>. We plot this point on the objective function plot we created in the <span class="No-Break">previous step:</span><pre class="console">
x0 = np.array([-0.8, 1.3])</pre><pre class="console">
surf_ax.plot([x0[0]], [x0[1]], func(x0), "k*")</pre></li>
			</ol>
			<p>The surface plot of the objective function, along with the initial value, can be seen in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer1017">
					<img alt="Figure 9.5 – The surface of the objective function with the initial position&#13;&#10;" src="image/9.5.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.5 – The surface of the objective function with the initial position</p>
			<ol>
				<li value="12">Our <strong class="source-inline">descend</strong> routine <a id="_idIndexMarker998"/>requires a function that <a id="_idIndexMarker999"/>evaluates the gradient of the objective function, so we will <span class="No-Break">define one:</span><pre class="console">
def grad(x):</pre><pre class="console">
    c1 = x[0]**2 - x[0] + x[1]**2 + x[1] + 0.5</pre><pre class="console">
    cos_t = np.cos(0.5*x[0]*x[1])</pre><pre class="console">
    sin_t = np.sin(0.5*x[0]*x[1])</pre><pre class="console">
    return np.array([</pre><pre class="console">
        (2*x[0]-1)*cos_t - 0.5*x[1]*c1*sin_t,</pre><pre class="console">
        (2*x[1]+1)*cos_t - 0.5*x[0]*c1*sin_t</pre><pre class="console">
    ])</pre></li>
				<li>We will plot the iterations on a contour plot, so we set this up <span class="No-Break">as follows:</span><pre class="console">
cont_fig, cont_ax = plt.subplots()</pre><pre class="console">
cont_ax.set(xlabel="x", ylabel="y")</pre><pre class="console">
cont_ax.set_title("Contour plot with iterates")</pre><pre class="console">
cont_ax.contour(x, y, z, levels=25, cmap="gray",</pre><pre class="console">
    vmax=8.0, opacity=0.6)</pre></li>
				<li>Now, we create a variable that holds the bounds in the <img alt="" src="image/Formula_09_027.png"/> and <img alt="" src="image/Formula_09_031.png"/> directions as a tuple of tuples. These are the same bounds from the <strong class="source-inline">linspace</strong> calls in <span class="No-Break"><em class="italic">step 10</em></span><span class="No-Break">:</span><pre class="console">
bounds = ((-1, 1), (-2, 2))</pre></li>
				<li>We can now use a <strong class="source-inline">for</strong> loop to drive the <strong class="source-inline">descend</strong> generator to produce each of the iterations and add the steps to the <span class="No-Break">contour plot:</span><pre class="console">
xnm1 = x0</pre><pre class="console">
for i, xn, fxn, grad_xn in descend(func, x0, grad, bounds):</pre><pre class="console">
    cont_ax.plot([xnm1[0], xn[0]], [xnm1[1], xn[1]],           	        "k*--")</pre><pre class="console">
    xnm1, grad_xnm1 = xn, grad_xn</pre></li>
				<li>Once the loop is complete, we print the final values to <span class="No-Break">the Terminal:</span><pre class="console">
print(f"iterations={i}")</pre><pre class="console">
print(f"min val at {xn}")</pre><pre class="console">
print(f"min func value = {fxn}")</pre></li>
			</ol>
			<p>The output <a id="_idIndexMarker1000"/>of the preceding <strong class="source-inline">print</strong> <a id="_idIndexMarker1001"/>statements is <span class="No-Break">as follows:</span></p>
			<pre class="console">
iterations=37
min val at [ 0.49999999 -0.49999999]
min func value = 2.1287163880894953e-16</pre>
			<p>Here, we can see that our routine used 37 iterations to find a minimum at approximately (0.5, -0.5), which <span class="No-Break">is correct.</span></p>
			<p>The contour plot with its iterations plotted can be seen in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer1020">
					<img alt="Figure 9.6 – A contour plot of the objective function with the gradient descent iterating to a minimum value" src="image/9.6.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.6 – A contour plot of the objective function with the gradient descent iterating to a minimum value</p>
			<p>Here, we <a id="_idIndexMarker1002"/>can see that the direction of <a id="_idIndexMarker1003"/>each iteration – shown by the dashed lines – is in the direction where the objective function is decreasing most rapidly. The final iteration lies at the center of the <em class="italic">bowl</em> of the objective function, which is where the <span class="No-Break">minimum occurs.</span></p>
			<h2 id="_idParaDest-377"><a id="_idTextAnchor376"/>How it works...</h2>
			<p>The heart of this recipe is <a id="_idIndexMarker1004"/>the <strong class="source-inline">descend</strong> routine. The process that’s defined in this routine is a very simple implementation of the gradient descent method. Computing the gradient at a given point is handled by the <strong class="source-inline">grad</strong> argument, which is then used to deduce the direction of travel for the iteration by taking <strong class="source-inline">direction = -grad</strong>. We multiply this direction by a fixed scale<a id="_idIndexMarker1005"/> factor (sometimes called the <strong class="bold">learning rate</strong>) with a value of 0.2 to obtain the scaled step, and then take this step by adding <strong class="source-inline">0.2*direction</strong> to the <span class="No-Break">current position.</span></p>
			<p>The solution in the recipe took 37 iterations to converge, which is a mild improvement on the Nelder-Mead simplex algorithm from the <em class="italic">Minimizing a non-linear function</em> recipe, which took 58 iterations. (This is not a perfect comparison, since we changed the starting position for this recipe.) This performance is heavily dependent on the step size that we choose. In this case, we fixed the maximum step size to be 0.2 times the size of the direction vector. This keeps the algorithm simple, but it is not <span class="No-Break">particularly efficient.</span></p>
			<p>In this recipe, we chose to implement the algorithm as a generator function so that we could see the output of each step and plot this on our contour plot as we stepped through the iteration. In practice, we probably wouldn’t want to do this and instead return the calculated minimum once the iterations have finished. To do this, we can simply remove the <strong class="source-inline">yield</strong> statement and replace it with <strong class="source-inline">return xn</strong> at the very end of the function, at the main function’s indentation (that is, not inside the loop). If you want to guard against non-convergence, you can use the <strong class="source-inline">else</strong> feature of the <strong class="source-inline">for</strong> loop to catch cases where the loop finishes because it has reached the end of its iterator without hitting the <strong class="source-inline">break</strong> keyword. This <strong class="source-inline">else</strong> block could raise an exception to indicate that the algorithm has failed to stabilize to a solution. The condition we used to end the iteration <a id="_idIndexMarker1006"/>in this recipe does not guarantee <a id="_idIndexMarker1007"/>that the method has reached a minimum, but this will usually be <span class="No-Break">the case.</span></p>
			<h2 id="_idParaDest-378"><a id="_idTextAnchor377"/>There’s more...</h2>
			<p>In practice, you would not usually implement the gradient descent algorithm for yourself and instead use a general-purpose routine from a library such as the SciPy <strong class="source-inline">optimize</strong> module. We can <a id="_idIndexMarker1008"/>use the same <strong class="source-inline">minimize</strong> routine that we used in the previous recipe to perform <a id="_idIndexMarker1009"/>minimization with a variety of different algorithms, including several gradient descent algorithms. These implementations are likely to have much higher performance and be more robust than a custom implementation such <span class="No-Break">as this.</span></p>
			<p>The gradient descent method we used in this recipe is a very naive implementation and can be greatly improved by allowing the routine to choose the step size at each step. (Methods that are allowed to choose their own step size are sometimes called adaptive methods.) The difficult part of this improvement is choosing the size of the step to take in this direction. For this, we need to consider the function of a single variable, which is given by the <span class="No-Break">following equation:</span></p>
			<p class="IMG---Figure"><img alt="" src="image/Formula_09_032.png"/></p>
			<p>Here, <img alt="" src="image/Formula_09_033.png"/> represents the current point, <img alt="" src="image/Formula_09_034.png"/> represents the current direction, and <img alt="" src="image/Formula_09_035.png"/> is a parameter. For simplicity, we can use a minimization routine called <strong class="source-inline">minimize_scalar</strong> for scalar-valued functions from<a id="_idIndexMarker1010"/> the SciPy <strong class="source-inline">optimize</strong> module. Unfortunately, it is not quite as simple as passing in this auxiliary function and finding the minimum value. We have to bound the possible value of <img alt="" src="image/Formula_09_036.png"/> so that the computed minimizing point, <img alt="" src="image/Formula_09_037.png"/>, lies within the region that we are <span class="No-Break">interested in.</span></p>
			<p>To understand how we bound the values of <img alt="" src="image/Formula_09_038.png"/>, we must first look at the construction geometrically. The auxiliary function that we introduce evaluates the objective function along a single line in the given direction. We can picture this as taking a single cross section through the surface that passes through the current <img alt="" src="image/Formula_09_039.png"/> point in the <img alt="" src="image/Formula_09_040.png"/> direction. The next step of the algorithm is finding the step size, <img alt="" src="image/Formula_09_041.png"/>, that minimizes the values of the objective function along this line – this is a scalar function, which is much easier to minimize. The bounds should then be the range of <img alt="" src="image/Formula_09_042.png"/> values, during which this line lies within the rectangle defined by the <img alt="" src="image/Formula_09_043.png"/> and <img alt="" src="image/Formula_09_044.png"/> boundary values. We determine the four values at which this line crosses those <img alt="" src="image/Formula_09_045.png"/> and <img alt="" src="image/Formula_09_046.png"/> boundary lines, two of which will be negative and two of which will be positive. (This is because the current point must lie within the rectangle.) We take the minimum of the two positive values and the maximum of the two negative values and pass these bounds to the scalar minimization routine. This is achieved using the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
alphas = np.array([
    (bounds[0][0] - xn[0]) / direction[0],
    # x lower
   (bounds[1][0] - xn[1]) / direction[1],
    # y lower
    (bounds[0][1] - xn[0]) / direction[0],
    # x upper
    (bounds[1][1] - xn[1]) / direction[1] 
    # y upper
])
alpha_max = alphas[alphas &gt;= 0].min()
alpha_min = alphas[alphas &lt; 0].max()
result = minimize_scalar(lambda t: 
    func(xn + t*direction),
    method="bounded",
    bounds=(alpha_min, alpha_max))
amount = result.x</pre>
			<p>Once the step size has been chosen, the only remaining step is to update the current <strong class="source-inline">xn</strong> value, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
xn = xn + amount * direction</pre>
			<p>Using this adaptive step size increases the complexity of the routine, but the performance is massively improved. Using this revised routine, the method converged in just three iterations, which is far fewer than the number of iterations used by the naive code in this recipe (37 iterations) or by the Nelder-Mead simplex algorithm in the previous recipe (58 iterations). This reduction in the number of iterations is exactly what we expected by providing the method with more information in the form of the <span class="No-Break">gradient function.</span></p>
			<p>We created a function that returned the gradient of the function at a given point. We computed this gradient by hand before we started, which will not always be easy or even possible. Instead, it is much more common to replace the <em class="italic">analytic</em> gradient used here with a numerically computed gradient that’s been estimated using finite differences or a similar algorithm. This has an impact on performance and accuracy, as all approximations do, but these concerns are usually minor given the improvement in the speed of convergence offered by gradient <span class="No-Break">descent methods.</span></p>
			<p>Gradient descent-type algorithms are particularly popular in machine learning applications. Most of the popular Python machine learning libraries – including PyTorch, TensorFlow, and Theano – offer utilities for automatically computing gradients numerically for data arrays. This allows gradient descent methods<a id="_idIndexMarker1011"/> to be used in the background to <span class="No-Break">improve performance.</span></p>
			<p>A popular variation of the gradient descent method<a id="_idIndexMarker1012"/> is <strong class="bold">stochastic gradient descent</strong>, where the gradient is estimated by sampling randomly rather than using the whole set of data. This can dramatically reduce the computational burden of the method – at the cost of slower convergence – especially for high-dimensional problems such as those that are common in machine learning applications. Stochastic gradient descent methods are often combined with backpropagation to form the <a id="_idIndexMarker1013"/>basis for training artificial neural networks in machine <span class="No-Break">learning applications.</span></p>
			<p>There are several extensions of the basic stochastic gradient descent algorithm. For example, the momentum algorithm incorporates the previous increment into the calculation of the next increment. Another example is the adaptive gradient algorithm, which incorporates per-parameter learning rates to improve the rate of convergence for problems that involve a large number of <span class="No-Break">sparse parameters.</span></p>
			<h1 id="_idParaDest-379"><a id="_idTextAnchor378"/>Using least squares to fit a curve to data</h1>
			<p>Least squares is<a id="_idIndexMarker1014"/> a powerful technique for finding a function from a relatively small family of potential functions that best describe a particular set of data. This technique is especially common in statistics. For example, least squares is used in linear regression problems – here, the family of potential functions is the collection of all linear functions. Usually, the family of functions that we try to fit has relatively few parameters that can be adjusted to solve <span class="No-Break">the problem.</span></p>
			<p>The idea of least squares is relatively simple. For each data point, we compute the square of the residual – the difference between the value of the point and the expected value given a function – and try to make the sum of these squared residuals as small as possible (hence, <span class="No-Break">least squares).</span></p>
			<p>In this recipe, we’ll learn <a id="_idIndexMarker1015"/>how to use least squares to fit a curve to a sample set <span class="No-Break">of data.</span></p>
			<h2 id="_idParaDest-380"><a id="_idTextAnchor379"/>Getting ready</h2>
			<p>For this recipe, we will need the NumPy package imported, as usual, as <strong class="source-inline">np</strong>, and the Matplotlib <strong class="source-inline">pyplot</strong> module imported <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">plt</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
import numpy as np
import matplotlib.pyplot as plt</pre>
			<p>We will also need an instance of the default random number generator from the NumPy <strong class="source-inline">random</strong> module imported, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
from numpy.random import default_rng
rng = default_rng(12345)</pre>
			<p>Finally, we need the <strong class="source-inline">curve_fit</strong> routine from the SciPy <span class="No-Break"><strong class="source-inline">optimize</strong></span><span class="No-Break"> module:</span></p>
			<pre class="source-code">
from scipy.optimize import curve_fit</pre>
			<p>Let’s see how to use this routine to fit a non-linear curve to <span class="No-Break">some data.</span></p>
			<h2 id="_idParaDest-381"><a id="_idTextAnchor380"/>How to do it...</h2>
			<p>The<a id="_idIndexMarker1016"/> following steps show you how to use the <strong class="source-inline">curve_fit</strong> routine to fit a curve to a set <span class="No-Break">of data:</span></p>
			<ol>
				<li value="1">The first step is to create the <span class="No-Break">sample data:</span><pre class="console">
SIZE = 100</pre><pre class="console">
x_data = rng.uniform(-3.0, 3.0, size=SIZE)</pre><pre class="console">
noise = rng.normal(0.0, 0.8, size=SIZE)</pre><pre class="console">
y_data = 2.0*x_data**2 - 4*x_data + noise</pre></li>
				<li>Next, we produce a scatter plot of the data to see whether we can identify the underlying trend in <span class="No-Break">the data:</span><pre class="console">
fig, ax = plt.subplots()</pre><pre class="console">
ax.scatter(x_data, y_data)</pre><pre class="console">
ax.set(xlabel="x", ylabel="y",</pre><pre class="console">
    title="Scatter plot of sample data")</pre></li>
			</ol>
			<p>The scatter plot that we have produced can be seen in the following diagram. Here, we can see that the data certainly doesn’t follow a linear trend (straight line). Since we know the trend is a polynomial, our next guess would be a quadratic trend. This is what we’re <span class="No-Break">using here:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer1036">
					<img alt="Figure 9.7 – Scatter plot of the sample data – we can see that it does not follow a linear trend&#13;&#10;" src="image/9.7.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.7 – Scatter plot of the sample data – we can see that it does not follow a linear trend</p>
			<ol>
				<li value="3">Next, we<a id="_idIndexMarker1017"/> create a function that represents the model that we wish <span class="No-Break">to fit:</span><pre class="console">
def func(x, a, b, c):</pre><pre class="console">
    return a*x**2 + b*x + c</pre></li>
				<li>Now, we can use the <strong class="source-inline">curve_fit</strong> routine to fit the model function to the <span class="No-Break">sample data:</span><pre class="console">
coeffs, _ = curve_fit(func, x_data, y_data)</pre><pre class="console">
print(coeffs)</pre><pre class="console">
# [ 1.99611157 -3.97522213 0.04546998]</pre></li>
				<li>Finally, we plot the best fit curve on top of the scatter plot to evaluate how well the fitted curve describes <span class="No-Break">the data:</span><pre class="console">
x = np.linspace(-3.0, 3.0, SIZE)</pre><pre class="console">
y = func(x, coeffs[0], coeffs[1], coeffs[2])</pre><pre class="console">
ax.plot(x, y, "k--")</pre></li>
			</ol>
			<p>The updated scatter plot can be seen in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer1037">
					<img alt="Figure 9.8 – A scatter plot with the curve of the best fit found using superimposed least squares&#13;&#10;" src="image/9.8.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.8 – A scatter plot with the curve of the best fit found using superimposed least squares</p>
			<p>Here, we can see<a id="_idIndexMarker1018"/> that the curve we have found fits the data reasonably well. The coefficients are not exactly equal to the true model – this is the effect of the <span class="No-Break">added noise.</span></p>
			<h2 id="_idParaDest-382"><a id="_idTextAnchor381"/>How it works...</h2>
			<p>The <strong class="source-inline">curve_fit</strong> routine<a id="_idIndexMarker1019"/> performs least-squares fitting to fit the model’s curve to the sample data. In practice, this amounts to minimizing the following <span class="No-Break">objective function:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer1038">
					<img alt="" src="image/Formula_09_047.jpg"/>
				</div>
			</div>
			<p>Here, the pairs <img alt="" src="image/Formula_09_048.png"/> are the points from the sample data. In this case, we are optimizing over a three-dimensional parameter space, with one dimension for each of the parameters. The routine returns the estimated coefficients – the point in the parameter space at which the objective function is minimized – and a second variable that contains estimates for the covariance matrix for the fit. We ignored this in <span class="No-Break">this recipe.</span></p>
			<p>The estimated covariance matrix that’s returned <a id="_idIndexMarker1020"/>from the <strong class="source-inline">curve_fit</strong> routine can be used to give a confidence interval for the estimated parameters. This is done by taking the square root of the diagonal elements divided by the sample size (100 in this recipe). This gives the standard error for the estimate that, when multiplied by the appropriate values corresponding to the confidence, gives us the size of the confidence interval. (We discussed confidence intervals in <a href="B19085_06.xhtml#_idTextAnchor226"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>, <em class="italic">Working with Data </em><span class="No-Break"><em class="italic">and Statistics</em></span><span class="No-Break">.)</span></p>
			<p>You might have noticed that the parameters estimated by the <strong class="source-inline">curve_fit</strong> routine are close, but not exactly equal, to the parameters that we used to define the sample data in <em class="italic">step 1</em>. The fact that these are not exactly equal is due to the normally distributed noise that we added to the data. In this recipe, we knew that the underlying structure of the data was<a id="_idIndexMarker1021"/> quadratic – that is, a degree 2 polynomial – and not some other, more esoteric, function. In practice, we are unlikely to know so much about the underlying structure of the data, which is the reason we added noise to <span class="No-Break">the sample.</span></p>
			<h2 id="_idParaDest-383"><a id="_idTextAnchor382"/>There’s more...</h2>
			<p>There is another routine in the SciPy <strong class="source-inline">optimize</strong> module for performing least-squares fitting called <strong class="source-inline">least_squares</strong>. This routine has a slightly less intuitive signature but does return an object containing more information about the optimization process. However, the way this routine is set up is perhaps more similar to the way that we constructed the underlying mathematical problem in the <em class="italic">How it works...</em> section. To use this routine, we define the objective function <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
def func(params, x, y):
    return y -(
        params[0]*x**2 + params[1]*x + params[2])</pre>
			<p>We pass this function along with a starting estimate in the parameter space, <strong class="source-inline">x0</strong>, such as <strong class="source-inline">(1, 0, 0)</strong>. The additional parameters for the objective function, <strong class="source-inline">func</strong>, can be passed using the <strong class="source-inline">args</strong> keyword argument – for example, we could use <strong class="source-inline">args=(x_data, y_data)</strong>. These arguments are passed into the <strong class="source-inline">x</strong> and <strong class="source-inline">y</strong> arguments of the objective function. To summarize, we could have estimated the parameters using the following call <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">least_squares</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
results = least_squares(func, [1, 0, 0], args=(x_data, y_data))</pre>
			<p>The <strong class="source-inline">results</strong> object that’s returned from the <strong class="source-inline">least_squares</strong> routine is actually the same as the one returned by the other optimization routines described in this chapter. It contains details such as the number of iterations used, whether the process was successful, detailed error messages, the parameter values, and the value of the objective function at the <span class="No-Break">minimum value.</span></p>
			<h1 id="_idParaDest-384"><a id="_idTextAnchor383"/>Analyzing simple two-player games</h1>
			<p>Game theory<a id="_idIndexMarker1022"/> is a branch of mathematics concerned with the analysis of decision-making and strategy. It has applications in economics, biology, and behavioral science. Many seemingly complex situations can be reduced to a relatively simple mathematical game that can be analyzed in a systematic way to find <span class="No-Break"><em class="italic">optimal</em></span><span class="No-Break"> solutions.</span></p>
			<p>A classic problem in game theory is<a id="_idIndexMarker1023"/> the <em class="italic">prisoner’s dilemma</em>, which, in its original form, is as follows: two co-conspirators are caught and must decide whether to remain quiet or to testify against the other. If both remain quiet, they both serve a 1-year sentence; if one testifies but the other does not, the testifier is released and the other serves a 3-year sentence; and if both testify against one another, they both serve a 2-year sentence. What should each conspirator do? It turns out that the best choice each conspirator can make, given any reasonable distrust of the other, is to testify. Adopting this strategy, they will either serve no sentence or a 2-year <span class="No-Break">sentence maximum.</span></p>
			<p>Since this book is about Python, we will use a variation of this classic problem to illustrate just how universal the idea of this problem is. Consider the following problem: you and your colleague have to write some code for a client. You think that you could write the code faster in Python, but your colleague thinks that they could write it faster in C. The question is, which language should you choose for <span class="No-Break">the project?</span></p>
			<p>You think that you could write the Python code four times faster than in C, so you write C with speed 1 and Python with speed 4. Your colleague says that they can write C slightly faster than Python, so they write C with speed 3 and Python with speed 2. If you both agree on a language, then you write the code at the speed you predicted, but if you disagree, then the productivity of the faster programmer is reduced by 1. We can summarize this <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer1040">
					<table class="No-Table-Style" id="table001-1">
						<colgroup>
							<col/>
							<col/>
							<col/>
						</colgroup>
						<tbody>
							<tr class="No-Table-Style">
								<td class="No-Table-Style T---Body">
									<p><span class="No-Break">Colleague/You</span></p>
								</td>
								<td class="No-Table-Style T---Body">
									<p>C</p>
								</td>
								<td class="No-Table-Style T---Body">
									<p><span class="No-Break">Python</span></p>
								</td>
							</tr>
							<tr class="No-Table-Style">
								<td class="No-Table-Style T---Body">
									<p>C</p>
								</td>
								<td class="No-Table-Style T---Body">
									<p><span class="No-Break">3/1</span></p>
								</td>
								<td class="No-Table-Style T---Body">
									<p><span class="No-Break">3/2</span></p>
								</td>
							</tr>
							<tr class="No-Table-Style">
								<td class="No-Table-Style T---Body">
									<p><span class="No-Break">Python</span></p>
								</td>
								<td class="No-Table-Style T---Body">
									<p><span class="No-Break">2/1</span></p>
								</td>
								<td class="No-Table-Style T---Body">
									<p><span class="No-Break">2/4</span></p>
								</td>
							</tr>
						</tbody>
					</table>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.9 – A table of the predicted work speed in various configurations</p>
			<p>In this recipe, we will learn how to construct an object in Python to represent this simple two-player game, and then perform some elementary analysis regarding the outcomes of <span class="No-Break">this game.</span></p>
			<h2 id="_idParaDest-385"><a id="_idTextAnchor384"/>Getting ready</h2>
			<p>For this recipe, we<a id="_idIndexMarker1024"/> will need the NumPy package imported as <strong class="source-inline">np</strong>, and the Nashpy package imported <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">nash</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
import numpy as np
import nashpy as nash</pre>
			<p>Let’s see how to use the <strong class="source-inline">nashpy</strong> package to analyze a simple <span class="No-Break">two-player game.</span></p>
			<h2 id="_idParaDest-386"><a id="_idTextAnchor385"/>How to do it...</h2>
			<p>The following steps show you how to create and perform some simple analysis of a two-player game <span class="No-Break">using Nashpy:</span></p>
			<ol>
				<li value="1">First, we need to create matrices that hold the payoff information for each player (you and your colleague, in <span class="No-Break">this example):</span><pre class="console">
you = np.array([[1, 3], [1, 4]])</pre><pre class="console">
colleague = np.array([[3, 2], [2, 2]])</pre></li>
				<li>Next, we create a <strong class="source-inline">Game</strong> object that holds the game represented by these <span class="No-Break">payoff matrices:</span><pre class="console">
dilemma = nash.Game(you, colleague)</pre></li>
				<li>We compute the utility for the given choices using <span class="No-Break">index notation:</span><pre class="console">
print(dilemma[[1, 0], [1, 0]])      # [1 3]</pre><pre class="console">
print(dilemma[[1, 0], [0, 1]])      # [3 2]</pre><pre class="console">
print(dilemma[[0, 1], [1, 0]])      # [1 2]</pre><pre class="console">
print(dilemma[[0, 1], [0, 1]])      # [4 2]</pre></li>
				<li>We can also compute the expected utilities based on the probabilities of making a <span class="No-Break">specific choice:</span><pre class="console">
print(dilemma[[0.1, 0.9], [0.5, 0.5]]) # [2.45 2.05]</pre></li>
			</ol>
			<p>These expected <a id="_idIndexMarker1025"/>utilities represent what we’d expect (on average) to see if we repeated the game numerous times with the <span class="No-Break">specified probabilities.</span></p>
			<h2 id="_idParaDest-387"><a id="_idTextAnchor386"/>How it works...</h2>
			<p>In this recipe, we built a Python object that represents a very simple two-player strategic game. The idea here is that there are two <em class="italic">players</em> who have decisions to make, and each combination of both players’ choices gives a specific payoff value. What we’re aiming to do here is find the best choice that each player can make. The players are assumed to make a single move simultaneously, in the sense that neither is aware of the other’s choice. Each player has a strategy that determines the choice <span class="No-Break">they make.</span></p>
			<p>In <em class="italic">step 1</em>, we create two matrices – one for each player – that are assigned to each combination of choices for the payoff value. These two matrices are wrapped by the <strong class="source-inline">Game</strong> class from Nashpy, which provides a convenient and intuitive (from a game-theoretic point of view) interface for working with games. We can quickly calculate the utility of a given combination of choices by passing in the choices using <span class="No-Break">index notation.</span></p>
			<p>We can also calculate expected utilities based on a strategy where choices are chosen at random according to some probability distribution. The syntax is the same as for the deterministic case described previously, except we provide a vector of probabilities for each choice. We compute the expected utilities based on the probability that you choose Python 90% of the time, while your colleague chooses Python 50% of the time. The expected speeds <a id="_idIndexMarker1026"/>are 2.45 and 2.05 for you and your <span class="No-Break">colleague respectively.</span></p>
			<h2 id="_idParaDest-388"><a id="_idTextAnchor387"/>There’s more...</h2>
			<p>There is an alternative to computational game theory in Python. The Gambit project<a id="_idIndexMarker1027"/> is a collection of tools used for computation in game theory that has a Python interface (<a href="http://www.gambit-project.org/">http://www.gambit-project.org/</a>). This is a mature project built around C libraries and offers more performance <span class="No-Break">than Nashpy.</span></p>
			<h1 id="_idParaDest-389"><a id="_idTextAnchor388"/>Computing Nash equilibria</h1>
			<p>A <em class="italic">Nash equilibrium</em> is <a id="_idIndexMarker1028"/>a two-player strategic game – similar to the one we saw in the <em class="italic">Analyzing simple two-player games</em> recipe – that represents a <em class="italic">steady state</em> in which every player sees the <em class="italic">best possible</em> outcome. However, this doesn’t mean that the outcome linked to a Nash equilibrium is the best overall. Nash equilibria are more subtle than this. An informal definition of a Nash equilibrium is as follows: an action profile in which no individual player can improve their outcome, assuming that all other players adhere to <span class="No-Break">the profile.</span></p>
			<p>We will explore the notion of a Nash equilibrium with the classic game of rock-paper-scissors. The rules are as follows. Each player can choose one of the options: rock, paper, or scissors. Rock beats scissors, but loses to paper; paper beats rock, but loses to scissors; scissors beats paper, but loses to rock. Any game in which both players make the same choice is a draw. Numerically, we represent a win by +1, a loss by -1, and a draw by 0. From this, we can construct a two-player game and compute Nash equilibria for <span class="No-Break">this game.</span></p>
			<p>In this recipe, we will compute Nash equilibria for the classic game <span class="No-Break">of rock-paper-scissors.</span></p>
			<h2 id="_idParaDest-390"><a id="_idTextAnchor389"/>Getting ready</h2>
			<p>For this <a id="_idIndexMarker1029"/>recipe, we will need the NumPy package imported as <strong class="source-inline">np</strong>, and the Nashpy package imported <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">nash</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
import numpy as np
import nashpy as nash</pre>
			<p>Let’s see how to use the <strong class="source-inline">nashpy</strong> package to compute Nash equilibria for a two-player <span class="No-Break">strategy game.</span></p>
			<h2 id="_idParaDest-391"><a id="_idTextAnchor390"/>How to do it...</h2>
			<p>The following steps show you how to compute Nash equilibria for a simple <span class="No-Break">two-player game:</span></p>
			<ol>
				<li value="1">First, we need to create a payoff matrix for each player. We will start with the <span class="No-Break">first player:</span><pre class="console">
rps_p1 = np.array([</pre><pre class="console">
    [ 0, -1, 1], # rock payoff</pre><pre class="console">
    [ 1, 0, -1], # paper payoff</pre><pre class="console">
    [-1, 1, 0] # scissors payoff</pre><pre class="console">
])</pre></li>
				<li>The payoff matrix for the second player is the transpose <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">rps_p1</strong></span><span class="No-Break">:</span><pre class="console">
rps_p2 = rps_p1.transpose()</pre></li>
				<li>Next, we create the <strong class="source-inline">Game</strong> object to represent <span class="No-Break">the game:</span><pre class="console">
rock_paper_scissors = nash.Game(rps_p1, rps_p2)</pre></li>
				<li>We compute the Nash equilibria for the game using the support <span class="No-Break">enumeration algorithm:</span><pre class="console">
equilibria = rock_paper_scissors.support_enumeration()</pre></li>
				<li>We iterate over the equilibria and print the profile for <span class="No-Break">each player:</span><pre class="console">
for p1, p2 in equilibria:</pre><pre class="console">
    print("Player 1", p1)</pre><pre class="console">
    print("Player 2", p2)</pre></li>
			</ol>
			<p>The output of these print statements is <span class="No-Break">as follows:</span></p>
			<pre class="console">
Player 1 [0.33333333 0.33333333 0.33333333]
Player 2 [0.33333333 0.33333333 0.33333333]</pre>
			<h2 id="_idParaDest-392"><a id="_idTextAnchor391"/>How it works...</h2>
			<p>Nash <a id="_idIndexMarker1030"/>equilibria are extremely important in game theory because they allow us to analyze the outcomes of strategic games and identify advantageous positions. They were first described by John F. Nash in 1950 and have played a pivotal role in modern game theory. A two-player game may have many Nash equilibria, but any finite two-player game must have at least one. The problem is finding all the possible Nash equilibria for a <span class="No-Break">given game.</span></p>
			<p>In this recipe, we used the support enumeration, which effectively enumerates all possible strategies and filters down to those that are Nash equilibria. In this recipe, the support enumeration algorithm found just one Nash equilibrium, which is a mixed strategy. This means that the only strategy for which there is no improvement involves picking one of the choices at random, each with a 1/3 probability. This is hardly a surprise to anyone who has played rock-paper-scissors, since for any choice we make, our opponent has a 1 in 3 chance of choosing (at random) the move that beats our choice. Equally, we have a 1 in 3 chance of drawing or winning the game, so our expected value over all these possibilities is <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer1041">
					<img alt="" src="image/Formula_09_049.jpg"/>
				</div>
			</div>
			<p>Without knowing exactly which of the choices our opponent will choose, there is no way to improve this <span class="No-Break">expected outcome.</span></p>
			<h2 id="_idParaDest-393"><a id="_idTextAnchor392"/>There’s more...</h2>
			<p>The Nashpy package also provides other algorithms for computing Nash equilibria. Specifically, the <strong class="source-inline">vertex_enumeration</strong> method, when used on a <strong class="source-inline">Game</strong> object, uses the <em class="italic">vertex enumeration</em> algorithm, while <a id="_idIndexMarker1031"/>the <strong class="source-inline">lemke_howson_enumeration</strong> method uses<a id="_idIndexMarker1032"/> the <em class="italic">Lemke-Howson</em> algorithm. These alternative algorithms have different characteristics and may be more efficient for <span class="No-Break">some problems.</span></p>
			<h2 id="_idParaDest-394"><a id="_idTextAnchor393"/>See also</h2>
			<p>The documentation for the Nashpy package contains more detailed information about the algorithms and game theory involved. This includes a number of references to texts on game theory. This documentation can be found <span class="No-Break">at </span><a href="https://nashpy.readthedocs.io/en/latest/"><span class="No-Break">https://nashpy.readthedocs.io/en/latest/</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-395"><a id="_idTextAnchor394"/>Further reading</h1>
			<p>As usual, the <em class="italic">Numerical Recipes</em> book is a good source of numerical algorithms. <a href="B19085_10.xhtml#_idTextAnchor395"><span class="No-Break"><em class="italic">Chapter 10</em></span></a>, <em class="italic">Minimization or Maximization of Functions</em>, deals with the maximization and minimization <span class="No-Break">of functions:</span></p>
			<ul>
				<li>Press, W.H., Teukolsky, S.A., Vetterling, W.T., and Flannery, B.P., 2017. <em class="italic">Numerical recipes: the art of scientific computing</em>. 3rd ed. Cambridge: Cambridge <span class="No-Break">University Press.</span></li>
			</ul>
			<p>More specific information on optimization can be found in the <span class="No-Break">following books:</span></p>
			<ul>
				<li>Boyd, S.P. and Vandenberghe, L., 2018. <em class="italic">Convex optimization</em>. Cambridge: Cambridge <span class="No-Break">University Press.</span></li>
				<li>Griva, I., Nash, S., and Sofer, A., 2009. <em class="italic">Linear and nonlinear optimization</em>. 2nd ed. Philadelphia: Society for Industrial and <span class="No-Break">Applied Mathematics.</span></li>
			</ul>
			<p>Finally, the following book is a good introduction to <span class="No-Break">game theory:</span></p>
			<ul>
				<li>Osborne, M.J., 2017. <em class="italic">An introduction to game theory</em>. Oxford: Oxford <span class="No-Break">University Press.</span></li>
			</ul>
		</div>
	</body></html>