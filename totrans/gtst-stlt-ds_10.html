<html><head></head><body>
		<div id="_idContainer087">
			<h1 id="_idParaDest-80"><em class="italic"><a id="_idTextAnchor081"/>Chapter 8</em>: Deploying Streamlit Apps with Heroku and AWS</h1>
			<p>In <a href="B16864_05_Final_VK_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 5</em></a>, <em class="italic">Deploying Streamlit with Streamlit Sharing</em>, we learned how to deploy our Streamlit applications with Streamlit Sharing. Streamlit Sharing is quick, easy, and very effective for most applications but has a few downsides, mainly that we are limited by only being able to host three free applications at once and that we also are limited in the computational power at hand. The following excerpt is from the Streamlit Sharing page: </p>
			<p class="author-quote">Apps get up to 1 CPU, 800 MB of RAM, and 800 MB of dedicated storage in a shared execution environment.</p>
			<p>If you are in a situation where you want to deploy more than three applications at a time, or you want more compute as you run, for example, more complex ML models that would benefit from a GPU or more RAM, then this chapter is for you! We will cover how to set up accounts with AWS and Heroku and how to fully deploy your Streamlit applications there. </p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Choosing between AWS, Streamlit Sharing, and Heroku</li>
				<li>Deploying Streamlit with Heroku</li>
				<li>Deploying Streamlit with AWS</li>
			</ul>
			<h1 id="_idParaDest-81"><a id="_idTextAnchor082"/>Technical requirements</h1>
			<p>Here is a list of installments required for this chapter:</p>
			<ul>
				<li><strong class="bold">Heroku account</strong>: Heroku is a popular platform that data scientists and software engineers use to host their applications, models, and APIs (application programming interfaces), and is owned by Salesforce. To get a Heroku account, please head over to <a href="https://signup.heroku.com">https://signup.heroku.com</a> to make your free account. </li>
				<li><strong class="bold">Heroku Command-Line Interface</strong> (<strong class="bold">CLI</strong>): To use Heroku effectively, we will need to download the Heroku CLI, which will allow us to run Heroku commands. To download this, please follow the instructions listed here: <a href="https://devcenter.heroku.com/articles/heroku-cli">https://devcenter.heroku.com/articles/heroku-cli</a>. </li>
				<li><strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>) <strong class="bold">account</strong>: Before we can use AWS, we first need to sign up for our own Amazon account, which you can do at <a href="https://aws.amazon.com/free">https://aws.amazon.com/free</a>. Thankfully, there is a generous free tier available for students with .edu accounts, for start-up founders and entrepreneurs, and also for non-profits. Once you do this, I would strongly recommend setting billing alerts on your account (see <a href="https://console.aws.amazon.com/billing/home?#preferences">https://console.aws.amazon.com/billing/home?#preferences</a> for more details) to make sure that you do not overshoot your free tier, and when you have deployed your own app, to make sure you are not spending more than desired. </li>
				<li><strong class="bold">PuTTy</strong> (Windows only): If you are using Windows, you will need to download and install the PuTTY program, which allows Windows OSes to use a protocol called <strong class="bold">Secure Shell</strong> (<strong class="bold">SSH</strong>). To download PuTTY, head over to <a href="https://www.putty.org/">https://www.putty.org/</a> and follow the installation instructions. Then, wherever we are using SSH in this chapter, open PuTTY and follow the directions as normal! </li>
			</ul>
			<p>Now that we have the requirements, let's begin!</p>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor083"/>Choosing between AWS, Streamlit Sharing, and Heroku</h1>
			<p>At a<a id="_idIndexMarker287"/> high<a id="_idIndexMarker288"/> level, whenever<a id="_idIndexMarker289"/> we<a id="_idIndexMarker290"/> are <a id="_idIndexMarker291"/>trying <a id="_idIndexMarker292"/>to deploy our Streamlit application such that users on the internet can see our applications, what we are really doing is renting a computer owned by someone else (such as Amazon) and giving that computer a set of instructions to start up our application. Choosing which platform to use is difficult to know how to do without either having a background in deploying systems or without trying each option out first, but there are a few heuristics that should help you out. The two most important factors for this decision are the flexibility of the system and the time it takes to get up and running. Note that these two factors directly trade off with one another. If you are using Streamlit Sharing, you cannot say "I want this to run on a macOS, and I want to add two GPUs to this app," and so on, but in return, you get a wildly simple process where you can simply point Streamlit Sharing to your GitHub repository, and it will take care of all the other little decisions that need to be made. </p>
			<p>On the other hand, AWS and Heroku give you much more flexibility but take time to set up (as you will find out!). The biggest difference between the two is that Heroku is a <em class="italic">Platform as a Service product</em>, while Amazon is an <em class="italic">Infrastructure as a Service product</em>, which <a id="_idIndexMarker293"/>means, in practical terms, that Heroku <a id="_idIndexMarker294"/>gives <a id="_idIndexMarker295"/>you<a id="_idIndexMarker296"/> more flexibility<a id="_idIndexMarker297"/> than<a id="_idIndexMarker298"/> Streamlit Sharing by allowing you to do things such as provide more computational resources, and is faster to deploy than AWS, as you can see in the following graphic:</p>
			<div>
				<div id="_idContainer076" class="IMG---Figure">
					<img src="image/B16864_08_1.jpg" alt="Figure 8.1 – Heroku versus AWS versus Sharing&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.1 – Heroku versus AWS versus Sharing</p>
			<p>The AWS advantage, however, is in its extreme flexibility. AWS will let you choose between Ubuntu, macOS, Windows, and Red Hat Linux, between dozens of different database types, and is seemingly infinitely customizable. When you are making your Streamlit applications, if you want to get out a quick prototype to test out an idea, Streamlit Sharing is perfect for you. For full-fledged public applications that need more compute, Heroku might be the best call. And if you require ultimate flexibility for a complex ML application, or if you are running a business entirely on Streamlit, then AWS might be<a id="_idIndexMarker299"/> the<a id="_idIndexMarker300"/> best call. Throughout <a id="_idIndexMarker301"/>the rest of this<a id="_idIndexMarker302"/> chapter, we will dive into how to deploy<a id="_idIndexMarker303"/> your <a id="_idIndexMarker304"/>own app on both AWS and Heroku, as we have covered Streamlit Sharing directly in <a href="B16864_05_Final_VK_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 5</em></a>, <em class="italic">Deploying Streamlit with Streamlit Sharing</em>. Let's get started with Heroku!</p>
			<h1 id="_idParaDest-83"><a id="_idTextAnchor084"/>Deploying Streamlit with Heroku</h1>
			<p>Heroku is <a id="_idIndexMarker305"/>slightly faster and simpler than AWS, and more <a id="_idIndexMarker306"/>cumbersome than Streamlit Sharing. But if you have run out of your Streamlit Sharing repositories, or need some more compute than Sharing has to offer but require fewer configuration options than the infinite ones provided by AWS, then Heroku is the place for you. One other win is that you can get custom URLs for your apps with Heroku, which Streamlit Sharing does not support (yet!). To deploy our Streamlit apps on Heroku, we need to do the following:</p>
			<ol>
				<li>Set up and log in to Heroku.</li>
				<li>Clone and configure our local repository.</li>
				<li>Deploy to Heroku.</li>
			</ol>
			<p>Let's look at each of these steps in detail!</p>
			<h2 id="_idParaDest-84"><a id="_idTextAnchor085"/>Setting up and logging in to Heroku</h2>
			<p>In<a id="_idIndexMarker307"/> the <em class="italic">Technical requirements</em> section of this chapter, we covered <a id="_idIndexMarker308"/>how to download Heroku and create an account. Now, we need to log in to our Heroku from our command line by running the following command and logging in when prompted:</p>
			<p class="source-code">heroku login</p>
			<p>This will take us to the Heroku page, and once we log in, we will be good to go. This command <a id="_idIndexMarker309"/>will keep you logged in on your machine indefinitely unless your<a id="_idIndexMarker310"/> password changes or you purposely log out of Heroku. </p>
			<h2 id="_idParaDest-85"><a id="_idTextAnchor086"/>Cloning and configuring our local repository</h2>
			<p>Next, we<a id="_idIndexMarker311"/> need to change <a id="_idIndexMarker312"/>our directory to where the penguin machine learning app is located. My app folder is inside my <strong class="source-inline">Documents</strong> folder, so the following command takes me there, but your folder might be different: </p>
			<p class="source-code">cd ~/Documents/penguin_ml</p>
			<p>If you do not already have the repository downloaded locally with a corresponding repository on GitHub, go ahead and stop by <a href="B16864_05_Final_VK_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 5</em></a>, <em class="italic">Deploying Streamlit with Streamlit Sharing</em>, to see how to get started with GitHub. Instead, you can also run the following command to download the repository locally from my personal GitHub, just as we did with deploying from AWS: </p>
			<p class="source-code">git clone https://github.com/tylerjrichards/penguin_ml.git</p>
			<p>It is highly encouraged that you practice with your own GitHub repository, as this is much better practice than cloning an app from me to use to deploy to Heroku. </p>
			<p>Now we need to create a Heroku app with a unique name for our app with the next command (the app will be deployed as this name with <strong class="source-inline">.heroku.com</strong> appended to the end of it). Mine will be <strong class="source-inline">penguin-machine-learning</strong>, but go ahead and pick your own! </p>
			<p class="source-code">heroku create penguin-machine-learning</p>
			<p>Once we have this, we need to explicitly make the connection between our Git repository and the Heroku app we have just created, which can be done with the following command:</p>
			<p class="source-code">heroku git:remote -a penguin-machine-learning</p>
			<p>And finally, we are going to add two files to our repository that are needed to start up with Heroku, the <strong class="source-inline">Procfile</strong> file and the <strong class="source-inline">streamlit_setup.sh</strong> file. Heroku uses something<a id="_idIndexMarker313"/> called a <strong class="bold">Procfile</strong> as a way to declare which commands the app should perform when starting up, and also to tell Heroku what type of application this is. For our Heroku apps, we also need this Procfile to configure some setup for our app specific to Streamlit apps (such as the port configuration), and then also to run the <strong class="source-inline">streamlit run</strong> command to launch our app. Let's start by creating the <strong class="source-inline">streamlit_setup.sh</strong> file using the following command:</p>
			<p class="source-code">touch streamlit_setup.sh</p>
			<p>We can<a id="_idIndexMarker314"/> open<a id="_idIndexMarker315"/> this file with our text editor and put the following lines inside it, which creates our familiar <strong class="source-inline">config.toml</strong> file in the base directory:</p>
			<p class="source-code">mkdir -p ~/.streamlit</p>
			<p class="source-code">echo "[server]</p>
			<p class="source-code">headless = true</p>
			<p class="source-code">port = $PORT</p>
			<p class="source-code">enableCORS = false</p>
			<p class="source-code">" &gt; ~/.streamlit/config.toml</p>
			<p>Once we save this file, we need to create a Procfile that runs this <strong class="source-inline">streamlit_setup.sh</strong> file and then also runs our Streamlit app:</p>
			<p class="source-code">touch Procfile</p>
			<p>Within the <strong class="source-inline">Procfile</strong> file we just created, we will next add the following line:</p>
			<p class="source-code">web: sh streamlit_setup.sh &amp;&amp; streamlit run penguins_streamlit.py</p>
			<p>Now that we have our Streamlit app all set up, our final step is to deploy to Heroku!</p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor087"/>Deploying to Heroku</h2>
			<p>Before <a id="_idIndexMarker316"/>we<a id="_idIndexMarker317"/> deploy, we have a couple of new files on our app, so we need to add those to our Git repository using the following commands:</p>
			<p class="source-code">git add .</p>
			<p class="source-code">git commit -m 'added heroku files'</p>
			<p class="source-code">git push</p>
			<p>And now, our final step in this chapter is to push to Heroku, which we can do with this next command: </p>
			<p class="source-code">git push heroku main</p>
			<p>This will kick off the Heroku build, and soon enough we will see our Penguin app deployed <a id="_idIndexMarker318"/>to <a id="_idIndexMarker319"/>Heroku for anyone to go and view. The app we have been working on and just deployed can be found at the following link (with a screenshot attached!), <a href="https://penguin-machine-learning.herokuapp.com/">https://penguin-machine-learning.herokuapp.com/</a>, and the GitHub repository for this app can be found at <a href="https://github.com/tylerjrichards/penguin_ml">https://github.com/tylerjrichards/penguin_ml</a>. It is the same as the app we deployed on AWS earlier in the chapter, shown in the following screenshot: </p>
			<div>
				<div id="_idContainer077" class="IMG---Figure">
					<img src="image/B16864_08_2.jpg" alt="Figure 8.2 – Heroku App deployment&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.2 – Heroku App deployment</p>
			<p>We have now successfully deployed one of our Streamlit apps on the Heroku platform, but if <a id="_idIndexMarker320"/>we<a id="_idIndexMarker321"/> need more control over the types of servers behind our app, we need to build directly on AWS, as demonstrated in the next section!</p>
			<h1 id="_idParaDest-87"><a id="_idTextAnchor088"/>Deploying Streamlit with AWS</h1>
			<p>In comparison <a id="_idIndexMarker322"/>to deploying with Heroku, deploying apps on AWS is significantly more cumbersome but has seemingly infinite options. There are a few steps to deploying your own apps with AWS, and these include the following:</p>
			<ol>
				<li value="1">Selecting and launching a virtual machine</li>
				<li>Installing the necessary software</li>
				<li>Cloning and running your app</li>
				<li>Long-term AWS deployment</li>
			</ol>
			<p>We will run<a id="_idIndexMarker323"/> through these sequentially!</p>
			<h2 id="_idParaDest-88"><a id="_idTextAnchor089"/>Selecting and launching a virtual machine</h2>
			<p>AWS has<a id="_idIndexMarker324"/> literally hundreds of service <a id="_idIndexMarker325"/>options for everything from deploying ML models to compute resources to everything in between. In this book so far, we have referred to the services listed in the following screenshot under the <a id="_idIndexMarker326"/>central name <em class="italic">AWS</em>, but to be more precise, we are<a id="_idIndexMarker327"/> going to be using <strong class="bold">Amazon Elastic Compute Cloud</strong>, or <strong class="bold">Amazon EC2</strong> for short. This next screenshot shows the breadth of services available just for compute resources, which does not include any of the services available for machine learning, business applications, or storage:</p>
			<div>
				<div id="_idContainer078" class="IMG---Figure">
					<img src="image/B16864_08_3.jpg" alt="Figure 8.3 – AWS Compute&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.3 – AWS Compute</p>
			<p>Amazon EC2 is a dynamic, pay-as-you-go service that will scale automatically based on use. If there are 10, 100, or 10,000 concurrent users of your Streamlit app, EC2 will change the compute resources given to your application to accommodate the users. You pay for what you use!</p>
			<p>To get started, head over to <a href="https://console.aws.amazon.com/ec2/v2/home">https://console.aws.amazon.com/ec2/v2/home</a> and click the button that says <strong class="bold">Launch instance</strong>, as shown in the following screenshot. Your default region may be different than mine, which is totally fine! AWS regions allow you to select where you want the compute to be physically located, in case your app needs low latency, or <a id="_idIndexMarker328"/>there are regulatory <a id="_idIndexMarker329"/>reasons for where your data is hosted (for example, because of <strong class="bold">General Data Privacy Regulation</strong> (<strong class="bold">GDPR</strong>), in the <a id="_idIndexMarker330"/>European Union). The overwhelming majority of the time, the default region AWS puts you in is perfectly fine: </p>
			<div>
				<div id="_idContainer079" class="IMG---Figure">
					<img src="image/B16864_08_4.jpg" alt="Figure 8.4 – EC2 launch&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.4 – EC2 launch</p>
			<p>Once you launch your instance, there are seven tabs: </p>
			<ul>
				<li><strong class="bold">Choose AMI</strong> (Amazon Machine Image) or the OS used by your virtual machine</li>
				<li><strong class="bold">Choose Instance Type</strong> (choosing the compute/memory/storage of your virtual machine)</li>
				<li><strong class="bold">Configure Instance</strong></li>
				<li><strong class="bold">Add Storage</strong></li>
				<li><strong class="bold">Add Tags</strong></li>
				<li><strong class="bold">Configure Security Group</strong></li>
				<li><strong class="bold">Review</strong> </li>
			</ul>
			<p>You might be starting to understand what I was talking about earlier when I mentioned flexibility versus speed! Luckily, we only really need to start with a few of these, starting with choosing our AMI from a list of options. When we click the <strong class="bold">Launch instance</strong> button, we will see options including, but not limited to, the following:</p>
			<ul>
				<li>Amazon Linux 2 AMI<p>This option is Amazon's own option, is free tier-eligible, and is designed to work well with EC2. </p></li>
				<li>Red Hat Enterprise Linux<p>This option<a id="_idIndexMarker331"/> is an enterprise <a id="_idIndexMarker332"/>version of Linux created by the Red Hat foundation, which creates open source enterprise solutions (<a href="https://www.redhat.com/en">https://www.redhat.com/en</a>). There are a variety of options depending on versions and volume type. </p></li>
				<li>Ubuntu Server <p>Ubuntu is another open source OS built on Linux similar to Red Hat. They also have a variety of free and paid options, the same as Red Hat. </p></li>
			</ul>
			<p>I would recommend selecting the OS that you are most comfortable with already. If you have already used Ubuntu servers, try the newest Ubuntu option, which is, in this case, Ubuntu Server 20.04. The most commonly used AMI options are all based on Linux, which is an open source OS with many flavors, including Red Hat, Debian, and Ubuntu. </p>
			<p>To follow along with this chapter, select the default Amazon option, <strong class="bold">Amazon Linux 2</strong>. When you check this option and are taken to the <strong class="bold">Choose Instance Type</strong> page, select any type that is free tier-eligible, as shown in the following screenshot. Of course, if you would like to pay for more memory or vCPUs you absolutely can, but they are not necessary at this time: </p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="image/B16864_08_5.jpg" alt="Figure 8.5 – AWS AMI options&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.5 – AWS AMI options</p>
			<p>Next, we can skip past the next few options until you get to the sixth tab entitled <strong class="bold">Configure Security Group</strong>. There are a few edits that we need to make here:</p>
			<ul>
				<li>TCP Rule<p>We need to set our <strong class="bold">Security</strong> settings in a way to allow other users online to interact <a id="_idIndexMarker333"/>with <a id="_idIndexMarker334"/>our web app by adding a new <strong class="bold">Transmission Control Protocol</strong> (<strong class="bold">TCP</strong>) rule by clicking <strong class="bold">Add Rule</strong> and setting<a id="_idIndexMarker335"/> the <strong class="bold">Port Range</strong> column to <strong class="source-inline">8501</strong>, the custom Streamlit port. </p></li>
				<li>Access Source<p>We also need to allow anyone to access our app, so we will also set the source to <strong class="bold">Anywhere</strong>, as shown in the following screenshot:</p></li>
			</ul>
			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="image/B16864_08_6.jpg" alt="Figure 8.6 – Security settings &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.6 – Security settings </p>
			<p>Now, we are ready to launch! Head over to the seventh tab, <strong class="bold">Review</strong>, and click the <strong class="bold">Launch</strong> button if everything looks correct. What will pop up next is a way to create a public and private key, one held by AWS and the other held by you, to allow you to access this new<a id="_idIndexMarker336"/> virtual<a id="_idIndexMarker337"/> computer from your command line, as shown in the following screenshot: </p>
			<div>
				<div id="_idContainer082" class="IMG---Figure">
					<img src="image/B16864_08_7.jpg" alt=" Figure 8.7 – Key-value pairs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption"> Figure 8.7 – Key-value pairs</p>
			<p>Think of it like a unique password that is downloaded as its own file. You can keep this file wherever is easiest and most secure for you, but make sure to never upload this file to a public location, such as a GitHub repository, otherwise, others could come and access your virtual machine! Now that we have launched our EC2 instance, we can access it from our command line and download our app. </p>
			<h2 id="_idParaDest-89"><a id="_idTextAnchor090"/>Installing the necessary software </h2>
			<p>For this<a id="_idIndexMarker338"/> example, we are going to try and deploy the penguin ML app that we created in <a href="B16864_04_Final_VK_ePub.xhtml#_idTextAnchor049"><em class="italic">Chapter 4</em></a>, <em class="italic">Using Machine Learning with Streamlit</em>, and deployed in <a href="B16864_05_Final_VK_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 5</em></a>, <em class="italic">Deploying Streamlit with Streamlit Sharing</em>, on Streamlit Sharing. Now that we have our virtual machine and our objective, we need to access our virtual machine from our command line. To begin, we need to first find out the AWS instance's public DNS. Locate your AWS instance using this link, <a href="https://console.aws.amazon.com/ec2/v2/home#Instances">https://console.aws.amazon.com/ec2/v2/home#Instances</a>, and look for <strong class="bold">Public DNS</strong>, which will be in the format <strong class="source-inline">ec2-10-857-84-485.compute-1.amazonaws.com</strong>. I made up those numbers, but yours should be close to this. </p>
			<p>Now, we can access our virtual machine using SSH, which is the Secure Shell Protocol, using the following command, which combines our password and our public DNS:</p>
			<p class="source-code">ssh -i "path_to_private_key.pem" ec2-user@&lt;insert_Public_DNS&gt;</p>
			<p>Often, AWS commands feel like magic incantations, especially when you are first getting started. After some experience, you will certainly get more comfortable with this. At this point, AWS may ask you some questions on the command line about allowing certain types of access depending on how your security settings are set up on your local machine, and after you confirm that you would like to connect, you will know that you are connected if you see something similar to the following screenshot:</p>
			<div>
				<div id="_idContainer083" class="IMG---Figure">
					<img src="image/B16864_08_8.jpg" alt="Figure 8.8 – AWS login &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.8 – AWS login </p>
			<p>This is your own new virtual computer! There are no programs, folders, or really almost anything else on this computer; it is brand new right out of the Amazon box. Each computer that we rent out using <strong class="source-inline">ec2</strong> starts out with next to nothing, so we have to download all that we need for this project. There are a good number of ways in which to do this. We can do the following:</p>
			<ul>
				<li>Install everything manually.</li>
				<li>Install a prepackaged installer such as Anaconda or Miniconda.</li>
				<li>Use Docker to create a set of installation instructions.</li>
			</ul>
			<p>I would advise going with the second option for most use cases, as Anaconda or Miniconda are designed to handle all the difficulties that come with installing Python, dealing with our path, and also with installing various Python and R packages. Anaconda, and its<a id="_idIndexMarker339"/> bootstrapped (that is, smaller) version, Miniconda, are notorious for making installation difficult outside of their environment on your computer. If you require other installations of Python on your virtual or local machine, I would advocate either <em class="italic">option 1</em> or <em class="italic">option 3</em>. </p>
			<p>For installing and setting up Miniconda on our virtual machine, we can run the following commands, which use <strong class="source-inline">wget</strong> to download Miniconda to the file location, <strong class="source-inline">~/miniconda.sh</strong>, then run the installation file using <strong class="source-inline">bash</strong>, and then change our path so that we can use <strong class="source-inline">conda</strong> more easily to download packages: </p>
			<p class="source-code">wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh</p>
			<p class="source-code">bash ~/miniconda.sh -b -p ~/miniconda</p>
			<p class="source-code">export PATH="$HOME/miniconda/bin":$PATH</p>
			<p>Great! Now we have the latest versions of <strong class="source-inline">python</strong>, <strong class="source-inline">pip</strong>, and a whole host of Python packages. Miniconda does not come with Streamlit, however, so we will use the next command to download, install, and test the installation of Streamlit by launching the Streamlit demo app:</p>
			<p class="source-code">pip install Streamlit</p>
			<p class="source-code">streamlit hello</p>
			<p>When we run this command, we should see the following in our terminal (albeit with different network and external URLs):</p>
			<div>
				<div id="_idContainer084" class="IMG---Figure">
					<img src="image/B16864_08_9.jpg" alt="Figure 8.9 – First Streamlit command&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.9 – First Streamlit command</p>
			<p>When you head over to the external URL from any browser, you will see the Streamlit demo app, as <a id="_idIndexMarker340"/>shown in the following screenshot:</p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="image/B16864_08_10.jpg" alt="Figure 8.10 – Streamlit demo&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.10 – Streamlit demo</p>
			<p>We have now deployed our very first Streamlit app from AWS. Now, to deploy a Streamlit <a id="_idIndexMarker341"/>app that we have built. </p>
			<h2 id="_idParaDest-90"><a id="_idTextAnchor091"/>Cloning and running your app</h2>
			<p>We now <a id="_idIndexMarker342"/>have a virtual machine that can run Streamlit, and <a id="_idIndexMarker343"/>our next step is to download our own app onto our machine. The most straightforward method for doing this is by using Git and cloning the repository where your penguin machine learning app is held. If you have not already done this in <a href="B16864_05_Final_VK_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 5</em></a>, <em class="italic">Deploying Streamlit with Streamlit Sharing</em>, feel free to use my GitHub repository at <a href="https://github.com/tylerjrichards/penguin_ml.git">https://github.com/tylerjrichards/penguin_ml.git</a>. The following code downloads <strong class="source-inline">git</strong> and then downloads our app from GitHub: </p>
			<p class="source-code">conda install git</p>
			<p class="source-code">git clone https://github.com/tylerjrichards/penguin_ml.git</p>
			<p>This will make a new folder in our current directory called <strong class="source-inline">penguin_ml</strong>, which contains all the files for the Streamlit app. This app requires a few more libraries than come from Miniconda, such as Seaborn and scikit-learn, so we need to download them before we run our app. We have already placed the names of these libraries into a file called <strong class="source-inline">requirements.txt</strong>, so we need to point <strong class="source-inline">pip</strong> to the file using the next set of commands: </p>
			<p class="source-code">cd penguin_ml</p>
			<p class="source-code">pip install -r penguin_ml/requirements.txt</p>
			<p>Now, our final step is to run our Streamlit app:</p>
			<p class="source-code">streamlit run penguins_streamlit.py</p>
			<p>When we go to the external URL in our AWS terminal, we will see our Streamlit app fully functioning there, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer086" class="IMG---Figure">
					<img src="image/B16864_08_11.jpg" alt="Figure 8.11 – AWS Penguin app &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.11 – AWS Penguin app </p>
			<p>And there<a id="_idIndexMarker344"/> we <a id="_idIndexMarker345"/>go! We now have our app running on AWS, visible to the entire world. From this point, we can link to our app from a personal website you may already have or send it to others who may be interested in classifying their own set of penguins. </p>
			<h2 id="_idParaDest-91"><a id="_idTextAnchor092"/>Long-term AWS deployment</h2>
			<p>Our final <a id="_idIndexMarker346"/>problem is that the SSH session we have running to connect our local machine to AWS needs to be running in order for the Streamlit app to stay up. For most use cases, this will not work as you will ideally want the user to interact with your Streamlit app if your local computer disconnects from AWS. Enter <strong class="source-inline">tmux</strong>, or the terminal mutiplexer, which can keep a terminal session going regardless of our local connection to it. To download <strong class="source-inline">tmux</strong>, we can run the following command while connected to our AWS virtual machine: </p>
			<p class="source-code">sudo yum install tmux</p>
			<p>And now, we can begin a new <strong class="source-inline">tmux</strong> session and kick off our Streamlit app by running these next commands:</p>
			<p class="source-code">tmux </p>
			<p class="source-code">streamlit run penguins_streamlit.py</p>
			<p>If our connection to AWS gets disconnected, <strong class="source-inline">tmux</strong> will keep our app running. We can leave the <strong class="source-inline">tmux</strong> session at any time by pressing <em class="italic">Ctrl + D</em> and can re-enter the session by running <strong class="source-inline">tmux attach</strong>. </p>
			<p>And that covers deploying Streamlit with AWS! As you can see, Streamlit Sharing handles the <a id="_idIndexMarker347"/>majority of these difficulties out of the box, so I would make an effort to make Streamlit Sharing work whenever possible. However, this session should have given you an appreciation for the true breadth of options and configuration controls in front of us when we use AWS, which may come in handy in the future.</p>
			<p>Summary </p>
			<p>This has been by far the most technical of our chapters so far, so congratulations on making it through! Deploying applications is notoriously difficult and time-consuming, and requires skills from software engineering and DevOps, along with often requiring experience with version control software (such as Git) and Unix-style commands and systems. This is part of the reason why Streamlit Sharing is such a crucial innovation, but in this chapter, we have learned how to push the edge of Streamlit deployment through renting our own virtual machines and deploying these on AWS and Heroku. We have also learned how to figure out what the right deployment strategy is before starting out, which will save hours or days of work (nothing is worse than finishing the deployment of an app and finding out you need to use another platform!). </p>
			<p>Next, we'll be moving on to the third and final section of this book, which will focus on the various applications of Streamlit, starting with improving job applications with Streamlit. This next chapter will focus on impressing hiring managers and recruiters with Streamlit applications, on using Streamlit apps within actual job application sections, such as the infamous take-home portion of many interviews, and also on proof-of-skill data projects for improving on the data science résumé. </p>
		</div>
	</body></html>