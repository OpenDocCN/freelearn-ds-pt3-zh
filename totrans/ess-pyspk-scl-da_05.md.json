["```py\nstream_df = (spark.readStream\n                    .format(\"csv\")\n                    .option(\"header\", \"true\")\n                    .schema(eventSchema)\n                    .option(\"maxFilesPerTrigger\", 1)\n                    .load(\"/FileStore/shared_uploads/online_retail/\"))\n```", "```py\n    retail_batch_df = (spark\n                     .read\n                     .option(\"header\", \"true\")\n                     .option(\"inferSchema\", \"true\")\n                     .csv(\"/FileStore/shared_uploads/online_retail/online_retail.csv\"))\n    ```", "```py\n    (retail_batch_df\n           .write\n           .mode(\"overwrite\")\n           .format(\"delta\")\n           .option(\"path\", \"/tmp/data-lake/online_retail.delta\")\n           .saveAsTable(\"online_retail\"))\n    ```", "```py\n    retail_stream_df = (spark\n                     .readStream\n                     .schema(retailSchema)\n                     .csv(\"/FileStore/shared_uploads/online_retail/\"))\n    ```", "```py\n    (retail_stream_df\n           .writeStream\n           .outputMode(\"append\")\n           .format(\"delta\")\n           .option(\"checkpointLocation\", \"/tmp/data-lake/online_retail.delta/\")\n           .start(\"/tmp/data-lake/online_retail.delta\"))\n    ```", "```py\n(spark\n   .read\n     .option(\"header\", \"true\")\n     .option(\"inferSchema\", \"true\")\n     .csv(\"/FileStore/shared_uploads/online_retail/online_retail.csv\")\n   .write\n     .mode(\"overwrite\")\n     .format(\"delta\")\n     .option(\"path\", \"/tmp/data-lake/online_retail.delta\")\n     .saveAsTable(\"online_retail\"))\n```", "```py\nretail_stream_df = (spark\n                 .readStream\n                 .schema(retailSchema)\n                 .csv(\"/FileStore/shared_uploads/online_retail/\"))\n```", "```py\nfrom delta.tables import *\ndeltaTable = DeltaTable.forPath(spark, \"/tmp/data-lake/online_retail.delta\")\ndef upsertToDelta(microBatchOutputDF, batchId):\n  deltaTable.alias(\"a\").merge(\n      microBatchOutputDF.dropDuplicates([\"InvoiceNo\", \"InvoiceDate\"]).alias(\"b\"),\n      \"a.InvoiceNo = b.InvoiceNo and a.InvoiceDate = b.InvoiceDate\") \\\n    .whenMatchedUpdateAll() \\\n    .whenNotMatchedInsertAll() \\\n    .execute()\n```", "```py\n    aggregated_df = (\n        raw_stream_df.withWatermark(\"InvoiceTime\", \n                                    \"1 minutes\")\n        .groupBy(\"InvoiceNo\", window(\"InvoiceDate\", \n                                     \"30 seconds\", \n                                     \"10 seconds\", \n                                     \"0 seconds\"))\n        .agg(max(\"InvoiceDate\").alias(\"event_time\"),\n             count(\"InvoiceNo\").alias(\"order_count\"))\n    )\n    ```", "```py\n    (aggregated_df\n       .writeStream\n       .queryName(\"aggregated_df\")\n       .format(\"memory\")\n       .outputMode(\"complete\")\n       .start())\n    ```", "```py\n     raw_stream_df = (spark\n                     .readStream\n                     .schema(retailSchema)\n                     .option(\"header\", True)\n                     .csv(\"/FileStore/shared_uploads/online_retail/\"))\n    (raw_stream_df\n       .writeStream\n         .format(\"delta\")\n         .option(\"checkpointLocation\", \n                 \"/tmp/delta/raw_stream.delta/checkpoint\")\n         .start(\"/tmp/delta/raw_stream.delta/\"))\n    ```", "```py\n    integrated_stream_df = (raw_stream_df\n                              .withColumn(\"InvoiceTime\", to_timestamp(\"InvoiceDate\", 'dd/M/yy HH:mm')))\n    (integrated_stream_df\n       .writeStream\n         .format(\"delta\")\n         .option(\"checkpointLocation\", \"/tmp/delta/int_stream.delta/checkpoint\")\n         .start(\"/tmp/delta/int_stream.delta/\"))\n    ```", "```py\n    aggregated_stream_df = (integrated_stream_df\n    .withWatermark(\"InvoiceTime\", \"1 minutes\")\n    .groupBy(\"InvoiceNo\", window(\"InvoiceTime\", \n             \"30 seconds\", \"10 seconds\", \"0 seconds\"))\n    .agg(max(\"InvoiceTime\").alias(\"event_time\"),\n             count(\"InvoiceNo\").alias(\"order_count\")))\n    (aggregated_stream_df\n       .writeStream\n         .format(\"delta\")\n         .option(\"checkpointLocation\", \n                 \"/tmp/delta/agg_stream.delta/checkpoint\")\n         .start(\"/tmp/delta/agg_stream.delta/\"))\n    ```"]