- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cleaning and Exploring Data with Series Operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can view the recipes in the first few chapters of this book as, essentially,
    diagnostic. We imported some raw data and then generated descriptive statistics
    about key variables. This gave us a sense of how the values for those variables
    were distributed and helped us identify outliers and unexpected values. We then
    examined the relationships between variables to look for patterns, and deviations
    from those patterns, including logical inconsistencies. In short, our primary
    goal so far has been to figure out what is going on with our data.
  prefs: []
  type: TYPE_NORMAL
- en: But, not very long into a data exploration and cleaning project, we invariably
    need to alter the initial values for some of our variables across some of our
    observations. For example, we might need to create a new column that is based
    on the values of one or more other columns. Or, we might want to change values
    that are in a certain range, say less than 0, or over some threshold amount, perhaps
    setting them to the mean, or to missing. Fortunately, the pandas Series object
    offers a large number of methods for manipulating data values.
  prefs: []
  type: TYPE_NORMAL
- en: The recipes in this chapter demonstrate how to use pandas methods to update
    Series values once we have figured out what needs to be done. Ideally, we need
    to take the time to carefully examine our data before manipulating the values
    of our variables. We should have measures of central tendency, indicators of distribution
    shape and spread, correlations, and visualizations in front of us before we update
    the variable’s values, or before creating new variables based on them. We should
    also have a good sense of outliers and missing values, understand how they affect
    summary statistics, and have preliminary plans for imputing new values or otherwise
    adjusting them.
  prefs: []
  type: TYPE_NORMAL
- en: Having done that, we will be ready to perform some data cleaning tasks. These
    tasks usually involve working directly with a pandas Series object, regardless
    of whether we are changing values for an existing Series or creating a new one.
    This often involves changing values conditionally, altering only those values
    that meet specific criteria, or assigning multiple possible values based on existing
    values for that Series, or values for another Series.
  prefs: []
  type: TYPE_NORMAL
- en: How we assign such values varies significantly by the Series’ data type, either
    for the Series to be changed or a criterion Series. Querying and cleaning string
    data bears little resemblance to those tasks with date or numeric data. With strings,
    we often need to evaluate whether some string fragment does or does not have a
    certain value, strip the string of some meaningless characters, or convert the
    value into a numeric or date value. With dates, we might need to look for invalid
    or out-of-range dates, or even calculate date intervals.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, pandas Series have an enormous number of tools for manipulating
    strings, numeric, and date values. We will explore many of the most useful tools
    in this chapter. Specifically, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Getting values from a pandas Series
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Showing summary statistics for a pandas Series
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changing Series values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changing Series values conditionally
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating and cleaning string Series data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with dates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using OpenAI for Series operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need pandas, NumPy, and Matplotlib to complete the recipes in this
    chapter. I used pandas 2.1.4, but the code will run on pandas 1.5.3 or later.
  prefs: []
  type: TYPE_NORMAL
- en: The code in this chapter can be downloaded from the book’s GitHub repository,
    [https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition](https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition).
  prefs: []
  type: TYPE_NORMAL
- en: Getting values from a pandas Series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A pandas Series is a one-dimensional array-like structure that takes a NumPy
    data type. Each Series also has an index, an array of data labels. If an index
    is not specified when the Series is created, it will be the default index of 0
    through N-1.
  prefs: []
  type: TYPE_NORMAL
- en: There are several ways to create a pandas Series, including from a list, dictionary,
    NumPy array, or a scalar. In our data cleaning work, we will most frequently be
    accessing data Series by selecting columns of DataFrames, using either attribute
    access (`dataframename.columname`) or bracket notation (`dataframename['columnname']`).
    Attribute access cannot be used to set values for Series, but bracket notation
    will work for all Series operations.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we’ll explore several ways we can get values from a pandas Series.
    These techniques are very similar to the methods we used to get rows from a pandas
    DataFrame, which we covered in the *Selecting rows* recipe of *Chapter 3*, *Taking
    the Measure of Your Data*.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will be working with data from the **National Longitudinal Survey** (**NLS**)
    in this recipe—primarily with data about each respondent’s overall high school
    **Grade Point Average** (**GPA**).
  prefs: []
  type: TYPE_NORMAL
- en: '**Data note**'
  prefs: []
  type: TYPE_NORMAL
- en: The National Longitudinal Survey of Youth is conducted by the United States
    Bureau of Labor Statistics. This survey started with a cohort of individuals in
    1997 who were born between 1980 and 1985, with annual follow-ups each year until
    2023\. Survey data is available for public use at [nlsinfo.org](https://nlsinfo.org).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this recipe, we select Series values using the bracket operator and the
    `loc` and `iloc` accessors. Let’s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the required `pandas` and NLS data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Note**'
  prefs: []
  type: TYPE_NORMAL
- en: Whether you use the bracket operator, the `loc` accessor, or the `iloc` accessor
    is largely a matter of preference. It is usually easier to use the `loc` accessor
    when you know the index label for the rows you want. When it is easier to refer
    to rows by their absolute position, the bracket operator or `iloc` accessor will
    probably be a better choice. The examples in this recipe illustrate this.
  prefs: []
  type: TYPE_NORMAL
- en: Create a Series from the GPA overall column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Show the first few values and associated index labels using `head`. The default
    number of values shown for `head` is 5\. The index for the Series is the same
    as the DataFrame’s index, which is `personid`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Select GPA values using the bracket operator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use slicing to create a Series with every value from the first value to the
    fifth. Notice that we get the same values that we got with the `head` method in
    *step 2*. Not including a value to the left of the colon in `gpaoverall[:5]` means
    that it will start from the beginning. `gpaoverall[0:5]` will give the same results.
    Similarly, `gpaoverall[-5:]` shows the values from the fifth to the last position.
    This produces the same results as `gpaoverall.tail()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Select values using the `loc` accessor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We pass an index label (a value for `personid` in this case) to the `loc` accessor
    to return a scalar. We get a Series if we pass a list of index labels, regardless
    of whether there’s one or more. We can even pass a range, separated by a colon.
    We’ll do this here with `gpaoverall.loc[135335:151672]`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Select values using the `iloc` accessor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`iloc` differs from `loc` in that it takes a list of row numbers rather than
    labels. It works similarly to bracket operator slicing. In this step, we pass
    a one-item list with a value of 0\. We then pass a five-item list, `[0,1,2,3,4]`,
    to return a Series containing the first five values. We get the same result if
    we pass `[:5]` to the accessor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Each of these ways of accessing pandas Series values—the bracket operator, the
    `loc` accessor, and the `iloc` accessor—has many use cases, particularly the `loc`
    accessor.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We used the `[]` bracket operator in *step 3* to perform standard Python-like
    slicing to create a Series. This operator allows us to easily select data based
    on position using a list, or a range of values indicated with slice notation.
    This notation takes the form of `[start:end:step]`, where `1` is assumed for `step`
    if no value is provided. When a negative number is used for `start`, it represents
    the number of rows from the end of the original Series.
  prefs: []
  type: TYPE_NORMAL
- en: The `loc` accessor, used in *step 4*, selects data by index labels. Since `personid`
    is the index for the Series, we can pass a list of one or more `personid` values
    to the `loc` accessor to get a Series with those labels and associated GPA values.
    We can also pass a range of labels to the accessor, which will return a Series
    with GPA values from the index label to the left of the colon and the index label
    to the right inclusive. So, `gpaoverall.loc[135335:151672]` returns a Series with
    GPA values for `personid` between `135335` and `151672`, including those two values.
  prefs: []
  type: TYPE_NORMAL
- en: As shown in *step 5*, the `iloc` accessor takes row positions rather than index
    labels. We can pass either a list of integers or a range using slicing notation.
  prefs: []
  type: TYPE_NORMAL
- en: Showing summary statistics for a pandas Series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a large number of pandas Series methods for generating summary statistics.
    We can easily get the mean, median, maximum, or minimum values for a Series with
    the `mean`, `median`, `max`, and `min` methods, respectively. The incredibly handy
    `describe` method will return all of these statistics, as well as several others.
    We can also get the Series value at any percentile using `quantile`. These methods
    can be used across all values for a Series, or just for selected values. This
    will be demonstrated in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will continue working with the overall GPA column from the NLS.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s take a good look at the distribution of the overall GPA for the DataFrame
    and for the selected rows. To do this, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and `numpy` and load the NLS data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Gather some descriptive statistics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Show descriptives for a subset of the Series:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Test for a condition across all values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Check for GPA values above 4 and if all the values are above or equal to 0\.
    (We generally expect GPA to be between 0 and 4.) Also, count how many values are
    missing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Show descriptives for a subset of the Series based on values in a different
    column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Show the mean high school GPA for individuals with a wage income in 2020 that’s
    above the 75^(th) percentile, as well as for those with a wage income that’s below
    the 25^(th) percentile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Show descriptives and frequencies for a Series containing categorical data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Once we have a Series, we can use a wide variety of pandas tools to calculate
    descriptive statistics for all or part of that Series.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Series `describe` method is quite useful as it gives us a good sense of
    the central tendency and spread of continuous variables. It is also often helpful
    to see the value at each decile. We obtained this in *step 2* by passing a list
    of values ranging from 0.1 to 1.0 to the `quantile` method of the Series.
  prefs: []
  type: TYPE_NORMAL
- en: We can use these methods on subsets of a Series. In *step 3*, we obtained the
    count of GPA values between 3 and 3.5\. We can also select values based on their
    relationship to a summary statistic; for example, `gpaoverall>gpaoverall.quantile(0.99)`
    selects GPA values that are greater than the 99^(th) percentile value. We then
    passed the resulting Series to the `agg` method using method chaining, which returned
    multiple summary statistics (`agg(['count','min','max'])`).
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, we need to test whether some condition is true across all the values
    in a Series. The `any` and `all` methods are useful for this. `any` returns `True`
    when at least one value in the Series satisfies the condition (such as (`gpaoverall>4).any()`).
    `all` returns `True` when all the values in the Series satisfy the condition.
    When we chain the test condition with sum (`(gpaoverall>=0).sum()`), we get a
    count of all the `True` values since pandas interprets `True` values as 1 when
    performing numerical operations.
  prefs: []
  type: TYPE_NORMAL
- en: '`(gpaoverall>4)` is a shorthand for creating a Boolean Series with the same
    index as `gpaoverall`. It has a value of `True` when `gpaoverall` is greater than
    4, and `False` otherwise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: We sometimes need to generate summary statistics for a Series that has been
    filtered by another Series. We did this in *step 5* by calculating the mean high
    school GPA for individuals with a wage income that’s above the third quartile,
    as well as for individuals with a wage income that’s below the first quartile.
  prefs: []
  type: TYPE_NORMAL
- en: The `describe` method is most useful with continuous variables, such as `gpaoverall`,
    but it also provides useful information when used with categorical variables,
    such as `maritalstatus` (see *step 6*). This returns the count of non-missing
    values, the number of different values, the category that occurs most frequently,
    and the frequency of that category.
  prefs: []
  type: TYPE_NORMAL
- en: However, when working with categorical data, the `value_counts` method is more
    frequently used. It provides the frequency of each category in the Series.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Working with Series is so fundamental to pandas data cleaning tasks that data
    analysts quickly find that the tools that were used in this recipe are part of
    their daily data cleaning workflow. Typically, not much time elapses between the
    initial data import stage and using Series methods such as `describe`, `mean`,
    `sum`, `isnull`, `all`, and `any`.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are just scratching the surface of aggregating data in this chapter. We’ll
    go through this more thoroughly in *Chapter 9*, *Fixing Messy Data When Aggregating*.
  prefs: []
  type: TYPE_NORMAL
- en: Changing Series values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: During the data cleaning process, we often need to change the values in a data
    Series or create a new one. We can change all the values in a Series, or just
    the values in a subset of our data. Most of the techniques we have been using
    to get values from a Series can be used to update Series values, though some minor
    modifications are necessary.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will work with the overall high school GPA column from the NLS in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can change the values in a pandas Series for all rows, as well as for selected
    rows. We can update a Series with scalars by performing arithmetic operations
    on other Series, and by using summary statistics. Let’s take a look at this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and load the NLS data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Edit all the values based on a scalar.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Multiply `gpaoverall` by 100:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: Set values using index labels.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the `loc` accessor to specify which values to change by index label:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Set values using an operator on more than one Series.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the `+` operator to calculate the number of children, which is the sum
    of children who live at home and children who do not live at home:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: Use index labels to set values to a summary statistic.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the `loc` accessor to select `personid` from `100061` to `100292`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: Set values using position.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the `iloc` accessor to select by position. An integer, or slice notation
    (`start:end:step`), can be used to the left of the comma to indicate the rows
    where the values should be changed. An integer is used to the right of the comma
    to select the column. The `gpaoverall` column is in the 16^(th) position (which
    is 15 since the column index is zero-based):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: Set the GPA values after filtering.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Change all GPA values over `4` to `4`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: The preceding steps showed us how to update Series values with scalars, arithmetic
    operations, and summary statistics values.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first thing to observe is that, in *step 2*, pandas vectorizes the multiplication
    by a scalar. It knows that we want to apply the scalar to all rows. Essentially,
    `nls97['gpaoverall'] * 100`, creates a temporary Series with all values set to
    100, and with the same index as the `gpaoverall` Series. It then multiplies `gpaoverall`
    by that Series of 100 values. This is known as broadcasting.
  prefs: []
  type: TYPE_NORMAL
- en: We can use a lot of what we learned in the first recipe of this chapter, about
    how to get values from a Series, to select particular values to update. The main
    difference here is that we use the `loc` and `iloc` accessors of the DataFrame
    (`nls97.loc`) rather than the Series (`nls97.gpaoverall.loc`). This is to prevent
    the dreaded `SettingwithCopyWarning`, which warns us about setting values on a
    copy of a DataFrame. `nls97.gpaoverall.loc[[135335]] = 3` triggers that warning,
    while `nls97.loc[[135335], 'gpaoverall'] = 3` does not.
  prefs: []
  type: TYPE_NORMAL
- en: In *step 4*, we saw how pandas handles numerical operations with two or more
    Series. Operations such as addition, subtraction, multiplication, and division
    are very much like the operations we perform on scalars in standard Python, only
    with vectorization. (This is made possible by pandas index alignment. Remember
    that Series in the same DataFrame will have the same index.) If you are familiar
    with NumPy, then you already have a good idea of how this works.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It is useful to notice that `nls97.loc[[135335], ''gpaoverall'']` returns a
    Series, while `nls97.loc[[135335], [''gpaoverall'']]` returns a DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: If the second argument of the `loc` accessor is a string, it will return a Series.
    If it is a list, even if the list contains only 1 item, it will return a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: For any of the operations we discussed in this recipe, it is good to be mindful
    of how pandas treats missing values. For example, in *step 4*, if either `childathome`
    or `childnotathome` is missing, then the operation will return `missing`. We’ll
    discuss how to handle situations like this in*, Identifying and Fixing Missing
    Values* recipe in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Chapter 3*, *Taking the Measure of Your Data*, goes into greater detail on
    the use of the `loc` and `iloc` accessors, particularly in the *Selecting rows*
    and *Selecting and organizing columns* recipes.'
  prefs: []
  type: TYPE_NORMAL
- en: Changing Series values conditionally
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Changing Series values is often more complicated than the previous recipe suggests.
    We often need to set Series values based on the values of one or more other Series
    for that row of data. This is complicated further when we need to set Series values
    based on values from *other* rows; say, a previous value for an individual, or
    the mean for a subset. We will deal with these complications in this and the next
    recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will work with land temperature data and the NLS data in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data note**'
  prefs: []
  type: TYPE_NORMAL
- en: The land temperature dataset contains the average temperature readings (in Celsius)
    in 2023 from over 12,000 stations across the world, though the majority of the
    stations are in the United States. The raw dataset was retrieved from the Global
    Historical Climatology Network integrated database. It has been made available
    for public use by the United States National Oceanic and Atmospheric Administration
    at [https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-monthly](https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-monthly).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will use NumPy’s `where` and `select` methods to assign Series values based
    on the values of that Series, the values of other Series, and summary statistics.
    We’ll then use the `lambda` and `apply` functions to construct more complicated
    criteria for assignment. Let’s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and `numpy`, and then load the NLS and land temperature data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Use NumPy’s `where` function to create a categorical Series containing two values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s do a quick check of the distribution of `elevation` values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '**Note**'
  prefs: []
  type: TYPE_NORMAL
- en: You may have noticed that we passed a value of `False` to the `groupby` `observed`
    attribute. This is the default value of observed for all pandas versions prior
    to 2.1.0\. `observed=True` is the default for `groupby` in subsequent pandas versions.
    When `observed` is `True` and there is a column in `groupby` that is categorical,
    only observed values are shown. This does not affect the summary statistics in
    the previous step. I show it only to alert you to the upcoming change in the default
    value. I omit it in the rest of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Use NumPy’s `where` method to create a categorical Series containing three values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set values above the 80^(th) percentile to `''High''`, values above the median
    and up to the 80^(th) percentile to `''Medium''`, and the remaining values to
    `''Low''`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: Use NumPy’s `select` method to evaluate a list of conditions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set up a list of test conditions and another list for the result. We want individuals
    with a GPA less than 2 and no degree earned to be in one category, individuals
    with no degree but with a higher GPA to be in a second category, individuals with
    a degree but a low GPA in a third category, and the remaining individuals in a
    fourth category:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: While NumPy’s `select` method is very handy for relatively straightforward assignment
    of values conditionally, it can be difficult to use when the assignment is more
    complicated. We can use a user-defined function when `select` would be unwieldy.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s use `apply` and a user-defined function to do the same Series value assignment
    that we did in the previous step. We create a function, `gethsachieve`, with the
    logic for assigning values to a new variable, `hsachieve2`. We pass this function
    to `apply` and indicate `axis=1` to apply the function to all rows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will use this same technique in the next step to handle a more complicated
    assignment, one based on more columns and conditions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we get the same values for `hsachieve2` in this step that we got
    for `hsachieve` in the previous step.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s use `apply` and a user-defined function for a more complicated calculation,
    one that is based on the values of several variables.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `getsleepdeprivedreason` function below creates a variable that categorizes
    survey respondents by the possible reasons why they might get fewer than 6 hours
    of sleep a night. We base this on NLS survey responses about a respondent’s employment
    status, the number of children who live with the respondent, wage income, and
    highest grade completed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'Use `apply` to run the function for all rows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can use a lambda function with `transform` if we want to work with particular
    columns but we do not need to pass them to a user-defined function. Let’s try
    that by using `lambda` to test several columns in one statement.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `colenr` columns have enrollment status in February and October of each
    year for each person. We want to test whether any of the college enrollment columns
    has a value of `3\. 4-year college`. Use `filter` to create a DataFrame of the
    `colenr` columns. Then, use `transform` to call a lambda function that tests the
    first character of each `colenr` column. (We can just look at the first character
    and see whether it has a value of 3.) That is then passed to `any` to evaluate
    whether any (one or more) of the columns has a 3 in the first character. (We only
    show values for college enrollment between 2000 and 2004 due to space considerations,
    but we check all the values for the college enrollment columns between 1997 and
    2022.) This can be seen in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: The preceding steps demonstrate several techniques we can use to set the values
    for a Series conditionally.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have used `if-then-else` statements in SQL or Microsoft Excel, then NumPy’s
    `where` should be familiar to you. It follows the form of `where` (test condition,
    clause if `True`, clause if `False`). In *step 2*, we tested whether the value
    of elevation for each row is greater than the value at the 80^(th) percentile.
    If `True`, we returned `'High'`. We returned `'Low'` otherwise. This is a basic
    `if-then-else` construction.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, we need to nest a test within a test. We did this in *step 3* to
    create three elevation groups; high, medium, and low. Instead of a simple statement
    in the `False` section (after the second comma), we used another `where` statement.
    This changes it from an `else` clause to an `else if` clause. It takes the form
    of `where`(test condition, statement if `True`, `where`(test condition, statement
    if `True`, statement if `False`)).
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to add many more nested `where` statements, though that is not
    advisable. When we need to evaluate a slightly more complicated test, NumPy’s
    `select` method comes in handy. In *step 4*, we passed a list of tests, as well
    as a list of results of that test, to `select`. We also provided a default value
    of `4\. Did Okay` for any case where none of the tests was `True`. When multiple
    tests are `True`, the first one that is `True` is used.
  prefs: []
  type: TYPE_NORMAL
- en: Once the logic becomes even more complicated, we can use `apply`. The DataFrame
    `apply` method can be used to send each row of a DataFrame to a function by specifying
    `axis=1`. *step 5* demonstrates how to reproduce the same logic as with *step
    4* using `apply` and a user-defined function.
  prefs: []
  type: TYPE_NORMAL
- en: In *steps 6* and *7*, we created a Series that categorizes reasons for being
    sleep deprived based on weeks worked, the number of children living with the respondent,
    wage income, and highest grade completed. If the respondent did not work most
    of 2020 and 2021, and if more than two children lived with them, `sleepdeprivedreason`
    is set to “Child Rearing.” If the respondent did not work most of 2020 and 2021
    and two or fewer children lived with them, `sleepdeprivedreason` is set to “Other
    Reasons.” If they worked most of 2020 and 2021, then `sleepdeprivedreason` is
    “Work Pressure” if they had a high salary or completed 4 years of college, and
    is “Income Pressure” otherwise. Of course, these categories are somewhat contrived,
    but they do illustrate how to use a function to create a Series based on complicated
    relationships among other Series.
  prefs: []
  type: TYPE_NORMAL
- en: In *step 8*, we used `transform` to call a lambda function that tests whether
    the first character of each college enrollment value is 3\. But first, we used
    the `filter` DataFrame method to select all the college enrollment columns. We
    could have paired the `lambda` function with `apply` to achieve the same result,
    but `transform` is typically more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: You may have noticed that we changed the data type of the new Series we created
    in *steps 2* and *3* to `category`. The new Series was an `object` data type initially.
    We reduced memory usage by changing the type to `category`.
  prefs: []
  type: TYPE_NORMAL
- en: We used another incredibly useful method in *step 2*, somewhat incidentally.
    `landtemps.groupby(['elevation_group'])` creates a DataFrame `groupby` object
    that we pass to an aggregate (`agg`) function. This gives us a count, min, and
    max for each `elevation_group`, allowing us to confirm that our group classification
    works as expected.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It has been a long time since I have had a data cleaning project that did not
    involve a NumPy `where` or `select` statement, nor a `lambda` or `apply` statement.
    At some point, we need to create or update a Series based on values from one or
    more other Series. It is a good idea to get comfortable with these techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever there is a built-in pandas function that does what we need, it is better
    to use that than `apply`. The great advantage of `apply` is that it is quite generic
    and flexible, but that is also why it is more resource-intensive than the optimized
    functions. However, it is a great tool when we want to create a Series based on
    complicated relationships between existing Series.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way to perform *steps 6* and *7* is to add a lambda function to `apply`.
    This produces the same results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: One advantage of this approach is that it makes it more clear which Series contribute
    to the calculation.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ll go over DataFrame `groupby` objects in detail in *Chapter 9*, *Fixing
    Messy Data When Aggregating*. We examined various techniques we can use to select
    columns from a DataFrame, including `filter`, in *Chapter 3*, *Taking the Measure
    of Your Data*.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating and cleaning string Series data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are many string cleaning methods in Python and pandas. This is a good
    thing. Given the great variety of data stored in strings, it is important to have
    a wide range of tools to call upon when performing string evaluation and manipulation:
    when selecting fragments of a string by position, when checking whether a string
    contains a pattern, when splitting a string, when testing a string’s length, when
    joining two or more strings, when changing the case of a string, and so on. We’ll
    explore some of the methods that are used most frequently for string evaluation
    and cleaning in this recipe.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will work with the NLS data in this recipe. (The NLS data was actually a
    little too clean for this recipe. To illustrate working with strings with trailing
    spaces, I added trailing spaces to the `maritalstatus` column values.)
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we will perform some common string evaluation and cleaning tasks.
    We’ll use `contains`, `endswith`, and `findall` to search for patterns, trailing
    blanks, and more complicated patterns, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will also create a function for processing string values before assigning
    values to a new Series and then use `replace` for simpler processing. Let’s get
    started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and `numpy`, and then load the NLS data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Test whether a pattern exists in a string.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use `contains` to examine the `govprovidejobs` (government should provide jobs)
    responses for the “Definitely not” and “Probably not” values. In the `where` call,
    handle missing values first to make sure that they do not end up in the first
    `else` clause (the section after the second comma):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: Handle leading or trailing spaces in a string.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create an ever-married Series. First, examine the values of `maritalstatus`.
    Notice that there are two stray values indicating never-married. They are “Never-married”
    with an extra space at the end, unlike the other values of “Never-married” with
    no trailing spaces. Use `startswith` and `endswith` to test for a leading or trailing
    space, respectively. Use `strip` to remove the trailing space before testing for
    ever-married. `strip` removes leading and trailing spaces (`lstrip` removes leading
    spaces, while `rstrip` removes trailing spaces, so `rstrip` would have also worked
    in this example):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: 'Use `isin` to compare a string value to a list of values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE121]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We occasionally need to identify the location of a particular character in a
    string. This is sometimes because we need to get text before or after that point,
    or treat that text differently. Let’s try this with the highest degree attained
    column that we have already worked with. We will create a new column that does
    not have the number prefix. For example, *2\. High School* will become *High School*.
  prefs: []
  type: TYPE_NORMAL
- en: Use `find` to get the location of the period in `highestdegree` values and retrieve
    the text after that.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Before we do that, we assign *99\. Unknown* to missing values. This is not necessary
    but it helps us be clear about how we are handling all values, including the missing
    ones. It also adds a useful complication. After we do that, the leading numbers
    can be 1 or 2 digits.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we create a lambda function, `onlytext`, that we will use to identify
    the location of the text we want and then use it to pull that text. We then use
    the `transform` method of the `highestdegree` Series to call the `onlytext` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: You probably noticed that there is a space between the period and the start
    of the text we want. To account for this, the `onlytext` function pulls text starting
    two spaces over from the period.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**'
  prefs: []
  type: TYPE_NORMAL
- en: We did not need to name a lambda function to achieve the results we wanted.
    We could have just entered a lambda function in the `transform` method. However,
    since we have a number of columns in the NLS data that have a similar prefix,
    it is good to have a function that we can reuse with another column.
  prefs: []
  type: TYPE_NORMAL
- en: We sometimes need to find all occurrences in a string of a certain value or
    a certain type of value, say a number. The pandas Series function, `findall`,
    can be used to return one or more occurrences of a value in a string. A list is
    returned of the string fragments that satisfy the given criteria. Let’s do a straightforward
    example before moving on to a more complicated one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `findall` to count the number of times `r` appears for each `maritalstatus`
    value for the first few rows of data. First, show the values for `maritalstatus`,
    then show the list that is returned from `findall` for each value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: Let’s also show a count of the number of times that `r` appears.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use `concat` to show the `maritalstatus` value, the list from `findall`, and
    the length of the list all on the same line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: We can also use `findall` to return types of values. For example, we can use
    a regular expression to return a list with all numbers in a string. We do that
    in the next couple of steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `findall` to create a list of all numbers in the `weeklyhrstv` (hours spent
    each week watching television) string. The `"\d+"` regular expression that’s passed
    to `findall` indicates that we just want numbers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE131]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Use the list created by `findall` to create a numerical Series from the `weeklyhrstv`
    text.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s define a function that retrieves the last element in the list created
    by `findall` for each value of `weeklyhrstv`. The `getnum` function also adjusts
    that number so that it’s closer to the midpoint of the two numbers, where there
    is more than one number. We then use `apply` to call this function, passing it
    the list created by `findall` for each value. `crosstab` shows that the new `weeklyhrstvnum`
    column does what we want it to do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: Replace the values in a Series with alternative values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `weeklyhrscomputer` (hours spent each week on a computer) Series does not
    sort nicely with its current values. We can fix this by replacing the values with
    letters that indicate order. We’ll start by creating a list containing the old
    values and another list containing the new values that we want. We then use the
    Series `replace` method to replace the old values with the new values. Whenever
    `replace` finds a value from the old values list, it replaces it with a value
    from the same list position in the new list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: The steps in this recipe demonstrate some of the common string evaluation and
    manipulation tasks we can perform in pandas.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We frequently need to examine a string to see whether there is a pattern. We
    can use the string `contains` method to do this. If we know exactly where the
    expected pattern will be, we can use standard slice notation, `[start:stop:step]`,
    to select text from start through stop-1\. (The default value for `step` is 1.)
    For example, in *step 4*, we got the first character from `highestdegree` with
    `nls97.highestdegree.str[0:1]`. We then used `isin` to test whether the first
    string appears in a list of values. (`isin` works for both character and numeric
    data.)
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, we need to pull multiple values from a string that satisfy a condition.
    `findall` is helpful in those situations as it returns a list of all values satisfying
    the condition. It can be paired with a regular expression when we are looking
    for something more general than a literal. In *steps 8* and *9*, we were looking
    for any number.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is important to be deliberate while handling missing values when creating
    a Series based on values for another Series. Missing values may satisfy the `else`
    condition in a `where` call when that is not our intention. In *steps 2*, *3*,
    and *4*, we made sure that we handled the missing values appropriately by testing
    for them at the beginning of the `where` call.
  prefs: []
  type: TYPE_NORMAL
- en: We also need to be careful about the casing of the letters when making string
    comparisons. For example, `Probably` and `probably` are not equal. One way to
    get around this is to use the `upper` or `lower` methods when doing comparisons
    when a potential difference in case is not meaningful. `upper("Probably") == upper("PROBABLY")`
    is actually `True`.
  prefs: []
  type: TYPE_NORMAL
- en: Working with dates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with dates is rarely straightforward. Data analysts need to successfully
    parse date values, identify invalid or out-of-range dates, impute dates when they’re
    missing, and calculate time intervals. There are surprising hurdles at each of
    these steps, but we are halfway there once we’ve parsed the date value and have
    a datetime value in pandas. We will start by parsing date values in this recipe
    before working our way through the other challenges.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will work with the NLS and COVID-19 case daily data in this recipe. The COVID-19
    daily data contains one row for each reporting day for each country. (The NLS
    data was actually a little too clean for this purpose. To illustrate working with
    missing date values, I set one of the values for birth month to missing.)
  prefs: []
  type: TYPE_NORMAL
- en: '**Data note**'
  prefs: []
  type: TYPE_NORMAL
- en: Our World in Data provides COVID-19 public use data at [https://ourworldindata.org/covid-cases](https://ourworldindata.org/covid-cases).
    The data used in this recipe was downloaded on March 3, 2024.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we will convert numeric data into datetime data, first by confirming
    that the data has valid date values and then by using `fillna` to replace missing
    dates. We will then calculate some date intervals; that is, the age of respondents
    for the NLS data and the days since the first COVID-19 case for the COVID-19 daily
    data. Let’s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and the `relativedelta` module from `dateutils`, and then load
    the NLS and COVID-19 case daily data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Show the birth month and year values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Notice that there is one missing value for birth month. Other than that, the
    data that we will use to create the `birthdate` Series looks pretty clean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: Use the `fillna` method to set a value for the missing birth month.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pass the average of `birthmonth`, rounded to the nearest integer, to `fillna`.
    This will replace the missing value for `birthmonth` with the mean of `birthmonth`.
    Notice that one more person now has a value of 6 for `birthmonth`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: Use `month` and year `integers` to create a datetime column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can pass a dictionary to the pandas `to_datetime` function. The dictionary
    needs to contain a key for year, month, and day. Notice that there are no missing
    values for `birthmonth`, `birthyear`, and `birthdate`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: Calculate age using a datetime column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, define a function that will calculate age when given a start date and
    an end date. Notice that we create a **Timestamp** object, `rundate`, and assign
    it a value of `2024-03-01` to use for the end date of our age calculation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use the `relativedelta` module instead for the age calculation. We just
    need to do the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We should confirm that we get the same values as in *step 5*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE156]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE157]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE158]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE159]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Convert a string column into a datetime column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `casedate` column is an `object` data type, not a `datetime` data type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE160]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE161]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE162]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE163]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE164]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE165]'
  prefs: []
  type: TYPE_PRE
- en: 'Show descriptive statistics for the datetime column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE166]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE167]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE168]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE169]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Create a `timedelta` object to capture a date interval.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For each day, calculate the number of days since the first case was reported
    for each country. First, create a DataFrame that shows the first day of new cases
    for each country and then merge it with the full COVID-19 cases data. Then, for
    each day, calculate the number of days from `firstcasedate` to `casedate`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE170]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE171]'
  prefs: []
  type: TYPE_PRE
- en: This recipe showed how it’s possible to parse date values and create a datetime
    Series, as well as how to calculate time intervals.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first task when working with dates in pandas is converting them properly
    into a pandas datetime Series. We tackled a couple of the most common issues in
    *steps 3*, *4*, and *8*: missing values, date conversion from integer parts, and
    date conversion from strings. `birthmonth` and `birthyear` are integers in the
    NLS data. We confirmed that those values are valid values for date months and
    date years. If, for example, there were month values of 0 or 20, the conversion
    to pandas datetime would fail.'
  prefs: []
  type: TYPE_NORMAL
- en: Missing values for `birthmonth` or `birthyear` will result in a missing `birthdate`.
    We used `fillna` for the missing value for `birthmonth`, assigning it to the mean
    value of `birthmonth`. In *step 5*, we calculated an age for each person as of
    March 1, 2024, using the new `birthdate` column. The `calcage` function that we
    created adjusts for individuals whose birth dates come later in the year than
    March 1.
  prefs: []
  type: TYPE_NORMAL
- en: Data analysts often receive data files containing date values as strings. The
    `to_datetime` function is the analyst’s key ally when this happens. It is often
    smart enough to figure out the format of the string date data without us having
    to specify a format explicitly. However, in *step 8*, we told `to_datetime` to
    use the `%Y-%m-%d` format with our data.
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 9* told us that there were 214 unique days where COVID-19 cases were
    reported. The first reported day was January 5, 2020, and the last was February
    4, 2024.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first two statements in *step 10* involved techniques (sorting and dropping
    duplicates) that we will not explore in detail until *Chapter 9*, *Fixing Messy
    Data When Aggregating*, and *Chapter 10*, *Addressing Data Issues When Combining
    DataFrames*. All you need to understand here is the objective: creating a DataFrame
    with one row per `location` (country), and with the date of the first reported
    COVID-19 case. We did this by only selecting rows from the full data where `new_cases`
    is greater than 0, before sorting that by `location` and `casedate` and keeping
    the first row for each `location`. We then changed the name of `casedate` to `firstcasedate`
    before merging the new `firstcase` DataFrame with the COVID-19 daily cases data.'
  prefs: []
  type: TYPE_NORMAL
- en: Since both `casedate` and `firstcasedate` are datetime columns, subtracting
    the latter from the former will result in a timedelta value. This gives us a Series
    that is the number of days after the first day of `new_cases` for each country
    for each reporting day. The greatest duration (`dayssincefirstcase`) between a
    reported case date (`casedate`) and date of first case (`firstcasedate`) is 1491
    days, or just over 4 years. This interval calculation is useful if we want to
    track trends by how long the virus has been obviously present in a country, rather
    than by date.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instead of using `sort_values` and `drop_duplicates` in *step 10*, we could
    have used `groupby` to achieve similar results. We’ll explore `groupby` a fair
    bit in *Chapter 9*, *Fixing Messy Data When Aggregating*. We also did a merge
    in *step 10*. *Chapter 10*, *Addressing Data Issues When Combining DataFrames*,
    will be devoted to this topic.
  prefs: []
  type: TYPE_NORMAL
- en: Using OpenAI for Series operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many of the Series operations demonstrated in the previous recipes in this chapter
    can be assisted by AI tools, including by PandasAI, with the large language model
    from OpenAI. In this recipe, we examine how to use PandasAI to query Series values,
    create new Series, set Series values conditionally, and do some rudimentary reshaping
    of DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will work with the NLS and COVID-19 case daily data again in this recipe.
    We will also work with PandasAI, which can be installed with `pip install pandasai`.
    You also need to get a token from [openai.com](https://openai.com) to send a request
    to the OpenAI API.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps create a PandasAI `SmartDataframe` object, and then use
    the chat method of that object to submit natural language instructions for a range
    of Series operations:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We first need to import the `OpenAI` and `SmartDataframe` modules from PandasAI.
    We also have to instantiate an `llm` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE172]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We load the NLS and COVID-19 data and create a `SmartDateFrame` object. We
    pass the `llm` object as well as a pandas DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE173]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we are ready to generate summary statistics on Series from our `SmartDataframe`.
    We can ask for the average for a single Series, or for multiple Series:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE174]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE175]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE176]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE177]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can also summarize Series values by another Series, usually one that is
    categorical:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE178]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE179]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can also create a new Series with the `chat` method of `SmartDataframe`.
    We do not need to use the actual column names. For example, PandasAI will figure
    out that we want the `childathome` Series when we write *child at home*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE180]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE181]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can use the `chat` method to create Series values conditionally:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE182]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE183]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'PandasAI is quite flexible regarding the language you might use here. For example,
    the following provides the same results as in *step 6*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE184]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE185]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can do calculations across a number of similarly named columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE186]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will calculate the average of all `weeksworked00`-`weeksworked22` columns
    and assign that to a new column called `weeksworkedavavg`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can easily impute values where they are missing based on summary statistics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE187]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE188]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE189]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE190]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can also use PandasAI to do some reshaping, similar to what we did in the
    previous recipe. Recall that we worked with the COVID-19 cases data and wanted
    the first row of data for each country. Let’s do a simplified version of that
    the traditional way first:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE191]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE192]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE193]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE194]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can get the same results by creating a `SmartDataframe` and using the `chat`
    method. The natural language I use here is remarkably straightforward, *Show first
    casedate and location and other values for each country*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE195]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE196]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE197]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE198]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice that PandasAI makes smart choices about the columns to get. We get the
    columns we need rather than all of them. We could have also just passed the names
    of the columns we wanted to the `chat`.
  prefs: []
  type: TYPE_NORMAL
- en: That’s a little PandasAI and OpenAI magic for you! One pretty ordinary sentence
    passed to the `chat` method did all of the work for us.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Much of the work when using PandasAI is really just importing the relevant libraries
    and instantiating large language model and `SmartDataframe` objects. Once that’s
    done, simple sentences sent to the `chat` method of the `SmartDataframe` are sufficient
    to summarize Series values and create new Series.
  prefs: []
  type: TYPE_NORMAL
- en: PandasAI excels at generating simple statistics from Series. We don’t even need
    to remember the Series name exactly, as we saw in *step 3*. Often the natural
    language we might use can be more intuitive than traditional pandas methods like
    `groupby`. The *Show satmath average by gender* value passed to `chat` in *step
    4* is a good example of that.
  prefs: []
  type: TYPE_NORMAL
- en: Operations on Series, including the creation of a new Series, is also quite
    straightforward. In *step 5*, we create a total number of children Series (*childnum*)
    by instructing the `SmartDataframe` to add the number of children living at home
    to the number of children not living at home. We don’t even provide the literal
    Series names, *childathome* and *childnotathome* respectively. PandasAI figures
    out what we mean.
  prefs: []
  type: TYPE_NORMAL
- en: '*Steps 6* and *7* demonstrate the flexibility that being able to use natural
    language for our Series operations provides. We get the same result if we pass
    *evermarried is ‘No’ when maritalstatus is ‘Never-married’, else ‘Yes’* to `chat`
    in *step 6* or *if maritalstatus is ‘Never-married’ set evermarried2 to ‘No’,
    otherwise ‘Yes’* in *step 7*.'
  prefs: []
  type: TYPE_NORMAL
- en: We can also do fairly extensive DataFrame reshaping with simple natural language
    instructions, as in *step 11*. We add *and other values* to the instructions to
    get columns other than *casedate*. PandasAI also figures out that *location* makes
    sense as the index.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Given that PandasAI tools are still so new, data scientists are just figuring
    out now how to best integrate these tools into our data cleaning and analysis
    workflow. There are two obvious use cases for PandasAI: 1) checking the accuracy
    of Series operations we do in a more traditional way, and 2) doing Series operations
    in a more intuitive way when pandas or NumPy tools are somewhat less straightforward,
    such as with pandas `groupby` or the NumPy `where` function.'
  prefs: []
  type: TYPE_NORMAL
- en: PandasAI can also be used to build interactive interfaces for querying a data
    store, such as a data dashboard. We can use AI tools to help end users interrogate
    organizational data more effectively. As we saw in *Chapter 3*, *Taking the Measure
    of Your Data*, PandasAI is also great for quickly creating visualizations.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We do much more aggregating of data in *Chapter 9*, *Fixing Messy Data When
    Aggregating*, including aggregating data across rows and resampling of date and
    time data.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter explored a wide range of pandas Series methods for exploring and
    handling data of different types: numeric, strings, and dates. We learned how
    to get values from and generate summary statistics from a Series. We also learned
    how to update Series values, and how to do that for subsets of data or conditionally.
    We also explored specific challenges of working with string or date Series, and
    how to use Series methods to address those challenges. Finally, we saw how PandasAI
    could be used to explore and make changes to Series. In the next chapter, we will
    explore how to identify and fix missing values.'
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://discord.gg/p8uSgEAETX](https://discord.gg/p8uSgEAETX )'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code10336218961138498953.png)'
  prefs: []
  type: TYPE_IMG
